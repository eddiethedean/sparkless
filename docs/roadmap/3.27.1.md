# Sparkless 3.27.1 Roadmap

**Target Release Date**: Completed (fixes included in 3.28.0+ releases)  
**Status**: Completed

This document tracked the bug fixes for Sparkless version 3.27.1. Both fixes have been implemented and merged; the scope is complete.

## Overview

Version 3.27.1 will focus on fixing **2 actual bugs** where implemented functionality behaves incorrectly compared to PySpark. These are bugs where the feature exists but doesn't work as expected, not missing features.

## Bug Fixes

### Issue #356 - create_map() doesn't return empty map

**Status**: Completed  
**Branch**: `fix/issue-356-create-map-empty` (merged)  
**PR**: Merged; fix present in `sparkless/functions/map.py` (allow 0 args, empty map literal).

#### Details

- **Type**: Function behavior bug
- **Error**: `ValueError: create_map requires an even number of arguments (key-value pairs)`
- **GitHub Issue**: [#356](https://github.com/eddiethedean/sparkless/issues/356)

#### Description

The `create_map()` function exists and is implemented, but incorrectly raises an error when called with no arguments. PySpark returns an empty map `{}` when no arguments are passed.

#### Example Code

```python
from sparkless.sql import SparkSession
import sparkless.sql.functions as F

spark = SparkSession.builder.appName("Example").getOrCreate()

df = spark.createDataFrame([
    {"Name": "Alice"},
    {"Name": "Bob"},
])

# This should work but currently raises ValueError
df = df.withColumn("NewMap", F.create_map())
df.show()
```

#### Current Behavior

- Raises `ValueError: create_map requires an even number of arguments (key-value pairs)`

#### Expected Behavior

- Returns an empty map `{}` for each row
- PySpark output:
  ```
  +-----+------+
  |Name |NewMap|
  +-----+------+
  |Alice|{}    |
  |Bob  |{}    |
  +-----+------+
  ```

#### Implementation Plan

- **File to Fix**: `sparkless/functions/map.py` (line 167-170, validation logic)
- **Fix**: Modify validation to allow 0 arguments and return empty map literal
- **Tests**: Add test case for `F.create_map()` returning empty map
- **PySpark Parity**: Verify behavior matches PySpark

---

### Issue #357 - array() function parameter format limitations

**Status**: Completed  
**Branch**: `fix/issue-357-array-parameter-formats` (merged)  
**PR**: Merged; Polars translator updated to handle all array() parameter formats; tests in `tests/unit/test_array_parameter_formats.py`.

#### Details

- **Type**: Function parameter handling bug
- **Error**: `ValueError: array function requires Python evaluation to create array of arrays`
- **GitHub Issue**: [#357](https://github.com/eddiethedean/sparkless/issues/357)

#### Description

The `array()` function exists and accepts parameters, but fails in the translation layer when handling certain parameter formats that PySpark supports. The function definition accepts these formats, but the Polars translator fails to handle them correctly.

#### Example Code

```python
from sparkless.sql import SparkSession
import sparkless.sql.functions as F

spark = SparkSession.builder.appName("Example").getOrCreate()

df = spark.createDataFrame([
    {"Name": "Alice", "Type": "A"},
    {"Name": "Bob", "Type": "B"},
])

# These should all work but currently raise ValueError
df = df.withColumn("Array-Field-1", F.array("Name", "Type"))
df = df.withColumn("Array-Field-2", F.array(["Name", "Type"]))
df = df.withColumn("Array-Field-3", F.array(F.col("Name"), F.col("Type")))
df = df.withColumn("Array-Field-4", F.array([F.col("Name"), F.col("Type")]))

df.show()
```

#### Current Behavior

- Raises `ValueError: array function requires Python evaluation to create array of arrays` in the translation layer
- The function definition in `sparkless/functions/array.py` (line 906-941) accepts these formats, but the Polars translator fails to handle them correctly

#### Expected Behavior

- Should create array column from provided columns
- All four formats should work:
  - Strings representing column names: `F.array("Name", "Type")`
  - List of strings: `F.array(["Name", "Type"])`
  - Column objects: `F.array(F.col("Name"), F.col("Type"))`
  - List of Column objects: `F.array([F.col("Name"), F.col("Type")])`
- PySpark output:
  ```
  +-----+----+-------------+-------------+-------------+-------------+
  | Name|Type|Array-Field-1|Array-Field-2|Array-Field-3|Array-Field-4|
  +-----+----+-------------+-------------+-------------+-------------+
  |Alice|   A|   [Alice, A]|   [Alice, A]|   [Alice, A]|   [Alice, A]|
  |  Bob|   B|     [Bob, B]|     [Bob, B]|     [Bob, B]|     [Bob, B]|
  +-----+----+-------------+-------------+-------------+-------------+
  ```

#### Implementation Plan

- **File to Fix**: `sparkless/backend/polars/expression_translator.py` (line 3165, `_translate_function_call` method for array function)
- **Fix**: Update Polars translator to handle all array() parameter formats correctly
- **Tests**: Add test cases for:
  - String columns: `F.array("Name", "Type")`
  - List of strings: `F.array(["Name", "Type"])`
  - Column objects: `F.array(F.col("Name"), F.col("Type"))`
  - List of Column objects: `F.array([F.col("Name"), F.col("Type")])`
- **PySpark Parity**: Verify all formats match PySpark behavior

---

## Excluded Issues

The following issues are **missing features** (functionality doesn't exist) rather than bugs, and are excluded from this release:

- **#361** - createDataFrame() doesn't support df.rdd (missing feature)
- **#360** - input_file_name() function not implemented (missing feature)
- **#359** - NAHandler.drop() method missing (missing feature)
- **#358** - Column.getField() method missing (missing feature)
- **#352, #351, #350, #349, #348, #347, #346** - SQL command features (missing features)
- **#199-178** - Enhancements and refactoring tasks (not bugs)

## Implementation Workflow

Each bug fix will follow this workflow:

1. Create feature branch from `main`
2. Implement the fix
3. Add comprehensive test cases
4. Run full test suite
5. Update documentation if needed
6. Create pull request
7. Review and merge

## Progress Tracking

- [x] Issue #356 - create_map() empty map fix
- [x] Issue #357 - array() parameter formats fix

## Notes

- Only 2 issues are actual bugs where functionality exists but behaves incorrectly
- Issues #356 and #357 are function behavior bugs that need validation/translation fixes
- Each bug fix will be a separate PR to allow independent review and merging
- All fixes must maintain PySpark compatibility and include comprehensive test coverage
