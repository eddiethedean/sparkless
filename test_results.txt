Running Sparkless Test Suite (Overhauled)
==========================================
Backend: mock

âœ… pytest-xdist available - using parallel execution (10 workers)
Running unit tests...
============================= test session starts ==============================
platform darwin -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
cachedir: .pytest_cache
hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
rootdir: /Users/odosmatthews/Documents/coding/sparkless
configfile: pyproject.toml
plugins: anyio-4.11.0, cov-7.0.0, green-light-0.2.0, asyncio-1.2.0, xdist-3.8.0, timeout-2.4.0, hypothesis-6.148.7, alt-pytest-asyncio-0.9.3, async-sqlalchemy-0.2.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
timeout: 300.0s
timeout method: thread
timeout func_only: False
created: 10/10 workers
10 workers [1048 items]

scheduling tests via LoadFileScheduling

tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_basic 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_literals 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_string_single_column 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int64_with_string 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_default_no_infer_schema 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_multiplication 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_add_new_field 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_eq_numeric_int 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_string 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_select_all_case_variations 
[gw0] [  0%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_default_no_infer_schema 
[gw2] [  0%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_string_single_column 
[gw8] [  0%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_select_all_case_variations 
[gw9] [  0%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int64_with_string 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_explicit_infer_schema_false 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_list_multiple_columns 
[gw2] [  0%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_list_multiple_columns 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_select_with_f_col_all_cases 
[gw8] [  0%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_select_with_f_col_all_cases 
[gw4] [  0%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_multiplication 
[gw0] [  0%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_explicit_infer_schema_false 
[gw1] [  0%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_eq_numeric_int 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_explicit_infer_schema_true 
[gw0] [  0%] SKIPPED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_explicit_infer_schema_true 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_filter_all_case_variations 
[gw6] [  1%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_string 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_int 
[gw7] [  1%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_basic 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_first 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_string_with_int64 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_no_header_default_behavior 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_tuple_multiple_columns 
[gw2] [  1%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_tuple_multiple_columns 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_only_specified_columns_filled 
[gw2] [  1%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_only_specified_columns_filled 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_eq_numeric_float 
[gw1] [  1%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_eq_numeric_float 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_addition 
[gw4] [  1%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_addition 
[gw0] [  1%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_no_header_default_behavior 
[gw6] [  1%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_int 
[gw5] [  1%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_add_new_field 
[gw9] [  1%] FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_string_with_int64 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_subtraction 
[gw4] [  2%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_subtraction 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_other_columns_unchanged 
[gw8] [  2%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_filter_all_case_variations 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_mixed_int_float_raises_error 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int32_with_string 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_lt_numeric 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_existing_field 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_groupBy_all_case_variations 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_division 
[gw4] [  2%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_division 
[gw9] [  2%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int32_with_string 
[gw3] [  2%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_literals 
[gw1] [  2%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_lt_numeric 
[gw5] [  2%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_existing_field 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_column_values 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_modulo 
[gw0] [  2%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_mixed_int_float_raises_error 
[gw7] [  2%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_first 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_column_operation 
[gw6] [  2%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_column_operation 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_issue_239_example 
[gw8] [  2%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_groupBy_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_agg_all_case_variations 
[gw8] [  3%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_agg_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_orderBy_all_case_variations 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_type_inference 
[gw0] [  3%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_type_inference 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_infer_schema_with_numeric_strings 
[gw0] [  3%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_infer_schema_with_numeric_strings 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last 
[gw7] [  3%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_column_expression 
[gw3] [  3%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_column_values 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_pairs 
[gw2] [  3%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_other_columns_unchanged 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_dict_value_ignores_subset 
[gw2] [  3%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_dict_value_ignores_subset 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_nonexistent_column_raises_error 
[gw2] [  3%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_nonexistent_column_raises_error 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_float_with_string 
[gw9] [  3%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_float_with_string 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int32_with_int64 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_le_numeric 
[gw1] [  3%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_le_numeric 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_gt_numeric 
[gw1] [  4%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_gt_numeric 
[gw9] [  4%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int32_with_int64 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_ge_numeric 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_multiple_nonexistent_columns_raises_error 
[gw2] [  4%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_multiple_nonexistent_columns_raises_error 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_infer_schema_boolean_strings 
[gw1] [  4%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_string_ge_numeric 
[gw4] [  4%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_modulo 
[gw7] [  4%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first 
[gw0] [  4%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_infer_schema_boolean_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_leading_zeros 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int_with_float 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_empty_list 
[gw2] [  4%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_empty_list 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_numeric_eq_string 
[gw8] [  4%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_orderBy_all_case_variations 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_integers 
[gw9] [  4%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int_with_float 
[gw5] [  4%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_column_expression 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_chained_arithmetic_issue_237_example 
[gw4] [  5%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_chained_arithmetic_issue_237_example 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_computed_expression 
[gw0] [  5%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_leading_zeros 
[gw3] [  5%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_pairs 
[gw7] [  5%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_integers 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_negative_numbers 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_all_nulls 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_issue_242_exact_scenario 
[gw9] [  5%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_issue_242_exact_scenario 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_int64_string 
[gw9] [  5%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_int64_string 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_string_int64 
[gw5] [  5%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_computed_expression 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_chained 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_all_columns 
[gw2] [  5%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_all_columns 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_no_subset_backward_compatibility 
[gw2] [  5%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_no_subset_backward_compatibility 
[gw6] [  5%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_issue_239_example 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_datatype_object 
[gw1] [  6%] FAILED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_numeric_eq_string 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_coercion_with_null 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_complex_chained_operations 
[gw4] [  6%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_complex_chained_operations 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_reverse_operations 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_issue_234_example 
[gw1] [  6%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_coercion_with_null 
tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_coercion_invalid_string 
[gw1] [  6%] PASSED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_coercion_invalid_string 
[gw0] [  6%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_negative_numbers 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_scientific_notation 
[gw0] [  6%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_scientific_notation 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_empty_strings 
[gw0] [  6%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_empty_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_null_values 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_values 
[gw3] [  6%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_values 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_validation_odd_args 
[gw3] [  6%] PASSED tests/unit/test_create_map.py::TestCreateMap::test_create_map_validation_odd_args 
[gw2] [  6%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_issue_234_example 
tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_list 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_withColumn_all_case_variations 
[gw8] [  6%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_withColumn_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_withColumnRenamed_all_case_variations 
[gw8] [  7%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_withColumnRenamed_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_drop_all_case_variations 
[gw8] [  7%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_drop_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_join_all_case_variations 
[gw7] [  7%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_all_nulls 
[gw0] [  7%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_null_values 
[gw1] [  7%] PASSED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_list 
tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_star_args 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_returns_empty_map 
[gw6] [  7%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_datatype_object 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_issue_234_string_variant 
[gw2] [  7%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_issue_234_string_variant 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_unicode_characters 
[gw5] [  7%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_chained 
[gw1] [  7%] PASSED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_star_args 
[gw8] [  7%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_join_all_case_variations 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_equals_cast 
[gw4] [  8%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_reverse_operations 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_no_nulls 
[gw7] [  8%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_no_nulls 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_multiple_nulls 
[gw0] [  8%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_unicode_characters 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_special_characters 
[gw0] [  8%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_special_characters 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_large_numbers 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_numeric_value 
[gw3] [  8%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_returns_empty_map 
[gw7] [  8%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_multiple_nulls 
[gw2] [  8%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_numeric_value 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_returns_empty_map 
[gw3] [  8%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_returns_empty_map 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_withcolumn 
[gw0] [  8%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_large_numbers 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_decimal_precision 
[gw9] [  8%] FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_string_int64 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_multiple_numeric_string_columns 
[gw9] [  8%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_multiple_numeric_string_columns 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_null_values 
[gw9] [  9%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_null_values 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_union_by_name 
[gw9] [  9%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_union_by_name 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_double_with_string 
[gw9] [  9%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_double_with_string 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_float_with_double 
tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_strings 
[gw1] [  9%] PASSED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_strings 
tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_mixed_types 
[gw1] [  9%] PASSED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_mixed_types 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_integers 
[gw4] [  9%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_integers 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_boolean_values 
[gw2] [  9%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_boolean_values 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_float_values 
[gw2] [  9%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_float_values 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_multiple_nulls_same_column 
[gw2] [  9%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_multiple_nulls_same_column 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_all_nulls_in_column 
[gw2] [  9%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_all_nulls_in_column 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_no_nulls_in_subset_columns 
[gw2] [ 10%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_no_nulls_in_subset_columns 
tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_empty_list 
[gw1] [ 10%] FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_empty_list 
tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_single_value 
[gw1] [ 10%] PASSED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_single_value 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_floats 
[gw4] [ 10%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_floats 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_nested_chained_operations 
[gw4] [ 10%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_nested_chained_operations 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_select 
[gw4] [ 10%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_select 
[gw6] [ 10%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_equals_cast 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_select 
[gw6] [ 10%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_select 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_withColumn 
[gw6] [ 10%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_withColumn 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_filter 
[gw6] [ 10%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_filter 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_null 
[gw3] [ 10%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_withcolumn 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_mixed_data_types 
[gw0] [ 11%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_decimal_precision 
[gw9] [ 11%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_float_with_double 
[gw6] [ 11%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_null 
[gw2] [ 11%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_mixed_data_types 
tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_column_method 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_null_struct 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_unionByName_all_case_variations 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first_multiple_nulls 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_filter 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_negative_numbers 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_filter 
[gw3] [ 11%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_filter 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_mixed_boolean_strings 
[gw1] [ 11%] PASSED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_column_method 
tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_array_index 
[gw1] [ 11%] FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_array_index 
[gw5] [ 11%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_null_struct 
[gw0] [ 11%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_mixed_boolean_strings 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_all_literals 
[gw7] [ 11%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first_multiple_nulls 
[gw9] [ 12%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_negative_numbers 
[gw6] [ 12%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double 
[gw4] [ 12%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_filter 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_empty_dataframe 
[gw8] [ 12%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_unionByName_all_case_variations 
[gw3] [ 12%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_all_literals 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_boolean 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_mixed_forward_and_reverse_operations 
tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_split_result 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_issue_235_example 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_null_column 
[gw0] [ 12%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_null_column 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_with_sort_method 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_zero_values 
[gw6] [ 12%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_boolean 
[gw2] [ 12%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_empty_dataframe 
[gw1] [ 12%] FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_split_result 
[gw5] [ 12%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_issue_235_example 
[gw4] [ 12%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_mixed_forward_and_reverse_operations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_selectExpr_all_case_variations 
[gw7] [ 13%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_with_sort_method 
[gw9] [ 13%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_zero_values 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_partial_nulls 
[gw0] [ 13%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_partial_nulls 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_complex_types 
[gw0] [ 13%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_complex_types 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_date_strings 
[gw0] [ 13%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_date_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_numeric_strings 
[gw0] [ 13%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_numeric_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_empty_file 
[gw0] [ 13%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_empty_file 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_single_row 
[gw0] [ 13%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_single_row 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_null_values 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_single_row 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_numeric_types 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_column_methods_exist 
[gw7] [ 13%] PASSED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_column_methods_exist 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_multiple_columns_ordering 
[gw7] [ 13%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_multiple_columns_ordering 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_float 
tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_map_key 
[gw4] [ 14%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_null_values 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_negative_numbers 
[gw4] [ 14%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_negative_numbers 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_chained_with_arithmetic 
[gw4] [ 14%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_chained_with_arithmetic 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_operator_precedence 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_chained_operations 
[gw6] [ 14%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_chained_operations 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_literal 
[gw6] [ 14%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_literal 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_from_string 
[gw6] [ 14%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_from_string 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_to_date 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_empty_list 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_different_data_types 
[gw8] [ 14%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_selectExpr_all_case_variations 
[gw2] [ 14%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_single_row 
[gw4] [ 14%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_operator_precedence 
[gw3] [ 14%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_numeric_types 
[gw7] [ 14%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_float 
[gw5] [ 15%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_different_data_types 
[gw0] [ 15%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_empty_list 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_chained_operations_all_cases 
[gw8] [ 15%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_chained_operations_all_cases 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_negative_numbers 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_operator_precedence_with_parentheses_equivalent 
[gw4] [ 15%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_operator_precedence_with_parentheses_equivalent 
[gw1] [ 15%] FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_map_key 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_boolean_values 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_expressions_with_case_variations 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_large_numbers 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_sparse_data 
[gw0] [ 15%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_sparse_data 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_type_conflict_raises_error 
[gw0] [ 15%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_type_conflict_raises_error 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_trailing_whitespace 
[gw0] [ 15%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_trailing_whitespace 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_operators_in_single_expression 
[gw4] [ 15%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_operators_in_single_expression 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_zero 
[gw8] [ 15%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_expressions_with_case_variations 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_chained_operations 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_custom_delimiter 
[gw0] [ 16%] SKIPPED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_custom_delimiter 
[gw2] [ 16%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_chained_operations 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_unicode_and_special_characters 
[gw2] [ 16%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_unicode_and_special_characters 
[gw7] [ 16%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_negative_numbers 
[gw5] [ 16%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_struct 
[gw5] [ 16%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_struct 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_then_add 
[gw5] [ 16%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_then_add 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_deeply_nested_struct 
[gw5] [ 16%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_deeply_nested_struct 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_zero_values 
[gw0] [ 16%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_zero_values 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_large_dataset 
[gw2] [ 16%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_large_dataset 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_single_column_all_rows 
[gw2] [ 16%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_single_column_all_rows 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_zero_value 
[gw2] [ 17%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_zero_value 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_negative_value 
[gw2] [ 17%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_negative_value 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_empty_string 
[gw2] [ 17%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_empty_string 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_whitespace_string 
[gw2] [ 17%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_whitespace_string 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_very_long_string 
[gw2] [ 17%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_very_long_string 
[gw9] [ 17%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_large_numbers 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_decimal_precision 
[gw9] [ 17%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_decimal_precision 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_scientific_notation_strings 
[gw9] [ 17%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_scientific_notation_strings 
[gw6] [ 17%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_to_date 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_multiple_numeric_types 
[gw3] [ 17%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_boolean_values 
[gw4] [ 18%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_zero 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_computed_values 
[gw9] [ 18%] FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_multiple_numeric_types 
tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_out_of_bounds 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_partial_column_fill 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_window_functions_with_case_variations 
[gw3] [ 18%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_computed_values 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_types 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last_empty_dataframe 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_boolean_column 
[gw8] [ 18%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_window_functions_with_case_variations 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_complex_expression 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_chained_unions 
[gw1] [ 18%] FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_out_of_bounds 
[gw6] [ 18%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_types 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_one 
[gw0] [ 18%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_boolean_column 
[gw7] [ 18%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last_empty_dataframe 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_single_row 
[gw2] [ 18%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_partial_column_fill 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_maps_in_select 
[gw4] [ 18%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_one 
[gw5] [ 18%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_complex_expression 
[gw7] [ 19%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_single_row 
[gw9] [ 19%] FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_chained_unions 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_distinct_with_case_variations 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_negative_literals 
[gw4] [ 19%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_negative_literals 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_preserves_column_name 
[gw8] [ 19%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_distinct_with_case_variations 
tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_negative_index 
[gw6] [ 19%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_preserves_column_name 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_integer_column 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_single_null_row 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_conditional_expression 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_empty_dataframe 
[gw1] [ 19%] FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_negative_index 
[gw0] [ 19%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_integer_column 
[gw9] [ 19%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_empty_dataframe 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_float_column 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_decimal_literals 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_subset_operations_with_case_variations 
[gw8] [ 19%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_subset_operations_with_case_variations 
[gw0] [ 19%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_float_column 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_all_null_columns 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_schema_access_with_case_variations 
tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookbehind 
[gw8] [ 20%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_schema_access_with_case_variations 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_alias 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_empty_dataframe_with_case_variations 
[gw6] [ 20%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_alias 
[gw5] [ 20%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_conditional_expression 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_complex_expressions 
[gw9] [ 20%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_all_null_columns 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_mixed_nulls_and_values 
[gw9] [ 20%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_mixed_nulls_and_values 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_three_dataframes 
[gw9] [ 20%] FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_three_dataframes 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_exact_output_match 
[gw1] [ 20%] FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookbehind 
[gw4] [ 20%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_decimal_literals 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_chained_operations_with_mixed_types 
[gw4] [ 20%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_chained_operations_with_mixed_types 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_very_long_chained_expression 
[gw3] [ 20%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_maps_in_select 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_groupby_agg 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_large_dataset 
[gw0] [ 20%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_large_dataset 
[gw7] [ 21%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_single_null_row 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_nulls_at_beginning_middle_end 
[gw7] [ 21%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_nulls_at_beginning_middle_end 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_unicode_characters 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_cast_operation 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_column_order_preserved 
[gw4] [ 21%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_very_long_chained_expression 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_orderby 
[gw4] [ 21%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_orderby 
[gw0] [ 21%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_column_order_preserved 
[gw7] [ 21%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_unicode_characters 
[gw8] [ 21%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_empty_dataframe_with_case_variations 
[gw5] [ 21%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_cast_operation 
[gw6] [ 21%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_complex_expressions 
[gw9] [ 21%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_exact_output_match 
[gw3] [ 22%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_groupby_agg 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_complex_query_all_case_variations 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_with_filter_operation 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_groupby_aggregation 
[gw4] [ 22%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_groupby_aggregation 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_when_otherwise 
[gw4] [ 22%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_when_otherwise 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_cast 
[gw4] [ 22%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_cast 
[gw2] [ 22%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_with_filter_operation 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_string_columns 
[gw8] [ 22%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_complex_query_all_case_variations 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_invalid_string_to_int 
[gw4] [ 22%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_string_columns 
[gw6] [ 22%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_invalid_string_to_int 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_attribute_access_all_case_variations 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_float_string_decimal_values 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_with_different_type 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_asc_desc_nulls_variants 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_special_characters_in_keys 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_with_select_operation 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_column_order_alphabetical 
[gw5] [ 22%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_with_different_type 
[gw8] [ 22%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_attribute_access_all_case_variations 
[gw9] [ 22%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_float_string_decimal_values 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_schema_verification 
[gw0] [ 23%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_column_order_alphabetical 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_fields_in_sequence 
[gw5] [ 23%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_fields_in_sequence 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_null_literal 
[gw9] [ 23%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_schema_verification 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_multiple_columns_comprehensive 
[gw9] [ 23%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_multiple_columns_comprehensive 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_order_preservation 
[gw9] [ 23%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_order_preservation 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_union_by_name_with_type_mismatch 
tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookahead 
[gw1] [ 23%] FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookahead 
tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_without_lookaround 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double_to_int 
[gw6] [ 23%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double_to_int 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_to_boolean 
[gw6] [ 23%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_to_boolean 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_orderBy 
[gw6] [ 23%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_orderBy 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_groupBy 
[gw6] [ 23%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_groupBy 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_chained 
[gw6] [ 24%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_chained 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_all_column_operations 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_division_by_zero 
[gw4] [ 24%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_division_by_zero 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_modulo_by_zero 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_fillna_all_case_variations 
[gw8] [ 24%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_fillna_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_replace_all_case_variations 
[gw8] [ 24%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_replace_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_pivot_all_case_variations 
[gw8] [ 24%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_pivot_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_coalesce_all_case_variations 
[gw8] [ 24%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_coalesce_all_case_variations 
[gw3] [ 24%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_special_characters_in_keys 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_nested_in_expressions 
[gw3] [ 24%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_nested_in_expressions 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_empty_string_keys 
[gw3] [ 24%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_empty_string_keys 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_union 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_small_numbers 
[gw0] [ 24%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_small_numbers 
[gw9] [ 25%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_union_by_name_with_type_mismatch 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_large_dataset 
[gw9] [ 25%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_large_dataset 
[gw2] [ 25%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_with_select_operation 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_preserves_data_types 
[gw2] [ 25%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_preserves_data_types 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_int_column_string_fill 
[gw2] [ 25%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_int_column_string_fill 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_string_column_int_fill 
[gw2] [ 25%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_string_column_int_fill 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_float_column_string_fill 
[gw1] [ 25%] FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_without_lookaround 
tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_complex_lookaround 
[gw1] [ 25%] FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_complex_lookaround 
tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas 
[gw2] [ 25%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_float_column_string_fill 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_boolean_column_string_fill 
[gw2] [ 25%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_boolean_column_string_fill 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_string_column_string_fill 
[gw2] [ 25%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_string_column_string_fill 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_int_column_int_fill 
[gw2] [ 26%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_int_column_int_fill 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_float_column_float_fill 
[gw2] [ 26%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_float_column_float_fill 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_float_column_int_fill 
[gw2] [ 26%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_compatible_float_column_int_fill 
[gw5] [ 26%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_null_literal 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_dropna_all_case_variations 
[gw8] [ 26%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_dropna_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_nested_struct_field_access_all_cases 
tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_numeric_promotion_order 
[gw9] [ 26%] PASSED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_numeric_promotion_order 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_boolean_and_string 
[gw0] [ 26%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_boolean_and_string 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_int_and_string 
[gw0] [ 26%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_int_and_string 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_float_and_string 
[gw0] [ 26%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_float_and_string 
[gw8] [ 26%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_nested_struct_field_access_all_cases 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_sql_queries_all_case_variations 
[gw8] [ 27%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_sql_queries_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_rollup_cube_all_case_variations 
[gw8] [ 27%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_rollup_cube_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_sampleBy_all_case_variations 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_bytes 
[gw0] [ 27%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_bytes 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_tab_delimiter 
[gw0] [ 27%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_tab_delimiter 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_semicolon_delimiter 
[gw0] [ 27%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_semicolon_delimiter 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_none_values 
[gw0] [ 27%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_none_values 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_quoted_values 
[gw0] [ 27%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_quoted_values 
[gw8] [ 27%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_sampleBy_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_freqItems_all_case_variations 
[gw8] [ 27%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_freqItems_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_crosstab_all_case_variations 
[gw8] [ 27%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_crosstab_all_case_variations 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_issue_264_withColumn_case_insensitive 
[gw7] [ 27%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_asc_desc_nulls_variants 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_very_large_numbers 
[gw7] [ 28%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_very_large_numbers 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_all_four_methods_comprehensive 
[gw7] [ 28%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_all_four_methods_comprehensive 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_comparison_with_default_desc_asc 
[gw7] [ 28%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_comparison_with_default_desc_asc 
tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_dict_value 
[gw2] [ 28%] PASSED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_type_mismatch_dict_value 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_array_field 
[gw6] [ 28%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_all_column_operations 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_three_column_ordering 
[gw4] [ 28%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_modulo_by_zero 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_division_by_numeric_literal 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_escaped_quotes 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimizer_init 
[gw2] [ 28%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimizer_init 
[gw9] [ 28%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_division_by_numeric_literal 
[gw3] [ 28%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_union 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_keys 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_simple_select 
[gw2] [ 28%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_simple_select 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_null_literals 
[gw4] [ 29%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_null_literals 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_numeric_literal_divided_by_string 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_variations 
[gw6] [ 29%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_variations 
[gw0] [ 29%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_escaped_quotes 
[gw7] [ 29%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_three_column_ordering 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_predicate_pushdown 
[gw9] [ 29%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_numeric_literal_divided_by_string 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_long_strings 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_very_complex_nested_expression 
[gw8] [ 29%] FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_issue_264_withColumn_case_insensitive 
[gw0] [ 29%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_long_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_multiple_headers 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_string_comparison_edge_cases 
[gw2] [ 29%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_predicate_pushdown 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_projection_elimination 
[gw2] [ 29%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_projection_elimination 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_zero_and_negative 
[gw4] [ 29%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_very_complex_nested_expression 
[gw5] [ 29%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_array_field 
[gw0] [ 30%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_multiple_headers 
tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_unpivot_all_case_variations 
[gw8] [ 30%] PASSED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_unpivot_all_case_variations 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_join_reordering 
[gw2] [ 30%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_join_reordering 
[gw7] [ 30%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_string_comparison_edge_cases 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_addition_with_numeric 
[gw9] [ 30%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_addition_with_numeric 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_string_columns 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_subtraction_with_numeric 
[gw9] [ 30%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_subtraction_with_numeric 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_boolean_edge_cases 
[gw0] [ 30%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_boolean_edge_cases 
[gw3] [ 30%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_keys 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_zeros 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_complex_ordering_scenario 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_multiplication_with_numeric 
[gw6] [ 30%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_zero_and_negative 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_float_string_conversions 
[gw9] [ 30%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_multiplication_with_numeric 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_select_multiple_columns 
[gw4] [ 31%] FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_select_multiple_columns 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_filter 
[gw6] [ 31%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_float_string_conversions 
[gw0] [ 31%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_zeros 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_float_precision 
[gw0] [ 31%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_float_precision 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_inconsistent_decimal_places 
[gw0] [ 31%] SKIPPED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_inconsistent_decimal_places 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_negative_floats 
[gw8] [ 31%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_string_columns 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_constant_folding 
[gw2] [ 31%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_constant_folding 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_redundant_operations 
[gw2] [ 31%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_with_redundant_operations 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_non_select_query 
[gw2] [ 31%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_optimize_non_select_query 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_large_number_of_pairs 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_modulo_with_numeric 
[gw5] [ 31%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_filter 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_select 
[gw2] [ 31%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_select 
[gw7] [ 32%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_complex_ordering_scenario 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_duplicate_values 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_empty_string_handling 
[gw6] [ 32%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_empty_string_handling 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_join 
[gw2] [ 32%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_join 
[gw0] [ 32%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_negative_floats 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_commas_in_quoted_strings 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_strings 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_preserve_precision 
[gw4] [ 32%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_preserve_precision 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_select 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_large_numbers 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_aggregate 
[gw2] [ 32%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_aggregate 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_equals_cast_comprehensive 
[gw6] [ 32%] PASSED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_equals_cast_comprehensive 
[gw4] [ 32%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_large_numbers 
[gw0] [ 32%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_commas_in_quoted_strings 
[gw3] [ 32%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_large_number_of_pairs 
[gw7] [ 33%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_duplicate_values 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_with_filter 
[gw2] [ 33%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_with_filter 
tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_small_numbers 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_select 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_same_values 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_after_when_otherwise 
[gw4] [ 33%] PASSED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_small_numbers 
[gw0] [ 33%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_same_values 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_with_sort 
[gw2] [ 33%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_with_sort 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_newlines_in_quoted_strings 
[gw6] [ 33%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_after_when_otherwise 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_with_limit 
[gw2] [ 33%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_with_limit 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validator_init 
[gw4] [ 33%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validator_init 
[gw9] [ 33%] FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_modulo_with_numeric 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_string_column 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_date_pyspark_parity 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_identical_nulls 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_non_select 
[gw2] [ 33%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_generate_execution_plan_non_select 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_simple_select 
[gw4] [ 33%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_simple_select 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_simple 
[gw2] [ 34%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_simple 
[gw9] [ 34%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_string_column 
[gw8] [ 34%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_strings 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_column_objects 
[gw0] [ 34%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_newlines_in_quoted_strings 
[gw5] [ 34%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_select 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_all_null_structs 
[gw7] [ 34%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_identical_nulls 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_data_types_ordering 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_large_integers 
[gw0] [ 34%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_large_integers 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_currency_symbols 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_select_with_where 
[gw4] [ 34%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_select_with_where 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_select_with_join 
[gw4] [ 34%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_select_with_join 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_complex 
[gw2] [ 34%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_complex 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_insert 
[gw4] [ 35%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_insert 
[gw3] [ 35%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_select 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_invalid_strings 
[gw9] [ 35%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_invalid_strings 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_null_strings 
[gw9] [ 35%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_null_strings 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_update 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_filter 
[gw2] [ 35%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_filter 
[gw4] [ 35%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_update 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_result_type 
[gw9] [ 35%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_result_type 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_different_data_types 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_groupby 
[gw2] [ 35%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_groupby 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_delete 
[gw4] [ 35%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_delete 
[gw6] [ 35%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_date_pyspark_parity 
[gw8] [ 35%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_column_objects 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_chained_operations 
[gw9] [ 36%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_chained_operations 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_create_table 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_sort 
[gw7] [ 36%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_data_types_ordering 
[gw2] [ 36%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_sort 
[gw4] [ 36%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_create_table 
tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_limit 
[gw2] [ 36%] PASSED tests/unit/session/test_sql_optimizer.py::TestSQLQueryOptimizer::test_estimate_cost_with_limit 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_last_parity 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_drop_table 
[gw4] [ 36%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_drop_table 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_column_objects 
[gw0] [ 36%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_currency_symbols 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_percentage_strings 
[gw0] [ 36%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_percentage_strings 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_integer_strings 
[gw9] [ 36%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_integer_strings 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_long_type 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_init 
[gw2] [ 36%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_init 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_invalid_syntax 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_percentage_values 
[gw4] [ 37%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_invalid_syntax 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_float_strings 
[gw9] [ 37%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_float_strings 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_init_with_children 
[gw6] [ 37%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_long_type 
[gw2] [ 37%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_init_with_children 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_reserved_keywords 
[gw4] [ 37%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_reserved_keywords 
[gw5] [ 37%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_all_null_structs 
[gw0] [ 37%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_percentage_values 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_phone_numbers 
[gw0] [ 37%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_phone_numbers 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_division_by_zero 
[gw9] [ 37%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_division_by_zero 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_init_with_properties 
[gw2] [ 37%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_init_with_properties 
tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_type_aliases 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_semantic_errors 
[gw4] [ 37%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_semantic_errors 
[gw7] [ 38%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_last_parity 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_dataframe 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_schema_errors 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_str 
[gw4] [ 38%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_schema_errors 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_type_errors 
[gw4] [ 38%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_type_errors 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_phone_numbers 
[gw2] [ 38%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_str 
[gw3] [ 38%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_different_data_types 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_repr 
[gw6] [ 38%] FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_type_aliases 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_after_filter 
[gw8] [ 38%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_column_objects 
tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_string_return_type 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_negative_numbers 
[gw2] [ 38%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_repr 
[gw0] [ 38%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_phone_numbers 
[gw3] [ 38%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_after_filter 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_first_parity 
[gw5] [ 39%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_dataframe 
[gw9] [ 39%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_negative_numbers 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_error_messages 
[gw4] [ 39%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_error_messages 
[gw7] [ 39%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_first_parity 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_nested_children 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_iso8601_dates 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_groupby_context 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_together 
[gw0] [ 39%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_iso8601_dates 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_scientific_notation 
[gw6] [ 39%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_string_return_type 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_complex_query 
[gw4] [ 39%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_complex_query 
[gw8] [ 39%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_together 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_iso8601_dates 
[gw0] [ 39%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_iso8601_dates 
[gw9] [ 39%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_scientific_notation 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_empty_strings 
[gw2] [ 39%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_query_plan_nested_children 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_cte 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_last_parity 
[gw9] [ 40%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_empty_strings 
[gw4] [ 40%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_cte 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_whitespace 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types 
[gw3] [ 40%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_groupby_context 
[gw7] [ 40%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_last_parity 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_reference_other_struct_field 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_time_values 
tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_integer_return_type 
[gw9] [ 40%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_whitespace 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_balanced_parentheses 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_optimization_rule_application 
[gw0] [ 40%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_time_values 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_very_large_numbers 
[gw2] [ 40%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_optimization_rule_application 
[gw4] [ 40%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_balanced_parentheses 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_balanced_quotes 
[gw9] [ 40%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_very_large_numbers 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_in_select 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_join 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_first_parity 
[gw5] [ 40%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_reference_other_struct_field 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_time_values 
[gw0] [ 41%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_time_values 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_hex_strings 
[gw0] [ 41%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_hex_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_hex_strings 
[gw0] [ 41%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_hex_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_whitespace_only_strings 
[gw0] [ 41%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_whitespace_only_strings 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_whitespace_only_values 
[gw0] [ 41%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_whitespace_only_values 
[gw4] [ 41%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_balanced_quotes 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_schema_method 
[gw4] [ 41%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_schema_method 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_get_validation_errors 
[gw4] [ 41%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_get_validation_errors 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_tokenize 
[gw4] [ 41%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_tokenize 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_is_quoted 
[gw4] [ 41%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_is_quoted 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_insert_with_select 
[gw4] [ 41%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_insert_with_select 
tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_optimization_idempotency 
[gw2] [ 42%] PASSED tests/unit/session/test_sql_optimizer.py::TestQueryPlan::test_optimization_idempotency 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_string_functions 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_numeric_string_prefixes 
[gw0] [ 42%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_numeric_string_prefixes 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_insert_with_columns 
[gw4] [ 42%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_insert_with_columns 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_basic_substr 
[gw9] [ 42%] FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_in_select 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_numeric_string_prefixes 
[gw8] [ 42%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types 
[gw6] [ 42%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_integer_return_type 
[gw7] [ 42%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_first_parity 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_multiple_values 
[gw0] [ 42%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_numeric_string_prefixes 
[gw4] [ 42%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_multiple_values 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_single_column 
[gw3] [ 42%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_join 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_filter 
[gw9] [ 43%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_filter 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_show_describe 
[gw4] [ 43%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_show_describe 
tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_double_return_type 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_special_numeric_formats 
[gw0] [ 43%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_special_numeric_formats 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_plus_prefix_numbers 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_window_functions 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_multi_column_parity 
tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_create_drop_database 
[gw4] [ 43%] PASSED tests/unit/session/test_sql_validation.py::TestSQLValidator::test_validate_create_drop_database 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_init 
[gw4] [ 43%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_init 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_mixed_with_numeric_column 
[gw9] [ 43%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_mixed_with_numeric_column 
[gw0] [ 43%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_plus_prefix_numbers 
[gw5] [ 43%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_string_functions 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_slowdown_valid 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_when_otherwise 
[gw4] [ 43%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_slowdown_valid 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_mixed_case_booleans 
[gw0] [ 43%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_mixed_case_booleans 
[gw7] [ 43%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_multi_column_parity 
[gw2] [ 44%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_basic_substr 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_case_booleans 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_slowdown_invalid 
[gw4] [ 44%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_slowdown_invalid 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_chained_multiple_times 
[gw6] [ 44%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_double_return_type 
[gw0] [ 44%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_case_booleans 
[gw3] [ 44%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_window_functions 
tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_boolean_return_type 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_memory_limit_valid 
[gw4] [ 44%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_memory_limit_valid 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_memory_limit_invalid 
[gw4] [ 44%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_set_memory_limit_invalid 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_infinity_and_nan 
[gw0] [ 44%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_infinity_and_nan 
[gw8] [ 44%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_single_column 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_three_columns 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_nested_expressions 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_integer_ordering_parity 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_from_second_position 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_check_memory_usage_within_limit 
[gw4] [ 44%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_check_memory_usage_within_limit 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_infinity_strings 
[gw1] [ 45%] PASSED tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_check_memory_usage_exceeds_limit 
[gw0] [ 45%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_infinity_strings 
[gw3] [ 45%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_nested_expressions 
[gw9] [ 45%] FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_when_otherwise 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_chained_with_cast 
[gw9] [ 45%] FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_chained_with_cast 
[gw4] [ 45%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_check_memory_usage_exceeds_limit 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_check_memory_usage_no_limit 
[gw8] [ 45%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_three_columns 
tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas_with_schema 
[gw5] [ 45%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_chained_multiple_times 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_null_handling 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_all_operations_comprehensive 
[gw2] [ 45%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_from_second_position 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_issue_238_example 
[gw2] [ 45%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_issue_238_example 
[gw3] [ 45%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_null_handling 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_multiple_times 
[gw1] [ 46%] PASSED tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas_with_schema 
tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas_empty 
[gw1] [ 46%] PASSED tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas_empty 
tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas_with_nulls 
[gw1] [ 46%] PASSED tests/unit/test_issues_225_231.py::TestIssue229PandasDataFrameSupport::test_createDataFrame_from_pandas_with_nulls 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_select_case_insensitive 
[gw1] [ 46%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_select_case_insensitive 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_selectExpr_case_insensitive 
[gw1] [ 46%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_selectExpr_case_insensitive 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_filter_case_insensitive 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_small_floats 
[gw0] [ 46%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_small_floats 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_small_floats 
[gw0] [ 46%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_small_floats 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_large_floats 
[gw0] [ 46%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_large_floats 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_large_floats 
[gw0] [ 46%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_large_floats 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_float_zeros 
[gw0] [ 46%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_float_zeros 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_float_zeros 
[gw0] [ 47%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_float_zeros 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_integer_zeros 
[gw0] [ 47%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_integer_zeros 
[gw6] [ 47%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_boolean_return_type 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_arithmetic_operations 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_columns 
[gw4] [ 47%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_check_memory_usage_no_limit 
[gw5] [ 47%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_arithmetic_operations 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_preserves_all_existing_fields 
[gw5] [ 47%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_preserves_all_existing_fields 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_field_access 
[gw5] [ 47%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_field_access 
tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_two_arguments 
[gw6] [ 47%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_two_arguments 
tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_three_arguments 
[gw9] [ 47%] FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_all_operations_comprehensive 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_integer_zeros 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_zero_string 
[gw9] [ 47%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_zero_string 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_decimal_precision 
[gw9] [ 47%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_decimal_precision 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_negative_zero 
[gw9] [ 48%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_negative_zero 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_complex_expression 
[gw9] [ 48%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_complex_expression 
[gw6] [ 48%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_three_arguments 
tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_mixed_types 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_apply_slowdown 
[gw4] [ 48%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_apply_slowdown 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_record_metrics 
[gw4] [ 48%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_record_metrics 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_reset_metrics 
[gw4] [ 48%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_reset_metrics 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_context_manager 
[gw4] [ 48%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_context_manager 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_enable_disable_performance_simulation 
[gw4] [ 48%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_enable_disable_performance_simulation 
[gw1] [ 48%] FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_filter_case_insensitive 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_withColumn_case_insensitive 
[gw1] [ 48%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_withColumn_case_insensitive 
[gw8] [ 49%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_columns 
[gw0] [ 49%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_integer_zeros 
[gw7] [ 49%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_integer_ordering_parity 
tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_float_ordering_parity 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_orderby 
[gw9] [ 49%] FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_orderby 
[gw7] [ 49%] FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_float_ordering_parity 
[gw6] [ 49%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_mixed_types 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_at_one 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_false_booleans 
[gw0] [ 49%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_false_booleans 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_wrap_method_with_memory_check 
[gw3] [ 49%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_multiple_times 
tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_groupby_aggregation 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_computed_columns 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_string_expression 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_groupBy_case_insensitive 
[gw4] [ 49%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulator::test_wrap_method_with_memory_check 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_false_booleans 
[gw2] [ 49%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_at_one 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_with_ignorenulls_true 
tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_select 
[gw6] [ 50%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_select 
tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_withColumn 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_init 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_init 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_slowdown 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_slowdown 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_memory_limit 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_memory_limit 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_enable_monitoring 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_enable_monitoring 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_build 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_build 
tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_fluent_interface 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestMockPerformanceSimulatorBuilder::test_builder_fluent_interface 
tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_slow_simulator 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_slow_simulator 
tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_slow_simulator_default 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_slow_simulator_default 
tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_memory_limited_simulator 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_memory_limited_simulator 
tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_memory_limited_simulator_default 
[gw4] [ 50%] PASSED tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_memory_limited_simulator_default 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_beyond_length 
[gw2] [ 51%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_beyond_length 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_null 
[gw2] [ 51%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_null 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_zero 
[gw3] [ 51%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_computed_columns 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_union 
[gw3] [ 51%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_union 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_preserves_type 
[gw7] [ 51%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_with_ignorenulls_true 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_with_ignorenulls_false 
[gw7] [ 51%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_with_ignorenulls_false 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_default_behavior 
[gw7] [ 51%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_default_behavior 
[gw5] [ 51%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_string_expression 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_nested_structs 
[gw5] [ 51%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_nested_structs 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_computed_columns 
[gw9] [ 51%] PASSED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_groupby_aggregation 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_groupby 
[gw7] [ 52%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_groupby 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_all_nulls 
[gw7] [ 52%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_all_nulls 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_no_nulls 
[gw7] [ 52%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_no_nulls 
[gw3] [ 52%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_preserves_type 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_very_deeply_nested_struct 
[gw8] [ 52%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_computed_columns 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_tuple_returns_empty_map 
tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_rule_can_apply 
[gw9] [ 52%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_rule_can_apply 
tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_rule_cannot_apply 
[gw9] [ 52%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_rule_cannot_apply 
[gw2] [ 52%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_zero 
[gw5] [ 52%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_very_deeply_nested_struct 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_null 
[gw5] [ 52%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_null 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_arithmetic 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_pyspark_parity 
[gw7] [ 52%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_pyspark_parity 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_numeric_values 
[gw7] [ 53%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_numeric_values 
tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_basic 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_mixed_types 
[gw7] [ 53%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_mixed_types 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_null_at_different_positions 
[gw1] [ 53%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_groupBy_case_insensitive 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_orderBy_case_insensitive 
tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_high_performance_simulator 
[gw4] [ 53%] PASSED tests/unit/test_performance_simulation.py::TestConvenienceFunctions::test_create_high_performance_simulator 
[gw3] [ 53%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_tuple_returns_empty_map 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_select 
[gw6] [ 53%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_withColumn 
[gw1] [ 53%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_orderBy_case_insensitive 
[gw9] [ 53%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_basic 
[gw3] [ 53%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_select 
[gw0] [ 53%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_false_booleans 
[gw7] [ 54%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_null_at_different_positions 
tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_before_join 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_exceeds_remaining 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int64_with_string 
[gw9] [ 54%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_before_join 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_withColumnRenamed_case_insensitive 
[gw1] [ 54%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_withColumnRenamed_case_insensitive 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_true_booleans 
[gw2] [ 54%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_exceeds_remaining 
[gw4] [ 54%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int64_with_string 
tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_not_before_groupby 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_boolean_values 
tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_filter 
[gw0] [ 54%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_all_true_booleans 
[gw9] [ 54%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_not_before_groupby 
[gw7] [ 54%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_boolean_values 
[gw6] [ 54%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_filter 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_string_with_int64 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_select 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_withColumnsRenamed_case_insensitive 
[gw4] [ 54%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_string_with_int64 
tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_not_before_orderby 
[gw1] [ 54%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_withColumnsRenamed_case_insensitive 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_float_values 
tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_groupBy_aggregation 
[gw2] [ 55%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_select 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_true_booleans 
[gw9] [ 55%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_not_before_orderby 
[gw6] [ 55%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_groupBy_aggregation 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_drop_case_insensitive 
[gw7] [ 55%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_float_values 
[gw0] [ 55%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_true_booleans 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_string 
tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_not_before_window 
[gw1] [ 55%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_drop_case_insensitive 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_empty_strings 
tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_input 
[gw9] [ 55%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestFilterPushdownRule::test_filter_pushdown_not_before_window 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_dropDuplicates_case_insensitive 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_single_character_strings 
[gw1] [ 55%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_dropDuplicates_case_insensitive 
[gw0] [ 55%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_single_character_strings 
[gw6] [ 55%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_input 
[gw7] [ 56%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_empty_strings 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_unionByName_case_insensitive 
[gw1] [ 56%] PASSED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_unionByName_case_insensitive 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_single_character_values 
[gw0] [ 56%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_single_character_values 
tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_return 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_numeric_string_suffixes 
tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_join_case_insensitive 
[gw0] [ 56%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_numeric_string_suffixes 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_single_row_group 
[gw7] [ 56%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_single_row_group 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_null_values 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_numeric_string_suffixes 
[gw8] [ 56%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_null_values 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_all_null_columns 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_different_data_types 
[gw8] [ 56%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_all_null_columns 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_empty_group 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_numeric_types 
[gw7] [ 56%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_empty_group 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_withColumn 
[gw8] [ 56%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_numeric_types 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_boolean_types 
[gw8] [ 56%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_boolean_types 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types_comprehensive 
[gw8] [ 56%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types_comprehensive 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_select_statement 
[gw8] [ 57%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_select_statement 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_after_filter 
[gw8] [ 57%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_after_filter 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_groupby_context 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_orderby 
[gw7] [ 57%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_orderby 
[gw4] [ 57%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_string 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_float_with_string 
[gw4] [ 57%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_float_with_string 
[gw8] [ 57%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_groupby_context 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_join 
[gw3] [ 57%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_different_data_types 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_after_filter 
[gw8] [ 57%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_join 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_window_functions 
[gw1] [ 57%] FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_join_case_insensitive 
[gw6] [ 57%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_return 
tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_dataframe 
[gw0] [ 58%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_numeric_string_suffixes 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_mixed_numeric_formats 
[gw0] [ 58%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_mixed_numeric_formats 
[gw6] [ 58%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_dataframe 
tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_single_row 
[gw5] [ 58%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_arithmetic 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_conditional 
[gw3] [ 58%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_after_filter 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_and_create_map_equivalent 
[gw3] [ 58%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_and_create_map_equivalent 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_multiple_times 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_numeric_formats 
[gw0] [ 58%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_numeric_formats 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_long_column_names 
[gw0] [ 58%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_very_long_column_names 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_long_column_names 
[gw0] [ 58%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_long_column_names 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_special_characters_in_column_names 
[gw0] [ 58%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_special_characters_in_column_names 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_special_characters_in_column_names 
[gw0] [ 58%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_special_characters_in_column_names 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_unicode_in_column_names 
[gw0] [ 59%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_unicode_in_column_names 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_unicode_in_column_names 
[gw0] [ 59%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_unicode_in_column_names 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_duplicate_column_names_in_data 
[gw0] [ 59%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_duplicate_column_names_in_data 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_duplicate_column_names 
[gw0] [ 59%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_duplicate_column_names 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_only_one_row 
[gw0] [ 59%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_only_one_row 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_one_row 
[gw0] [ 59%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_one_row 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_many_columns 
[gw0] [ 59%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_with_many_columns 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_many_columns 
[gw0] [ 59%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_many_columns 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_type_promotion_int_to_float 
[gw0] [ 59%] PASSED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_create_dataframe_type_promotion_int_to_float 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_int64 
[gw4] [ 59%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_int64 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_string_type_simpleString 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_multiple_aggregations 
[gw7] [ 60%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_multiple_aggregations 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_different_settings_same_group 
[gw7] [ 60%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_different_settings_same_group 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_column_expression 
[gw7] [ 60%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_column_expression 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_large_group 
[gw7] [ 60%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_large_group 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_type_preservation 
[gw7] [ 60%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_type_preservation 
[gw8] [ 60%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_window_functions 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_large_number_of_columns 
[gw1] [ 60%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_string_type_simpleString 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_integer_type_simpleString 
[gw1] [ 60%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_integer_type_simpleString 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_array_type_simpleString 
[gw1] [ 60%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_array_type_simpleString 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_array_type_nested_simpleString 
[gw1] [ 60%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_array_type_nested_simpleString 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_map_type_simpleString 
[gw1] [ 60%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_map_type_simpleString 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_map_type_complex_simpleString 
[gw1] [ 61%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_map_type_complex_simpleString 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_struct_type_simpleString 
[gw1] [ 61%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_struct_type_simpleString 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_struct_type_nested_simpleString 
[gw1] [ 61%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_struct_type_nested_simpleString 
[gw5] [ 61%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_conditional 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_outer_column 
[gw5] [ 61%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_outer_column 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_chained_operations 
[gw2] [ 61%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_withColumn 
[gw6] [ 61%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_single_row 
tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_large_dataframe 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_with_left_on_right_on 
[gw5] [ 61%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_chained_operations 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_filter 
[gw2] [ 61%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_filter 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_orderBy 
[gw2] [ 61%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_orderBy 
tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_reference_other_nested 
tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_rule_can_apply 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_rule_can_apply 
tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_basic 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_basic 
tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_preserves_needed 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_preserves_needed 
tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_preserves_aggregates 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestColumnPruningRule::test_column_pruning_preserves_aggregates 
tests/unit/optimizer/test_optimization_rules.py::TestJoinOptimizationRule::test_join_optimization_rule_can_apply 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestJoinOptimizationRule::test_join_optimization_rule_can_apply 
tests/unit/optimizer/test_optimization_rules.py::TestJoinOptimizationRule::test_join_optimization_small_first 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestJoinOptimizationRule::test_join_optimization_small_first 
tests/unit/optimizer/test_optimization_rules.py::TestPredicatePushdownRule::test_predicate_pushdown_rule_can_apply 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestPredicatePushdownRule::test_predicate_pushdown_rule_can_apply 
tests/unit/optimizer/test_optimization_rules.py::TestPredicatePushdownRule::test_predicate_pushdown_basic 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestPredicatePushdownRule::test_predicate_pushdown_basic 
tests/unit/optimizer/test_optimization_rules.py::TestProjectionPushdownRule::test_projection_pushdown_rule_can_apply 
[gw9] [ 62%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestProjectionPushdownRule::test_projection_pushdown_rule_can_apply 
tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_struct_type_with_array_simpleString 
[gw1] [ 62%] PASSED tests/unit/test_issues_225_231.py::TestIssue231DataTypeSimpleString::test_struct_type_with_array_simpleString 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_in_select 
tests/unit/optimizer/test_optimization_rules.py::TestProjectionPushdownRule::test_projection_pushdown_basic 
[gw8] [ 62%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_large_number_of_columns 
[gw9] [ 63%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestProjectionPushdownRule::test_projection_pushdown_basic 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_equals_substring_function 
[gw7] [ 63%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_in_select 
[gw6] [ 63%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_large_dataframe 
tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_string 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_with_structtype_schema 
[gw1] [ 63%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_with_structtype_schema 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_show_works 
[gw4] [ 63%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_with_left_on_right_on 
tests/unit/optimizer/test_optimization_rules.py::TestLimitPushdownRule::test_limit_pushdown_rule_can_apply 
[gw1] [ 63%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_show_works 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_multiple_keys_with_type_mismatch 
[gw4] [ 63%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_multiple_keys_with_type_mismatch 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_type_coercion_parity_pyspark 
[gw3] [ 63%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_multiple_times 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_union 
[gw3] [ 63%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_union 
[gw5] [ 63%] FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_reference_other_nested 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_all_primitive_types 
[gw5] [ 64%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_all_primitive_types 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_nested_arrays 
[gw5] [ 64%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_nested_arrays 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_expressions 
[gw8] [ 64%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_expressions 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_nested_expressions 
[gw8] [ 64%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_nested_expressions 
[gw6] [ 64%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_string 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_unionByName_works 
[gw1] [ 64%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_unionByName_works 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_operations_work 
[gw1] [ 64%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_operations_work 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_alias 
[gw7] [ 64%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_with_alias 
tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_type_promotion_int_to_float 
[gw0] [ 64%] FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_type_promotion_int_to_float 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_init 
[gw0] [ 64%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_init 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_init_with_name 
[gw0] [ 64%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_init_with_name 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_init_pandas_evaltype 
[gw0] [ 65%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_init_pandas_evaltype 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_as_nondeterministic 
[gw0] [ 65%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_as_nondeterministic 
tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_complex_scenario 
[gw9] [ 65%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestLimitPushdownRule::test_limit_pushdown_rule_can_apply 
[gw4] [ 65%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_type_coercion_parity_pyspark 
[gw7] [ 65%] PASSED tests/unit/functions/test_first_ignorenulls.py::TestFirstIgnoreNulls::test_first_ignorenulls_complex_scenario 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_show 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_union 
tests/unit/optimizer/test_optimization_rules.py::TestLimitPushdownRule::test_limit_pushdown_basic 
tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_zero_value 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_triple_nested 
[gw3] [ 65%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_show 
[gw8] [ 65%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_union 
[gw9] [ 65%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestLimitPushdownRule::test_limit_pushdown_basic 
[gw6] [ 65%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_zero_value 
[gw5] [ 65%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_triple_nested 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_mixed_tuple_and_dict_data 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_multiply 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_with_string_column 
[gw0] [ 66%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_with_string_column 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_with_column_object 
[gw0] [ 66%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_with_column_object 
tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_chained_operations 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_special_characters_in_column_names 
[gw2] [ 66%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_equals_substring_function 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_operations 
[gw2] [ 66%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_operations 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_empty_string 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_left_outer_with_type_mismatch 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_computed_columns 
[gw7] [ 66%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_multiply 
[gw2] [ 66%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_empty_string 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_with_multiple_columns 
[gw0] [ 66%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_with_multiple_columns 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_no_columns 
[gw0] [ 66%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_call_no_columns 
[gw8] [ 66%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_special_characters_in_column_names 
[gw4] [ 66%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_left_outer_with_type_mismatch 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_creates_column_operation 
[gw0] [ 66%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_creates_column_operation 
[gw3] [ 67%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_computed_columns 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_unicode 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rmul 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_stores_function 
tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_join 
[gw0] [ 67%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_stores_function 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_stores_return_type 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int64_string_inner 
[gw1] [ 67%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_mixed_tuple_and_dict_data 
[gw6] [ 67%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_chained_operations 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_preserves_order 
[gw4] [ 67%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int64_string_inner 
[gw2] [ 67%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_unicode 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_string_int64_inner 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_map_type 
[gw5] [ 67%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_map_type 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_struct_type 
[gw5] [ 67%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_struct_type 
[gw7] [ 67%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rmul 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_add 
[gw3] [ 67%] FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_join 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_empty_queue_returns_empty_plan 
[gw3] [ 68%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_empty_queue_returns_empty_plan 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_single_column 
[gw1] [ 68%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_single_column 
[gw0] [ 68%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_stores_return_type 
[gw8] [ 68%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_preserves_order 
tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_with_literal 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_nullable_element 
[gw2] [ 68%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_mismatched_length 
[gw5] [ 68%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_nullable_element 
[gw7] [ 68%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_add 
[gw1] [ 68%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_mismatched_length 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_empty_schema 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_non_nullable_array 
[gw5] [ 68%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_non_nullable_array 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_in_complex_schema 
[gw5] [ 68%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_in_complex_schema 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_select_operation 
[gw6] [ 68%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_with_literal 
tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_multiple_columns_same_udf 
[gw6] [ 69%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_multiple_columns_same_udf 
tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_in_orderBy 
[gw6] [ 69%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_in_orderBy 
[gw1] [ 69%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_empty_schema 
[gw4] [ 69%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_string_int64_inner 
[gw5] [ 69%] FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_select_operation 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_empty_strings 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_filter_select_limit_structure 
tests/unit/optimizer/test_optimization_rules.py::TestLimitPushdownRule::test_limit_pushdown_smallest_limit 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_zero_start 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_integration_with_dataframe 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_radd 
[gw8] [ 69%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_empty_strings 
[gw0] [ 69%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_integration_with_dataframe 
[gw3] [ 69%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_filter_select_limit_structure 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_filter_operation 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_with_filter 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_all_join_types 
[gw0] [ 69%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_with_filter 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_plan_is_json_serializable 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_list_data_with_structtype_schema 
[gw9] [ 69%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestLimitPushdownRule::test_limit_pushdown_smallest_limit 
[gw1] [ 70%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_list_data_with_structtype_schema 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_zero_and_negative_numbers 
[gw5] [ 70%] FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_filter_operation 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_explode_operation 
tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_long_type 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_pyspark_parity_exact_example 
[gw3] [ 70%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_plan_is_json_serializable 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_simple_ops_payload_keys 
[gw3] [ 70%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_simple_ops_payload_keys 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_withColumn_serialized 
[gw3] [ 70%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_withColumn_serialized 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_serialize_expression_column_literal 
[gw3] [ 70%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase1::test_serialize_expression_column_literal 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase2::test_materialize_from_plan_invoked_when_config_true 
[gw3] [ 70%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase2::test_materialize_from_plan_invoked_when_config_true 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase2::test_default_config_uses_standard_materialize 
[gw3] [ 70%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase2::test_default_config_uses_standard_materialize 
[gw1] [ 70%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_pyspark_parity_exact_example 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_with_none_values 
[gw1] [ 70%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_with_none_values 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_with_different_data_types 
[gw1] [ 70%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_with_different_data_types 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_with_long_schema 
[gw1] [ 71%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_with_long_schema 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_single_row 
[gw1] [ 71%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_single_row 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_with_select 
[gw0] [ 71%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_with_select 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_custom_name_in_operation 
[gw0] [ 71%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_custom_name_in_operation 
tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_union_optimization_rule_can_apply 
[gw2] [ 71%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_zero_start 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_alias 
[gw8] [ 71%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_zero_and_negative_numbers 
tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_with_mixed_types 
[gw4] [ 71%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_all_join_types 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_double_precision_string 
[gw7] [ 71%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_radd 
[gw9] [ 71%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_union_optimization_rule_can_apply 
[gw5] [ 71%] FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_explode_operation 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_subtract 
tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_union_optimization_basic 
[gw9] [ 72%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_union_optimization_basic 
tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_rule_application_order 
[gw9] [ 72%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_rule_application_order 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_join_payload_has_other_plan_data_schema 
[gw3] [ 72%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_join_payload_has_other_plan_data_schema 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_union_payload_has_other_plan_data_schema 
[gw3] [ 72%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_union_payload_has_other_plan_data_schema 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_empty_dataframe_with_schema 
[gw1] [ 72%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_empty_dataframe_with_schema 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_mixed_with_row_objects 
[gw1] [ 72%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_mixed_with_row_objects 
[gw7] [ 72%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_subtract 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_orderBy_payload_structure 
[gw3] [ 72%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_orderBy_payload_structure 
[gw2] [ 72%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_alias 
tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_default_name_in_operation 
[gw0] [ 72%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedFunction::test_udf_default_name_in_operation 
tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_init 
[gw6] [ 72%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_long_type 
[gw8] [ 73%] FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_with_mixed_types 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_operations_comprehensive 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_groupBy_payload_structure 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rsub 
[gw3] [ 73%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_groupBy_payload_structure 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_withcolumn_operation 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_pyspark_parity_comprehensive 
tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_float_type 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_type_mismatch_silently_ignored 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_groupBy_with_aggs_serialized 
[gw3] [ 73%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_groupBy_with_aggs_serialized 
[gw5] [ 73%] FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_withcolumn_operation 
[gw8] [ 73%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_type_mismatch_silently_ignored 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_dict_ignores_subset 
[gw8] [ 73%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_dict_ignores_subset 
[gw0] [ 73%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_init 
[gw1] [ 73%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_operations_comprehensive 
[gw4] [ 73%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_double_precision_string 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int_float_coercion 
[gw4] [ 73%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int_float_coercion 
tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_init_with_name 
[gw0] [ 74%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_init_with_name 
tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_call 
[gw0] [ 74%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_call 
tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_call_no_columns 
[gw0] [ 74%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_call_no_columns 
tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_call_with_multiple_columns 
[gw0] [ 74%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_call_with_multiple_columns 
tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_custom_name 
[gw0] [ 74%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_custom_name 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_groupby_operation 
[gw5] [ 74%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_groupby_operation 
[gw7] [ 74%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rsub 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_window_serialized_structure 
[gw3] [ 74%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase3::test_window_serialized_structure 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_polars_materialize_from_plan_simple_pipeline 
[gw3] [ 74%] SKIPPED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_polars_materialize_from_plan_simple_pipeline 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_groupBy_via_plan_interpreter 
tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_rule_idempotency 
[gw9] [ 74%] PASSED tests/unit/optimizer/test_optimization_rules.py::TestUnionOptimizationRule::test_rule_idempotency 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_returns_single_row 
[gw9] [ 75%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_returns_single_row 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_empty_dataframe_returns_none 
[gw9] [ 75%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_empty_dataframe_returns_none 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_multiple_columns 
tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_default_name 
[gw0] [ 75%] PASSED tests/unit/functions/test_udf.py::TestUserDefinedTableFunction::test_udf_table_function_default_name 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_null_values_in_join_keys 
[gw9] [ 75%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_multiple_columns 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_divide 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_filter 
[gw8] [ 75%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_filter 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_select 
[gw8] [ 75%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_select 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_withcolumn 
[gw8] [ 75%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_withcolumn 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_empty_subset 
[gw8] [ 75%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_empty_subset 
[gw2] [ 75%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_pyspark_parity_comprehensive 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_filter 
[gw9] [ 75%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_filter 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_groupBy 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_union_operations 
[gw3] [ 75%] FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_groupBy_via_plan_interpreter 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_long_issue_243 
[gw6] [ 76%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_float_type 
[gw7] [ 76%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_divide 
[gw4] [ 76%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_null_values_in_join_keys 
[gw2] [ 76%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_groupBy 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_union_operation 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_cast_between_power 
[gw3] [ 76%] FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_cast_between_power 
[gw0] [ 76%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_long_issue_243 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_window_row_number 
[gw3] [ 76%] FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_window_row_number 
tests/unit/functions/test_udf_comprehensive.py::TestUDFCustomName::test_udf_with_custom_name 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rdiv 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_string 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_partial_dict 
[gw8] [ 76%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_partial_dict 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_chained_multiple 
[gw8] [ 76%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_chained_multiple 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_numeric_types 
[gw8] [ 76%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_numeric_types 
[gw1] [ 77%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_union_operations 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_with_other_operations 
[gw6] [ 77%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFCustomName::test_udf_with_custom_name 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_join_operations 
[gw1] [ 77%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_join_operations 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_invalid_numeric_strings 
[gw4] [ 77%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_invalid_numeric_strings 
tests/unit/functions/test_udf_comprehensive.py::TestUDFRegression279::test_udf_with_withColumn_regression_279 
[gw7] [ 77%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rdiv 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_multiple_keys_complex 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_orderby 
[gw9] [ 77%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_orderby 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase5::test_robin_plan_path_simple_pipeline 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_schema_preservation 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_select 
[gw9] [ 77%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_select 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_vs_head_difference 
[gw9] [ 77%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_vs_head_difference 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_null_values 
[gw9] [ 77%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_null_values 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_single_row_dataframe 
[gw9] [ 77%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_single_row_dataframe 
[gw0] [ 77%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_string 
[gw3] [ 78%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase5::test_robin_plan_path_simple_pipeline 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_error_message_matches_pyspark 
[gw1] [ 78%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_error_message_matches_pyspark 
[gw8] [ 78%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_schema_preservation 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_groupby 
[gw8] [ 78%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_groupby 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_union 
[gw8] [ 78%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_union 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_all_operations_from_issue 
[gw1] [ 78%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_all_operations_from_issue 
[gw6] [ 78%] FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFRegression279::test_udf_with_withColumn_regression_279 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_int 
[gw2] [ 78%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_with_other_operations 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_sum 
[gw6] [ 78%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_sum 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_zero_numeric 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_negate 
[gw5] [ 78%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_union_operation 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_empty_array 
[gw5] [ 79%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_empty_array 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_array_with_nulls 
[gw5] [ 79%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_array_with_nulls 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_nullable_array_field 
[gw5] [ 79%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_nullable_array_field 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_pyspark_parity_simple 
[gw5] [ 79%] SKIPPED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_pyspark_parity_simple 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_pyspark_parity_complex 
[gw5] [ 79%] SKIPPED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_pyspark_parity_complex 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_date_type 
[gw5] [ 79%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_date_type 
tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase5::test_robin_plan_fallback_on_unsupported_expression 
[gw3] [ 79%] PASSED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase5::test_robin_plan_fallback_on_unsupported_expression 
[gw8] [ 79%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_zero_numeric 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_groupby_agg 
[gw9] [ 79%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_groupby_agg 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_very_long_string 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_join 
[gw0] [ 79%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_int 
[gw9] [ 79%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_join 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_avg 
[gw6] [ 80%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_avg 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_count 
[gw6] [ 80%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_count 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_empty_string 
[gw8] [ 80%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_empty_string 
[gw4] [ 80%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_multiple_keys_complex 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_type_promotion_int32_int64 
[gw4] [ 80%] PASSED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_type_promotion_int32_int64 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_left_on_right_on_different_names 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_boolean_false 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_basic 
[gw7] [ 80%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_negate 
[gw8] [ 80%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_boolean_false 
[gw4] [ 80%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_left_on_right_on_different_names 
[gw2] [ 80%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_very_long_string 
[gw3] [ 80%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_basic 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_chained_operations 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_max 
[gw6] [ 81%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_max 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_boolean_true 
[gw8] [ 81%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_boolean_true 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_timestamp_type 
[gw5] [ 81%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_timestamp_type 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_double 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_with_array_type 
[gw7] [ 81%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_chained_operations 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_with_schema 
[gw3] [ 81%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_with_schema 
[gw1] [ 81%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_with_array_type 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_union 
[gw9] [ 81%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_union 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_min 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_dense_rank_with_arithmetic 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_exceeds_length 
[gw6] [ 81%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_min 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_large_dict 
tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_preserves_order 
[gw1] [ 81%] PASSED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_preserves_order 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_nested_struct 
[gw9] [ 81%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_nested_struct 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_array_column 
[gw9] [ 81%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_array_column 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_multiple_transformations 
[gw9] [ 82%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_multiple_transformations 
tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_decimal_type 
[gw0] [ 82%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_double 
[gw5] [ 82%] PASSED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_decimal_type 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_scalar 
[gw5] [ 82%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_scalar 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_multiple_when 
[gw8] [ 82%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_large_dict 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_subset_all_columns 
[gw8] [ 82%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_subset_all_columns 
[gw7] [ 82%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_dense_rank_with_arithmetic 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_mixed_numeric_strings 
[gw4] [ 82%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_mixed_numeric_strings 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_count_distinct 
[gw6] [ 82%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_count_distinct 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_collect_list 
[gw6] [ 82%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_collect_list 
[gw2] [ 83%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_exceeds_length 
tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_with_matched_condition 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_collect_set 
[gw0] [ 83%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_multiple_when 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_rank_with_arithmetic 
[gw1] [ 83%] FAILED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_with_matched_condition 
tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_multiple_when_matched 
[gw6] [ 83%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_collect_set 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_first 
[gw6] [ 83%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_first 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_null_values 
tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start_exceeds_length 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_dict 
[gw5] [ 83%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_dict 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_subset 
[gw5] [ 83%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_subset 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_non_delta_table_raises 
[gw3] [ 83%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_non_delta_table_raises 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_matches_delta_table_detail 
[gw3] [ 83%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_matches_delta_table_detail 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_partition_columns 
tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_preserves_non_null_values 
[gw8] [ 83%] PASSED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_preserves_non_null_values 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_case_insensitive_match 
[gw8] [ 83%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_case_insensitive_match 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_case_sensitive_match 
[gw8] [ 84%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_case_sensitive_match 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_scientific_notation_strings 
[gw7] [ 84%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_rank_with_arithmetic 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_different_data_types 
[gw9] [ 84%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_different_data_types 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_distinct 
[gw9] [ 84%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_distinct 
[gw1] [ 84%] FAILED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_multiple_when_matched 
[gw4] [ 84%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_scientific_notation_strings 
[gw3] [ 84%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_partition_columns 
[gw2] [ 84%] FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start_exceeds_length 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_last 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_after_join 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_not_found 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_all_nulls 
[gw9] [ 84%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_with_all_nulls 
[gw0] [ 84%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_null_values 
[gw6] [ 85%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_last 
[gw5] [ 85%] FAILED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_after_join 
tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_first_clause_wins 
[gw1] [ 85%] PASSED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_first_clause_wins 
tests/unit/session/test_sql_complex_merge.py::TestMergeNotMatchedBySource::test_merge_delete_not_matched_by_source 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_whitespace_in_string_keys 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_empty_table 
[gw3] [ 85%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_empty_table 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_in_select 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_stddev 
[gw8] [ 85%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_not_found 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_ambiguity 
[gw8] [ 85%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_ambiguity 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_nonexistent_table 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_ntile_with_arithmetic 
tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_dropna 
[gw6] [ 85%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_stddev 
[gw2] [ 85%] FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency 
[gw9] [ 85%] PASSED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_dropna 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_columns_multiple 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_variance 
[gw6] [ 85%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_variance 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_with_elementtype_keyword 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_nonexistent_column 
[gw0] [ 85%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_in_select 
[gw9] [ 86%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_with_elementtype_keyword 
[gw4] [ 86%] FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_whitespace_in_string_keys 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_with_element_type_keyword 
[gw9] [ 86%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_with_element_type_keyword 
[gw1] [ 86%] FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeNotMatchedBySource::test_merge_delete_not_matched_by_source 
[gw7] [ 86%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_ntile_with_arithmetic 
[gw8] [ 86%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_columns_multiple 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_filters 
[gw3] [ 86%] FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_nonexistent_table 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_mean 
tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_schema_verification 
[gw5] [ 86%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_nonexistent_column 
tests/unit/session/test_sql_complex_merge.py::TestMergeNotMatchedBySource::test_merge_not_matched_by_source_no_condition 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_different_types 
[gw1] [ 86%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeNotMatchedBySource::test_merge_not_matched_by_source_no_condition 
[gw5] [ 86%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_different_types 
[gw6] [ 87%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_mean 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_multiple_aggregates 
[gw6] [ 87%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_multiple_aggregates 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_chained_operations 
[gw5] [ 87%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_chained_operations 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_pyspark_parity 
[gw5] [ 87%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_pyspark_parity 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_empty_dataframe 
[gw5] [ 87%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_empty_dataframe 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_no_nulls 
[gw5] [ 87%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_no_nulls 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_equivalence_with_fillna 
[gw5] [ 87%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_equivalence_with_fillna 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_multiple_writes 
[gw3] [ 87%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_multiple_writes 
[gw4] [ 87%] PASSED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_schema_verification 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_complex_schema 
[gw2] [ 87%] FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_filters 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_positional 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_columns_with_ambiguity 
tests/unit/session/test_sql_complex_merge.py::TestMergeComplexExpressions::test_merge_with_expression_in_set 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_translate_edge_cases 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_single_aggregate_with_alias 
[gw4] [ 87%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_translate_edge_cases 
[gw9] [ 88%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_positional 
[gw3] [ 88%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_complex_schema 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lag_with_arithmetic 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_datatype_object 
[gw6] [ 88%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_single_aggregate_with_alias 
[gw7] [ 88%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lag_with_arithmetic 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_both_keywords_error 
[gw8] [ 88%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_columns_with_ambiguity 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_all_required_columns 
[gw3] [ 88%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_all_required_columns 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_multiple_partitions 
[gw3] [ 88%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_multiple_partitions 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lead_with_arithmetic 
tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_empty_groups 
[gw7] [ 88%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lead_with_arithmetic 
[gw9] [ 88%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_both_keywords_error 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_missing_argument 
[gw9] [ 88%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_missing_argument 
[gw6] [ 89%] PASSED tests/unit/dataframe/test_pivot_grouped_data.py::TestPivotGroupedData::test_pivot_empty_groups 
tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_method_exists 
[gw6] [ 89%] PASSED tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_method_exists 
tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_returns_column_operation 
[gw6] [ 89%] PASSED tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_returns_column_operation 
tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_string_type 
[gw6] [ 89%] PASSED tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_string_type 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_select 
[gw2] [ 89%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_select 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_withColumn 
[gw2] [ 89%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_withColumn 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_three_branches 
[gw2] [ 89%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_three_branches 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_nested_transformations 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_elementtype_with_nullable 
[gw9] [ 89%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_elementtype_with_nullable 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_elementtype_with_different_types 
[gw9] [ 89%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_elementtype_with_different_types 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_nested_with_elementtype 
[gw9] [ 89%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_nested_with_elementtype 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_in_schema_with_elementtype 
[gw9] [ 89%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_in_schema_with_elementtype 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_columns_not_found 
[gw8] [ 90%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_columns_not_found 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_column_exists_case_insensitive 
[gw8] [ 90%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_column_exists_case_insensitive 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_column_exists_case_sensitive 
[gw8] [ 90%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_column_exists_case_sensitive 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_column_exists_ambiguous 
[gw8] [ 90%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_column_exists_ambiguous 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_empty_list 
[gw8] [ 90%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_empty_list 
[gw2] [ 90%] FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_nested_transformations 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_sum_window_with_arithmetic 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_substring_index_edge_cases 
[gw4] [ 90%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_substring_index_edge_cases 
tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_special_characters 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_subset_string 
[gw5] [ 90%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_subset_string 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_subset_tuple 
[gw5] [ 90%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_subset_tuple 
[gw0] [ 90%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_datatype_object 
[gw1] [ 91%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeComplexExpressions::test_merge_with_expression_in_set 
tests/unit/session/test_sql_complex_merge.py::TestMergeComplexExpressions::test_merge_with_arithmetic_expression 
tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_issue_247_example 
tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_data_type 
[gw6] [ 91%] PASSED tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_data_type 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_levenshtein_nulls_and_empty_strings 
[gw1] [ 91%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeComplexExpressions::test_merge_with_arithmetic_expression 
tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_all 
[gw1] [ 91%] FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_all 
tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_all_nulls 
[gw5] [ 91%] PASSED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_all_nulls 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_long 
[gw0] [ 91%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_long 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_string 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_aggregations 
[gw2] [ 91%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_aggregations 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_empty_branch 
[gw2] [ 91%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_empty_branch 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_single_row 
[gw2] [ 91%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_single_row 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_complex_expressions 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_table_properties 
[gw3] [ 91%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_table_properties 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_overwrite_operation 
[gw3] [ 91%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_overwrite_operation 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_special_characters_in_name 
[gw3] [ 92%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_special_characters_in_name 
[gw8] [ 92%] PASSED tests/unit/core/test_column_resolver.py::TestColumnResolver::test_resolve_column_name_special_characters 
tests/unit/session/test_sql_cte_robust.py::test_cte_with_join 
[gw8] [ 92%] FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_join 
tests/unit/session/test_sql_cte_robust.py::test_cte_with_multiple_joins 
tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_different_aggregates 
[gw6] [ 92%] PASSED tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_different_aggregates 
tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_column_name_format 
[gw6] [ 92%] PASSED tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_column_name_format 
[gw7] [ 92%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_sum_window_with_arithmetic 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_avg_window_with_arithmetic 
tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_execute_robin_plan_empty_plan_returns_data_as_rows 
[gw5] [ 92%] PASSED tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_execute_robin_plan_empty_plan_returns_data_as_rows 
[gw9] [ 92%] PASSED tests/unit/spark_types/test_array_type_keywords.py::TestArrayTypeKeywords::test_array_type_issue_247_example 
tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_only_unmatched 
[gw2] [ 92%] FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_complex_expressions 
[gw4] [ 92%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_levenshtein_nulls_and_empty_strings 
[gw7] [ 93%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_avg_window_with_arithmetic 
tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_null_values 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_soundex_null_and_empty 
tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_execute_robin_plan_filter_select_limit 
[gw5] [ 93%] PASSED tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_execute_robin_plan_filter_select_limit 
[gw6] [ 93%] PASSED tests/unit/functions/test_aggregate_function_cast.py::test_aggregate_function_cast_with_null_values 
tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_list_available_backends_returns_robin_only_v4 
[gw6] [ 93%] PASSED tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_list_available_backends_returns_robin_only_v4 
tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_create_storage_backend_robin_raises_when_not_available 
[gw6] [ 93%] PASSED tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_create_storage_backend_robin_raises_when_not_available 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_multiple_window_functions_with_arithmetic 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_large_table 
[gw3] [ 93%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_large_table 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_drop 
[gw2] [ 93%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_drop 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_multiple_unions 
tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_without_rsd 
[gw9] [ 93%] PASSED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_without_rsd 
tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_with_rsd 
[gw0] [ 93%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_string 
[gw2] [ 93%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_multiple_unions 
[gw1] [ 93%] FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_only_unmatched 
tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_no_matches 
[gw4] [ 94%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_soundex_null_and_empty 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_double 
[gw0] [ 94%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_double 
[gw8] [ 94%] FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_multiple_joins 
[gw9] [ 94%] PASSED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_with_rsd 
tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_rsd_default_value 
[gw9] [ 94%] PASSED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_rsd_default_value 
tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_rsd_different_values 
[gw9] [ 94%] PASSED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_rsd_different_values 
tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_in_groupby 
[gw9] [ 94%] PASSED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_in_groupby 
tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_in_window 
[gw9] [ 94%] SKIPPED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_in_window 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_window_functions 
tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_execute_robin_plan_unsupported_op_raises 
tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_window_without_rsd 
[gw7] [ 94%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_multiple_window_functions_with_arithmetic 
[gw5] [ 94%] PASSED tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_execute_robin_plan_unsupported_op_raises 
[gw9] [ 95%] SKIPPED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_window_without_rsd 
[gw2] [ 95%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_window_functions 
tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_preserves_original_data 
[gw2] [ 95%] PASSED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_preserves_original_data 
[gw1] [ 95%] FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_no_matches 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_with_nulls 
tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_robin_expr_to_column_col_and_lit 
tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_empty_source 
[gw1] [ 95%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_empty_source 
tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_different_data_types 
[gw3] [ 95%] PASSED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_different_data_types 
tests/unit/backend/test_robin_materializer.py::TestRobinMaterializerExpressionTranslation::test_with_column_alias_expression_robin 
[gw3] [ 95%] SKIPPED tests/unit/backend/test_robin_materializer.py::TestRobinMaterializerExpressionTranslation::test_with_column_alias_expression_robin 
tests/unit/backend/test_robin_materializer.py::TestRobinMaterializerExpressionTranslation::test_with_column_literal_plus_column_robin 
[gw3] [ 95%] SKIPPED tests/unit/backend/test_robin_materializer.py::TestRobinMaterializerExpressionTranslation::test_with_column_literal_plus_column_robin 
tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_create_materializer_robin_raises_when_not_available 
tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_timestamp_core_units 
tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_select_expression_raises 
[gw2] [ 95%] FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_timestamp_core_units 
[gw6] [ 95%] PASSED tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_create_materializer_robin_raises_when_not_available 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_crc32_known_values_and_null 
[gw7] [ 95%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_with_nulls 
[gw9] [ 96%] FAILED tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_select_expression_raises 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_complex_nested_arithmetic 
tests/unit/backend/test_robin_materializer.py::TestRobinMaterializerExpressionTranslation::test_with_column_literal_times_column_robin 
tests/unit/session/test_sql_cte_robust.py::test_cte_with_left_join 
[gw8] [ 96%] FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_left_join 
tests/unit/session/test_sql_cte_robust.py::test_cte_with_where_clause 
[gw5] [ 96%] PASSED tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_robin_expr_to_column_col_and_lit 
tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_robin_expr_to_column_op_raises_for_unknown 
[gw5] [ 96%] PASSED tests/unit/backend/robin/test_plan_executor.py::TestRobinPlanExecutor::test_robin_expr_to_column_op_raises_for_unknown 
tests/unit/dataframe/test_robin_plan.py::TestRobinPlan::test_filter_select_limit_robin_plan 
[gw5] [ 96%] PASSED tests/unit/dataframe/test_robin_plan.py::TestRobinPlan::test_filter_select_limit_robin_plan 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_partition 
tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_raises_with_clear_message 
tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_all_matched_deleted 
tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_create_export_backend_robin_raises_when_not_available 
[gw6] [ 96%] PASSED tests/unit/backend/test_robin_optional.py::TestRobinBackendOptional::test_create_export_backend_robin_raises_when_not_available 
[gw4] [ 96%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_crc32_known_values_and_null 
tests/unit/dataframe/test_grouped_aggregate_functions_accept_aggregatefunction.py::test_groupby_agg_accepts_aggregate_function_objects 
[gw6] [ 96%] PASSED tests/unit/dataframe/test_grouped_aggregate_functions_accept_aggregatefunction.py::test_groupby_agg_accepts_aggregate_function_objects 
[gw0] [ 96%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_partition 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_sum 
tests/unit/dataframe/test_robin_plan.py::TestRobinPlan::test_robin_plan_is_json_serializable 
tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_on_date_column 
[gw1] [ 96%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_all_matched_deleted 
tests/unit/session/test_sql_complex_merge.py::TestMergeParserComplex::test_parser_extracts_multiple_when_matched 
[gw1] [ 97%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeParserComplex::test_parser_extracts_multiple_when_matched 
[gw3] [ 97%] SKIPPED tests/unit/backend/test_robin_materializer.py::TestRobinMaterializerExpressionTranslation::test_with_column_literal_times_column_robin 
[gw5] [ 97%] PASSED tests/unit/dataframe/test_robin_plan.py::TestRobinPlan::test_robin_plan_is_json_serializable 
tests/unit/functions/test_udf_regression_279.py::test_udf_with_withColumn_regression_279 
tests/unit/functions/test_date_trunc_polars_backend.py::TestDateTruncPolarsBackend::test_date_trunc_month_on_date_column 
[gw8] [ 97%] FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_where_clause 
tests/unit/session/test_sql_cte_robust.py::test_cte_with_aggregation_after_join 
tests/unit/session/test_sql_in_clause.py::test_sql_in_clause_basic 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_xxhash64_known_values_and_null 
tests/unit/session/test_sql_complex_merge.py::TestMergeParserComplex::test_parser_extracts_not_matched_by_source 
[gw1] [ 97%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeParserComplex::test_parser_extracts_not_matched_by_source 
[gw0] [ 97%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_sum 
[gw7] [ 97%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_complex_nested_arithmetic 
[gw6] [ 97%] PASSED tests/unit/session/test_sql_in_clause.py::test_sql_in_clause_basic 
[gw9] [ 97%] FAILED tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_raises_with_clear_message 
[gw4] [ 97%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_xxhash64_known_values_and_null 
[gw2] [ 97%] FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_on_date_column 
[gw5] [ 98%] FAILED tests/unit/functions/test_udf_regression_279.py::test_udf_with_withColumn_regression_279 
tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_preserves_nulls 
tests/unit/functions/test_regexp_extract_all_189.py::test_regexp_extract_all_basic_groups 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_get_json_object_missing_path_and_invalid_json 
tests/unit/session/test_sql_like_clause.py::test_sql_like_simple_prefix_pattern 
[gw6] [ 98%] FAILED tests/unit/session/test_sql_like_clause.py::test_sql_like_simple_prefix_pattern 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_filter 
tests/unit/session/test_sql_complex_merge.py::TestMergeParserComplex::test_parser_extracts_complex_set_clause 
[gw1] [ 98%] PASSED tests/unit/session/test_sql_complex_merge.py::TestMergeParserComplex::test_parser_extracts_complex_set_clause 
[gw8] [ 98%] FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_aggregation_after_join 
tests/unit/session/test_sql_basic_select_schema.py::test_sql_basic_select_schema_matches_dataframe_select 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_in_select 
[gw3] [ 98%] FAILED tests/unit/functions/test_date_trunc_polars_backend.py::TestDateTruncPolarsBackend::test_date_trunc_month_on_date_column 
tests/unit/functions/test_null_handling_column_names.py::test_coalesce_column_name_matches_expected 
[gw3] [ 98%] PASSED tests/unit/functions/test_null_handling_column_names.py::test_coalesce_column_name_matches_expected 
[gw5] [ 98%] PASSED tests/unit/session/test_sql_basic_select_schema.py::test_sql_basic_select_schema_matches_dataframe_select 
[gw7] [ 98%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_filter 
[gw4] [ 98%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_get_json_object_missing_path_and_invalid_json 
tests/unit/session/test_sql_cte_robust.py::test_cte_with_self_join 
[gw9] [ 98%] FAILED tests/unit/functions/test_regexp_extract_all_189.py::test_regexp_extract_all_basic_groups 
[gw2] [ 99%] FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_preserves_nulls 
[gw0] [ 99%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_in_select 
tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_orderby 
tests/unit/session/test_sql_create_table_as_select.py::test_create_table_as_select_basic 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_json_tuple_missing_fields_and_invalid_json 
tests/unit/session/test_sql_update.py::test_update_table_basic 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_datatype_object 
[gw8] [ 99%] FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_self_join 
[gw2] [ 99%] FAILED tests/unit/session/test_sql_update.py::test_update_table_basic 
[gw0] [ 99%] FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_datatype_object 
[gw7] [ 99%] FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_orderby 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenWindowFunctionCastParity::test_casewhen_cast_parity_issue_243 
[gw0] [ 99%] SKIPPED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenWindowFunctionCastParity::test_casewhen_cast_parity_issue_243 
[gw4] [ 99%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_json_tuple_missing_fields_and_invalid_json 
[gw9] [ 99%] FAILED tests/unit/session/test_sql_create_table_as_select.py::test_create_table_as_select_basic 
tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenWindowFunctionCastParity::test_window_function_cast_parity 
[gw0] [ 99%] SKIPPED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenWindowFunctionCastParity::test_window_function_cast_parity 
tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_regexp_extract_all_multiple_matches_and_nulls 
[gw4] [100%] FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_regexp_extract_all_multiple_matches_and_nulls 

=================================== FAILURES ===================================
__________________ TestColumnAstype.test_basic_astype_string ___________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:57: in test_basic_astype_string
    assert rows[0]["num_str"] == "1"
E   AssertionError: assert None == '1'
______________ TestColumnOrderingNulls.test_desc_nulls_last_basic ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:52: in test_desc_nulls_last_basic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____________________ TestColumnAstype.test_basic_astype_int ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:77: in test_basic_astype_int
    assert rows[0]["num"] == 1
E   assert None == 1
__________________ TestWithField.test_withfield_add_new_field __________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:70: in test_withfield_add_new_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestUnionTypeCoercion.test_union_string_with_int64 ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'union' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_union_type_coercion.py:77: in test_union_string_with_int64
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1042: in materialize
    df = df.union(other_robin_df)
         ^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: type Int64 is incompatible with expected type String
___________ TestColumnCaseVariations.test_filter_all_case_variations ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_column_case_variations.py:90: in test_filter_all_case_variations
    result = sample_df.filter(F.col("name") == "Alice").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'Alice' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestCreateMap.test_create_map_with_literals __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:30: in test_create_map_with_literals
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestWithField.test_withfield_replace_existing_field ______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:125: in test_withfield_replace_existing_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestColumnOrderingNulls.test_desc_nulls_first _________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:77: in test_desc_nulls_first
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestColumnAstype.test_astype_on_column_operation _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_astype.py:95: in test_astype_on_column_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestInferSchemaParity.test_csv_infer_schema_with_numeric_strings _______
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:194: in test_csv_infer_schema_with_numeric_strings
    assert isinstance(field_dict_inferred["id"], LongType), (
E   AssertionError: id should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
_________________ TestColumnOrderingNulls.test_asc_nulls_last __________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:102: in test_asc_nulls_last
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestCreateMap.test_create_map_with_column_values _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:51: in test_create_map_with_column_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [first, last]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestChainedArithmetic.test_reverse_modulo ___________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: '%'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_chained_arithmetic.py:124: in test_reverse_modulo
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(2 % number_2)' not found. Available columns: [number_2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestColumnOrderingNulls.test_asc_nulls_first _________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:127: in test_asc_nulls_first
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________ TestInferSchemaParity.test_csv_infer_schema_boolean_strings __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:236: in test_csv_infer_schema_boolean_strings
    assert isinstance(field_dict_inferred["flag1"], BooleanType), (
E   AssertionError: flag1 should be BooleanType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), BooleanType)
__________ TestColumnCaseVariations.test_orderBy_all_case_variations ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_column_case_variations.py:188: in test_orderBy_all_case_variations
    result = sample_df.orderBy(F.col("name").desc()).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____________ TestWithField.test_withfield_with_column_expression ______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:169: in test_withfield_with_column_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, other_value, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestInferSchemaParity.test_csv_with_leading_zeros _______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:282: in test_csv_with_leading_zeros
    assert isinstance(field_dict_inferred["id"], LongType), (
E   AssertionError: id should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
_________________ TestCreateMap.test_create_map_multiple_pairs _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:70: in test_create_map_multiple_pairs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnOrderingNulls.test_desc_nulls_last_integers _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:152: in test_desc_nulls_last_integers
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____________ TestWithField.test_withfield_with_computed_expression _____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:210: in test_withfield_with_computed_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestColumnAstype.test_astype_issue_239_example ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_astype.py:119: in test_astype_issue_239_example
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestIssue225StringToNumericCoercion.test_numeric_eq_string __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_issues_225_231.py:208: in test_numeric_eq_string
    result = df.filter(F.col("value") == "150").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '150' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestInferSchemaParity.test_csv_with_negative_numbers _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:320: in test_csv_with_negative_numbers
    assert isinstance(field_dict["value"], LongType), "value should be LongType"
E   AssertionError: value should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
___________ TestInferSchemaParity.test_csv_with_scientific_notation ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:356: in test_csv_with_scientific_notation
    assert isinstance(field_dict["small"], DoubleType), (
E   AssertionError: small should be DoubleType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
________________ TestCreateMap.test_create_map_with_null_values ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:91: in test_create_map_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnOrderingNulls.test_desc_nulls_last_all_nulls ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:175: in test_desc_nulls_last_all_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestInferSchemaParity.test_csv_with_null_values ________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:445: in test_csv_with_null_values
    assert isinstance(field_dict["id"], LongType), "id should be LongType"
E   AssertionError: id should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
______________ TestColumnAstype.test_astype_with_datatype_object _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'sparkless.spark_types.StringType'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_astype.py:137: in test_astype_with_datatype_object
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'num_str' not found. Available columns: [num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestWithField.test_withfield_multiple_chained _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:254: in test_withfield_multiple_chained
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnCaseVariations.test_join_all_case_variations ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/test_column_case_variations.py:278: in test_join_all_case_variations
    result = df1.join(df2, on="id", how="inner").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: ID
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
______________ TestChainedArithmetic.test_all_reverse_operations _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: '%'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_chained_arithmetic.py:200: in test_all_reverse_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(5 - col)' not found. Available columns: [col, add]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnOrderingNulls.test_desc_nulls_last_no_nulls _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:194: in test_desc_nulls_last_no_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____________ TestCreateMap.test_create_map_empty_returns_empty_map _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:106: in test_create_map_empty_returns_empty_map
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestColumnOrderingNulls.test_desc_nulls_last_multiple_nulls __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:217: in test_desc_nulls_last_multiple_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________ TestCreateMap.test_create_map_empty_list_returns_empty_map __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:117: in test_create_map_empty_list_returns_empty_map
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestInferSchemaParity.test_csv_with_very_large_numbers ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:526: in test_csv_with_very_large_numbers
    assert isinstance(field_dict["big_int"], LongType), (
E   AssertionError: big_int should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
_________ TestUnionTypeCoercionParity.test_pyspark_parity_string_int64 _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'union' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_union_type_coercion.py:319: in test_pyspark_parity_string_int64
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1042: in materialize
    df = df.union(other_robin_df)
         ^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: type Int64 is incompatible with expected type String
_____________ TestIssue226IsinWithValues.test_isin_with_empty_list _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_issues_225_231.py:286: in test_isin_with_empty_list
    result = df.filter(F.col("value").isin([])).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________ TestChainedArithmetic.test_reverse_operations_in_select ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_chained_arithmetic.py:274: in test_reverse_operations_in_select
    assert rows[0]["result"] == 50.0  # 10 * 5.0
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 50.0
____________________ TestColumnAstype.test_astype_in_select ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:188: in test_astype_in_select
    assert rows[0]["num_str"] == "1"
E   AssertionError: assert None == '1'
_________________ TestCreateMap.test_create_map_in_withcolumn __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:135: in test_create_map_in_withcolumn
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map(name, name, age, age)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestInferSchemaParity.test_csv_with_decimal_precision _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:564: in test_csv_with_decimal_precision
    assert isinstance(field_dict["price"], DoubleType), (
E   AssertionError: price should be DoubleType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
____________________ TestColumnAstype.test_astype_with_null ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:247: in test_astype_with_null
    assert rows[0]["num_str"] == "1"
E   AssertionError: assert None == '1'
__________________ TestCreateMap.test_create_map_after_filter __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:154: in test_create_map_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestIssue227GetItem.test_getItem_with_array_index _______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'getItem'

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:323: in test_getItem_with_array_index
    result = df.select(F.col("arr").getItem(0).alias("first")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'first' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestWithField.test_withfield_null_struct ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:292: in test_withfield_null_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestInferSchemaParity.test_csv_mixed_boolean_strings _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:602: in test_csv_mixed_boolean_strings
    assert isinstance(field_dict["flag1"], BooleanType), (
E   AssertionError: flag1 should be BooleanType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), BooleanType)
_________ TestColumnOrderingNulls.test_asc_nulls_first_multiple_nulls __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:242: in test_asc_nulls_first_multiple_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____________________ TestColumnAstype.test_astype_double ______________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:266: in test_astype_double
    assert rows[0]["num_double"] == 1.0
E   assert None == 1.0
__________________ TestCreateMap.test_create_map_all_literals __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:168: in test_create_map_all_literals
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [dummy]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ TestColumnAstype.test_astype_boolean _____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:286: in test_astype_boolean
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:201: in execute_robin_plan
    df = df.select(*cols)
         ^^^^^^^^^^^^^^^^
E   RuntimeError: casting from string to boolean failed for value '5'
______________ TestIssue227GetItem.test_getItem_with_split_result ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:127: in serialize_expression
    left = serialize_expression(col_side) if col_side is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:335: in test_getItem_with_split_result
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'first' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestWithField.test_withfield_issue_235_example ________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:333: in test_withfield_issue_235_example
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestColumnOrderingNulls.test_desc_nulls_last_with_sort_method _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:267: in test_desc_nulls_last_with_sort_method
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________ TestInferSchemaParity.test_csv_with_mixed_numeric_strings ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:733: in test_csv_with_mixed_numeric_strings
    assert isinstance(field_dict["id"], LongType), "id should be LongType"
E   AssertionError: id should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
__________________ TestInferSchemaParity.test_csv_single_row ___________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:792: in test_csv_single_row
    assert isinstance(field_dict["age"], LongType), "age should be LongType"
E   AssertionError: age should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
____________ TestColumnOrderingNulls.test_multiple_columns_ordering ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:332: in test_multiple_columns_ordering
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestColumnAstype.test_astype_chained_operations ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:314: in test_astype_chained_operations
    assert rows[0]["doubled_str"] in ["2", "2.0"]
E   AssertionError: assert None in ['2', '2.0']
___________________ TestColumnAstype.test_astype_on_literal ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:331: in test_astype_on_literal
    assert rows[0]["lit_str"] == "123"
E   AssertionError: assert None == '123'
________________ TestColumnAstype.test_astype_date_from_string _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:349: in test_astype_date_from_string
    assert rows[0]["date_col"] is not None
E   assert None is not None
_________ TestColumnCaseVariations.test_selectExpr_all_case_variations _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_column_case_variations.py:323: in test_selectExpr_all_case_variations
    result = sample_df.selectExpr("name as full_name").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:201: in execute_robin_plan
    df = df.select(*cols)
         ^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'full_name' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestCreateMap.test_create_map_with_numeric_types _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:190: in test_create_map_with_numeric_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [float_val, int_val, long_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestColumnOrderingNulls.test_desc_nulls_last_float ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:360: in test_desc_nulls_last_float
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________ TestWithField.test_withfield_different_data_types _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:387: in test_withfield_different_data_types
    rows = result_int.collect()
           ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(int_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestIssue227GetItem.test_getItem_with_map_key _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'getItem'

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:350: in test_getItem_with_map_key
    result = df.select(F.col("map").getItem("key1").alias("val")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'val' not found. Available columns: [map]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestChainedArithmetic.test_all_operators_in_single_expression _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:77: in robin_expr_to_column
    right = robin_expr_to_column(right_d) if right_d is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: '%'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_chained_arithmetic.py:425: in test_all_operators_in_single_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '((((a * 2) + 10) - (5 / a)) + (3 % a))' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestColumnCaseVariations.test_expressions_with_case_variations ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'upper' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/test_column_case_variations.py:390: in test_expressions_with_case_variations
    result = sample_df.withColumn("upper_name", F.upper(F.col("name"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'upper(name)' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestColumnOrderingNulls.test_desc_nulls_last_negative_numbers _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:385: in test_desc_nulls_last_negative_numbers
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________________ TestWithField.test_withfield_nested_struct __________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:444: in test_withfield_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestWithField.test_withfield_empty_struct ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:471: in test_withfield_empty_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestWithField.test_withfield_replace_then_add _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:510: in test_withfield_replace_then_add
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestWithField.test_withfield_deeply_nested_struct _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:560: in test_withfield_deeply_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestColumnAstype.test_astype_substring_to_date ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:127: in serialize_expression
    left = serialize_expression(col_side) if col_side is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_astype.py:367: in test_astype_substring_to_date
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'date_col' not found. Available columns: [datetime_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestCreateMap.test_create_map_with_boolean_values _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:208: in test_create_map_with_boolean_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [flag1, flag2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestUnionTypeCoercionEdgeCases.test_union_multiple_numeric_types _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'union' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_union_type_coercion.py:618: in test_union_multiple_numeric_types
    rows = result2.collect()
           ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1042: in materialize
    df = df.union(other_robin_df)
         ^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: type Int64 is incompatible with expected type String
______________ TestCreateMap.test_create_map_with_computed_values ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:225: in test_create_map_with_computed_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestIssue227GetItem.test_getItem_out_of_bounds ________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'getItem'

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:362: in test_getItem_out_of_bounds
    result = df.select(F.col("arr").getItem(10).alias("val")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'val' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestColumnAstype.test_astype_multiple_types __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:391: in test_astype_multiple_types
    assert rows[0]["as_int"] == 123
E   assert None == 123
___________ TestInferSchemaParity.test_csv_with_only_boolean_column ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:974: in test_csv_with_only_boolean_column
    assert isinstance(df_inferred.schema.fields[0].dataType, BooleanType), (
E   AssertionError: Should be BooleanType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), BooleanType)
E    +    where StringType(nullable=True) = StructField(name='active', dataType=StringType(nullable=True), nullable=True).dataType
_________ TestColumnOrderingNulls.test_asc_nulls_last_empty_dataframe __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:401: in test_asc_nulls_last_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____________ TestWithField.test_withfield_with_complex_expression _____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:597: in test_withfield_with_complex_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(computed, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestColumnOrderingNulls.test_desc_nulls_last_single_row ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:412: in test_desc_nulls_last_single_row
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________ TestUnionTypeCoercionEdgeCases.test_union_chained_unions ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'union' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_union_type_coercion.py:636: in test_union_chained_unions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1042: in materialize
    df = df.union(other_robin_df)
         ^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: type Int64 is incompatible with expected type String
_________ TestColumnCaseVariations.test_distinct_with_case_variations __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'union' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/test_column_case_variations.py:440: in test_distinct_with_case_variations
    result = df_with_dupes.select("name").distinct().collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1042: in materialize
    df = df.union(other_robin_df)
         ^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: type Int64 is incompatible with expected type String
_______________ TestIssue227GetItem.test_getItem_negative_index ________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'getItem'

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:375: in test_getItem_negative_index
    result = df.select(F.col("arr").getItem(-1).alias("val")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'val' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestInferSchemaParity.test_csv_with_only_integer_column ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:1006: in test_csv_with_only_integer_column
    assert isinstance(df_inferred.schema.fields[0].dataType, LongType), (
E   AssertionError: Should be LongType, not IntegerType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
E    +    where StringType(nullable=True) = StructField(name='count', dataType=StringType(nullable=True), nullable=True).dataType
____________ TestInferSchemaParity.test_csv_with_only_float_column _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:1038: in test_csv_with_only_float_column
    assert isinstance(df_inferred.schema.fields[0].dataType, DoubleType), (
E   AssertionError: Should be DoubleType, not FloatType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
E    +    where StringType(nullable=True) = StructField(name='price', dataType=StringType(nullable=True), nullable=True).dataType
___________________ TestColumnAstype.test_astype_with_alias ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:427: in test_astype_with_alias
    assert rows[0]["num_as_string"] == "1"
E   AssertionError: assert None == '1'
___________ TestWithField.test_withfield_with_conditional_expression ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:635: in test_withfield_with_conditional_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(status, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestUnionTypeCoercionEdgeCases.test_union_three_dataframes __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'union' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_union_type_coercion.py:746: in test_union_three_dataframes
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1042: in materialize
    df = df.union(other_robin_df)
         ^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: type Float64 is incompatible with expected type String
___ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_with_lookbehind ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:393: in test_regexp_extract_with_lookbehind
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestCreateMap.test_create_map_multiple_maps_in_select _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:238: in test_create_map_multiple_maps_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'name_map' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestColumnOrderingNulls.test_desc_nulls_last_single_null_row _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:424: in test_desc_nulls_last_single_null_row
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________ TestColumnOrderingNulls.test_nulls_at_beginning_middle_end __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:446: in test_nulls_at_beginning_middle_end
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________ TestChainedArithmetic.test_reverse_operations_in_orderby ___________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_chained_arithmetic.py:561: in test_reverse_operations_in_orderby
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestColumnOrderingNulls.test_unicode_characters ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:478: in test_unicode_characters
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestWithField.test_withfield_with_cast_operation _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:678: in test_withfield_with_cast_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(id_int, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestColumnAstype.test_astype_on_complex_expressions ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:452: in test_astype_on_complex_expressions
    assert rows[0]["result_str"] in ["10", "10.0"]  # (2 + 3) * 2 = 10
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert None in ['10', '10.0']
_________________ TestCreateMap.test_create_map_in_groupby_agg _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:268: in test_create_map_in_groupby_agg
    rows2 = result2.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'info' not found. Available columns: [dept, name, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestChainedArithmetic.test_reverse_operations_with_when_otherwise _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_chained_arithmetic.py:612: in test_reverse_operations_with_when_otherwise
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(value * 2) > 10' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestChainedArithmetic.test_reverse_operations_with_cast ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_chained_arithmetic.py:630: in test_reverse_operations_with_cast
    assert rows[0]["result"] == 5  # (2 * 2.5) = 5.0, cast to int = 5
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 5
_______ TestColumnCaseVariations.test_complex_query_all_case_variations ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_column_case_variations.py:523: in test_complex_query_all_case_variations
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________ TestColumnAstype.test_astype_invalid_string_to_int ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:473: in test_astype_invalid_string_to_int
    assert rows[1]["as_int"] == 123  # "123" -> 123
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 123
___________ TestWithField.test_withfield_replace_with_different_type ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:711: in test_withfield_replace_with_different_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestWithField.test_withfield_multiple_fields_in_sequence ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:738: in test_withfield_multiple_fields_in_sequence
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(field1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_with_lookahead ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:406: in test_regexp_extract_with_lookahead
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestColumnAstype.test_astype_double_to_int __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:495: in test_astype_double_to_int
    assert rows[0]["as_int"] == 3  # 3.14 -> 3
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 3
________________ TestColumnAstype.test_astype_string_to_boolean ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:519: in test_astype_string_to_boolean
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:201: in execute_robin_plan
    df = df.select(*cols)
         ^^^^^^^^^^^^^^^^
E   RuntimeError: casting from string to boolean failed for value ''
________________ TestColumnAstype.test_astype_multiple_chained _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:607: in test_astype_multiple_chained
    assert rows[0]["result"] == "123"
E   AssertionError: assert None == '123'
__________ TestColumnCaseVariations.test_coalesce_all_case_variations __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'list'>

During handling of the above exception, another exception occurred:
tests/unit/test_column_case_variations.py:661: in test_coalesce_all_case_variations
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'result' not found. Available columns: [Col1, Col2, Col3]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestCreateMap.test_create_map_with_special_characters_in_keys _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:284: in test_create_map_with_special_characters_in_keys
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestCreateMap.test_create_map_nested_in_expressions ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:303: in test_create_map_nested_in_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestCreateMap.test_create_map_with_empty_string_keys _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:319: in test_create_map_with_empty_string_keys
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestInferSchemaParity.test_csv_with_very_small_numbers ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:1123: in test_csv_with_very_small_numbers
    assert isinstance(field_dict["tiny"], DoubleType), (
E   AssertionError: tiny should be DoubleType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
_ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_without_lookaround __
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:419: in test_regexp_extract_without_lookaround
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'domain' not found. Available columns: [email]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_with_complex_lookaround _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:433: in test_regexp_extract_with_complex_lookaround
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestWithField.test_withfield_with_null_literal ________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:769: in test_withfield_with_null_literal
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(null_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestColumnCaseVariations.test_nested_struct_field_access_all_cases ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:154: in execute_robin_plan
    raise ValueError("execute_robin_plan requires a non-empty schema")
E   ValueError: execute_robin_plan requires a non-empty schema

During handling of the above exception, another exception occurred:
tests/unit/test_column_case_variations.py:726: in test_nested_struct_field_access_all_cases
    result = df.select("Person.name").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:853: in materialize
    raise ValueError("RobinMaterializer requires a non-empty schema")
E   ValueError: RobinMaterializer requires a non-empty schema
________ TestColumnCaseVariations.test_sql_queries_all_case_variations _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_column_case_variations.py:751: in test_sql_queries_all_case_variations
    assert len(result) == 3
E   assert 6 == 3
E    +  where 6 = len([Row(Name=None), Row(Name=None), Row(Name=None), Row(Name=None), Row(Name=None), Row(Name=None)])
______________ TestInferSchemaParity.test_csv_with_tab_delimiter _______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:1279: in test_csv_with_tab_delimiter
    assert isinstance(field_dict["age"], LongType), "age should be LongType"
E   AssertionError: age should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
__________ TestColumnOrderingNulls.test_mixed_asc_desc_nulls_variants __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:507: in test_mixed_asc_desc_nulls_variants
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestColumnOrderingNulls.test_very_large_numbers ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:527: in test_very_large_numbers
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________ TestColumnOrderingNulls.test_all_four_methods_comprehensive __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:550: in test_all_four_methods_comprehensive
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
________ TestColumnOrderingNulls.test_comparison_with_default_desc_asc _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:594: in test_comparison_with_default_desc_asc
    rows_desc = result_desc.collect()
                ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____________ TestColumnAstype.test_astype_on_all_column_operations _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:76: in robin_expr_to_column
    left = robin_expr_to_column(left_d) if left_d is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'upper' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_astype.py:624: in test_astype_on_all_column_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'upper_str' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestChainedArithmetic.test_reverse_operations_modulo_by_zero _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: '%'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_chained_arithmetic.py:680: in test_reverse_operations_modulo_by_zero
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(10 % col)' not found. Available columns: [col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestCreateMap.test_create_map_after_union ___________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:330: in test_create_map_after_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestColumnOrderingNulls.test_three_column_ordering ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:628: in test_three_column_ordering
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____ TestColumnCaseVariations.test_issue_264_withColumn_case_insensitive ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'upper' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/test_column_case_variations.py:861: in test_issue_264_withColumn_case_insensitive
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'upper(Key)' not found. Available columns: [key]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestWithField.test_withfield_with_array_field _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:798: in test_withfield_with_array_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(array_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnOrderingNulls.test_string_comparison_edge_cases ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:652: in test_string_comparison_edge_cases
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________________ TestCreateMap.test_create_map_with_null_keys _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:353: in test_create_map_with_null_keys
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestColumnAstype.test_astype_zero_and_negative ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:673: in test_astype_zero_and_negative
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:201: in execute_robin_plan
    df = df.select(*cols)
         ^^^^^^^^^^^^^^^^
E   RuntimeError: casting from string to boolean failed for value '-1'
__ TestChainedArithmetic.test_reverse_operations_with_select_multiple_columns __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_chained_arithmetic.py:752: in test_reverse_operations_with_select_multiple_columns
    assert rows[0]["double"] == 6.0  # 2 * 3.0
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 6.0
____________ TestColumnAstype.test_astype_float_string_conversions _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:718: in test_astype_float_string_conversions
    assert "3.14" in rows[0]["double_str"] or "3.14159" in rows[0]["double_str"]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: argument of type 'NoneType' is not iterable
________________ TestInferSchemaParity.test_csv_with_only_zeros ________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:1462: in test_csv_with_only_zeros
    assert isinstance(field_dict["int_val"], LongType), (
E   AssertionError: int_val should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
___________ TestArrayParameterFormats.test_array_with_string_columns ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:34: in test_array_with_string_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestWithField.test_withfield_combined_with_filter _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:828: in test_withfield_combined_with_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnOrderingNulls.test_complex_ordering_scenario ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:685: in test_complex_ordering_scenario
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____________ TestCreateMap.test_create_map_large_number_of_pairs ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:368: in test_create_map_large_number_of_pairs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestColumnOrderingNulls.test_ordering_with_duplicate_values __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:714: in test_ordering_with_duplicate_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________ TestColumnAstype.test_astype_after_when_otherwise _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:812: in test_astype_after_when_otherwise
    assert rows[0]["doubled_str"] in ["2", "2.0"]
E   AssertionError: assert None in ['2', '2.0']
_____________ TestStringArithmetic.test_string_modulo_with_numeric _____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: '%'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_string_arithmetic.py:140: in test_string_modulo_with_numeric
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(string_1 % 3)' not found. Available columns: [string_1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestArrayParameterFormats.test_array_with_list_of_strings ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:49: in test_array_with_list_of_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestWithField.test_withfield_combined_with_select _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:867: in test_withfield_combined_with_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, other_col, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnOrderingNulls.test_ordering_with_identical_nulls __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:743: in test_ordering_with_identical_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
________________ TestCreateMap.test_create_map_empty_in_select _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:381: in test_create_map_empty_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'empty_map' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnAstype.test_astype_substring_date_pyspark_parity __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:127: in serialize_expression
    left = serialize_expression(col_side) if col_side is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_astype.py:830: in test_astype_substring_date_pyspark_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'final_date' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestArrayParameterFormats.test_array_with_column_objects ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:64: in test_array_with_column_objects
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnOrderingNulls.test_mixed_data_types_ordering ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:783: in test_mixed_data_types_ordering
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____________________ TestColumnAstype.test_astype_long_type ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:854: in test_astype_long_type
    assert rows[0]["as_long"] == 1
E   assert None == 1
________________ TestWithField.test_withfield_all_null_structs _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:912: in test_withfield_all_null_structs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestColumnOrderingParity.test_pyspark_desc_nulls_last_parity _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:816: in test_pyspark_desc_nulls_last_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
________ TestCreateMap.test_create_map_empty_with_different_data_types _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:393: in test_create_map_empty_with_different_data_types
    assert result1.collect()[0]["meta"] == {}
           ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestColumnAstype.test_astype_string_type_aliases _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_astype.py:872: in test_astype_string_type_aliases
    assert rows[0]["as_string"] == "123"
E   AssertionError: assert None == '123'
_______ TestArrayParameterFormats.test_array_with_list_of_column_objects _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:79: in test_array_with_list_of_column_objects
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestCreateMap.test_create_map_empty_after_filter _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:423: in test_create_map_empty_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestWithField.test_withfield_empty_dataframe _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:937: in test_withfield_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestColumnOrderingParity.test_pyspark_desc_nulls_first_parity _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:853: in test_pyspark_desc_nulls_first_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________ TestUDFBasicOperations.test_udf_string_return_type ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:22: in test_udf_string_return_type
    result = df.withColumn("upper_text", upper_udf(F.col("text"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestArrayParameterFormats.test_array_all_formats_together ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:99: in test_array_all_formats_together
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestCreateMap.test_create_map_empty_in_groupby_context ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:441: in test_create_map_empty_in_groupby_context
    result = df_with_map.groupBy("dept").agg(F.count("name").alias("count"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestColumnOrderingParity.test_pyspark_asc_nulls_last_parity __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:884: in test_pyspark_asc_nulls_last_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________ TestWithField.test_withfield_reference_other_struct_field ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:977: in test_withfield_reference_other_struct_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestInferSchemaParity.test_csv_with_hex_strings ________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:1857: in test_csv_with_hex_strings
    assert isinstance(field_dict["value"], LongType), "value should be LongType"
E   AssertionError: value should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
____________ TestStringArithmetic.test_string_arithmetic_in_select _____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_string_arithmetic.py:426: in test_string_arithmetic_in_select
    assert rows[0]["result"] == 2.0
E   assert None == 2.0
____________ TestArrayParameterFormats.test_array_with_mixed_types _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:124: in test_array_with_mixed_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(name, age, active)' not found. Available columns: [active, age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestUDFBasicOperations.test_udf_integer_return_type ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:37: in test_udf_integer_return_type
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestColumnOrderingParity.test_pyspark_asc_nulls_first_parity _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:909: in test_pyspark_asc_nulls_first_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________ TestInferSchemaParity.test_csv_with_numeric_string_prefixes __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:1946: in test_csv_with_numeric_string_prefixes
    assert isinstance(field_dict["id"], LongType), "id should be LongType"
E   AssertionError: id should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
_________________ TestCreateMap.test_create_map_empty_in_join __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:457: in test_create_map_empty_in_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestWithField.test_withfield_with_string_functions ______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1008: in test_withfield_with_string_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(upper_id, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnOrderingParity.test_pyspark_multi_column_parity ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:941: in test_pyspark_multi_column_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________________ TestColumnSubstr.test_basic_substr ______________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:49: in test_basic_substr
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial_name' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestUDFBasicOperations.test_udf_double_return_type ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:52: in test_udf_double_return_type
    result = df.withColumn("doubled", double_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestCreateMap.test_create_map_empty_with_window_functions ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:479: in test_create_map_empty_with_window_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestArrayParameterFormats.test_array_with_single_column ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'array' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:139: in test_array_with_single_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(Name)' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestCreateMap.test_create_map_empty_in_nested_expressions ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'sparkless.functions.conditional.CaseWhen'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:495: in test_create_map_empty_in_nested_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'val > 5' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestStringArithmetic.test_string_arithmetic_with_when_otherwise ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_string_arithmetic.py:489: in test_string_arithmetic_with_when_otherwise
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(string_1 / 5) > 3' not found. Available columns: [string_1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestStringArithmetic.test_string_arithmetic_chained_with_cast _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_string_arithmetic.py:507: in test_string_arithmetic_chained_with_cast
    assert rows[0]["result"] == 5  # 10.5 / 2 = 5.25, cast to int = 5
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 5
___________ TestArrayParameterFormats.test_array_with_three_columns ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:154: in test_array_with_three_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestWithField.test_withfield_chained_multiple_times ______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1037: in test_withfield_chained_multiple_times
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(field1, ...).withField(field2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestColumnSubstr.test_substr_from_second_position _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:69: in test_substr_from_second_position
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'from_second' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestColumnSubstr.test_substr_issue_238_example ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:88: in test_substr_issue_238_example
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestCreateMap.test_create_map_empty_with_null_handling ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:509: in test_create_map_empty_with_null_handling
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestInferSchemaParity.test_csv_with_very_small_floats _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2137: in test_csv_with_very_small_floats
    assert isinstance(df_inferred.schema.fields[0].dataType, DoubleType), (
E   AssertionError: Should be DoubleType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
E    +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
____________ TestInferSchemaParity.test_csv_with_very_large_floats _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2183: in test_csv_with_very_large_floats
    assert isinstance(df_inferred.schema.fields[0].dataType, DoubleType), (
E   AssertionError: Should be DoubleType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
E    +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
_____________ TestInferSchemaParity.test_csv_with_all_float_zeros ______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2229: in test_csv_with_all_float_zeros
    assert isinstance(df_inferred.schema.fields[0].dataType, DoubleType), (
E   AssertionError: Should be DoubleType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
E    +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
_____________ TestUDFBasicOperations.test_udf_boolean_return_type ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:67: in test_udf_boolean_return_type
    result = df.withColumn("is_adult", is_adult_udf(F.col("age"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(age)' not found. Available columns: [age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestWithField.test_withfield_with_arithmetic_operations ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1068: in test_withfield_with_arithmetic_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(product, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestWithField.test_withfield_preserves_all_existing_fields __________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1105: in test_withfield_preserves_all_existing_fields
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(field2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestWithField.test_withfield_nested_struct_field_access ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1166: in test_withfield_nested_struct_field_access
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(computed_from_nested, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestUDFMultiArgument.test_udf_two_arguments __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:96: in test_udf_two_arguments
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(first)' not found. Available columns: [first, second]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___ TestStringArithmetic.test_string_arithmetic_all_operations_comprehensive ___
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: '%'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_string_arithmetic.py:528: in test_string_arithmetic_all_operations_comprehensive
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(string_1 % 5)' not found. Available columns: [string_1, add, sub, mul, div]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestUDFMultiArgument.test_udf_three_arguments _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:120: in test_udf_three_arguments
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(a)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestIssue230CaseInsensitiveColumnMatching.test_filter_case_insensitive ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_issues_225_231.py:558: in test_filter_case_insensitive
    result = df.filter(F.col("name") == "Alice").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'Alice' not found. Available columns: [Age, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestArrayParameterFormats.test_array_with_computed_columns __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:167: in test_array_with_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array((a + b), (a * b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestInferSchemaParity.test_csv_with_all_integer_zeros _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2275: in test_csv_with_all_integer_zeros
    assert isinstance(df_inferred.schema.fields[0].dataType, LongType), (
E   AssertionError: Should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
E    +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
________ TestColumnOrderingParity.test_pyspark_integer_ordering_parity _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:976: in test_pyspark_integer_ordering_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________ TestStringArithmetic.test_string_arithmetic_with_orderby ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_string_arithmetic.py:628: in test_string_arithmetic_with_orderby
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________ TestColumnOrderingParity.test_pyspark_float_ordering_parity __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_column_ordering.py:1000: in test_pyspark_float_ordering_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________________ TestUDFMultiArgument.test_udf_mixed_types ___________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:146: in test_udf_mixed_types
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestCreateMap.test_create_map_empty_multiple_times ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:524: in test_create_map_empty_multiple_times
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map1' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestColumnSubstr.test_substr_start_at_one ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:106: in test_substr_start_at_one
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'first_three' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestUDFInDifferentOperations.test_udf_in_select ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:169: in test_udf_in_select
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestColumnSubstr.test_substr_start_beyond_length _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:124: in test_substr_start_beyond_length
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'beyond' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestColumnSubstr.test_substr_with_null ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:144: in test_substr_with_null
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestCreateMap.test_create_map_empty_with_computed_columns ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:541: in test_create_map_empty_with_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'sum' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestCreateMap.test_create_map_empty_in_union _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:556: in test_create_map_empty_in_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestWithField.test_withfield_nested_struct_string_expression _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1227: in test_withfield_nested_struct_string_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(combined_string, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestWithField.test_withfield_multiple_nested_structs _____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1282: in test_withfield_multiple_nested_structs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(combined, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestCreateMap.test_create_map_empty_preserves_type ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:573: in test_create_map_empty_preserves_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestArrayParameterFormats.test_array_with_list_of_computed_columns ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:178: in test_array_with_list_of_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array((a + b), (a - b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestColumnSubstr.test_substr_length_zero ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:162: in test_substr_length_zero
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'empty' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestWithField.test_withfield_very_deeply_nested_struct ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1362: in test_withfield_very_deeply_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(from_deep_nest, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestWithField.test_withfield_nested_struct_with_null _____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1418: in test_withfield_nested_struct_with_null
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestCreateMap.test_create_map_empty_tuple_returns_empty_map __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:582: in test_create_map_empty_tuple_returns_empty_map
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestUDFInDifferentOperations.test_udf_in_withColumn ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:183: in test_udf_in_withColumn
    result = df.withColumn("name_upper", upper_udf(F.col("name"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestCreateMap.test_create_map_empty_list_in_select ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:591: in test_create_map_empty_list_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'empty_map' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestInferSchemaParity.test_csv_with_all_false_booleans ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2321: in test_csv_with_all_false_booleans
    assert isinstance(df_inferred.schema.fields[0].dataType, BooleanType), (
E   AssertionError: Should be BooleanType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), BooleanType)
E    +    where StringType(nullable=True) = StructField(name='flag', dataType=StringType(nullable=True), nullable=True).dataType
____________ TestColumnSubstr.test_substr_length_exceeds_remaining _____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:178: in test_substr_length_exceeds_remaining
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'long' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestJoinTypeCoercion.test_join_int64_with_string _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:51: in test_join_int64_with_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
_______________ TestUDFInDifferentOperations.test_udf_in_filter ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/functions/test_udf_comprehensive.py:204: in test_udf_in_filter
    result = df.filter(is_adult_udf(F.col("age"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______________ TestJoinTypeCoercion.test_join_string_with_int64 _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:89: in test_join_string_with_int64
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: str on left does not match `key`: i64 on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
____________________ TestColumnSubstr.test_substr_in_select ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:202: in test_substr_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'first_two' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestUDFInDifferentOperations.test_udf_in_groupBy_aggregation _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:229: in test_udf_in_groupBy_aggregation
    .agg(F.sum("value_doubled").alias("total_doubled"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [category, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestInferSchemaParity.test_csv_with_all_true_booleans _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2367: in test_csv_with_all_true_booleans
    assert isinstance(df_inferred.schema.fields[0].dataType, BooleanType), (
E   AssertionError: Should be BooleanType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), BooleanType)
E    +    where StringType(nullable=True) = StructField(name='flag', dataType=StringType(nullable=True), nullable=True).dataType
_________________ TestUDFNullHandling.test_udf_with_null_input _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:259: in test_udf_with_null_input
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestArrayParameterFormats.test_array_with_null_values _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:202: in test_array_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(name, age)' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestArrayParameterFormats.test_array_with_all_null_columns __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:226: in test_array_with_all_null_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(val1, val2)' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestArrayParameterFormats.test_array_with_numeric_types ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:244: in test_array_with_numeric_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(int_val, float_val, long_val)' not found. Available columns: [float_val, int_val, long_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestArrayParameterFormats.test_array_with_boolean_types ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:256: in test_array_with_boolean_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(flag1, flag2)' not found. Available columns: [flag1, flag2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestArrayParameterFormats.test_array_with_mixed_types_comprehensive ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:282: in test_array_with_mixed_types_comprehensive
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(str_val, int_val, float_val, bool_val)' not found. Available columns: [bool_val, float_val, int_val, str_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestArrayParameterFormats.test_array_in_select_statement ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:297: in test_array_in_select_statement
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'format1' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestArrayParameterFormats.test_array_after_filter _______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:316: in test_array_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(a, b)' not found. Available columns: [a, b, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestJoinTypeCoercion.test_join_int32_with_string _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:129: in test_join_int32_with_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
_______________ TestJoinTypeCoercion.test_join_float_with_string _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:165: in test_join_float_with_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
___________ TestArrayParameterFormats.test_array_in_groupby_context ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:333: in test_array_in_groupby_context
    result = df_with_array.groupBy("dept").agg(F.count("name").alias("count"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(name, age)' not found. Available columns: [age, dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestCreateMap.test_create_map_empty_list_with_different_data_types ______
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:600: in test_create_map_empty_list_with_different_data_types
    assert df1.withColumn("meta", F.create_map([])).collect()[0]["meta"] == {}
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestArrayParameterFormats.test_array_in_join _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:348: in test_array_in_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(name)' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestIssue230CaseInsensitiveColumnMatching.test_join_case_insensitive _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/test_issues_225_231.py:694: in test_join_case_insensitive
    result = result_df.collect()
             ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: ID
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
________________ TestUDFNullHandling.test_udf_with_null_return _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:277: in test_udf_with_null_return
    result = df.withColumn("result", safe_divide_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestInferSchemaParity.test_csv_with_numeric_string_suffixes __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2453: in test_csv_with_numeric_string_suffixes
    assert isinstance(field_dict["id"], LongType), "id should be LongType"
E   AssertionError: id should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
__________________ TestUDFEdgeCases.test_udf_empty_dataframe ___________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:300: in test_udf_empty_dataframe
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value, upper]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestWithField.test_withfield_nested_struct_arithmetic _____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1470: in test_withfield_nested_struct_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(nested_product, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestCreateMap.test_create_map_empty_list_after_filter _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:627: in test_create_map_empty_list_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestCreateMap.test_create_map_empty_list_and_create_map_equivalent ______
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:641: in test_create_map_empty_list_and_create_map_equivalent
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map_no_args' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestInferSchemaParity.test_csv_with_mixed_numeric_formats ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2501: in test_csv_with_mixed_numeric_formats
    assert isinstance(df_inferred.schema.fields[0].dataType, DoubleType), (
E   AssertionError: Should be DoubleType (mixed numeric formats)
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
E    +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
_______________ TestInferSchemaParity.test_csv_with_only_one_row _______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2697: in test_csv_with_only_one_row
    assert isinstance(field_dict["age"], LongType), "age should be LongType"
E   AssertionError: age should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
_______________ TestInferSchemaParity.test_csv_with_many_columns _______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2748: in test_csv_with_many_columns
    assert isinstance(field.dataType, LongType), (
E   AssertionError: col_0 should be LongType
E   assert False
E    +  where False = isinstance(StringType(nullable=True), LongType)
E    +    where StringType(nullable=True) = StructField(name='col_0', dataType=StringType(nullable=True), nullable=True).dataType
_______________ TestJoinTypeCoercion.test_join_int32_with_int64 ________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_join_type_coercion.py:205: in test_join_int32_with_int64
    assert (1234, "A", "X") in values
E   AssertionError: assert (1234, 'A', 'X') in {(1234, 'A', None), (4567, 'B', None)}
__________ TestArrayParameterFormats.test_array_with_window_functions __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:369: in test_array_with_window_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(value)' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestWithField.test_withfield_nested_struct_conditional ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1518: in test_withfield_nested_struct_conditional
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(nested_status, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestWithField.test_withfield_nested_struct_with_outer_column _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1567: in test_withfield_nested_struct_with_outer_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(combined, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestColumnSubstr.test_substr_in_withColumn __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:224: in test_substr_in_withColumn
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ TestUDFEdgeCases.test_udf_single_row _____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:313: in test_udf_single_row
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestWithField.test_withfield_nested_struct_chained_operations _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1636: in test_withfield_nested_struct_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(field1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestColumnSubstr.test_substr_in_filter ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:112: in _convert_payload
    return {"condition": _expr_to_robin(condition)}
                         ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:244: in test_substr_in_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:890: in materialize
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestColumnSubstr.test_substr_in_orderBy ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_column_substr.py:263: in test_substr_in_orderBy
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______ TestArrayParameterFormats.test_array_with_large_number_of_columns _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:385: in test_array_with_large_number_of_columns
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(col_0, col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9)' not found. Available columns: [col_0, col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestUDFEdgeCases.test_udf_large_dataframe ___________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:328: in test_udf_large_dataframe
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestJoinTypeCoercion.test_join_with_left_on_right_on _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_join_type_coercion.py:228: in test_join_with_left_on_right_on
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______ TestJoinTypeCoercion.test_join_multiple_keys_with_type_mismatch ________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:253: in test_join_multiple_keys_with_type_mismatch
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key1`: i64 on left does not match `key1`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key1", "key2", "value_right"]; PROJECT */3 COLUMNS; SELECTION: None
___________ TestCreateMap.test_create_map_empty_list_multiple_times ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:657: in test_create_map_empty_list_multiple_times
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map1' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestCreateMap.test_create_map_empty_list_in_union _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:670: in test_create_map_empty_list_in_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestWithField.test_withfield_nested_struct_reference_other_nested _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_withfield.py:1689: in test_withfield_nested_struct_reference_other_nested
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_struct.withField(nested_sum, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestArrayParameterFormats.test_array_with_computed_expressions ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:400: in test_array_with_computed_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(val, (val * 2))' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestArrayParameterFormats.test_array_with_nested_expressions _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:422: in test_array_with_nested_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(((a + b) * 2), (a - b), (a * b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestUDFEdgeCases.test_udf_empty_string ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:344: in test_udf_empty_string
    result = df.withColumn("length", length_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestInferSchemaParity.test_csv_type_promotion_int_to_float __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_inferschema_parity.py:2796: in test_csv_type_promotion_int_to_float
    assert isinstance(df_inferred.schema.fields[0].dataType, DoubleType), (
E   AssertionError: Should be DoubleType (mixed int/float)
E   assert False
E    +  where False = isinstance(StringType(nullable=True), DoubleType)
E    +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
_________ TestJoinTypeCoercion.test_join_type_coercion_parity_pyspark __________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:283: in test_join_type_coercion_parity_pyspark
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
________________ TestCreateMap.test_create_map_empty_list_show _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:679: in test_create_map_empty_list_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestArrayParameterFormats.test_array_in_union _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'array' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:439: in test_array_in_union
    rows1 = df1_with_array.collect()
            ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(val)' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ TestUDFEdgeCases.test_udf_zero_value _____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:359: in test_udf_zero_value
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnSubstr.test_substr_equals_substring_function ____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:284: in test_substr_equals_substring_function
    rows_substr = result_substr.collect()
                  ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestColumnSubstr.test_substr_chained_operations ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:304: in test_substr_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestWindowFunctionArithmetic.test_window_function_multiply __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:41: in test_window_function_multiply
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'percentile' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestColumnSubstr.test_substr_empty_string ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:322: in test_substr_empty_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestArrayParameterFormats.test_array_with_special_characters_in_column_names _
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:461: in test_array_with_special_characters_in_column_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(col-name, col_name)' not found. Available columns: [col-name, col_name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestJoinTypeCoercion.test_join_left_outer_with_type_mismatch _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:340: in test_join_left_outer_with_type_mismatch
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
________ TestCreateMap.test_create_map_empty_list_with_computed_columns ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:694: in test_create_map_empty_list_with_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'sum' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestUDFComplexScenarios.test_udf_chained_operations ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:383: in test_udf_chained_operations
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestJoinTypeCoercionParity.test_pyspark_parity_int64_string_inner _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:372: in test_pyspark_parity_int64_string_inner
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
_____________________ TestColumnSubstr.test_substr_unicode _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:340: in test_substr_unicode
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestWindowFunctionArithmetic.test_window_function_rmul ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:64: in test_window_function_rmul
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'percentile' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestCreateMap.test_create_map_empty_list_in_join _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_create_map.py:705: in test_create_map_empty_list_in_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'map()' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestArrayParameterFormats.test_array_preserves_order _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:472: in test_array_preserves_order
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestColumnSubstr.test_substr_negative_start __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:369: in test_substr_negative_start
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestWindowFunctionArithmetic.test_window_function_add _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:80: in test_window_function_add
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_plus_10' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestUDFComplexScenarios.test_udf_with_literal _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:405: in test_udf_with_literal
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestUDFComplexScenarios.test_udf_multiple_columns_same_udf __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:421: in test_udf_multiple_columns_same_udf
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(first)' not found. Available columns: [first, second]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestUDFComplexScenarios.test_udf_in_orderBy __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:445: in test_udf_in_orderBy
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(age)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestJoinTypeCoercionParity.test_pyspark_parity_string_int64_inner _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:398: in test_pyspark_parity_string_int64_inner
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: str on left does not match `key`: i64 on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
____ TestArrayTypeRobust.test_array_type_elementtype_with_select_operation _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'size' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/spark_types/test_array_type_robust.py:273: in test_array_type_elementtype_with_select_operation
    rows2 = result2.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'size' not found. Available columns: [values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestArrayParameterFormats.test_array_with_empty_strings ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:482: in test_array_with_empty_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(val1, val2)' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestArrayTypeRobust.test_array_type_elementtype_with_filter_operation _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/spark_types/test_array_type_robust.py:296: in test_array_type_elementtype_with_filter_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________________ TestColumnSubstr.test_substr_zero_start ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:383: in test_substr_zero_start
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestArrayParameterFormats.test_array_with_zero_and_negative_numbers ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:491: in test_array_with_zero_and_negative_numbers
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestJoinTypeCoercionParity.test_pyspark_parity_all_join_types _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:444: in test_pyspark_parity_all_join_types
    inner_rows = inner.collect()
                 ^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "right_val"]; PROJECT */2 COLUMNS; SELECTION: None
____________ TestWindowFunctionArithmetic.test_window_function_radd ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:97: in test_window_function_radd
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'hundred_plus_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestArrayTypeRobust.test_array_type_elementtype_with_explode_operation ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'explode' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/spark_types/test_array_type_robust.py:320: in test_array_type_elementtype_with_explode_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'value' not found. Available columns: [id, values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestWindowFunctionArithmetic.test_window_function_subtract __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:113: in test_window_function_subtract
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'zero_indexed' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestColumnSubstr.test_substr_with_alias ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:400: in test_substr_with_alias
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'first_two_chars' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestUDFWithDifferentDataTypes.test_udf_with_long_type _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:466: in test_udf_with_long_type
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestArrayParameterFormats.test_array_all_formats_with_mixed_types _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/test_array_parameter_formats.py:515: in test_array_all_formats_with_mixed_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'array(name, age, active, score)' not found. Available columns: [active, age, name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__ TestArrayTypeRobust.test_array_type_elementtype_with_withcolumn_operation ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'size' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/spark_types/test_array_type_robust.py:341: in test_array_type_elementtype_with_withcolumn_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'size(values)' not found. Available columns: [id, values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestJoinTypeCoercionParity.test_pyspark_parity_double_precision_string ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:560: in test_pyspark_parity_double_precision_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
______ TestJoinTypeCoercionParity.test_pyspark_parity_int_float_coercion _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:590: in test_pyspark_parity_int_float_coercion
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: f64 on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
____________ TestWindowFunctionArithmetic.test_window_function_rsub ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:89: in _expr_to_robin
    robin_right = _expr_to_robin(right) if right is not None else None
                  ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:131: in test_window_function_rsub
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'ten_minus_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnSubstr.test_substr_pyspark_parity_comprehensive ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:443: in test_substr_pyspark_parity_comprehensive
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'result' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestLogicalPlanPhase4.test_groupBy_via_plan_interpreter ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_logical_plan.py:360: in test_groupBy_via_plan_interpreter
    from sparkless.backend.polars.plan_interpreter import execute_plan
sparkless/backend/polars/__init__.py:19: in <module>
    from .storage import PolarsStorageManager, PolarsTable, PolarsSchema
sparkless/backend/polars/storage.py:11: in <module>
    import polars as pl
E   ModuleNotFoundError: No module named 'polars'
____________ TestUDFWithDifferentDataTypes.test_udf_with_float_type ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:484: in test_udf_with_float_type
    result = df.withColumn("doubled", double_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestWindowFunctionArithmetic.test_window_function_divide ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:149: in test_window_function_divide
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_half' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___ TestJoinTypeCoercionParity.test_pyspark_parity_null_values_in_join_keys ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:620: in test_pyspark_parity_null_values_in_join_keys
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
___________________ TestColumnSubstr.test_substr_in_groupBy ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:469: in test_substr_in_groupBy
    result = df_with_first_char.groupBy("first_char").agg(
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestLogicalPlanPhase4.test_plan_interpreter_cast_between_power ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_logical_plan.py:394: in test_plan_interpreter_cast_between_power
    from sparkless.backend.polars.plan_interpreter import execute_plan
sparkless/backend/polars/__init__.py:19: in <module>
    from .storage import PolarsStorageManager, PolarsTable, PolarsSchema
sparkless/backend/polars/storage.py:11: in <module>
    import polars as pl
E   ModuleNotFoundError: No module named 'polars'
____________ TestCaseWhenCast.test_casewhen_cast_to_long_issue_243 _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:56: in test_casewhen_cast_to_long_issue_243
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110ef2010> ELSE <sparkless.functions.core.literals.Literal object at 0x110ef1490> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestLogicalPlanPhase4.test_plan_interpreter_window_row_number _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_logical_plan.py:454: in test_plan_interpreter_window_row_number
    from sparkless.backend.polars.plan_interpreter import execute_plan
sparkless/backend/polars/__init__.py:19: in <module>
    from .storage import PolarsStorageManager, PolarsTable, PolarsSchema
sparkless/backend/polars/storage.py:11: in <module>
    import polars as pl
E   ModuleNotFoundError: No module named 'polars'
_________________ TestUDFCustomName.test_udf_with_custom_name __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:505: in test_udf_with_custom_name
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'my_upper' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestJoinTypeCoercionParity.test_pyspark_parity_invalid_numeric_strings ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:646: in test_pyspark_parity_invalid_numeric_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
____________ TestWindowFunctionArithmetic.test_window_function_rdiv ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:89: in _expr_to_robin
    robin_right = _expr_to_robin(right) if right is not None else None
                  ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:168: in test_window_function_rdiv
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'twelve_div_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestCaseWhenCast.test_casewhen_cast_to_string _________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:90: in test_casewhen_cast_to_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b56bd0> ELSE <sparkless.functions.core.literals.Literal object at 0x110b54bd0> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestUDFRegression279.test_udf_with_withColumn_regression_279 _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_comprehensive.py:529: in test_udf_with_withColumn_regression_279
    rows = df2.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnSubstr.test_substr_chained_with_other_operations __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:127: in serialize_expression
    left = serialize_expression(col_side) if col_side is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:493: in test_substr_chained_with_other_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'upper_partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestCaseWhenCast.test_casewhen_cast_to_int __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:122: in test_casewhen_cast_to_int
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x1109b3e50> ELSE <sparkless.functions.core.literals.Literal object at 0x1109b1490> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestJoinTypeCoercionParity.test_pyspark_parity_multiple_keys_complex _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:671: in test_pyspark_parity_multiple_keys_complex
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key1`: i64 on left does not match `key1`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key1", "key2", "other"]; PROJECT */3 COLUMNS; SELECTION: None
___________ TestWindowFunctionArithmetic.test_window_function_negate ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:89: in _expr_to_robin
    robin_right = _expr_to_robin(right) if right is not None else None
                  ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:186: in test_window_function_negate
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'neg_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestJoinTypeCoercionParity.test_pyspark_parity_left_on_right_on_different_names _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_join_type_coercion.py:717: in test_pyspark_parity_left_on_right_on_different_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
________________ TestColumnSubstr.test_substr_very_long_string _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:511: in test_substr_very_long_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'first_100' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestWindowFunctionArithmetic.test_window_function_chained_operations _____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:209: in test_window_function_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'score' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestCaseWhenCast.test_casewhen_cast_to_double _________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:145: in test_casewhen_cast_to_double
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b56390> ELSE <sparkless.functions.core.literals.Literal object at 0x110b54a50> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestWindowFunctionArithmetic.test_dense_rank_with_arithmetic _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:234: in test_dense_rank_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'rank_score' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestJoinTypeCoercionParity.test_pyspark_parity_mixed_numeric_strings _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:749: in test_pyspark_parity_mixed_numeric_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
______________ TestColumnSubstr.test_substr_start_exceeds_length _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:527: in test_substr_start_exceeds_length
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'beyond' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestCaseWhenCast.test_casewhen_cast_with_multiple_when ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:179: in test_casewhen_cast_with_multiple_when
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'CASE WHEN ((value == 1)) THEN low ELSE high END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestComplexMergeBasic.test_merge_with_matched_condition ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_complex_merge.py:56: in test_merge_with_matched_condition
    result = spark.sql("SELECT * FROM test_db.target ORDER BY id").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____________ TestWindowFunctionArithmetic.test_rank_with_arithmetic ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:262: in test_rank_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'rank_times_5' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestComplexMergeBasic.test_merge_multiple_when_matched ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_complex_merge.py:97: in test_merge_multiple_when_matched
    result = spark.sql("SELECT * FROM test_db.target2 ORDER BY id").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__ TestJoinTypeCoercionParity.test_pyspark_parity_scientific_notation_strings __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:767: in test_pyspark_parity_scientific_notation_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
__________ TestColumnSubstr.test_substr_negative_start_exceeds_length __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_column_substr.py:545: in test_substr_negative_start_exceeds_length
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'result' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestCaseWhenCast.test_casewhen_cast_with_null_values _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:202: in test_casewhen_cast_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b55f10> ELSE <sparkless.functions.core.literals.Literal object at 0x110b55310> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________________ TestNaFill.test_na_fill_after_join ______________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/dataframe/test_na_fill.py:166: in test_na_fill_after_join
    assert row2["value_right"] == 2
E   assert 0 == 2
______ TestIssue355DiamondDependency.test_unionByName_diamond_dependency _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_issue_355.py:47: in test_unionByName_diamond_dependency
    combined = branch_a.unionByName(branch_b, allowMissingColumns=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:420: in unionByName
    return self._joins.unionByName(other, allowMissingColumns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/join_service.py:280: in unionByName
    self_materialized = LazyEvaluationEngine.materialize(self._df)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
________________ TestCaseWhenCast.test_casewhen_cast_in_select _________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:127: in serialize_expression
    left = serialize_expression(col_side) if col_side is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'sparkless.functions.conditional.CaseWhen'>

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:224: in test_casewhen_cast_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'result' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___ TestJoinTypeCoercionParity.test_pyspark_parity_whitespace_in_string_keys ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:142: in _convert_payload
    raise ValueError(f"Operation '{op_name}' is not yet supported for Robin plans")
E   ValueError: Operation 'join' is not yet supported for Robin plans

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_join_type_coercion.py:786: in test_pyspark_parity_whitespace_in_string_keys
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1031: in materialize
    df = df.join(other_robin_df, on=on_arg, how=how_str)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
_____ TestMergeNotMatchedBySource.test_merge_delete_not_matched_by_source ______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_complex_merge.py:161: in test_merge_delete_not_matched_by_source
    result = spark.sql("SELECT * FROM test_db.target3 ORDER BY id").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________ TestWindowFunctionArithmetic.test_ntile_with_arithmetic ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:286: in test_ntile_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'percentile_group' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestDescribeDetail.test_describe_detail_nonexistent_table ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/session/sql/executor.py:139: in execute
    return self._execute_describe(ast)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:2129: in _execute_describe
    raise AnalysisException(
E   sparkless.core.exceptions.analysis.AnalysisException: Table test_nonexistent_detail is not a Delta table. DESCRIBE DETAIL can only be used with Delta format tables.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_describe_detail.py:275: in test_describe_detail_nonexistent_table
    result = spark_with_delta.sql("DESCRIBE DETAIL test_nonexistent_detail")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:331: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:352: in _real_sql
    return self._sql_executor.execute(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:150: in execute
    raise QueryExecutionException(f"Failed to execute query: {str(e)}")
E   sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Table test_nonexistent_detail is not a Delta table. DESCRIBE DETAIL can only be used with Delta format tables.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_describe_detail.py:280: in test_describe_detail_nonexistent_table
    assert (
E   AssertionError: Expected table not found error, got: failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.
E   assert ('not found' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'does not exist' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'table or view' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'cannot be found' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.')
_ TestIssue355DiamondDependency.test_unionByName_diamond_dependency_with_filters _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:196: in execute_robin_plan
    expr = robin_expr_to_column(cond)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:76: in robin_expr_to_column
    left = robin_expr_to_column(left_d) if left_d is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: '%'

During handling of the above exception, another exception occurred:
tests/unit/test_issue_355.py:90: in test_unionByName_diamond_dependency_with_filters
    result = branch_a.unionByName(branch_b).orderBy("id").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:420: in unionByName
    return self._joins.unionByName(other, allowMissingColumns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/join_service.py:280: in unionByName
    self_materialized = LazyEvaluationEngine.materialize(self._df)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:890: in materialize
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(id % 2)' not found. Available columns: [id, name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestIssue189StringFunctionsRobust.test_translate_edge_cases __________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:37: in test_translate_edge_cases
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'm1' not found. Available columns: [s, t]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestWindowFunctionArithmetic.test_lag_with_arithmetic _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:89: in _expr_to_robin
    robin_right = _expr_to_robin(right) if right is not None else None
                  ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:311: in test_lag_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'diff' not found. Available columns: [date, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestWindowFunctionArithmetic.test_lead_with_arithmetic ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:337: in test_lead_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'diff' not found. Available columns: [date, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue355DiamondDependency.test_unionByName_diamond_dependency_nested_transformations _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_issue_355.py:228: in test_unionByName_diamond_dependency_nested_transformations
    assert row.result == row.id * 10 * 2, (
E   AssertionError: Expected result=20 for id=1, got None
E   assert None == ((1 * 10) * 2)
E    +  where None = Row(id=1, name=a, result=None).result
E    +  and   1 = Row(id=1, name=a, result=None).id
______ TestIssue189StringFunctionsRobust.test_substring_index_edge_cases _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:73: in test_substring_index_edge_cases
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'p2' not found. Available columns: [n, s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestCaseWhenCast.test_casewhen_cast_with_datatype_object ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:246: in test_casewhen_cast_with_datatype_object
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b56750> ELSE <sparkless.functions.core.literals.Literal object at 0x110b554d0> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestMergeInsertAll.test_merge_insert_all ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_complex_merge.py:288: in test_merge_insert_all
    result = spark.sql("SELECT * FROM test_db.target5 ORDER BY id").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________ TestWindowFunctionCast.test_window_function_cast_to_long ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:281: in test_window_function_cast_to_long
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________________________ test_cte_with_join ______________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_cte_robust.py:38: in test_cte_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________ TestWindowFunctionArithmetic.test_sum_window_with_arithmetic _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:368: in test_sum_window_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'running_sum_div_100' not found. Available columns: [amount, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue355DiamondDependency.test_unionByName_diamond_dependency_complex_expressions _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/test_issue_355.py:351: in test_unionByName_diamond_dependency_complex_expressions
    assert row.computed in [25, 5], (
E   AssertionError: Unexpected computed value None for id=1
E   assert None in [25, 5]
E    +  where None = Row(computed=None, id=1).computed
__ TestIssue189StringFunctionsRobust.test_levenshtein_nulls_and_empty_strings __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'levenshtein'

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:107: in test_levenshtein_nulls_and_empty_strings
    rows = df.select(F.levenshtein("a", "b").alias("d")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'd' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestWindowFunctionArithmetic.test_avg_window_with_arithmetic _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:395: in test_avg_window_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'double_avg' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestWindowFunctionCast.test_window_function_cast_to_string __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:312: in test_window_function_cast_to_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestMergeInsertAll.test_merge_insert_only_unmatched ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_complex_merge.py:318: in test_merge_insert_only_unmatched
    result = spark.sql("SELECT * FROM test_db.target6 ORDER BY id").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
________ TestIssue189StringFunctionsRobust.test_soundex_null_and_empty _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'soundex' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:116: in test_soundex_null_and_empty
    rows = df.select(F.soundex("s").alias("sx")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'sx' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestWindowFunctionCast.test_window_function_cast_to_double __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:343: in test_window_function_cast_to_double
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________________ test_cte_with_multiple_joins _________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/session/sql/executor.py:260: in _execute_select
    "DataFrame", df_renamed._materialize_if_lazy()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.

The above exception was the direct cause of the following exception:
sparkless/session/sql/executor.py:121: in execute
    return self._execute_select(ast)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:352: in _execute_select
    raise RuntimeError(f"Join execution failed: {e}") from e
E   RuntimeError: Join execution failed: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:88: in test_cte_with_multiple_joins
    result = spark.sql(
sparkless/session/core/session.py:331: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:352: in _real_sql
    return self._sql_executor.execute(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:150: in execute
    raise QueryExecutionException(f"Failed to execute query: {str(e)}")
E   sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Join execution failed: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_ TestWindowFunctionArithmetic.test_multiple_window_functions_with_arithmetic __
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:419: in test_multiple_window_functions_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_times_10' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestMergeEdgeCases.test_merge_no_matches ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_complex_merge.py:355: in test_merge_no_matches
    result = spark.sql("SELECT * FROM test_db.target7 ORDER BY id").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________ TestDateTruncRobust.test_date_trunc_timestamp_core_units ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'date_trunc'

During handling of the above exception, another exception occurred:
tests/unit/functions/test_date_trunc_robust.py:53: in test_date_trunc_timestamp_core_units
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'year_trunc' not found. Available columns: [ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestWindowFunctionArithmetic.test_window_arithmetic_with_nulls ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:445: in test_window_arithmetic_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_times_2' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestRobinUnsupportedRaises.test_unsupported_select_expression_raises _____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/backend/test_robin_unsupported_raises.py:41: in test_unsupported_select_expression_raises
    _trigger_collect_untyped(selected)
tests/unit/backend/test_robin_unsupported_raises.py:20: in _trigger_collect_untyped
    df.collect()  # type: ignore[attr-defined]
    ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________________ test_cte_with_left_join ____________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_cte_robust.py:135: in test_cte_with_left_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______ TestIssue189StringFunctionsRobust.test_crc32_known_values_and_null ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'crc32' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:123: in test_crc32_known_values_and_null
    rows = df.select(F.crc32("s").alias("c")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'c' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestWindowFunctionCast.test_window_function_cast_with_partition ________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:375: in test_window_function_cast_with_partition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_number() OVER (WindowSpec(partitionBy(category), orderBy(value)))' not found. Available columns: [category, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________________ test_cte_with_where_clause __________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_cte_robust.py:175: in test_cte_with_where_clause
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________ TestWindowFunctionCast.test_window_function_cast_with_sum ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:402: in test_window_function_cast_with_sum
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'sum() OVER (WindowSpec(orderBy(id), rowsBetween(-9223372036854775808, 0)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestWindowFunctionArithmetic.test_complex_nested_arithmetic __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:473: in test_complex_nested_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'complex' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestRobinUnsupportedRaises.test_unsupported_raises_with_clear_message _____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/backend/test_robin_unsupported_raises.py:53: in test_unsupported_raises_with_clear_message
    _trigger_collect_untyped(selected)
tests/unit/backend/test_robin_unsupported_raises.py:20: in _trigger_collect_untyped
    df.collect()  # type: ignore[attr-defined]
    ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestIssue189StringFunctionsRobust.test_xxhash64_known_values_and_null _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'list'>

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:131: in test_xxhash64_known_values_and_null
    rows = df.select(F.xxhash64("s").alias("h")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'h' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestDateTruncRobust.test_date_trunc_on_date_column ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'date_trunc'

During handling of the above exception, another exception occurred:
tests/unit/functions/test_date_trunc_robust.py:106: in test_date_trunc_on_date_column
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'year_trunc' not found. Available columns: [d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ test_udf_with_withColumn_regression_279 ____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'udf' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_udf_regression_279.py:19: in test_udf_with_withColumn_regression_279
    rows = df2.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'udf(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ test_sql_like_simple_prefix_pattern ______________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_like_clause.py:10: in test_sql_like_simple_prefix_pattern
    names = sorted(row["name"] for row in result.collect())
                                          ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____________________ test_cte_with_aggregation_after_join _____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/session/sql/executor.py:121: in execute
    return self._execute_select(ast)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:748: in _execute_select
    df = cast("DataFrame", grouped.agg(*agg_exprs))
                           ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:210: in test_cte_with_aggregation_after_join
    result = spark.sql(
sparkless/session/core/session.py:331: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:352: in _real_sql
    return self._sql_executor.execute(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:150: in execute
    raise QueryExecutionException(f"Failed to execute query: {str(e)}")
E   sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_______ TestDateTruncPolarsBackend.test_date_trunc_month_on_date_column ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'to_date' requires both left and right

During handling of the above exception, another exception occurred:
tests/unit/functions/test_date_trunc_polars_backend.py:42: in test_date_trunc_month_on_date_column
    rows = df_truncated.collect()
           ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'to_date(d)' not found. Available columns: [d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestWindowFunctionArithmetic.test_window_arithmetic_in_filter _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:510: in test_window_arithmetic_in_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(percent_rank() OVER (WindowSpec(partitionBy(dept), orderBy(salary))) * 100)' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue189StringFunctionsRobust.test_get_json_object_missing_path_and_invalid_json _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'get_json_object'

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:150: in test_get_json_object_missing_path_and_invalid_json
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'a' not found. Available columns: [j]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ test_regexp_extract_all_basic_groups _____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/functions/test_regexp_extract_all_189.py:19: in test_regexp_extract_all_basic_groups
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestDateTruncRobust.test_date_trunc_preserves_nulls ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'date_trunc'

During handling of the above exception, another exception occurred:
tests/unit/functions/test_date_trunc_robust.py:131: in test_date_trunc_preserves_nulls
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'month_trunc' not found. Available columns: [ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestWindowFunctionCast.test_window_function_cast_in_select __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:121: in _convert_payload
    robin_cols.append(_expr_to_robin(col))
                      ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:88: in _expr_to_robin
    robin_left = _expr_to_robin(left) if left is not None else None
                 ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:422: in test_window_function_cast_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'rank' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________________ test_cte_with_self_join ____________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_cte_robust.py:255: in test_cte_with_self_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________________________ test_update_table_basic ____________________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/unit/session/test_sql_update.py:32: in test_update_table_basic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____ TestWindowFunctionCast.test_window_function_cast_with_datatype_object _____
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:443: in test_window_function_cast_with_datatype_object
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestWindowFunctionArithmetic.test_window_arithmetic_in_orderby ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:89: in _expr_to_robin
    robin_right = _expr_to_robin(right) if right is not None else None
                  ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'window'

During handling of the above exception, another exception occurred:
tests/unit/test_window_arithmetic.py:541: in test_window_arithmetic_in_orderby
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column '(-row_number() OVER (WindowSpec(orderBy(score))))' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue189StringFunctionsRobust.test_json_tuple_missing_fields_and_invalid_json _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:178: in test_json_tuple_missing_fields_and_invalid_json
    out = df.select(F.json_tuple("j", "name", "age")).collect()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'json_tuple(j, ...)' not found. Available columns: [j]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________________ test_create_table_as_select_basic _______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/session/sql/executor.py:125: in execute
    return self._execute_create(ast)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:1443: in _execute_create
    writer.mode("overwrite").saveAsTable(table_full_name)
sparkless/dataframe/writer.py:368: in saveAsTable
    data = df_to_write.collect()
           ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'IT' not found. Available columns: [age, dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_create_table_as_select.py:31: in test_create_table_as_select_basic
    spark.sql(
sparkless/session/core/session.py:331: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:352: in _real_sql
    return self._sql_executor.execute(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:150: in execute
    raise QueryExecutionException(f"Failed to execute query: {str(e)}")
E   sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: not found: Column 'IT' not found. Available columns: [age, dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue189StringFunctionsRobust.test_regexp_extract_all_multiple_matches_and_nulls _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/unit/functions/test_issue_189_string_functions_robust.py:217: in test_regexp_extract_all_multiple_matches_and_nulls
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.11.13-final-0 _______________

Name                                                                 Stmts   Miss  Cover   Missing
--------------------------------------------------------------------------------------------------
sparkless/__init__.py                                                   24      0   100%
sparkless/_version.py                                                    8      4    50%   10-12, 16-19
sparkless/backend/__init__.py                                            3      0   100%
sparkless/backend/factory.py                                            72     28    61%   45, 79, 105, 113-115, 135-157, 176, 190-191
sparkless/backend/polars/__init__.py                                     4      3    25%   20-23
sparkless/backend/polars/_over_compat.py                                19     19     0%   8-40
sparkless/backend/polars/executors/__init__.py                           1      1     0%   13
sparkless/backend/polars/export.py                                      36     36     0%   7-114
sparkless/backend/polars/expression_translator.py                     2172   2172     0%   8-5251
sparkless/backend/polars/materializer.py                               852    852     0%   8-1944
sparkless/backend/polars/operation_executor.py                        2047   2047     0%   1-4555
sparkless/backend/polars/parquet_storage.py                             41     41     0%   8-119
sparkless/backend/polars/plan_interpreter.py                           381    381     0%   8-531
sparkless/backend/polars/schema_registry.py                             73     73     0%   8-222
sparkless/backend/polars/schema_utils.py                                31     31     0%   3-69
sparkless/backend/polars/storage.py                                    350    346     1%   13-771
sparkless/backend/polars/translators/__init__.py                         1      1     0%   14
sparkless/backend/polars/translators/arithmetic_translator.py           17     17     0%   8-70
sparkless/backend/polars/translators/string_translator.py              145    145     0%   8-302
sparkless/backend/polars/translators/type_translator.py                107    107     0%   8-190
sparkless/backend/polars/type_mapper.py                                 99     99     0%   8-173
sparkless/backend/polars/window_handler.py                             290    290     0%   7-563
sparkless/backend/protocols.py                                          14      0   100%
sparkless/backend/robin/__init__.py                                      4      0   100%
sparkless/backend/robin/export.py                                       46     34    26%   20-29, 36, 41-50, 55-62, 71-77, 80-85
sparkless/backend/robin/materializer.py                                714    368    48%   44-45, 64, 75-79, 88-89, 108, 128, 141, 143-147, 152, 155, 172, 175-176, 182, 195, 209, 213, 225, 228-239, 247-249, 266, 273, 281-282, 287, 291, 295-302, 305, 308, 312-313, 317, 324-325, 330-331, 334, 342-343, 351-383, 388-692, 731, 741, 746, 750-753, 758-762, 766, 771, 776-777, 796, 847, 861-864, 873-874, 907-911, 919, 921-932, 943, 955-967, 971-983, 1018, 1024, 1029, 1043-1049, 1069
sparkless/backend/robin/plan_executor.py                               191     55    71%   18-19, 30-32, 43, 50, 55, 68-75, 84, 87-89, 92-97, 124, 127, 142, 160-163, 171-172, 186, 190, 195, 205, 215, 217, 221, 227, 229, 235, 240-244, 246-247, 258-260, 263
sparkless/backend/robin/storage.py                                      52      8    85%   27, 33, 39, 45, 62, 77, 88, 99
sparkless/compat/__init__.py                                             2      0   100%
sparkless/compat/datetime.py                                            74     53    28%   43, 55-57, 61-67, 73-81, 96-103, 115-122, 128-133, 141-146, 162-182
sparkless/config.py                                                     55     17    69%   46-58, 64-65, 69, 77-81, 90-91, 106
sparkless/core/__init__.py                                               9      0   100%
sparkless/core/column_resolver.py                                       33      0   100%
sparkless/core/condition_evaluator.py                                  764    730     4%   27-34, 49-56, 71-245, 260-541, 556-576, 591-604, 619-781, 795-1203, 1218-1229, 1245-1274, 1290-1311, 1324-1340, 1353, 1366-1370, 1384-1403
sparkless/core/data_validation.py                                       80     41    49%   56-85, 91-113, 129, 136-137, 177-185, 205-206, 220-221
sparkless/core/ddl_adapter.py                                           31     12    61%   93-106
sparkless/core/exceptions/__init__.py                                    6      0   100%
sparkless/core/exceptions/analysis.py                                  100     57    43%   51, 57, 91, 109, 142, 145-154, 170-202, 230-245, 269-272, 302-323
sparkless/core/exceptions/base.py                                       22      4    82%   31, 61, 76, 91
sparkless/core/exceptions/execution.py                                  29     12    59%   45, 63, 87-90, 114-117, 135, 153
sparkless/core/exceptions/operation.py                                  87     55    37%   24-34, 49-58, 72-82, 96-106, 120-129, 152, 173-183
sparkless/core/exceptions/py4j_compat.py                                10     10     0%   8-41
sparkless/core/exceptions/runtime.py                                    41     24    41%   53-57, 75, 101-107, 131-134, 158-161, 187-193
sparkless/core/exceptions/validation.py                                 44     25    43%   45, 63, 81, 107-111, 141-147, 171-174, 202-207
sparkless/core/interfaces/__init__.py                                    5      0   100%
sparkless/core/interfaces/dataframe.py                                 180     56    69%   20, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 98, 103, 110, 115, 120, 125, 130, 136, 142, 151, 156, 161, 166, 171, 176, 181, 190, 195, 200, 205, 212, 217, 222, 227, 232, 241, 246, 251, 256, 261, 266, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320
sparkless/core/interfaces/functions.py                                 186     56    70%   23, 28, 33, 42, 47, 56, 61, 70, 75, 84, 89, 94, 99, 108, 113, 118, 123, 130, 135, 144, 149, 154, 159, 164, 173, 178, 185, 192, 197, 202, 207, 212, 221, 226, 231, 236, 241, 250, 255, 263, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 333, 338, 343, 348
sparkless/core/interfaces/session.py                                   117     34    71%   20, 26, 32, 38, 44, 50, 59, 64, 69, 76, 81, 86, 96, 101, 106, 115, 120, 125, 136, 141, 146, 151, 156, 161, 166, 171, 176, 185, 190, 195, 200, 209, 214, 219
sparkless/core/interfaces/storage.py                                   126     38    70%   29, 34, 39, 44, 54, 59, 64, 69, 76, 83, 90, 97, 102, 106, 110, 114, 120, 126, 136, 142, 148, 153, 158, 163, 168, 173, 186, 192, 198, 204, 210, 215, 220, 229, 234, 239, 248, 253
sparkless/core/protocols.py                                             42      0   100%
sparkless/core/safe_evaluator.py                                       125     88    30%   45-50, 66-67, 86, 88, 90, 95, 97-103, 105-134, 145-147, 150-152, 157-164, 168-179, 184-215
sparkless/core/schema_inference.py                                     107     25    77%   73, 132, 199, 218-237, 242-251, 256-265, 279-280, 297, 307
sparkless/core/type_utils.py                                            86     56    35%   20-21, 91-93, 116-121, 140-144, 164-168, 187-199, 223-259, 278, 290-292, 304
sparkless/core/types/__init__.py                                         4      0   100%
sparkless/core/types/data_types.py                                     139     38    73%   22, 27, 32, 37, 42, 47, 52, 57, 66, 76, 81, 91, 97, 102, 111, 121, 127, 132, 141, 146, 155, 160, 170, 175, 180, 190, 196, 201, 206, 211, 221, 226, 231, 240, 249, 254, 259, 264
sparkless/core/types/metadata.py                                       166     47    72%   18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 73, 79, 85, 91, 97, 103, 108, 113, 118, 128, 134, 140, 145, 150, 160, 166, 172, 177, 182, 187, 197, 203, 209, 215, 220, 225, 230, 239, 244, 249, 254, 259, 268, 273, 278, 283, 288
sparkless/core/types/schema.py                                         121     36    70%   22, 28, 34, 40, 45, 50, 55, 60, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 185, 190, 195, 200, 209, 214, 221, 226
sparkless/data_generation/__init__.py                                    4      4     0%   8-12
sparkless/data_generation/builder.py                                    28     28     0%   8-85
sparkless/data_generation/convenience.py                                 9      9     0%   8-64
sparkless/data_generation/generator.py                                 174    174     0%   8-337
sparkless/dataframe/__init__.py                                          6      0   100%
sparkless/dataframe/aggregations/__init__.py                             2      2     0%   8-10
sparkless/dataframe/aggregations/operations.py                          75     75     0%   8-208
sparkless/dataframe/assertions/__init__.py                               3      3     0%   7-10
sparkless/dataframe/assertions/assertions.py                            26     26     0%   8-88
sparkless/dataframe/assertions/operations.py                            16     16     0%   8-45
sparkless/dataframe/attribute_handler.py                                62     28    55%   77-85, 116-125, 176, 190-196, 213-217, 223-224
sparkless/dataframe/casting/__init__.py                                  2      0   100%
sparkless/dataframe/casting/type_converter.py                           95     79    17%   44, 54, 56-153, 158-180
sparkless/dataframe/collection_handler.py                               29      9    69%   27-29, 36, 47-53, 81
sparkless/dataframe/condition_handler.py                                52     34    35%   58-64, 80, 109-122, 136-180
sparkless/dataframe/dataframe.py                                       513    182    65%   187-191, 219-224, 240-243, 262-265, 305, 317, 345, 377, 381, 394, 408, 424, 428, 432, 436, 440, 486, 490, 507-508, 524, 532, 555-561, 565, 569, 596-609, 621, 625, 630, 634, 638, 642, 700, 715, 719, 723, 742, 746, 750, 756, 760, 780, 791, 795, 799, 803, 809, 813, 817, 821, 829, 835, 839, 843, 847, 852, 856, 860, 864, 875, 894, 899, 932, 960-969, 997, 1002, 1021-1026, 1041-1052, 1062, 1078-1097, 1103, 1152-1153, 1161-1162, 1195, 1201-1206, 1210, 1216, 1225, 1250, 1258, 1269, 1284, 1292, 1303, 1311, 1323, 1329, 1335, 1347-1353, 1368-1379, 1383, 1403-1411, 1420-1460
sparkless/dataframe/display/__init__.py                                  3      3     0%   3-6
sparkless/dataframe/display/formatter.py                                37     37     0%   3-57
sparkless/dataframe/display/operations.py                              118    118     0%   8-274
sparkless/dataframe/evaluation/__init__.py                               2      0   100%
sparkless/dataframe/evaluation/evaluators/__init__.py                    1      0   100%
sparkless/dataframe/evaluation/evaluators/conditional_evaluator.py      22     15    32%   35-63
sparkless/dataframe/evaluation/expression_evaluator.py                2615   2328    11%   96, 99, 108, 111, 117-122, 128-130, 134, 145-146, 150, 154, 170-171, 181, 193-259, 276-300, 307, 317-319, 322, 330-343, 350-393, 400, 403, 406-416, 422-448, 458-1021, 1027-1066, 1072-1257, 1263-1340, 1347-1385, 1391-1442, 1448-1534, 1539-1555, 1562-1574, 1578-1593, 1597-1612, 1616-1631, 1635-1650, 1661-1666, 1670-1693, 1944, 1948, 1952-1956, 1960-1964, 1968-1972, 1976-1989, 1993-2000, 2004-2014, 2018-2028, 2032-2034, 2040-2043, 2047-2050, 2054-2061, 2065-2070, 2085-2143, 2147-2152, 2163-2207, 2211-2222, 2226-2234, 2240-2242, 2246-2251, 2255-2257, 2261-2263, 2269, 2273-2279, 2283, 2287-2292, 2296-2298, 2302-2304, 2308, 2312, 2316, 2324, 2328, 2332-2335, 2339-2341, 2345-2350, 2354-2357, 2361-2373, 2380, 2384-2416, 2420-2425, 2429-2451, 2455-2477, 2483-2499, 2503-2534, 2540-2575, 2581-2588, 2592-2612, 2616-2659, 2663-2680, 2684-2697, 2702, 2706-2707, 2711, 2715, 2719, 2725-2734, 2738-2747, 2751-2758, 2764, 2768-2782, 2786-2793, 2797-2811, 2815-2822, 2826-2833, 2837-2844, 2848-2857, 2861-2870, 2874-2883, 2887-2894, 2898-2905, 2909-2916, 2920-2927, 2931-2938, 2944, 2948-2957, 2962, 2967, 2972-3004, 3008-3017, 3023, 3029, 3033-3044, 3050, 3057, 3062, 3068, 3073-3097, 3102, 3107, 3112, 3121-3153, 3157-3201, 3205-3249, 3253-3280, 3285-3306, 3314-3376, 3380-3387, 3391-3411, 3417, 3423, 3427-3542, 3547-3558, 3562-3571, 3575, 3579, 3583, 3587, 3591, 3595, 3599, 3603-3608, 3612-3618, 3622-3627, 3631-3636, 3645, 3659-3693, 3699, 3703-3710, 3714-3725, 3730-3739, 3745-3754, 3760-3765, 3771-3776, 3782-3790, 3796-3804, 3808, 3812-3818, 3822-3833, 3837-3840, 3844-3850, 3854-3856, 3861, 3866-3878, 3882, 3886-3892, 3896-3902, 3908-3918, 3922-3929, 3934, 3938-3940, 3944-3967, 3971-3994, 3999, 4004, 4009, 4014, 4019, 4024, 4028-4040, 4046-4053, 4059-4066, 4070-4079, 4085-4092, 4098-4105, 4111-4118, 4126-4140, 4144-4151, 4155-4162, 4167-4182, 4186-4201, 4221, 4226, 4231, 4237-4248, 4255-4258, 4264-4267, 4273-4278, 4283-4287, 4291-4308, 4314-4329, 4335-4350, 4356-4359, 4363-4365, 4370-4378, 4384-4411, 4416-4425, 4429-4431, 4435-4437, 4442-4461, 4465-4482, 4486-4503, 4507-4524, 4528-4533, 4539-4550, 4554-4565, 4569-4574
sparkless/dataframe/export.py                                           15     15     0%   8-46
sparkless/dataframe/grouped/__init__.py                                  5      0   100%
sparkless/dataframe/grouped/base.py                                   1064    738    31%   89, 95, 103, 111-113, 115-117, 122-144, 176-185, 188, 192-196, 271, 278, 296, 302-307, 314-322, 328, 347, 360, 367, 372-389, 419, 439-442, 465-466, 554-600, 609-624, 641-657, 673-689, 710-765, 802, 807-808, 810-811, 841-844, 851, 853-856, 863-883, 911-914, 921, 923-926, 954-955, 981-982, 987-993, 995-1001, 1003-1009, 1027, 1037-1047, 1050-1069, 1072-1089, 1091-1101, 1103-1121, 1123-1143, 1145-1151, 1153-1159, 1162-1175, 1178-1191, 1195-1250, 1253-1259, 1267, 1269-1272, 1290-1647, 1664-1934, 1945-1952, 1963-1970, 1985, 2003-2007, 2018-2025, 2036-2043, 2054-2063, 2074-2083, 2094-2103, 2114-2123, 2134-2143, 2154-2163, 2174-2201, 2212-2239, 2268, 2303-2370, 2392-2447
sparkless/dataframe/grouped/cube.py                                     86     24    72%   68-74, 85, 87-96, 123-129, 140, 142-151, 166, 201-209
sparkless/dataframe/grouped/pivot.py                                   493    238    52%   101, 113-119, 142-174, 181-184, 205-215, 236-237, 254, 273-274, 279, 285-289, 291-328, 356, 362-397, 420, 422-425, 435, 437-440, 449-450, 486-492, 498, 531-544, 546-555, 565-641, 649-810, 825, 845, 878-882, 896, 916
sparkless/dataframe/grouped/rollup.py                                   87     24    72%   73-79, 88, 90-99, 128-134, 145, 147-156, 171, 206-214
sparkless/dataframe/joins/__init__.py                                    2      2     0%   8-10
sparkless/dataframe/joins/operations.py                                146    146     0%   8-396
sparkless/dataframe/lazy.py                                           1222   1045    14%   47-73, 106-108, 120-153, 167-173, 188-258, 271-301, 313-337, 352-388, 402-415, 433-447, 453-489, 495-504, 517-519, 523, 562-563, 581-582, 594, 600, 603, 607-611, 617-621, 630-642, 645, 649-655, 668, 688-704, 727-734, 775-829, 839-922, 956, 966, 980-991, 1013, 1016, 1021, 1025, 1028, 1072-1085, 1095-1099, 1105, 1118-1123, 1134-1135, 1157-2251, 2264-2525, 2538-2594, 2609-2837, 2853-2865
sparkless/dataframe/logical_plan.py                                    223     58    74%   24, 26, 28, 31-33, 73, 84, 105-112, 120-123, 130, 146, 172-180, 184-201, 206, 208, 232, 249-254, 272, 276-277, 279-280, 294, 317-318, 402-407, 415-416, 425, 440-441, 454
sparkless/dataframe/operations/__init__.py                               2      0   100%
sparkless/dataframe/operations/aggregation_operations.py               128    128     0%   3-313
sparkless/dataframe/operations/join_operations.py                      157    157     0%   3-329
sparkless/dataframe/operations/misc.py                                 516    472     9%   56-77, 103-145, 167-215, 236-250, 267-308, 323-407, 421-501, 518-549, 566-593, 615-630, 643-659, 678-685, 710-742, 770-831, 863-922, 949-986, 1023-1074, 1082-1113, 1117-1135, 1149-1176, 1191-1196, 1216, 1232-1234, 1248-1255, 1266-1267, 1276, 1295-1304, 1323-1324, 1340-1345, 1353, 1366-1369, 1377, 1382, 1391-1392, 1401, 1415-1427
sparkless/dataframe/operations/set_operations.py                       168    140    17%   28-94, 99, 140, 160-290, 296-316, 322-339, 344-346
sparkless/dataframe/protocols.py                                        49      0   100%
sparkless/dataframe/rdd.py                                              83     56    33%   26, 34, 42, 53, 61, 69-70, 81, 92-95, 106, 117-125, 136-143, 155-166, 174, 185, 193, 201, 209, 217, 229, 240-243, 254-261, 269, 277
sparkless/dataframe/reader.py                                          187    104    44%   127-136, 163-170, 173, 179, 189, 206-259, 269-277, 281-288, 295, 298, 301-306, 311-321, 342-346, 348, 354-374, 377-382, 389, 397-399, 406, 414, 429, 444, 461-463
sparkless/dataframe/robin_plan.py                                       78      9    88%   54, 57, 61, 68, 111, 119, 128, 130, 159
sparkless/dataframe/schema/__init__.py                                   3      0   100%
sparkless/dataframe/schema/operations.py                                22      9    59%   23-31, 39-41, 46, 51
sparkless/dataframe/schema/schema_manager.py                           514    229    55%   49-75, 93, 118-120, 136-151, 168, 258, 284, 300-301, 304, 310-324, 356, 361, 378-401, 406, 453-465, 469-474, 482, 484, 486-487, 491, 493, 507, 509-510, 514-517, 523, 530, 555, 563, 573, 591, 633, 692-715, 724, 728, 745, 747, 761, 763-764, 768-771, 774, 777, 788-798, 803-839, 843-846, 850-853, 857-875, 879-887, 905-909, 922-930, 952-967, 975-978, 997, 1000-1019
sparkless/dataframe/services/__init__.py                                 8      0   100%
sparkless/dataframe/services/aggregation_service.py                     99     31    69%   32, 34, 37, 69, 128, 133, 148, 176, 181, 196, 224-250
sparkless/dataframe/services/assertion_service.py                       17      8    53%   25-27, 33-35, 41-43, 49-51
sparkless/dataframe/services/display_service.py                        126     65    48%   40-50, 78, 94, 101, 120-167, 171-174, 182-186, 195-204, 209-210, 220, 223, 227-232, 238-240, 244-250, 264-267, 280
sparkless/dataframe/services/join_service.py                           248     90    64%   58-94, 114, 129, 206, 226, 232, 238, 417, 426-428, 460, 472-496, 510-534, 549-590, 606-628
sparkless/dataframe/services/misc_service.py                           613    372    39%   57, 67-73, 96-98, 166, 251, 264-268, 304-352, 376, 387-389, 417-458, 476-560, 574-654, 683-685, 687-689, 753-755, 802-817, 830-846, 865-872, 897-929, 955-1016, 1066, 1077, 1153-1190, 1227-1277, 1285-1318, 1322-1340, 1354-1381, 1396-1401, 1419, 1435-1437, 1451-1458, 1469-1472, 1481, 1499-1503, 1518, 1529-1534, 1540, 1551-1554, 1562, 1567, 1576-1577, 1586, 1600-1612
sparkless/dataframe/services/schema_service.py                           4      0   100%
sparkless/dataframe/services/transformation_service.py                 349     98    72%   70-71, 88-93, 100, 150, 157, 177, 184-188, 198-202, 224, 246-247, 251-266, 271-275, 293, 308-315, 368, 372, 377, 385-386, 409-414, 421-425, 431-441, 448-452, 456-458, 499, 510, 533-543, 559, 671, 678-680, 713, 730, 751, 772-774, 779, 783, 825-827, 837-850, 854, 890-910
sparkless/dataframe/transformations/__init__.py                          2      2     0%   8-10
sparkless/dataframe/transformations/operations.py                      224    224     0%   8-629
sparkless/dataframe/types.py                                             8      8     0%   8-25
sparkless/dataframe/validation/__init__.py                               2      0   100%
sparkless/dataframe/validation/column_validator.py                     171     65    62%   94-115, 137, 141-161, 164-165, 185-198, 218, 245-289, 337, 343, 348, 385-392, 401, 422, 429, 461, 473, 485, 514, 533-578
sparkless/dataframe/validation_handler.py                               21      5    76%   42, 57-58, 75-76
sparkless/dataframe/window_handler.py                                  315    315     0%   8-698
sparkless/dataframe/writer.py                                          395    240    39%   113-115, 129, 159-160, 192-194, 205-210, 228-232, 235-238, 248-250, 258, 288, 294-296, 308-360, 416, 418, 469-495, 509, 521, 537, 549, 561, 573, 580-586, 590-606, 610-613, 617-622, 627-642, 647-656, 661-670, 675-690, 694-699, 720-753, 782-865, 888-892, 896, 908, 912-917, 942-1022
sparkless/delta.py                                                     308    240    22%   46-51, 61-74, 104, 112, 121-122, 127, 131-132, 137-152, 156-185, 189, 198, 210, 281-283, 300-341, 345, 348-352, 355-357, 360-368, 373-379, 384-408, 421-430, 434, 438, 441-446, 449-450, 455-456, 459-461, 464-466, 470-514, 517-523, 526-540, 547-551, 563-576, 581-584, 589-593, 601-629, 637-657
sparkless/error_simulation.py                                           89     89     0%   29-338
sparkless/errors.py                                                     28     10    64%   57, 62, 67, 72, 79, 86, 91, 96, 101, 106
sparkless/functions/__init__.py                                         29      4    86%   562-566
sparkless/functions/aggregate.py                                       323    154    52%   64-66, 70, 299-300, 315-316, 331-332, 370-371, 386-387, 402-403, 439-443, 461-472, 490-501, 516-517, 534-535, 552-553, 570-571, 591-597, 617-623, 640-641, 658-659, 733-734, 751-752, 769-770, 787-788, 803-807, 825-826, 843-844, 857-859, 874-890, 904-912, 930-940, 958-967, 985-994, 1014-1026, 1044-1053, 1071-1080, 1098-1107, 1125-1134, 1152-1161, 1182-1222
sparkless/functions/array.py                                           272    161    41%   55-58, 78-83, 106-111, 134-139, 160-163, 184-187, 213-219, 245-251, 277-283, 309-315, 346-356, 385-396, 418-421, 440-443, 465-468, 486-490, 511-514, 538-541, 561-564, 579-585, 626-629, 644-647, 698-701, 716-719, 737-742, 762-765, 779-782, 794-797, 811-830, 853-883, 900-903, 928-929, 938-939, 948, 964, 997-1000, 1018-1022, 1040-1043, 1058-1059, 1074-1086, 1098-1100, 1112-1116
sparkless/functions/base.py                                            135     62    54%   121, 134, 137, 150-161, 165-171, 175-184, 188-201, 205-217, 221-233, 237-239, 277, 281, 285, 289, 293, 297, 302, 307, 312, 317, 322
sparkless/functions/bitwise.py                                         108     67    38%   31-34, 50-53, 71, 86-89, 107-110, 125-128, 143-146, 161-168, 183-198, 213-228, 243-258, 276-283, 300-307, 324-331, 347-350, 367-370, 387-390, 405-408, 425-428
sparkless/functions/conditional.py                                     396    292    26%   33-115, 147, 152, 226, 230, 234, 238, 242, 246, 251, 256, 261, 266, 271, 275, 279, 283, 295-300, 304-367, 381-384, 396-412, 426-455, 475, 498-502, 514-521, 533-538, 553, 570-603, 622, 637-648, 661-682, 707-722, 737-752, 767-782, 797-812, 827-842, 854-861, 873-880, 895-908, 923-939, 954-970, 985-1001
sparkless/functions/core/__init__.py                                     6      0   100%
sparkless/functions/core/column.py                                     457    161    65%   43, 53, 97, 131, 139, 143, 147, 155, 163, 199, 209-210, 216, 220, 224, 336, 339, 389, 399, 417-436, 464-466, 470-472, 476-478, 482-484, 492, 500-510, 518-528, 536-546, 554-564, 572-582, 590-600, 609, 696, 706, 713, 735, 737, 740, 743-745, 748, 751-757, 760, 763-765, 768, 772, 776, 780, 784, 788, 807, 818-825, 828-836, 838-842, 844-848, 850-854, 856-860, 863-885, 891, 958, 970, 972-973, 975-991, 994, 1009, 1030, 1046
sparkless/functions/core/expressions.py                                109     74    32%   28-32, 55, 73, 91-94, 108-115, 127-129, 141-143, 155-157, 169-171, 188-228, 240-247, 259-266, 278-285, 297-304, 320-323
sparkless/functions/core/lambda_parser.py                              146    126    14%   58-134, 142-148, 167-175, 189-247, 260-274, 285-298, 309-314, 327-332, 359-361, 369, 377, 381-385
sparkless/functions/core/literals.py                                   131     70    47%   52, 65-76, 86, 108-110, 117-119, 123-125, 129-131, 135-137, 141-143, 147-149, 153-155, 159-161, 171-173, 177-179, 183-185, 189-191, 195-197, 201-203, 207-209, 213, 217, 227-229, 233-240, 244-246, 250-252, 256-258, 262-268, 272-274, 278-280, 306-308, 312-314, 318-320
sparkless/functions/core/operations.py                                 106     67    37%   27-29, 33-35, 39-41, 45-47, 51-53, 57-59, 63-65, 69, 73, 77-79, 83-85, 89-91, 95-97, 101-103, 107-109, 122, 126, 130, 134, 145, 150-154, 158, 162, 176-189, 199, 203, 211, 219-221, 225-227, 235-237
sparkless/functions/core/sql_expr_parser.py                            308    199    35%   70, 75-78, 90-101, 107-157, 163-171, 175-183, 188-204, 209-226, 248-253, 279-289, 294-300, 308-314, 322-339, 345-381, 395, 399, 401, 405, 410, 419, 428, 443-448, 480-485, 489, 491, 501-507, 520-551
sparkless/functions/crypto.py                                           48     39    19%   49-71, 91-113, 133-155
sparkless/functions/datetime.py                                        474    322    32%   49-52, 69-74, 86-89, 98, 107, 119-125, 137-143, 155-161, 173-179, 188-189, 205-218, 231-237, 262-301, 327-366, 390-429, 455-500, 520-549, 564-580, 595-601, 616-622, 637-646, 658-664, 676-682, 694-700, 712-718, 730-736, 748-754, 783, 813-844, 856-860, 872-876, 888-892, 904-908, 920-924, 936-942, 954-960, 972-978, 990-994, 1006-1010, 1022-1026, 1039-1048, 1063-1074, 1087-1093, 1106-1112, 1125-1134, 1149-1159, 1179-1191, 1211-1222, 1231-1234, 1248-1253, 1262-1273, 1283-1294, 1317-1320, 1340-1343, 1368-1372, 1422-1468, 1492-1497, 1518-1537, 1557-1560, 1576-1579, 1600-1603, 1622-1627, 1646-1647, 1664-1665, 1685-1693, 1711-1727, 1745-1761
sparkless/functions/functions.py                                      1547    560    64%   67-77, 92, 133-136, 142-162, 168-187, 193-212, 218-238, 249, 259, 264, 269, 274, 279, 286, 317, 329, 334, 341, 346, 351, 356, 361, 366, 371, 376, 381, 394-396, 401, 408, 415, 422, 427, 432, 437, 442, 447, 452, 457, 462, 467, 472, 483, 490, 497, 502, 507, 523, 533, 543, 548, 564, 569, 574, 593, 598, 605, 610, 615, 627, 632, 637, 642, 652, 657, 664, 669, 680, 685, 690, 695, 700, 705, 710, 721, 726, 731, 736, 741, 748, 755, 760, 765, 770, 775, 780, 785, 790, 795, 800, 805, 810, 817, 822, 827, 832, 837, 842, 847, 852, 857, 862, 867, 872, 877, 882, 887, 892, 902, 907, 912, 917, 922, 927, 932, 937, 942, 1002, 1007, 1012, 1023, 1028, 1033, 1045, 1052, 1059, 1082, 1087, 1092, 1097, 1104, 1109, 1114, 1119, 1128, 1133, 1138, 1143, 1148, 1155, 1162, 1167, 1172, 1182-1183, 1192-1193, 1202-1205, 1219, 1224, 1231, 1238, 1243, 1248, 1253, 1258, 1263, 1274, 1279, 1284, 1296, 1301, 1306, 1311, 1316, 1321, 1326, 1331, 1336, 1341, 1346, 1378-1420, 1425, 1430, 1435, 1442, 1447, 1452, 1457, 1466, 1476, 1483, 1491, 1496, 1501, 1506, 1511, 1516, 1521, 1533-1538, 1549, 1556, 1563, 1569-1571, 1579-1586, 1595-1597, 1706-1713, 1738-1745, 1770-1777, 1786-1793, 1798-1803, 1814, 1819, 1824, 1829, 1834, 1841, 1848, 1855, 1860, 1865, 1873, 1880, 1887, 1894, 1904, 1913, 1919, 1924, 1929, 1934, 1939, 1946, 1951, 1956, 1963, 1973, 1978, 1993, 2000, 2005, 2010, 2015, 2020, 2029, 2034, 2040, 2045, 2050, 2055, 2062, 2073, 2078, 2085, 2092, 2099, 2108, 2114-2138, 2152-2158, 2169, 2174, 2179, 2185, 2190, 2195, 2200, 2205, 2210, 2215, 2220, 2225, 2233, 2242-2243, 2248, 2253, 2259, 2264, 2269, 2279, 2285, 2290, 2297, 2302, 2307, 2316-2318, 2326-2328, 2336-2338, 2346-2348, 2353-2355, 2360-2362, 2369-2371, 2378-2380, 2387-2389, 2396-2398, 2404, 2409, 2414, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2464-2466, 2471-2473, 2492-2494, 2503-2505, 2510-2512, 2517-2519, 2525-2527, 2532-2534, 2539-2541, 2546-2548, 2553-2555, 2561-2563, 2568-2570, 2575-2577, 2582-2584, 2589-2591, 2596-2598, 2603-2605, 2641-2642, 2645, 2655, 2661, 2671-2672, 2685, 2716-2741, 2765-2772, 2789-2791, 2797, 2804, 2809, 2814, 2821, 2828, 2833, 2842, 2847, 2854, 2861, 2866, 2871, 2879, 2884, 2891, 2898, 2905, 2913, 2920, 2927, 2933, 2938, 2945, 2950, 2962, 2975, 2989, 3004, 3016, 3023, 3030, 3037, 3044, 3049, 3054, 3059, 3064, 3069, 3074, 3080, 3085, 3090, 3097, 3102, 3107, 3112, 3117, 3122, 3130, 3135, 3140, 3149, 3155, 3160, 3165, 3170, 3175, 3196-3213
sparkless/functions/json_csv.py                                         41     16    61%   31-34, 51-54, 105-107, 127-130, 144-147, 159-161
sparkless/functions/map.py                                             101     51    50%   51-54, 69-72, 87-90, 107-115, 138-143, 192, 204-207, 219, 243-246, 266-269, 292-298, 324-330, 356-362, 391-400, 423-430
sparkless/functions/math.py                                            320    207    35%   50-54, 66-70, 82-86, 99-105, 117-121, 133, 145-149, 161-165, 177-182, 204-231, 246-249, 264-267, 284-287, 304-307, 322-334, 349, 361-365, 377-381, 393-397, 409-414, 426-439, 451-461, 476-477, 489-490, 505-506, 518-519, 531-532, 544-545, 567-574, 586-587, 599-600, 612-613, 625-626, 638-639, 651-652, 664-665, 677-679, 696-698, 715-716, 729-730, 745-748, 768-792, 809-810, 823-824, 836-837, 849-850, 859-862, 871-874, 886-887, 902-907, 921-926, 941-960, 972, 990-1003, 1026-1067
sparkless/functions/metadata.py                                         33     33     0%   8-109
sparkless/functions/ordering.py                                         28     28     0%   7-93
sparkless/functions/pandas_types.py                                      6      0   100%
sparkless/functions/string.py                                          547    319    42%   50, 65-69, 82, 97-103, 115-121, 133-137, 149-153, 165-169, 184-196, 209-218, 231-237, 250-256, 268-274, 287-296, 309-318, 331-337, 350-356, 370-379, 395, 411-420, 435-450, 462-468, 480-484, 496, 508, 521-534, 550-561, 579, 629, 654-667, 705-709, 721-725, 737-741, 791-803, 818-822, 838-844, 859-863, 900-903, 923-926, 941-944, 960-971, 1004, 1054-1057, 1075-1078, 1099-1102, 1124-1127, 1146-1149, 1202-1223, 1235-1238, 1250-1253, 1265-1268, 1280-1299, 1321, 1329-1332, 1352-1355, 1370-1373, 1391-1394, 1414-1417, 1432-1435, 1451-1457, 1492-1495, 1508-1514, 1529-1540, 1553-1562, 1575-1584, 1601-1610, 1627-1636, 1649-1655, 1673-1684, 1698-1710, 1725-1731, 1746-1752, 1764-1768, 1781-1792, 1807, 1832-1854, 1872-1879, 1897-1902, 1918-1927, 1939-1940
sparkless/functions/udf.py                                              51      1    98%   138
sparkless/functions/window_execution.py                                651    567    13%   58-67, 269, 283, 297, 311, 325, 339, 350, 361, 377, 390-428, 432-471, 478-553, 557-607, 613-629, 633-694, 698-742, 746-790, 794-845, 849-916, 920-981, 987-1024, 1028-1087, 1092, 1101-1146, 1150-1230, 1234-1260, 1268-1304, 1308-1372, 1376-1420, 1424-1468
sparkless/functions/xml.py                                              65     39    40%   25-28, 50-64, 84-87, 107-110, 131-134, 155-158, 179-182, 203-206, 227-230, 251-254, 275-278
sparkless/optimizer/__init__.py                                          3      0   100%
sparkless/optimizer/optimization_rules.py                              174     20    89%   17, 84, 132-140, 151, 162, 193, 242, 264, 278, 287, 299, 342, 376
sparkless/optimizer/query_optimizer.py                                 256    179    30%   48, 50, 52, 54, 56, 58, 67, 72, 80-125, 129-130, 135, 147-174, 178-179, 183-206, 214-234, 238-239, 245-248, 256-288, 292, 297, 305-330, 334, 339-342, 379-392, 403-408, 413, 418-456, 459-472, 477-504, 508, 512, 518
sparkless/performance_simulation.py                                     91      1    99%   150
sparkless/session/__init__.py                                            4      0   100%
sparkless/session/catalog.py                                           258    215    17%   39, 43, 47, 60-61, 65, 69, 111, 119, 130-134, 142, 150, 170, 173, 177-180, 187-190, 211-233, 250-318, 335-352, 374, 386-414, 430-450, 462-487, 498-519, 528, 537, 546, 566-575, 605-661, 666, 683-716
sparkless/session/config/__init__.py                                     2      0   100%
sparkless/session/config/configuration.py                               54     21    61%   85-86, 94, 102, 110, 118-119, 130, 141, 146, 150, 188, 199-200, 211-212, 224-225, 236-237, 245
sparkless/session/context.py                                            36     10    72%   47, 51, 55, 92, 101, 110, 119, 123, 127, 131
sparkless/session/core/__init__.py                                       4      0   100%
sparkless/session/core/builder.py                                       30      3    90%   31, 54, 71
sparkless/session/core/session.py                                      227     76    67%   12-13, 122, 174-177, 182, 187, 237-239, 249-254, 258-260, 273, 277, 287, 293, 306-308, 350, 368, 380, 391, 414, 421-436, 444-446, 468, 474, 479-482, 509-510, 525, 530-536, 544, 553-555, 575-580, 597, 604, 611, 621, 628, 633-643, 652, 661-662, 667
sparkless/session/performance_tracker.py                                39     19    51%   57, 87-109, 117
sparkless/session/services/__init__.py                                   6      0   100%
sparkless/session/services/dataframe_factory.py                        216    104    52%   14-15, 73-78, 97-99, 102-103, 106, 119, 131-170, 190, 197-199, 206, 211, 218, 255, 271, 281, 313, 321-323, 343, 350, 361-364, 403, 428, 440, 447, 465-472, 490-506, 517-587
sparkless/session/services/lifecycle_manager.py                         21     10    52%   32-34, 42-43, 55-59
sparkless/session/services/mocking_coordinator.py                       32     21    34%   39-57, 69-72, 84-86, 102-104, 109
sparkless/session/services/protocols.py                                 20      0   100%
sparkless/session/services/sql_parameter_binder.py                      29     25    14%   28-51, 62-74
sparkless/session/session.py                                             0      0   100%
sparkless/session/sql/__init__.py                                        5      0   100%
sparkless/session/sql/executor.py                                     1280    651    49%   83-90, 123, 135, 137, 140-143, 149, 179-190, 204-211, 232-239, 281, 284, 289, 310-342, 366-381, 409-419, 425-444, 514, 517-520, 544-545, 556-569, 609-612, 616-631, 633-646, 648-652, 654-658, 668, 681-733, 751-1011, 1035-1036, 1040-1138, 1161-1172, 1185-1192, 1197-1198, 1221-1243, 1268-1271, 1282-1283, 1296-1348, 1390, 1401-1415, 1425-1432, 1442, 1446, 1451-1453, 1462-1465, 1472-1473, 1500, 1510, 1517-1519, 1554, 1556, 1560, 1565, 1588, 1596-1598, 1603, 1607-1641, 1658, 1680, 1690, 1692, 1700-1705, 1729, 1738-1740, 1760-1761, 1799, 1802, 1805, 1807, 1811, 1816-1829, 1839, 1853, 1871-1872, 1894-1988, 2002-2030, 2042-2088, 2102, 2123, 2192-2407, 2443, 2484, 2566-2576, 2609-2610, 2619-2627, 2637, 2700, 2707-2708, 2711, 2731, 2742-2748, 2768, 2771-2779, 2813-2816, 2860-2867, 2943-2945, 2955, 2963-2971, 2976-2985, 2990, 2995, 2997-3001
sparkless/session/sql/optimizer.py                                      65      0   100%
sparkless/session/sql/parser.py                                        496    119    76%   45, 49, 263, 271-272, 287, 295, 303, 305, 307, 310-315, 344, 354, 358, 432, 443, 472-486, 509, 561-566, 599, 601, 603, 651, 668-671, 674-677, 685, 726-737, 755-765, 790, 820-821, 833, 857-861, 892, 915, 930-931, 936, 978-993, 1019, 1027, 1042-1044, 1046-1047, 1049-1050, 1052-1053, 1085-1106, 1121-1141, 1338, 1349-1374
sparkless/session/sql/validation.py                                     85      0   100%
sparkless/spark_types.py                                               404    177    56%   60-74, 111, 115, 123, 285, 333-334, 350, 368, 420, 432, 439-440, 443, 450-451, 454, 466, 475-477, 480, 489-491, 494, 503-505, 508, 531, 570-575, 585-590, 593, 605-606, 625-633, 654-656, 660, 664-665, 669, 673, 685, 698, 704-713, 718-733, 738-739, 756, 758, 760, 762, 764, 766, 823-826, 838-848, 859-880, 886-888, 892-899, 903-910, 914, 918-943, 957-978, 983-984, 989, 995-997, 1011-1012
sparkless/sql/__init__.py                                               10      0   100%
sparkless/sql/functions.py                                              30      8    73%   63-66, 70-72, 84-92
sparkless/sql/types.py                                                   2      0   100%
sparkless/sql/utils.py                                                   7      0   100%
sparkless/storage/__init__.py                                           10      0   100%
sparkless/storage/backends/__init__.py                                   0      0   100%
sparkless/storage/backends/file.py                                     206     60    71%   39, 49, 68-69, 93, 96-98, 119, 142, 146, 150, 154-155, 159-161, 224-232, 238, 242, 246, 250, 254, 258, 262-264, 268, 272, 276, 321-328, 336, 409-414, 431, 449, 493-502, 507, 518-520, 538
sparkless/storage/backends/memory.py                                   133     84    37%   22-25, 34, 39, 44, 53-61, 72-77, 85, 93, 97, 101, 105, 109-110, 114-115, 139-141, 152, 160-161, 169, 187-188, 199, 208-209, 217, 229-231, 246-249, 258-259, 271-275, 290-295, 310-312, 324-330, 342, 352-370, 381-390, 402-406, 418-423, 430
sparkless/storage/manager.py                                           135     86    36%   40-45, 58, 70, 82, 94-98, 108, 119, 128-130, 138, 142-149, 153-159, 171, 186, 195, 208, 223, 237, 249, 258, 269, 283, 295, 303, 312, 325, 336, 344-349, 353-358, 366-378, 382, 390-400, 411-432
sparkless/storage/models.py                                             67      1    99%   77
sparkless/storage/serialization/__init__.py                              0      0   100%
sparkless/storage/serialization/csv.py                                  46     32    30%   23-30, 42-47, 57-62, 76-92, 104-120
sparkless/storage/serialization/json.py                                 39     25    36%   23-24, 36-41, 51-63, 75-90, 102-118
sparkless/utils/profiling.py                                            96     40    58%   47-48, 58, 61, 71-76, 85, 88-90, 94, 99, 102, 118-135, 161-172, 182, 188
sparkless/window.py                                                     67     14    79%   78, 83, 91, 114, 119, 127, 148, 166-170, 186, 234, 239
--------------------------------------------------------------------------------------------------
TOTAL                                                                33879  22918    32%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_string - AssertionError: assert None == '1'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_basic - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_int - assert None == 1
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_add_new_field - RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_string_with_int64 - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_filter_all_case_variations - RuntimeError: not found: Column 'Alice' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_literals - RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_existing_field - RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_first - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_column_operation - RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_infer_schema_with_numeric_strings - AssertionError: id should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_column_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [first, last]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_modulo - RuntimeError: not found: Column '(2 % number_2)' not found. Available columns: [number_2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_infer_schema_boolean_strings - AssertionError: flag1 should be BooleanType
assert False
 +  where False = isinstance(StringType(nullable=True), BooleanType)
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_orderBy_all_case_variations - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_column_expression - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, other_value, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_leading_zeros - AssertionError: id should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_pairs - RuntimeError: not found: Column 'map_col' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_integers - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_computed_expression - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_issue_239_example - RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_numeric_eq_string - RuntimeError: not found: Column '150' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_negative_numbers - AssertionError: value should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_scientific_notation - AssertionError: small should be DoubleType
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_all_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_null_values - AssertionError: id should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_datatype_object - RuntimeError: not found: Column 'num_str' not found. Available columns: [num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_chained - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_join_all_case_variations - RuntimeError: not found: ID

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_reverse_operations - RuntimeError: not found: Column '(5 - col)' not found. Available columns: [col, add]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_no_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_returns_empty_map - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_multiple_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_returns_empty_map - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_large_numbers - AssertionError: big_int should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_string_int64 - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_empty_list - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_select - assert None == 50.0
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_select - AssertionError: assert None == '1'
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_withcolumn - RuntimeError: not found: Column 'map(name, name, age, age)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_decimal_precision - AssertionError: price should be DoubleType
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_null - AssertionError: assert None == '1'
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_filter - RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_array_index - RuntimeError: not found: Column 'first' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_null_struct - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_mixed_boolean_strings - AssertionError: flag1 should be BooleanType
assert False
 +  where False = isinstance(StringType(nullable=True), BooleanType)
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first_multiple_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double - assert None == 1.0
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_all_literals - RuntimeError: not found: Column 'map_col' not found. Available columns: [dummy]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_boolean - RuntimeError: casting from string to boolean failed for value '5'
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_split_result - RuntimeError: not found: Column 'first' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_issue_235_example - RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_with_sort_method - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_numeric_strings - AssertionError: id should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_single_row - AssertionError: age should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_multiple_columns_ordering - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_chained_operations - AssertionError: assert None in ['2', '2.0']
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_literal - AssertionError: assert None == '123'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_from_string - assert None is not None
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_selectExpr_all_case_variations - RuntimeError: not found: Column 'full_name' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_numeric_types - RuntimeError: not found: Column 'map_col' not found. Available columns: [float_val, int_val, long_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_float - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_different_data_types - RuntimeError: not found: Column 'my_struct.withField(int_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_map_key - RuntimeError: not found: Column 'val' not found. Available columns: [map]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_operators_in_single_expression - RuntimeError: not found: Column '((((a * 2) + 10) - (5 / a)) + (3 % a))' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_expressions_with_case_variations - RuntimeError: not found: Column 'upper(name)' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_negative_numbers - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_struct - RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_then_add - RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_deeply_nested_struct - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_to_date - RuntimeError: not found: Column 'date_col' not found. Available columns: [datetime_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_boolean_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [flag1, flag2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_multiple_numeric_types - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_computed_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_out_of_bounds - RuntimeError: not found: Column 'val' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_types - assert None == 123
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_boolean_column - AssertionError: Should be BooleanType
assert False
 +  where False = isinstance(StringType(nullable=True), BooleanType)
 +    where StringType(nullable=True) = StructField(name='active', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last_empty_dataframe - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_complex_expression - RuntimeError: not found: Column 'my_struct.withField(computed, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_single_row - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_chained_unions - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_distinct_with_case_variations - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_negative_index - RuntimeError: not found: Column 'val' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_integer_column - AssertionError: Should be LongType, not IntegerType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
 +    where StringType(nullable=True) = StructField(name='count', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_float_column - AssertionError: Should be DoubleType, not FloatType
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
 +    where StringType(nullable=True) = StructField(name='price', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_alias - AssertionError: assert None == '1'
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_conditional_expression - RuntimeError: not found: Column 'my_struct.withField(status, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_three_dataframes - RuntimeError: type Float64 is incompatible with expected type String
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookbehind - RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_maps_in_select - RuntimeError: not found: Column 'name_map' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_single_null_row - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_nulls_at_beginning_middle_end - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_orderby - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_unicode_characters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_cast_operation - RuntimeError: not found: Column 'my_struct.withField(id_int, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_complex_expressions - AssertionError: assert None in ['10', '10.0']
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_groupby_agg - RuntimeError: not found: Column 'info' not found. Available columns: [dept, name, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_when_otherwise - RuntimeError: not found: Column '(value * 2) > 10' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_cast - assert None == 5
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_complex_query_all_case_variations - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_invalid_string_to_int - assert None == 123
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_with_different_type - RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_fields_in_sequence - RuntimeError: not found: Column 'my_struct.withField(field1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookahead - RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double_to_int - assert None == 3
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_to_boolean - RuntimeError: casting from string to boolean failed for value ''
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_chained - AssertionError: assert None == '123'
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_coalesce_all_case_variations - RuntimeError: not found: Column 'result' not found. Available columns: [Col1, Col2, Col3]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_special_characters_in_keys - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_nested_in_expressions - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_empty_string_keys - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_small_numbers - AssertionError: tiny should be DoubleType
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_without_lookaround - RuntimeError: not found: Column 'domain' not found. Available columns: [email]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_complex_lookaround - RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_null_literal - RuntimeError: not found: Column 'my_struct.withField(null_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_nested_struct_field_access_all_cases - ValueError: RobinMaterializer requires a non-empty schema
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_sql_queries_all_case_variations - assert 6 == 3
 +  where 6 = len([Row(Name=None), Row(Name=None), Row(Name=None), Row(Name=None), Row(Name=None), Row(Name=None)])
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_tab_delimiter - AssertionError: age should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_asc_desc_nulls_variants - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_very_large_numbers - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_all_four_methods_comprehensive - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_comparison_with_default_desc_asc - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_all_column_operations - RuntimeError: not found: Column 'upper_str' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_modulo_by_zero - RuntimeError: not found: Column '(10 % col)' not found. Available columns: [col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_union - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_three_column_ordering - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_issue_264_withColumn_case_insensitive - RuntimeError: not found: Column 'upper(Key)' not found. Available columns: [key]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_array_field - RuntimeError: not found: Column 'my_struct.withField(array_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_string_comparison_edge_cases - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_keys - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_zero_and_negative - RuntimeError: casting from string to boolean failed for value '-1'
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_select_multiple_columns - assert None == 6.0
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_float_string_conversions - TypeError: argument of type 'NoneType' is not iterable
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_zeros - AssertionError: int_val should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_string_columns - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_filter - RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_complex_ordering_scenario - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_large_number_of_pairs - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_duplicate_values - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_after_when_otherwise - AssertionError: assert None in ['2', '2.0']
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_modulo_with_numeric - RuntimeError: not found: Column '(string_1 % 3)' not found. Available columns: [string_1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_strings - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_select - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, other_col, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_identical_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_select - RuntimeError: not found: Column 'empty_map' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_date_pyspark_parity - RuntimeError: not found: Column 'final_date' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_column_objects - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_data_types_ordering - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_long_type - assert None == 1
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_all_null_structs - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_last_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_different_data_types - RuntimeError: not found: Column 'map()' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_type_aliases - AssertionError: assert None == '123'
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_column_objects - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_after_filter - RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_dataframe - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_first_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_string_return_type - RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_together - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_groupby_context - RuntimeError: not found: Column 'map()' not found. Available columns: [dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_last_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_reference_other_struct_field - RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_hex_strings - AssertionError: value should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_in_select - assert None == 2.0
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types - RuntimeError: not found: Column 'array(name, age, active)' not found. Available columns: [active, age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_integer_return_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_first_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_numeric_string_prefixes - AssertionError: id should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_join - RuntimeError: not found: Column 'map()' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_string_functions - RuntimeError: not found: Column 'my_struct.withField(upper_id, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_multi_column_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_basic_substr - RuntimeError: not found: Column 'partial_name' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_double_return_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_window_functions - RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_single_column - RuntimeError: not found: Column 'array(Name)' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_nested_expressions - RuntimeError: not found: Column 'val > 5' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_when_otherwise - RuntimeError: not found: Column '(string_1 / 5) > 3' not found. Available columns: [string_1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_chained_with_cast - assert None == 5
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_three_columns - RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_chained_multiple_times - RuntimeError: not found: Column 'my_struct.withField(field1, ...).withField(field2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_from_second_position - RuntimeError: not found: Column 'from_second' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_issue_238_example - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_null_handling - RuntimeError: not found: Column 'map()' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_small_floats - AssertionError: Should be DoubleType
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
 +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_very_large_floats - AssertionError: Should be DoubleType
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
 +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_float_zeros - AssertionError: Should be DoubleType
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
 +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_boolean_return_type - RuntimeError: not found: Column 'udf(age)' not found. Available columns: [age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_arithmetic_operations - RuntimeError: not found: Column 'my_struct.withField(product, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_preserves_all_existing_fields - RuntimeError: not found: Column 'my_struct.withField(field2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_field_access - RuntimeError: not found: Column 'my_struct.withField(computed_from_nested, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_two_arguments - RuntimeError: not found: Column 'udf(first)' not found. Available columns: [first, second]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_all_operations_comprehensive - RuntimeError: not found: Column '(string_1 % 5)' not found. Available columns: [string_1, add, sub, mul, div]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_three_arguments - RuntimeError: not found: Column 'udf(a)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_filter_case_insensitive - RuntimeError: not found: Column 'Alice' not found. Available columns: [Age, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_columns - RuntimeError: not found: Column 'array((a + b), (a * b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_integer_zeros - AssertionError: Should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
 +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_integer_ordering_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_orderby - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_float_ordering_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_mixed_types - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_multiple_times - RuntimeError: not found: Column 'map1' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_at_one - RuntimeError: not found: Column 'first_three' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_select - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_beyond_length - RuntimeError: not found: Column 'beyond' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_null - RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_computed_columns - RuntimeError: not found: Column 'sum' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_union - RuntimeError: not found: Column 'map()' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_string_expression - RuntimeError: not found: Column 'my_struct.withField(combined_string, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_nested_structs - RuntimeError: not found: Column 'my_struct.withField(combined, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_preserves_type - RuntimeError: not found: Column 'map()' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_computed_columns - RuntimeError: not found: Column 'array((a + b), (a - b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_zero - RuntimeError: not found: Column 'empty' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_very_deeply_nested_struct - RuntimeError: not found: Column 'my_struct.withField(from_deep_nest, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_null - RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_tuple_returns_empty_map - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_withColumn - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_select - RuntimeError: not found: Column 'empty_map' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_false_booleans - AssertionError: Should be BooleanType
assert False
 +  where False = isinstance(StringType(nullable=True), BooleanType)
 +    where StringType(nullable=True) = StructField(name='flag', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_exceeds_remaining - RuntimeError: not found: Column 'long' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int64_with_string - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_string_with_int64 - RuntimeError: datatypes of join keys don't match - `key`: str on left does not match `key`: i64 on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_select - RuntimeError: not found: Column 'first_two' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_groupBy_aggregation - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [category, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_all_true_booleans - AssertionError: Should be BooleanType
assert False
 +  where False = isinstance(StringType(nullable=True), BooleanType)
 +    where StringType(nullable=True) = StructField(name='flag', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_input - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_null_values - RuntimeError: not found: Column 'array(name, age)' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_all_null_columns - RuntimeError: not found: Column 'array(val1, val2)' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_numeric_types - RuntimeError: not found: Column 'array(int_val, float_val, long_val)' not found. Available columns: [float_val, int_val, long_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_boolean_types - RuntimeError: not found: Column 'array(flag1, flag2)' not found. Available columns: [flag1, flag2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types_comprehensive - RuntimeError: not found: Column 'array(str_val, int_val, float_val, bool_val)' not found. Available columns: [bool_val, float_val, int_val, str_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_select_statement - RuntimeError: not found: Column 'format1' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_after_filter - RuntimeError: not found: Column 'array(a, b)' not found. Available columns: [a, b, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_string - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_float_with_string - RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_groupby_context - RuntimeError: not found: Column 'array(name, age)' not found. Available columns: [age, dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_different_data_types - RuntimeError: not found: Column 'map()' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_join - RuntimeError: not found: Column 'array(name)' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_join_case_insensitive - RuntimeError: not found: ID

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_return - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_numeric_string_suffixes - AssertionError: id should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_dataframe - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value, upper]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_arithmetic - RuntimeError: not found: Column 'my_struct.withField(nested_product, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_after_filter - RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_and_create_map_equivalent - RuntimeError: not found: Column 'map_no_args' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_mixed_numeric_formats - AssertionError: Should be DoubleType (mixed numeric formats)
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
 +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_only_one_row - AssertionError: age should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_with_many_columns - AssertionError: col_0 should be LongType
assert False
 +  where False = isinstance(StringType(nullable=True), LongType)
 +    where StringType(nullable=True) = StructField(name='col_0', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_int64 - AssertionError: assert (1234, 'A', 'X') in {(1234, 'A', None), (4567, 'B', None)}
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_window_functions - RuntimeError: not found: Column 'array(value)' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_conditional - RuntimeError: not found: Column 'my_struct.withField(nested_status, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_outer_column - RuntimeError: not found: Column 'my_struct.withField(combined, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_withColumn - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_single_row - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_chained_operations - RuntimeError: not found: Column 'my_struct.withField(field1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_filter - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_orderBy - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_large_number_of_columns - RuntimeError: not found: Column 'array(col_0, col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9)' not found. Available columns: [col_0, col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_large_dataframe - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_with_left_on_right_on - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_multiple_keys_with_type_mismatch - RuntimeError: datatypes of join keys don't match - `key1`: i64 on left does not match `key1`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key1", "key2", "value_right"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_multiple_times - RuntimeError: not found: Column 'map1' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_union - RuntimeError: not found: Column 'map()' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_reference_other_nested - RuntimeError: not found: Column 'my_struct.withField(nested_sum, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_expressions - RuntimeError: not found: Column 'array(val, (val * 2))' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_nested_expressions - RuntimeError: not found: Column 'array(((a + b) * 2), (a - b), (a * b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_string - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_inferschema_parity.py::TestInferSchemaParity::test_csv_type_promotion_int_to_float - AssertionError: Should be DoubleType (mixed int/float)
assert False
 +  where False = isinstance(StringType(nullable=True), DoubleType)
 +    where StringType(nullable=True) = StructField(name='value', dataType=StringType(nullable=True), nullable=True).dataType
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_type_coercion_parity_pyspark - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_show - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_union - RuntimeError: not found: Column 'array(val)' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_zero_value - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_equals_substring_function - RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_operations - RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_multiply - RuntimeError: not found: Column 'percentile' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_empty_string - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_special_characters_in_column_names - RuntimeError: not found: Column 'array(col-name, col_name)' not found. Available columns: [col-name, col_name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_left_outer_with_type_mismatch - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_computed_columns - RuntimeError: not found: Column 'sum' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_chained_operations - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int64_string_inner - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_unicode - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rmul - RuntimeError: not found: Column 'percentile' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_join - RuntimeError: not found: Column 'map()' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_preserves_order - RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_add - RuntimeError: not found: Column 'row_plus_10' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_with_literal - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_multiple_columns_same_udf - RuntimeError: not found: Column 'udf(first)' not found. Available columns: [first, second]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_in_orderBy - RuntimeError: not found: Column 'udf(age)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_string_int64_inner - RuntimeError: datatypes of join keys don't match - `key`: str on left does not match `key`: i64 on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_select_operation - RuntimeError: not found: Column 'size' not found. Available columns: [values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_empty_strings - RuntimeError: not found: Column 'array(val1, val2)' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_filter_operation - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_zero_start - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_zero_and_negative_numbers - RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_all_join_types - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "right_val"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_radd - RuntimeError: not found: Column 'hundred_plus_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_explode_operation - RuntimeError: not found: Column 'value' not found. Available columns: [id, values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_subtract - RuntimeError: not found: Column 'zero_indexed' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_alias - RuntimeError: not found: Column 'first_two_chars' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_long_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_with_mixed_types - RuntimeError: not found: Column 'array(name, age, active, score)' not found. Available columns: [active, age, name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_withcolumn_operation - RuntimeError: not found: Column 'size(values)' not found. Available columns: [id, values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_double_precision_string - RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int_float_coercion - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: f64 on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rsub - RuntimeError: not found: Column 'ten_minus_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_pyspark_parity_comprehensive - RuntimeError: not found: Column 'result' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_groupBy_via_plan_interpreter - ModuleNotFoundError: No module named 'polars'
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_float_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_divide - RuntimeError: not found: Column 'row_half' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_null_values_in_join_keys - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_groupBy - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_cast_between_power - ModuleNotFoundError: No module named 'polars'
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_long_issue_243 - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110ef2010> ELSE <sparkless.functions.core.literals.Literal object at 0x110ef1490> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_window_row_number - ModuleNotFoundError: No module named 'polars'
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFCustomName::test_udf_with_custom_name - RuntimeError: not found: Column 'my_upper' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_invalid_numeric_strings - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rdiv - RuntimeError: not found: Column 'twelve_div_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_string - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b56bd0> ELSE <sparkless.functions.core.literals.Literal object at 0x110b54bd0> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFRegression279::test_udf_with_withColumn_regression_279 - RuntimeError: not found: Column 'udf(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_with_other_operations - RuntimeError: not found: Column 'upper_partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_int - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x1109b3e50> ELSE <sparkless.functions.core.literals.Literal object at 0x1109b1490> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_multiple_keys_complex - RuntimeError: datatypes of join keys don't match - `key1`: i64 on left does not match `key1`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key1", "key2", "other"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_negate - RuntimeError: not found: Column 'neg_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_left_on_right_on_different_names - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_very_long_string - RuntimeError: not found: Column 'first_100' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_chained_operations - RuntimeError: not found: Column 'score' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_double - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b56390> ELSE <sparkless.functions.core.literals.Literal object at 0x110b54a50> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_dense_rank_with_arithmetic - RuntimeError: not found: Column 'rank_score' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_mixed_numeric_strings - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_exceeds_length - RuntimeError: not found: Column 'beyond' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_multiple_when - RuntimeError: not found: Column 'CASE WHEN ((value == 1)) THEN low ELSE high END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_with_matched_condition - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_rank_with_arithmetic - RuntimeError: not found: Column 'rank_times_5' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_multiple_when_matched - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_scientific_notation_strings - RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start_exceeds_length - RuntimeError: not found: Column 'result' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_null_values - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b55f10> ELSE <sparkless.functions.core.literals.Literal object at 0x110b55310> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_after_join - assert 0 == 2
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_in_select - RuntimeError: not found: Column 'result' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_whitespace_in_string_keys - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeNotMatchedBySource::test_merge_delete_not_matched_by_source - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_ntile_with_arithmetic - RuntimeError: not found: Column 'percentile_group' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_nonexistent_table - AssertionError: Expected table not found error, got: failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.
assert ('not found' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'does not exist' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'table or view' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'cannot be found' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.')
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_filters - RuntimeError: not found: Column '(id % 2)' not found. Available columns: [id, name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_translate_edge_cases - RuntimeError: not found: Column 'm1' not found. Available columns: [s, t]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lag_with_arithmetic - RuntimeError: not found: Column 'diff' not found. Available columns: [date, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lead_with_arithmetic - RuntimeError: not found: Column 'diff' not found. Available columns: [date, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_nested_transformations - AssertionError: Expected result=20 for id=1, got None
assert None == ((1 * 10) * 2)
 +  where None = Row(id=1, name=a, result=None).result
 +  and   1 = Row(id=1, name=a, result=None).id
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_substring_index_edge_cases - RuntimeError: not found: Column 'p2' not found. Available columns: [n, s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_datatype_object - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x110b56750> ELSE <sparkless.functions.core.literals.Literal object at 0x110b554d0> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_all - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_long - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_sum_window_with_arithmetic - RuntimeError: not found: Column 'running_sum_div_100' not found. Available columns: [amount, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_complex_expressions - AssertionError: Unexpected computed value None for id=1
assert None in [25, 5]
 +  where None = Row(computed=None, id=1).computed
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_levenshtein_nulls_and_empty_strings - RuntimeError: not found: Column 'd' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_avg_window_with_arithmetic - RuntimeError: not found: Column 'double_avg' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_string - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_only_unmatched - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_soundex_null_and_empty - RuntimeError: not found: Column 'sx' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_double - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_multiple_joins - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Join execution failed: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_multiple_window_functions_with_arithmetic - RuntimeError: not found: Column 'row_times_10' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_no_matches - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_timestamp_core_units - RuntimeError: not found: Column 'year_trunc' not found. Available columns: [ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_with_nulls - RuntimeError: not found: Column 'row_times_2' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_select_expression_raises - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_left_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_crc32_known_values_and_null - RuntimeError: not found: Column 'c' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_partition - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(partitionBy(category), orderBy(value)))' not found. Available columns: [category, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_where_clause - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_sum - RuntimeError: not found: Column 'sum() OVER (WindowSpec(orderBy(id), rowsBetween(-9223372036854775808, 0)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_complex_nested_arithmetic - RuntimeError: not found: Column 'complex' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_raises_with_clear_message - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_xxhash64_known_values_and_null - RuntimeError: not found: Column 'h' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_on_date_column - RuntimeError: not found: Column 'year_trunc' not found. Available columns: [d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_regression_279.py::test_udf_with_withColumn_regression_279 - RuntimeError: not found: Column 'udf(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_like_clause.py::test_sql_like_simple_prefix_pattern - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_aggregation_after_join - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_date_trunc_polars_backend.py::TestDateTruncPolarsBackend::test_date_trunc_month_on_date_column - RuntimeError: not found: Column 'to_date(d)' not found. Available columns: [d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_filter - RuntimeError: not found: Column '(percent_rank() OVER (WindowSpec(partitionBy(dept), orderBy(salary))) * 100)' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_get_json_object_missing_path_and_invalid_json - RuntimeError: not found: Column 'a' not found. Available columns: [j]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_regexp_extract_all_189.py::test_regexp_extract_all_basic_groups - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_preserves_nulls - RuntimeError: not found: Column 'month_trunc' not found. Available columns: [ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_in_select - RuntimeError: not found: Column 'rank' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_self_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/session/test_sql_update.py::test_update_table_basic - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_datatype_object - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_orderby - RuntimeError: not found: Column '(-row_number() OVER (WindowSpec(orderBy(score))))' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_json_tuple_missing_fields_and_invalid_json - RuntimeError: not found: Column 'json_tuple(j, ...)' not found. Available columns: [j]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_create_table_as_select.py::test_create_table_as_select_basic - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: not found: Column 'IT' not found. Available columns: [age, dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_regexp_extract_all_multiple_matches_and_nulls - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
================= 399 failed, 636 passed, 13 skipped in 27.75s =================
Running parity tests (PySpark parity validation)...
  - DataFrame operations parity
  - Function operations parity
  - Join operations parity
  - SQL operations parity
  - Internal operations parity
============================= test session starts ==============================
platform darwin -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
cachedir: .pytest_cache
hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
rootdir: /Users/odosmatthews/Documents/coding/sparkless
configfile: pyproject.toml
plugins: anyio-4.11.0, cov-7.0.0, green-light-0.2.0, asyncio-1.2.0, xdist-3.8.0, timeout-2.4.0, hypothesis-6.148.7, alt-pytest-asyncio-0.9.3, async-sqlalchemy-0.2.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
timeout: 300.0s
timeout method: thread
timeout func_only: False
created: 10/10 workers
10 workers [249 items]

scheduling tests via LoadFileScheduling

tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_abs 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_row_number 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_contains 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_database 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_mean_cast_string_issue_265 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_upper 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_year 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_databases 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_inner_join <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_sum_aggregation 
[gw2] [  0%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_databases 
[gw7] [  0%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_database 
[gw4] [  1%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_mean_cast_string_issue_265 
[gw8] [  1%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_sum_aggregation 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_create_database_catalog 
[gw2] [  2%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_create_database_catalog 
[gw1] [  2%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_abs 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_database_if_not_exists 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_all_aggregate_functions_with_string_cast 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_avg_aggregation 
[gw3] [  2%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_row_number 
[gw8] [  3%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_avg_aggregation 
[gw0] [  3%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_upper 
[gw7] [  4%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_database_if_not_exists 
[gw9] [  4%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_year 
[gw5] [  4%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_contains 
[gw4] [  5%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_all_aggregate_functions_with_string_cast 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_to_different_types 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_count_aggregation 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_month 
[gw4] [  5%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_to_different_types 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_position 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_database 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_rank 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_drop_database_catalog 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_round 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lower 
[gw2] [  6%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_drop_database_catalog 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_set_current_database 
[gw7] [  6%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_database 
[gw8] [  6%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_count_aggregation 
[gw1] [  7%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_round 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_from_dataframe 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_null_values 
[gw4] [  7%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_null_values 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_max_aggregation 
[gw9] [  8%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_month 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofmonth 
[gw9] [  8%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofmonth 
[gw7] [  8%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_from_dataframe 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_with_select 
[gw5] [  9%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_position 
[gw7] [  9%] FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_with_select 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_size 
[gw3] [ 10%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_rank 
[gw6] [ 10%] FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_inner_join <- ../mock-spark/tests/parity/sql/test_advanced.py 
[gw2] [ 10%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_set_current_database 
[gw8] [ 11%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_max_aggregation 
[gw0] [ 11%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lower 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofweek 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sqrt 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_column_name_format 
[gw4] [ 12%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_column_name_format 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_length 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_table 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_min_aggregation 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_tables 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_dense_rank 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_left_join <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_multiple_casts_same_aggregate 
[gw0] [ 12%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_length 
[gw1] [ 12%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sqrt 
[gw8] [ 13%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_min_aggregation 
[gw2] [ 13%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_tables 
[gw4] [ 14%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_multiple_casts_same_aggregate 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substring 
[gw6] [ 14%] FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_left_join <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_pow 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_multiple_aggregations 
[gw8] [ 14%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_multiple_aggregations 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_tables_in_database 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_empty_groups 
[gw5] [ 15%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_size 
[gw3] [ 15%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_dense_rank 
[gw0] [ 16%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substring 
[gw9] [ 16%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofweek 
[gw1] [ 16%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_pow 
[gw7] [ 17%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_table 
[gw2] [ 17%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_tables_in_database 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_groupby_multiple_columns 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_add 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_order_by <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substr_method 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_table_if_exists 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_table_exists 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_sum_over_window 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_log 
[gw8] [ 18%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_groupby_multiple_columns 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_element_at 
[gw7] [ 18%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_table_if_exists 
[gw3] [ 18%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_sum_over_window 
[gw1] [ 19%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_log 
[gw9] [ 19%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_add 
[gw2] [ 20%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_table_exists 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_schema 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lag 
[gw5] [ 20%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_element_at 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_explode 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_global_aggregation 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_sub 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_exp 
[gw8] [ 20%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_global_aggregation 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_table_exists_in_database 
[gw7] [ 21%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_schema 
[gw4] [ 21%] FAILED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_empty_groups 
[gw2] [ 22%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_table_exists_in_database 
tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_aggregation_with_nulls 
[gw3] [ 22%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lag 
[gw5] [ 22%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_explode 
[gw8] [ 23%] PASSED tests/parity/dataframe/test_aggregations.py::TestAggregationsParity::test_aggregation_with_nulls 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_get_table 
[gw1] [ 23%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_exp 
[gw9] [ 24%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_sub 
[gw0] [ 24%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substr_method 
[gw2] [ 24%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_get_table 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_format 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_coalesce 
[gw6] [ 25%] FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_order_by <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_limit <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_get_table_in_database 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_column_astype_method 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lead 
[gw6] [ 25%] PASSED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_limit <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sin 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_set_current_database 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_different_numeric_types 
[gw4] [ 26%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_different_numeric_types 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_distinct 
[gw9] [ 26%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_format 
[gw8] [ 26%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_coalesce 
[gw1] [ 27%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sin 
[gw5] [ 27%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_distinct 
tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_to_date 
[gw2] [ 28%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_get_table_in_database 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnull 
[gw3] [ 28%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lead 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_having <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_join 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_chain_operations 
[gw4] [ 28%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_chain_operations 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_cache_table 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_cos 
[gw7] [ 29%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_set_current_database 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_cume_dist 
tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_table_in_specific_database 
[gw9] [ 29%] FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_to_date 
[gw2] [ 30%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_cache_table 
[gw7] [ 30%] PASSED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_table_in_specific_database 
[gw8] [ 30%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnull 
[gw5] [ 31%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_join 
[gw1] [ 31%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_cos 
[gw3] [ 32%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_cume_dist 
[gw6] [ 32%] PASSED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_having <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_count_distinct 
[gw4] [ 32%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_count_distinct 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnotnull 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_uncache_table 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_first_value 
[gw0] [ 33%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_column_astype_method 
tests/parity/dataframe/test_join.py::TestJoinParity::test_inner_join 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_tan 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_union <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_union 
tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_stddev_variance 
[gw4] [ 33%] PASSED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_stddev_variance 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_table 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_concat 
[gw1] [ 34%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_tan 
[gw8] [ 34%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnotnull 
[gw2] [ 34%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_uncache_table 
[gw3] [ 35%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_first_value 
[gw7] [ 35%] PASSED tests/parity/dataframe/test_join.py::TestJoinParity::test_inner_join 
[gw5] [ 36%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_union 
[gw0] [ 36%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_concat 
tests/parity/dataframe/test_join.py::TestJoinParity::test_left_join 
[gw6] [ 36%] PASSED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_union <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/internal/test_catalog.py::TestCatalogParity::test_is_cached 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_ceil 
tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_databases <- ../mock-spark/tests/parity/sql/test_show_describe.py 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_sort 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_when_otherwise 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_subquery <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_last_value 
[gw9] [ 37%] FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_table 
[gw7] [ 37%] PASSED tests/parity/dataframe/test_join.py::TestJoinParity::test_left_join 
[gw6] [ 38%] PASSED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_subquery <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_case_when <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_specific_columns 
[gw3] [ 38%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_last_value 
[gw2] [ 38%] PASSED tests/parity/internal/test_catalog.py::TestCatalogParity::test_is_cached 
tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_filter_comparison_operations_not_treated_as_column_existence 
[gw8] [ 39%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_when_otherwise 
[gw5] [ 39%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_sort 
tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_remove 
[gw4] [ 40%] PASSED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_databases <- ../mock-spark/tests/parity/sql/test_show_describe.py 
tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_tables <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw1] [ 40%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_ceil 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_floor 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_split 
tests/parity/dataframe/test_join.py::TestJoinParity::test_right_join 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_percent_rank 
[gw7] [ 40%] PASSED tests/parity/dataframe/test_join.py::TestJoinParity::test_right_join 
[gw4] [ 41%] PASSED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_tables <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw2] [ 41%] PASSED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_filter_comparison_operations_not_treated_as_column_existence 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nvl 
[gw9] [ 42%] FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_specific_columns 
[gw0] [ 42%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_split 
[gw5] [ 42%] FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_remove 
[gw1] [ 43%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_floor 
[gw3] [ 43%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_percent_rank 
[gw6] [ 44%] FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_case_when <- ../mock-spark/tests/parity/sql/test_advanced.py 
[gw8] [ 44%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nvl 
tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_filter_on_table_with_comparison_operations 
tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_tables_in_database <- ../mock-spark/tests/parity/sql/test_show_describe.py 
tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_sum_parity 
[gw5] [ 44%] PASSED tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_sum_parity 
tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_avg_parity 
[gw5] [ 45%] PASSED tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_avg_parity 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_like <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_ntile 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nullif 
tests/parity/dataframe/test_join.py::TestJoinParity::test_outer_join 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_regexp_extract 
[gw8] [ 45%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nullif 
[gw0] [ 46%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_regexp_extract 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_trim 
[gw0] [ 46%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_trim 
[gw7] [ 46%] PASSED tests/parity/dataframe/test_join.py::TestJoinParity::test_outer_join 
tests/parity/dataframe/test_join.py::TestJoinParity::test_cross_join 
[gw6] [ 47%] FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_like <- ../mock-spark/tests/parity/sql/test_advanced.py 
[gw7] [ 47%] PASSED tests/parity/dataframe/test_join.py::TestJoinParity::test_cross_join 
tests/parity/dataframe/test_join.py::TestJoinParity::test_semi_join 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_ltrim 
[gw2] [ 48%] FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_filter_on_table_with_comparison_operations 
tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_arithmetic_operations_in_filters 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_ifnull 
[gw8] [ 48%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_ifnull 
[gw4] [ 48%] PASSED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_tables_in_database <- ../mock-spark/tests/parity/sql/test_show_describe.py 
tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_table <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw4] [ 49%] PASSED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_table <- ../mock-spark/tests/parity/sql/test_show_describe.py 
tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_extended <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw4] [ 49%] PASSED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_extended <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw3] [ 50%] FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_ntile 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_multiple_values 
[gw9] [ 50%] FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_multiple_values 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_table 
tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_count_parity 
[gw5] [ 51%] PASSED tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_count_parity 
tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_max_parity 
[gw5] [ 51%] PASSED tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_max_parity 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_greatest 
[gw1] [ 51%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_greatest 
tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_least 
tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_in_clause <- ../mock-spark/tests/parity/sql/test_advanced.py 
tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_column <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw7] [ 52%] PASSED tests/parity/dataframe/test_join.py::TestJoinParity::test_semi_join 
tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_with_column 
[gw3] [ 52%] PASSED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_with_column 
tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_drop_column 
[gw3] [ 53%] PASSED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_drop_column 
tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_distinct 
[gw4] [ 53%] PASSED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_column <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw0] [ 53%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_ltrim 
[gw3] [ 54%] PASSED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_distinct 
tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nanvl 
[gw1] [ 54%] FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_least 
tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_min_parity 
tests/parity/dataframe/test_join.py::TestJoinParity::test_anti_join 
[gw5] [ 55%] PASSED tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_min_parity 
[gw6] [ 55%] PASSED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_in_clause <- ../mock-spark/tests/parity/sql/test_advanced.py 
[gw2] [ 55%] PASSED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_arithmetic_operations_in_filters 
[gw8] [ 56%] FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nanvl 
tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_complex_nested_operations_in_filters 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rtrim 
[gw2] [ 56%] PASSED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_complex_nested_operations_in_filters 
[gw0] [ 57%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rtrim 
[gw7] [ 57%] PASSED tests/parity/dataframe/test_join.py::TestJoinParity::test_anti_join 
tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_issue_266 
[gw9] [ 57%] FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_table 
tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_order_by 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lpad 
tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_issue_267_example 
[gw3] [ 58%] PASSED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_order_by 
tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_string_operations_in_filters 
tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_union 
tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_operations 
tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_columns <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw5] [ 58%] PASSED tests/parity/dataframe/test_pivot_grouped_data_parity.py::TestPivotGroupedDataParity::test_pivot_issue_267_example 
tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_sum 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_multiple_columns 
[gw8] [ 59%] PASSED tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_union 
[gw7] [ 59%] PASSED tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_sum 
tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_order_by_desc 
[gw4] [ 59%] PASSED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_columns <- ../mock-spark/tests/parity/sql/test_show_describe.py 
[gw1] [ 60%] PASSED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_operations 
tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_yyyy_mm_dd_format 
tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_with_boolean 
[gw1] [ 60%] PASSED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_with_boolean 
tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_union_all 
tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_avg 
[gw0] [ 61%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lpad 
[gw8] [ 61%] PASSED tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_union_all 
tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_parity 
[gw7] [ 61%] PASSED tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_avg 
[gw6] [ 62%] FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_issue_266 
[gw3] [ 62%] FAILED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_order_by_desc 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rpad 
tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_count 
tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_with_and_operator 
[gw1] [ 63%] PASSED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_with_and_operator 
tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_parity 
[gw6] [ 63%] PASSED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_parity 
tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_intersect 
tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_limit 
[gw7] [ 63%] PASSED tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_count 
[gw8] [ 64%] PASSED tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_intersect 
[gw3] [ 64%] PASSED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_limit 
tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_with_or_operator 
tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_except 
[gw0] [ 65%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rpad 
tests/parity/dataframe/test_column_subscript_parity.py::TestColumnSubscriptParity::test_column_subscript_single_field_parity 
[gw2] [ 65%] FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_string_operations_in_filters 
[gw1] [ 65%] PASSED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_with_or_operator 
[gw3] [ 66%] SKIPPED tests/parity/dataframe/test_column_subscript_parity.py::TestColumnSubscriptParity::test_column_subscript_single_field_parity 
tests/parity/dataframe/test_column_subscript_parity.py::TestColumnSubscriptParity::test_column_subscript_multiple_fields_parity 
[gw3] [ 66%] SKIPPED tests/parity/dataframe/test_column_subscript_parity.py::TestColumnSubscriptParity::test_column_subscript_multiple_fields_parity 
tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_logical_operations_in_filters 
tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_max 
tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_parity 
[gw4] [ 67%] FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_parity 
tests/parity/dataframe/test_column_subscript_parity.py::TestColumnSubscriptParity::test_column_subscript_equals_dot_notation_parity 
[gw3] [ 67%] SKIPPED tests/parity/dataframe/test_column_subscript_parity.py::TestColumnSubscriptParity::test_column_subscript_equals_dot_notation_parity 
tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_append_data_visible_immediately 
[gw8] [ 67%] PASSED tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_except 
[gw7] [ 68%] PASSED tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_max 
tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_1_parity 
[gw9] [ 68%] FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_multiple_columns 
tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_on_table_with_complex_schema 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_like 
tests/parity/dataframe/test_grouped_data_mean_parity.py::TestGroupedDataMeanParity::test_grouped_data_mean_single_column 
tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_min 
[gw8] [ 69%] PASSED tests/parity/dataframe/test_grouped_data_mean_parity.py::TestGroupedDataMeanParity::test_grouped_data_mean_single_column 
[gw7] [ 69%] PASSED tests/parity/functions/test_aggregate.py::TestAggregateFunctionsParity::test_agg_min 
tests/parity/dataframe/test_grouped_data_mean_parity.py::TestGroupedDataMeanParity::test_grouped_data_mean_multiple_columns 
[gw8] [ 69%] PASSED tests/parity/dataframe/test_grouped_data_mean_parity.py::TestGroupedDataMeanParity::test_grouped_data_mean_multiple_columns 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_delete_from_table 
[gw0] [ 70%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_like 
[gw5] [ 70%] FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_yyyy_mm_dd_format 
[gw3] [ 71%] FAILED tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_append_data_visible_immediately 
tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_basic_parity 
tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_mm_slash_dd_slash_yyyy_format 
[gw6] [ 71%] FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_parity 
[gw2] [ 71%] FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_logical_operations_in_filters 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rlike 
tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_append_to_new_table 
tests/parity/dataframe/test_grouped_data_mean_parity.py::TestGroupedDataMeanParity::test_grouped_data_mean_equals_avg 
[gw8] [ 72%] PASSED tests/parity/dataframe/test_grouped_data_mean_parity.py::TestGroupedDataMeanParity::test_grouped_data_mean_equals_avg 
tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_basic_select 
tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_without_rsd_parity 
[gw6] [ 72%] PASSED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_without_rsd_parity 
[gw0] [ 73%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rlike 
[gw4] [ 73%] FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_1_parity 
tests/parity/functions/test_cast_alias_select_parity.py::TestCastAliasSelectParity::test_cast_alias_select_basic_parity 
[gw8] [ 73%] PASSED tests/parity/functions/test_cast_alias_select_parity.py::TestCastAliasSelectParity::test_cast_alias_select_basic_parity 
tests/parity/functions/test_cast_alias_select_parity.py::TestCastAliasSelectParity::test_cast_alias_select_multiple_aggregations_parity 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_concat_ws 
tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_different_values_parity 
[gw8] [ 74%] PASSED tests/parity/functions/test_cast_alias_select_parity.py::TestCastAliasSelectParity::test_cast_alias_select_multiple_aggregations_parity 
tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_without_limit_parity 
[gw6] [ 74%] PASSED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_different_values_parity 
[gw7] [ 75%] FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_basic_parity 
tests/parity/functions/test_cast_alias_select_parity.py::TestCastAliasSelectParity::test_cast_alias_select_with_filter_parity 
[gw5] [ 75%] FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_mm_slash_dd_slash_yyyy_format 
tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_multiple_matches_parity 
[gw8] [ 75%] PASSED tests/parity/functions/test_cast_alias_select_parity.py::TestCastAliasSelectParity::test_cast_alias_select_with_filter_parity 
[gw0] [ 76%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_concat_ws 
tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_without_rsd_parity 
tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format 
tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_float_base_parity 
[gw2] [ 76%] PASSED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_basic_select 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_ascii 
[gw7] [ 77%] FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_multiple_matches_parity 
tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_left_parity 
tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_filtered_select 
[gw6] [ 77%] FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_without_rsd_parity 
[gw0] [ 77%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_ascii 
[gw3] [ 78%] PASSED tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_append_to_new_table 
[gw4] [ 78%] FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_without_limit_parity 
[gw2] [ 79%] PASSED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_filtered_select 
tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_orderby_ascending_true_parity 
[gw6] [ 79%] PASSED tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_orderby_ascending_true_parity 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_hex 
tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_group_by 
tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_multiple_append_operations 
tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_minus_one_parity 
[gw7] [ 79%] FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_left_parity 
tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_orderby_ascending_false_parity 
[gw5] [ 80%] FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format 
[gw6] [ 80%] PASSED tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_orderby_ascending_false_parity 
tests/parity/functions/test_window_function_comparison_parity.py::TestWindowFunctionComparisonParity::test_window_function_gt_comparison_parity 
[gw7] [ 81%] SKIPPED tests/parity/functions/test_window_function_comparison_parity.py::TestWindowFunctionComparisonParity::test_window_function_gt_comparison_parity 
[gw9] [ 81%] FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_delete_from_table 
tests/parity/functions/test_window_function_comparison_parity.py::TestWindowFunctionComparisonParity::test_window_function_eq_comparison_parity 
[gw7] [ 81%] SKIPPED tests/parity/functions/test_window_function_comparison_parity.py::TestWindowFunctionComparisonParity::test_window_function_eq_comparison_parity 
tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_without_format_string 
tests/parity/functions/test_window_function_comparison_parity.py::TestWindowFunctionComparisonParity::test_window_function_comparison_in_filter_parity 
[gw7] [ 82%] SKIPPED tests/parity/functions/test_window_function_comparison_parity.py::TestWindowFunctionComparisonParity::test_window_function_comparison_in_filter_parity 
tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_sort_with_ascending_parity 
tests/parity/dataframe/test_double_join_empty_aggregated.py::TestDoubleJoinEmptyAggregated::test_columns_preserved_in_double_join_with_empty_aggregated 
[gw6] [ 82%] PASSED tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_sort_with_ascending_parity 
[gw0] [ 83%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_hex 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_delete_all_rows 
tests/parity/dataframe/test_groupby.py::TestGroupByParity::test_group_by 
[gw8] [ 83%] FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_float_base_parity 
[gw6] [ 83%] PASSED tests/parity/dataframe/test_groupby.py::TestGroupByParity::test_group_by 
[gw2] [ 84%] PASSED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_group_by 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_base64 
[gw9] [ 84%] PASSED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_delete_all_rows 
[gw4] [ 85%] FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_minus_one_parity 
tests/parity/dataframe/test_groupby.py::TestGroupByParity::test_aggregation 
tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_natural_log_parity 
[gw6] [ 85%] PASSED tests/parity/dataframe/test_groupby.py::TestGroupByParity::test_aggregation 
[gw1] [ 85%] FAILED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_on_table_with_complex_schema 
[gw0] [ 86%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_base64 
tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_parity 
tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_from_select 
tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_aggregation 
[gw2] [ 86%] PASSED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_aggregation 
tests/parity/dataframe/test_select.py::TestSelectParity::test_basic_select 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_initcap 
[gw5] [ 87%] FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_without_format_string 
[gw1] [ 87%] PASSED tests/parity/dataframe/test_select.py::TestSelectParity::test_basic_select 
[gw7] [ 87%] FAILED tests/parity/dataframe/test_double_join_empty_aggregated.py::TestDoubleJoinEmptyAggregated::test_columns_preserved_in_double_join_with_empty_aggregated 
tests/parity/internal/test_session.py::TestSessionParity::test_createDataFrame_from_list_of_dicts 
[gw2] [ 88%] PASSED tests/parity/internal/test_session.py::TestSessionParity::test_createDataFrame_from_list_of_dicts 
tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_basic_parity 
[gw5] [ 88%] PASSED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_basic_parity 
tests/parity/functions/test_to_date_issue_126.py::TestToDateIssue126::test_issue_126_reproduction 
[gw3] [ 89%] PASSED tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_multiple_append_operations 
[gw0] [ 89%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_initcap 
[gw4] [ 89%] FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_parity 
tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_multiple_columns_parity 
tests/parity/internal/test_session.py::TestSessionParity::test_createDataFrame_with_explicit_schema 
tests/parity/dataframe/test_select.py::TestSelectParity::test_select_with_alias 
[gw2] [ 90%] PASSED tests/parity/internal/test_session.py::TestSessionParity::test_createDataFrame_with_explicit_schema 
tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_multiple_fields_parity 
tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_basic_parity 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_soundex 
[gw5] [ 90%] FAILED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_multiple_columns_parity 
[gw1] [ 91%] FAILED tests/parity/dataframe/test_select.py::TestSelectParity::test_select_with_alias 
[gw8] [ 91%] FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_natural_log_parity 
tests/parity/internal/test_session.py::TestSessionParity::test_createDataFrame_empty 
tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_partitionby_list_parity 
[gw2] [ 91%] PASSED tests/parity/internal/test_session.py::TestSessionParity::test_createDataFrame_empty 
[gw0] [ 92%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_soundex 
[gw5] [ 92%] PASSED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_partitionby_list_parity 
tests/parity/dataframe/test_select.py::TestSelectParity::test_column_access 
tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_different_bases_parity 
[gw1] [ 93%] PASSED tests/parity/dataframe/test_select.py::TestSelectParity::test_column_access 
[gw9] [ 93%] FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_from_select 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_translate 
[gw7] [ 93%] FAILED tests/parity/functions/test_to_date_issue_126.py::TestToDateIssue126::test_issue_126_reproduction 
[gw4] [ 94%] FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_multiple_fields_parity 
[gw0] [ 94%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_translate 
[gw3] [ 95%] FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_basic_parity 
tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_and_other_columns_parity 
tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_multiple_args_parity 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_levenshtein 
[gw8] [ 95%] FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_different_bases_parity 
[gw0] [ 95%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_levenshtein 
[gw4] [ 96%] FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_and_other_columns_parity 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_crc32 
[gw3] [ 96%] FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_multiple_args_parity 
[gw0] [ 97%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_crc32 
tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_with_null_parity 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_xxhash64 
[gw0] [ 97%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_xxhash64 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_get_json_object 
[gw3] [ 97%] FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_with_null_parity 
[gw0] [ 98%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_get_json_object 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_json_tuple 
[gw0] [ 98%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_json_tuple 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_substring_index 
[gw0] [ 99%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_substring_index 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_repeat 
[gw0] [ 99%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_repeat 
tests/parity/functions/test_string.py::TestStringFunctionsParity::test_reverse 
[gw0] [100%] FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_reverse 

==================================== ERRORS ====================================
_ ERROR collecting tests/parity/dataframe/test_parquet_format_table_append.py __
ImportError while importing test module '/Users/odosmatthews/Documents/coding/sparkless/tests/parity/dataframe/test_parquet_format_table_append.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
../../../.local/lib/python3.11/site-packages/_pytest/python.py:498: in importtestmodule
    mod = import_path(
../../../.local/lib/python3.11/site-packages/_pytest/pathlib.py:587: in import_path
    importlib.import_module(module_name)
../../../.pyenv/versions/3.11.13/lib/python3.11/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
<frozen importlib._bootstrap>:1204: in _gcd_import
    ???
<frozen importlib._bootstrap>:1176: in _find_and_load
    ???
<frozen importlib._bootstrap>:1147: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:690: in _load_unlocked
    ???
../../../.local/lib/python3.11/site-packages/_pytest/assertion/rewrite.py:186: in exec_module
    exec(co, module.__dict__)
tests/parity/dataframe/test_parquet_format_table_append.py:11: in <module>
    from sparkless.backend.polars.storage import PolarsStorageManager
sparkless/backend/polars/__init__.py:19: in <module>
    from .storage import PolarsStorageManager, PolarsTable, PolarsSchema
sparkless/backend/polars/storage.py:11: in <module>
    import polars as pl
E   ModuleNotFoundError: No module named 'polars'
=================================== FAILURES ===================================
____________________ TestMathFunctionsParity.test_math_abs _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:21: in test_math_abs
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestWindowOperationsParity.test_row_number __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:32: in test_row_number
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Numerical mismatch in column 'row_num' row 2: mock=2, expected=3, diff=1.0
E   Numerical mismatch in column 'row_num' row 3: mock=3, expected=2, diff=1.0
_________________ TestStringFunctionsParity.test_string_upper __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:21: in test_string_upper
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestDatetimeFunctionsParity.test_year _____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:21: in test_year
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestArrayFunctionsParity.test_array_contains _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:21: in test_array_contains
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestMathFunctionsParity.test_math_round ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:30: in test_math_round
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestDatetimeFunctionsParity.test_month ____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:30: in test_month
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestDatetimeFunctionsParity.test_dayofmonth __________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:39: in test_dayofmonth
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestArrayFunctionsParity.test_array_position _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:30: in test_array_position
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestSQLDDLParity.test_create_table_with_select ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/sql/test_ddl.py:102: in test_create_table_with_select
    assert result.count() == 2
E   assert 0 == 2
E    +  where 0 = count()
E    +    where count = DataFrame[0 rows, 0 columns].count
_____________________ TestWindowOperationsParity.test_rank _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:45: in test_rank
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Numerical mismatch in column 'rank' row 2: mock=1, expected=3, diff=2.0
E   Numerical mismatch in column 'rank' row 3: mock=1, expected=2, diff=1.0
________________ TestSQLAdvancedParity.test_sql_with_inner_join ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
/Users/odosmatthews/Documents/coding/mock-spark/tests/parity/sql/test_advanced.py:32: in test_sql_with_inner_join
    ???
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________________ TestStringFunctionsParity.test_string_lower __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:30: in test_string_lower
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestStringFunctionsParity.test_string_length _________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:39: in test_string_length
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestMathFunctionsParity.test_math_sqrt ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:39: in test_math_sqrt
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestSQLAdvancedParity.test_sql_with_left_join _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
/Users/odosmatthews/Documents/coding/mock-spark/tests/parity/sql/test_advanced.py:58: in test_sql_with_left_join
    ???
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________________ TestArrayFunctionsParity.test_size ______________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:39: in test_size
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestWindowOperationsParity.test_dense_rank __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:58: in test_dense_rank
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Numerical mismatch in column 'dense_rank' row 2: mock=1, expected=3, diff=2.0
E   Numerical mismatch in column 'dense_rank' row 3: mock=1, expected=2, diff=1.0
_______________ TestStringFunctionsParity.test_string_substring ________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:48: in test_string_substring
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestDatetimeFunctionsParity.test_dayofweek __________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:48: in test_dayofweek
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestMathFunctionsParity.test_math_pow _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:48: in test_math_pow
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______________ TestWindowOperationsParity.test_sum_over_window ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:73: in test_sum_over_window
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
____________________ TestMathFunctionsParity.test_math_log _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:57: in test_math_log
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestDatetimeFunctionsParity.test_date_add ___________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:57: in test_date_add
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestArrayFunctionsParity.test_element_at ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:48: in test_element_at
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ TestAggregateCastParity.test_cast_with_empty_groups ______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_aggregate_cast_parity.py:381: in test_cast_with_empty_groups
    result = filtered_df.groupby("group").agg(
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'A' not found. Available columns: [group, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ TestWindowOperationsParity.test_lag ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:86: in test_lag
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Value mismatch in column 'lag_salary' row 2: mock='IT', expected=55000
E   Value mismatch in column 'lag_salary' row 3: mock='IT', expected=50000
____________________ TestArrayFunctionsParity.test_explode _____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:57: in test_explode
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=9
____________________ TestMathFunctionsParity.test_math_exp _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:66: in test_math_exp
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestDatetimeFunctionsParity.test_date_sub ___________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:66: in test_date_sub
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ TestStringFunctionsParity.test_string_substr_method ______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:153: in to_robin_plan
    base_plan = _to_sparkless_plan(df)
                ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in to_logical_plan
    columns = [_serialize_select_column(c) for c in payload]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:330: in <listcomp>
    columns = [_serialize_select_column(c) for c in payload]
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:262: in _serialize_select_column
    return serialize_expression(col)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:132: in serialize_expression
    right = serialize_expression(val_side) if val_side is not None else None
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/logical_plan.py:226: in serialize_expression
    raise ValueError(f"Unsupported expression type for serialization: {type(expr)}")
E   ValueError: Unsupported expression type for serialization: <class 'tuple'>

During handling of the above exception, another exception occurred:
tests/parity/functions/test_string.py:62: in test_string_substr_method
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'partial_name' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestSQLAdvancedParity.test_sql_with_order_by _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
/Users/odosmatthews/Documents/coding/mock-spark/tests/parity/sql/test_advanced.py:74: in test_sql_with_order_by
    ???
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________________ TestDatetimeFunctionsParity.test_date_format _________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:75: in test_date_format
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestNullHandlingFunctionsParity.test_coalesce _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:21: in test_coalesce
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
____________________ TestMathFunctionsParity.test_math_sin _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:75: in test_math_sin
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestArrayFunctionsParity.test_array_distinct _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:73: in test_array_distinct
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________________ TestWindowOperationsParity.test_lead _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:99: in test_lead
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Value mismatch in column 'lead_salary' row 0: mock='IT', expected=55000
E   Null mismatch in column 'lead_salary' row 2: mock='IT', expected=None
E   Null mismatch in column 'lead_salary' row 3: mock=None, expected=70000
___________________ TestDatetimeFunctionsParity.test_to_date ___________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_datetime.py:84: in test_to_date
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestNullHandlingFunctionsParity.test_isnull __________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:30: in test_isnull
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
___________________ TestArrayFunctionsParity.test_array_join ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:82: in test_array_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestMathFunctionsParity.test_math_cos _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:84: in test_math_cos
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestWindowOperationsParity.test_cume_dist ___________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:112: in test_cume_dist
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_____________ TestStringFunctionsParity.test_column_astype_method ______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_string.py:84: in test_column_astype_method
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestMathFunctionsParity.test_math_tan _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:93: in test_math_tan
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestNullHandlingFunctionsParity.test_isnotnull ________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:39: in test_isnotnull
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_________________ TestWindowOperationsParity.test_first_value __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:125: in test_first_value
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
__________________ TestArrayFunctionsParity.test_array_union ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:91: in test_array_union
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestStringFunctionsParity.test_string_concat _________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:99: in test_string_concat
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestSQLDMLParity.test_insert_into_table ____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/sql/test_dml.py:33: in test_insert_into_table
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________________ TestWindowOperationsParity.test_last_value __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:138: in test_last_value
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_____________ TestNullHandlingFunctionsParity.test_when_otherwise ______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:48: in test_when_otherwise
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
___________________ TestArrayFunctionsParity.test_array_sort ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:100: in test_array_sort
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestMathFunctionsParity.test_math_ceil ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:102: in test_math_ceil
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
______________ TestSQLDMLParity.test_insert_into_specific_columns ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/sql/test_dml.py:53: in test_insert_into_specific_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________________ TestStringFunctionsParity.test_string_split __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:108: in test_string_split
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestArrayFunctionsParity.test_array_remove __________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array.py:109: in test_array_remove
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestMathFunctionsParity.test_math_floor ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:111: in test_math_floor
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestWindowOperationsParity.test_percent_rank _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:151: in test_percent_rank
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Null mismatch in column 'percent_rank' row 1: mock=nan, expected=0.0
E   Numerical mismatch in column 'percent_rank' row 2: mock=0.0, expected=1.0, diff=1.0
E   Numerical mismatch in column 'percent_rank' row 3: mock=0.0, expected=0.5, diff=0.5
________________ TestSQLAdvancedParity.test_sql_with_case_when _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
/Users/odosmatthews/Documents/coding/mock-spark/tests/parity/sql/test_advanced.py:188: in test_sql_with_case_when
    ???
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: select' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
___________________ TestNullHandlingFunctionsParity.test_nvl ___________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:57: in test_nvl
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_________________ TestNullHandlingFunctionsParity.test_nullif __________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:66: in test_nullif
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_____________ TestStringFunctionsParity.test_string_regexp_extract _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:117: in test_string_regexp_extract
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestStringFunctionsParity.test_string_trim __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:126: in test_string_trim
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestSQLAdvancedParity.test_sql_with_like ___________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
/Users/odosmatthews/Documents/coding/mock-spark/tests/parity/sql/test_advanced.py:206: in test_sql_with_like
    ???
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____ TestIsInstanceOrdering.test_filter_on_table_with_comparison_operations ____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_filter_isinstance_ordering.py:97: in test_filter_on_table_with_comparison_operations
    assert result1.count() == 2, "Should return 2 rows with status='active'"
           ^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'active' not found. Available columns: [id, score, status]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ TestNullHandlingFunctionsParity.test_ifnull __________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:75: in test_ifnull
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestWindowOperationsParity.test_ntile _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_window.py:164: in test_ntile
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_________________ TestSQLDMLParity.test_insert_multiple_values _________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/sql/test_dml.py:74: in test_insert_multiple_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________________ TestMathFunctionsParity.test_math_greatest __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:120: in test_math_greatest
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestStringFunctionsParity.test_string_ltrim __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:135: in test_string_ltrim
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestMathFunctionsParity.test_math_least ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_math.py:129: in test_math_least
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestNullHandlingFunctionsParity.test_nanvl __________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_null_handling.py:84: in test_nanvl
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestStringFunctionsParity.test_string_rtrim __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:144: in test_string_rtrim
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
______________________ TestSQLDMLParity.test_update_table ______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/sql/test_dml.py:99: in test_update_table
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'Alice' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestStringFunctionsParity.test_string_lpad __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:153: in test_string_lpad
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__ TestApproxCountDistinctRsdParity.test_approx_count_distinct_rsd_issue_266 ___
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_approx_count_distinct_rsd_parity.py:34: in test_approx_count_distinct_rsd_issue_266
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________________ TestTransformationsParity.test_order_by_desc _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_transformations.py:56: in test_order_by_desc
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
__________________ TestStringFunctionsParity.test_string_rpad __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:162: in test_string_rpad
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________ TestIsInstanceOrdering.test_string_operations_in_filters ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_filter_isinstance_ordering.py:216: in test_string_operations_in_filters
    assert result1.count() == 1, "Should return 1 row where name starts with 'A'"
           ^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________ TestSplitLimitParity.test_split_with_limit_parity _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_split_limit_parity.py:32: in test_split_with_limit_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'split(StringValue, ,, 3)' not found. Available columns: [Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestSQLDMLParity.test_update_multiple_columns _________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/sql/test_dml.py:125: in test_update_multiple_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'Alice' not found. Available columns: [name, age, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestStringFunctionsParity.test_string_like __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:171: in test_string_like
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________ TestToDateWithFormat.test_to_date_with_yyyy_mm_dd_format ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'to_date'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_to_date_format.py:48: in test_to_date_with_yyyy_mm_dd_format
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'to_date(date_of_birth, 'yyyy-MM-dd')' not found. Available columns: [id, name, date_of_birth]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestTableAppendPersistence.test_append_data_visible_immediately ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_table_append_persistence.py:28: in test_append_data_visible_immediately
    assert result1.count() == 1, "Initial table should have 1 row"
E   AssertionError: Initial table should have 1 row
E   assert 0 == 1
E    +  where 0 = count()
E    +    where count = DataFrame[0 rows, 2 columns].count
__ TestApproxCountDistinctRsdParity.test_approx_count_distinct_window_parity ___
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_approx_count_distinct_rsd_parity.py:107: in test_approx_count_distinct_window_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
__________ TestIsInstanceOrdering.test_logical_operations_in_filters ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_filter_isinstance_ordering.py:258: in test_logical_operations_in_filters
    assert result3.count() == 2, "Should return 2 rows where NOT (a == 20)"
           ^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_________________ TestStringFunctionsParity.test_string_rlike __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:180: in test_string_rlike
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ TestSplitLimitParity.test_split_with_limit_1_parity ______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_split_limit_parity.py:56: in test_split_with_limit_1_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'split(Value, ,, 1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestArrayContainsJoinParity.test_array_contains_join_basic_parity _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array_contains_join_parity.py:36: in test_array_contains_join_basic_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____ TestToDateWithFormat.test_to_date_with_mm_slash_dd_slash_yyyy_format _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'to_date'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_to_date_format.py:84: in test_to_date_with_mm_slash_dd_slash_yyyy_format
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'to_date(event_date, 'MM/dd/yyyy')' not found. Available columns: [id, event_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestStringFunctionsParity.test_concat_ws ___________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:189: in test_concat_ws
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestArrayContainsJoinParity.test_array_contains_join_multiple_matches_parity _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array_contains_join_parity.py:73: in test_array_contains_join_multiple_matches_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_ TestApproxCountDistinctRsdParity.test_approx_count_distinct_window_without_rsd_parity _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_approx_count_distinct_rsd_parity.py:196: in test_approx_count_distinct_window_without_rsd_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
_____________________ TestStringFunctionsParity.test_ascii _____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:198: in test_ascii
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ TestSplitLimitParity.test_split_without_limit_parity _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_split_limit_parity.py:77: in test_split_without_limit_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestArrayContainsJoinParity.test_array_contains_join_left_parity _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_array_contains_join_parity.py:110: in test_array_contains_join_left_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
____ TestToDateWithFormat.test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'to_date'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_to_date_format.py:114: in test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'to_date(event_date, 'dd-MM-yyyy')' not found. Available columns: [id, event_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestSQLDMLParity.test_delete_from_table ____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/sql/test_dml.py:152: in test_delete_from_table
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:542: in materialize
    raise SparkUnsupportedOperationError(
E   sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
E   Reason: Backend 'robin' does not support these operations
E   Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
______________________ TestStringFunctionsParity.test_hex ______________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:207: in test_hex
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________ TestLogFloatConstantParity.test_log_with_float_base_parity __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'log'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_log_float_constant_parity.py:30: in test_log_with_float_base_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestSplitLimitParity.test_split_with_limit_minus_one_parity __________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_split_limit_parity.py:101: in test_split_with_limit_minus_one_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestFilterParity.test_filter_on_table_with_complex_schema ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_filter.py:245: in test_filter_on_table_with_complex_schema
    ).saveAsTable(table_fqn)
      ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/writer.py:371: in saveAsTable
    self.storage.insert_data(schema, table, dict_data)
sparkless/backend/robin/storage.py:72: in insert_data
    self._file.insert_data(schema_name, table_name, data)
sparkless/storage/backends/file.py:394: in insert_data
    self.schemas[schema_name].tables[table_name].insert_data(data)
sparkless/storage/backends/file.py:100: in insert_data
    self._save_data(current_data)
sparkless/storage/backends/file.py:78: in _save_data
    json.dump(data, f, indent=2)
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:179: in dump
    for chunk in iterable:
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:430: in _iterencode
    yield from _iterencode_list(o, _current_indent_level)
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:326: in _iterencode_list
    yield from chunks
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:406: in _iterencode_dict
    yield from chunks
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:439: in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type datetime is not JSON serializable

During handling of the above exception, another exception occurred:
tests/parity/dataframe/test_filter.py:247: in test_filter_on_table_with_complex_schema
    df.write.format("parquet").mode("overwrite").saveAsTable(table_fqn)
sparkless/dataframe/writer.py:371: in saveAsTable
    self.storage.insert_data(schema, table, dict_data)
sparkless/backend/robin/storage.py:72: in insert_data
    self._file.insert_data(schema_name, table_name, data)
sparkless/storage/backends/file.py:394: in insert_data
    self.schemas[schema_name].tables[table_name].insert_data(data)
sparkless/storage/backends/file.py:100: in insert_data
    self._save_data(current_data)
sparkless/storage/backends/file.py:78: in _save_data
    json.dump(data, f, indent=2)
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:179: in dump
    for chunk in iterable:
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:430: in _iterencode
    yield from _iterencode_list(o, _current_indent_level)
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:326: in _iterencode_list
    yield from chunks
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:406: in _iterencode_dict
    yield from chunks
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:439: in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type datetime is not JSON serializable
____________________ TestStringFunctionsParity.test_base64 _____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:216: in test_base64
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________ TestToDateWithFormat.test_to_date_without_format_string ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'to_date' requires both left and right

During handling of the above exception, another exception occurred:
tests/parity/functions/test_to_date_format.py:141: in test_to_date_without_format_string
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'to_date(date_str)' not found. Available columns: [id, date_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestDoubleJoinEmptyAggregated.test_columns_preserved_in_double_join_with_empty_aggregated _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/dataframe/test_double_join_empty_aggregated.py:144: in test_columns_preserved_in_double_join_with_empty_aggregated
    rows = result3.collect()
           ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'concat(first_name,  , last_name)' not found. Available columns: [patient_id, first_name, last_name, age, age_group, gender, insurance_provider]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestStringFunctionsParity.test_initcap ____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:225: in test_initcap
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________ TestStructFieldAliasParity.test_struct_field_with_alias_parity ________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_struct_field_alias_parity.py:29: in test_struct_field_with_alias_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:201: in execute_robin_plan
    df = df.select(*cols)
         ^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestWindowOrderByListParity.test_window_orderby_list_multiple_columns_parity _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_window_orderby_list_parity.py:68: in test_window_orderby_list_multiple_columns_parity
    assert type_a_rows[0]["Score"] == 90  # Bob first (lower score)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert 100 == 90
___________________ TestSelectParity.test_select_with_alias ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/dataframe/test_select.py:29: in test_select_with_alias
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
____________ TestLogFloatConstantParity.test_log_natural_log_parity ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:79: in robin_expr_to_column
    raise ValueError(f"Robin op '{op}' requires both left and right")
E   ValueError: Robin op 'log' requires both left and right

During handling of the above exception, another exception occurred:
tests/parity/functions/test_log_float_constant_parity.py:56: in test_log_natural_log_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'Ln' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestStringFunctionsParity.test_soundex ____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:234: in test_soundex
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestSQLDMLParity.test_insert_from_select ___________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/session/sql/executor.py:131: in execute
    return self._execute_insert(ast)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:1626: in _execute_insert
    for row in select_df.collect():
               ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:197: in execute_robin_plan
    df = df.filter(expr)
         ^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'IT' not found. Available columns: [name, age, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).

During handling of the above exception, another exception occurred:
tests/parity/sql/test_dml.py:196: in test_insert_from_select
    spark.sql(
sparkless/session/core/session.py:331: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:352: in _real_sql
    return self._sql_executor.execute(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/sql/executor.py:150: in execute
    raise QueryExecutionException(f"Failed to execute query: {str(e)}")
E   sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: not found: Column 'IT' not found. Available columns: [name, age, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestToDateIssue126.test_issue_126_reproduction ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:230: in execute_robin_plan
    expr = robin_expr_to_column(expr_p)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'to_date'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_to_date_issue_126.py:54: in test_issue_126_reproduction
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'to_date(date_of_birth, 'yyyy-MM-dd')' not found. Available columns: [id, name, date_of_birth]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestStructFieldAliasParity.test_struct_field_with_alias_multiple_fields_parity _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_struct_field_alias_parity.py:56: in test_struct_field_with_alias_multiple_fields_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:201: in execute_robin_plan
    df = df.select(*cols)
         ^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestStringFunctionsParity.test_translate ___________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:243: in test_translate
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________ TestFormatStringParity.test_format_string_basic_parity ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_format_string_parity.py:32: in test_format_string_basic_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'format_string('%s-%s', StringValue, IntegerValue)' not found. Available columns: [IntegerValue, Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestLogFloatConstantParity.test_log_with_different_bases_parity ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in execute_robin_plan
    cols = [robin_expr_to_column(c) for c in columns]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:200: in <listcomp>
    cols = [robin_expr_to_column(c) for c in columns]
            ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:125: in robin_expr_to_column
    raise ValueError(f"Unsupported Robin plan op: {op!r}")
E   ValueError: Unsupported Robin plan op: 'log'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_log_float_constant_parity.py:77: in test_log_with_different_bases_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:917: in materialize
    df = df.select(*robin_cols)
         ^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestStringFunctionsParity.test_levenshtein __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:252: in test_levenshtein
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestStructFieldAliasParity.test_struct_field_with_alias_and_other_columns_parity _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_struct_field_alias_parity.py:88: in test_struct_field_with_alias_and_other_columns_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:601: in materialize
    rows = use_plan(df.data, df.schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/materializer.py:838: in materialize_from_plan
    return execute_robin_plan(data, schema, logical_plan)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/backend/robin/plan_executor.py:201: in execute_robin_plan
    df = df.select(*cols)
         ^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestFormatStringParity.test_format_string_multiple_args_parity ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_format_string_parity.py:65: in test_format_string_multiple_args_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'format_string('%s is %d years old and lives in %s', Name, Age, City)' not found. Available columns: [Age, City, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ TestStringFunctionsParity.test_crc32 _____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:261: in test_crc32
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestStringFunctionsParity.test_xxhash64 ____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:270: in test_xxhash64
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________ TestFormatStringParity.test_format_string_with_null_parity __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
sparkless/dataframe/lazy.py:592: in materialize
    logical_plan = to_robin_plan(df)
                   ^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:160: in to_robin_plan
    robin_payload = _convert_payload(op_name, payload)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:131: in _convert_payload
    return {"name": name, "expression": _expr_to_robin(expr)}
                                        ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/robin_plan.py:94: in _expr_to_robin
    raise ValueError(f"Unsupported expression kind for Robin plan: {expr_type!r}")
E   ValueError: Unsupported expression kind for Robin plan: 'opaque'

During handling of the above exception, another exception occurred:
tests/parity/functions/test_format_string_parity.py:91: in test_format_string_with_null_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:626: in materialize
    rows = materializer.materialize(
sparkless/backend/robin/materializer.py:1005: in materialize
    df = df.with_column(col_name, robin_expr)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   RuntimeError: not found: Column 'format_string('%s-%s', Value, Number)' not found. Available columns: [Name, Number, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestStringFunctionsParity.test_get_json_object ________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:281: in test_get_json_object
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestStringFunctionsParity.test_json_tuple ___________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:292: in test_json_tuple
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestStringFunctionsParity.test_substring_index ________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:301: in test_substring_index
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestStringFunctionsParity.test_repeat _____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:310: in test_repeat
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestStringFunctionsParity.test_reverse ____________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
tests/parity/functions/test_string.py:319: in test_reverse
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.11.13-final-0 _______________

Name                                                                 Stmts   Miss  Cover   Missing
--------------------------------------------------------------------------------------------------
sparkless/__init__.py                                                   24      0   100%
sparkless/_version.py                                                    8      4    50%   10-12, 16-19
sparkless/backend/__init__.py                                            3      0   100%
sparkless/backend/factory.py                                            72     33    54%   45, 50, 79, 84, 104-115, 135-157, 176, 190-191
sparkless/backend/polars/__init__.py                                     4      3    25%   20-23
sparkless/backend/polars/_over_compat.py                                19     19     0%   8-40
sparkless/backend/polars/executors/__init__.py                           1      1     0%   13
sparkless/backend/polars/export.py                                      36     36     0%   7-114
sparkless/backend/polars/expression_translator.py                     2172   2172     0%   8-5251
sparkless/backend/polars/materializer.py                               852    852     0%   8-1944
sparkless/backend/polars/operation_executor.py                        2047   2047     0%   1-4555
sparkless/backend/polars/parquet_storage.py                             41     41     0%   8-119
sparkless/backend/polars/plan_interpreter.py                           381    381     0%   8-531
sparkless/backend/polars/schema_registry.py                             73     73     0%   8-222
sparkless/backend/polars/schema_utils.py                                31     31     0%   3-69
sparkless/backend/polars/storage.py                                    350    346     1%   13-771
sparkless/backend/polars/translators/__init__.py                         1      1     0%   14
sparkless/backend/polars/translators/arithmetic_translator.py           17     17     0%   8-70
sparkless/backend/polars/translators/string_translator.py              145    145     0%   8-302
sparkless/backend/polars/translators/type_translator.py                107    107     0%   8-190
sparkless/backend/polars/type_mapper.py                                 99     99     0%   8-173
sparkless/backend/polars/window_handler.py                             290    290     0%   7-563
sparkless/backend/protocols.py                                          14      0   100%
sparkless/backend/robin/__init__.py                                      4      0   100%
sparkless/backend/robin/export.py                                       46     34    26%   20-29, 36, 41-50, 55-62, 71-77, 80-85
sparkless/backend/robin/materializer.py                                714    359    50%   44-45, 62-64, 75-79, 88-89, 108, 128, 141, 147, 152, 155, 158, 172, 175-176, 182, 195, 209, 213, 228, 230-238, 247-249, 266, 273, 275-277, 281-282, 287, 293-308, 312-313, 317, 324-325, 330-331, 334, 342-343, 361-362, 364-365, 370-371, 376, 378, 380, 382, 388-692, 731, 746, 750-753, 758-762, 766, 771, 776-777, 796, 847, 853, 861-864, 873-877, 907-911, 919, 931, 943, 952-1001, 1024, 1029, 1043-1049, 1069
sparkless/backend/robin/plan_executor.py                               191     64    66%   18-19, 30-32, 43, 50, 55, 68-75, 82-89, 92-97, 127, 142, 154, 160-163, 171-175, 186, 190, 195, 205, 215, 217, 221, 227, 229, 235, 239-249, 258-260, 263
sparkless/backend/robin/storage.py                                      52      5    90%   27, 33, 77, 94, 99
sparkless/compat/__init__.py                                             2      0   100%
sparkless/compat/datetime.py                                            74     53    28%   43, 55-57, 61-67, 73-81, 96-103, 115-122, 128-133, 141-146, 162-182
sparkless/config.py                                                     55     17    69%   46-58, 64-65, 69, 77-81, 90-91, 106
sparkless/core/__init__.py                                               9      0   100%
sparkless/core/column_resolver.py                                       33     11    67%   48, 72-73, 105-116, 139
sparkless/core/condition_evaluator.py                                  764    730     4%   27-34, 49-56, 71-245, 260-541, 556-576, 591-604, 619-781, 795-1203, 1218-1229, 1245-1274, 1290-1311, 1324-1340, 1353, 1366-1370, 1384-1403
sparkless/core/data_validation.py                                       80     41    49%   56-85, 91-113, 129, 136-137, 177-185, 205-206, 220-221
sparkless/core/ddl_adapter.py                                           31     12    61%   93-106
sparkless/core/exceptions/__init__.py                                    6      0   100%
sparkless/core/exceptions/analysis.py                                  100     81    19%   37-63, 70-73, 91, 109, 137-162, 170-202, 230-245, 269-272, 302-323
sparkless/core/exceptions/base.py                                       22      4    82%   31, 61, 76, 91
sparkless/core/exceptions/execution.py                                  29     12    59%   45, 63, 87-90, 114-117, 135, 153
sparkless/core/exceptions/operation.py                                  87     55    37%   24-34, 49-58, 72-82, 96-106, 120-129, 152, 173-183
sparkless/core/exceptions/py4j_compat.py                                10     10     0%   8-41
sparkless/core/exceptions/runtime.py                                    41     25    39%   27, 53-57, 75, 101-107, 131-134, 158-161, 187-193
sparkless/core/exceptions/validation.py                                 44     26    41%   27, 45, 63, 81, 107-111, 141-147, 171-174, 202-207
sparkless/core/interfaces/__init__.py                                    5      0   100%
sparkless/core/interfaces/dataframe.py                                 180     56    69%   20, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 98, 103, 110, 115, 120, 125, 130, 136, 142, 151, 156, 161, 166, 171, 176, 181, 190, 195, 200, 205, 212, 217, 222, 227, 232, 241, 246, 251, 256, 261, 266, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320
sparkless/core/interfaces/functions.py                                 186     56    70%   23, 28, 33, 42, 47, 56, 61, 70, 75, 84, 89, 94, 99, 108, 113, 118, 123, 130, 135, 144, 149, 154, 159, 164, 173, 178, 185, 192, 197, 202, 207, 212, 221, 226, 231, 236, 241, 250, 255, 263, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 333, 338, 343, 348
sparkless/core/interfaces/session.py                                   117     34    71%   20, 26, 32, 38, 44, 50, 59, 64, 69, 76, 81, 86, 96, 101, 106, 115, 120, 125, 136, 141, 146, 151, 156, 161, 166, 171, 176, 185, 190, 195, 200, 209, 214, 219
sparkless/core/interfaces/storage.py                                   126     38    70%   29, 34, 39, 44, 54, 59, 64, 69, 76, 83, 90, 97, 102, 106, 110, 114, 120, 126, 136, 142, 148, 153, 158, 163, 168, 173, 186, 192, 198, 204, 210, 215, 220, 229, 234, 239, 248, 253
sparkless/core/protocols.py                                             42      0   100%
sparkless/core/safe_evaluator.py                                       125     83    34%   45-50, 66-67, 86, 88, 90, 95, 97-103, 105-134, 145-147, 150-152, 157-164, 169, 171, 173, 176-179, 184-215
sparkless/core/schema_inference.py                                     107     36    66%   73, 83-84, 99, 111, 132, 158, 167, 187-200, 218-237, 242-251, 256-265, 297, 307
sparkless/core/type_utils.py                                            86     56    35%   20-21, 91-93, 116-121, 140-144, 164-168, 187-199, 223-259, 278, 290-292, 304
sparkless/core/types/__init__.py                                         4      0   100%
sparkless/core/types/data_types.py                                     139     38    73%   22, 27, 32, 37, 42, 47, 52, 57, 66, 76, 81, 91, 97, 102, 111, 121, 127, 132, 141, 146, 155, 160, 170, 175, 180, 190, 196, 201, 206, 211, 221, 226, 231, 240, 249, 254, 259, 264
sparkless/core/types/metadata.py                                       166     47    72%   18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 73, 79, 85, 91, 97, 103, 108, 113, 118, 128, 134, 140, 145, 150, 160, 166, 172, 177, 182, 187, 197, 203, 209, 215, 220, 225, 230, 239, 244, 249, 254, 259, 268, 273, 278, 283, 288
sparkless/core/types/schema.py                                         121     36    70%   22, 28, 34, 40, 45, 50, 55, 60, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 185, 190, 195, 200, 209, 214, 221, 226
sparkless/data_generation/__init__.py                                    4      4     0%   8-12
sparkless/data_generation/builder.py                                    28     28     0%   8-85
sparkless/data_generation/convenience.py                                 9      9     0%   8-64
sparkless/data_generation/generator.py                                 174    174     0%   8-337
sparkless/dataframe/__init__.py                                          6      0   100%
sparkless/dataframe/aggregations/__init__.py                             2      2     0%   8-10
sparkless/dataframe/aggregations/operations.py                          75     75     0%   8-208
sparkless/dataframe/assertions/__init__.py                               3      3     0%   7-10
sparkless/dataframe/assertions/assertions.py                            26     26     0%   8-88
sparkless/dataframe/assertions/operations.py                            16     16     0%   8-45
sparkless/dataframe/attribute_handler.py                                62     30    52%   30, 54, 77-85, 116-125, 176, 190-196, 213-217, 223-224
sparkless/dataframe/casting/__init__.py                                  2      0   100%
sparkless/dataframe/casting/type_converter.py                           95     75    21%   54, 56-58, 62-153, 158-180
sparkless/dataframe/collection_handler.py                               29     17    41%   27-29, 35-41, 47-53, 68-72, 81
sparkless/dataframe/condition_handler.py                                52     34    35%   58-64, 80, 109-122, 136-180
sparkless/dataframe/dataframe.py                                       513    211    59%   187-191, 219-224, 240-243, 262-265, 280, 305, 317, 325, 339, 345, 373, 377, 381, 390, 394, 420, 424, 432, 440, 453, 457, 469-477, 486, 490, 507-508, 518-532, 551, 555-561, 565, 569, 596-609, 621, 625, 630, 634, 638, 642, 652, 674, 689-691, 700, 709, 715, 719, 723, 727, 733, 742, 746, 750, 756, 760, 770, 780, 791, 795, 799, 803, 809, 813, 817, 821, 829, 835, 839, 843, 847, 852, 856, 860, 864, 875, 894, 899, 960-969, 997, 1002, 1021-1026, 1041-1052, 1062, 1078-1097, 1103, 1128, 1152-1153, 1161-1162, 1195, 1201-1206, 1210, 1216, 1225, 1250, 1258, 1269, 1284, 1292, 1303, 1311, 1323, 1329, 1335, 1342, 1347-1353, 1368-1379, 1383, 1403-1411, 1420-1460
sparkless/dataframe/display/__init__.py                                  3      3     0%   3-6
sparkless/dataframe/display/formatter.py                                37     37     0%   3-57
sparkless/dataframe/display/operations.py                              118    118     0%   8-274
sparkless/dataframe/evaluation/__init__.py                               2      0   100%
sparkless/dataframe/evaluation/evaluators/__init__.py                    1      0   100%
sparkless/dataframe/evaluation/evaluators/conditional_evaluator.py      22     15    32%   35-63
sparkless/dataframe/evaluation/expression_evaluator.py                2615   2358    10%   96, 99, 103, 106-113, 117-122, 128-130, 134, 145-146, 150, 154, 160-181, 193-259, 269-300, 306-416, 422-448, 458-1021, 1027-1066, 1072-1257, 1263-1340, 1347-1385, 1391-1442, 1448-1534, 1539-1555, 1562-1574, 1578-1593, 1597-1612, 1616-1631, 1635-1650, 1661-1666, 1670-1693, 1697, 1944, 1948, 1952-1956, 1960-1964, 1968-1972, 1976-1989, 1993-2000, 2004-2014, 2018-2028, 2032-2034, 2040-2043, 2047-2050, 2054-2061, 2065-2070, 2085-2143, 2147-2152, 2163-2207, 2211-2222, 2226-2234, 2240-2242, 2246-2251, 2255-2257, 2261-2263, 2269, 2273-2279, 2283, 2287-2292, 2296-2298, 2302-2304, 2308, 2312, 2316, 2324, 2328, 2332-2335, 2339-2341, 2345-2350, 2354-2357, 2361-2373, 2380, 2384-2416, 2420-2425, 2429-2451, 2455-2477, 2483-2499, 2503-2534, 2540-2575, 2581-2588, 2592-2612, 2616-2659, 2663-2680, 2684-2697, 2702, 2706-2707, 2711, 2715, 2719, 2725-2734, 2738-2747, 2751-2758, 2764, 2768-2782, 2786-2793, 2797-2811, 2815-2822, 2826-2833, 2837-2844, 2848-2857, 2861-2870, 2874-2883, 2887-2894, 2898-2905, 2909-2916, 2920-2927, 2931-2938, 2944, 2948-2957, 2962, 2967, 2972-3004, 3008-3017, 3023, 3029, 3033-3044, 3050, 3057, 3062, 3068, 3073-3097, 3102, 3107, 3112, 3121-3153, 3157-3201, 3205-3249, 3253-3280, 3285-3306, 3314-3376, 3380-3387, 3391-3411, 3417, 3423, 3427-3542, 3547-3558, 3562-3571, 3575, 3579, 3583, 3587, 3591, 3595, 3599, 3603-3608, 3612-3618, 3622-3627, 3631-3636, 3645, 3659-3693, 3699, 3703-3710, 3714-3725, 3730-3739, 3745-3754, 3760-3765, 3771-3776, 3782-3790, 3796-3804, 3808, 3812-3818, 3822-3833, 3837-3840, 3844-3850, 3854-3856, 3861, 3866-3878, 3882, 3886-3892, 3896-3902, 3908-3918, 3922-3929, 3934, 3938-3940, 3944-3967, 3971-3994, 3999, 4004, 4009, 4014, 4019, 4024, 4028-4040, 4046-4053, 4059-4066, 4070-4079, 4085-4092, 4098-4105, 4111-4118, 4126-4140, 4144-4151, 4155-4162, 4167-4182, 4186-4201, 4221, 4226, 4231, 4237-4248, 4255-4258, 4264-4267, 4273-4278, 4283-4287, 4291-4308, 4314-4329, 4335-4350, 4356-4359, 4363-4365, 4370-4378, 4384-4411, 4416-4425, 4429-4431, 4435-4437, 4442-4461, 4465-4482, 4486-4503, 4507-4524, 4528-4533, 4539-4550, 4554-4565, 4569-4574
sparkless/dataframe/export.py                                           15     15     0%   8-46
sparkless/dataframe/grouped/__init__.py                                  5      0   100%
sparkless/dataframe/grouped/base.py                                   1064    737    31%   93, 95, 101-145, 181, 188, 192-196, 271, 302-307, 314-322, 328, 347, 357-389, 406-422, 439-442, 465-466, 515-516, 554-600, 609-624, 657-689, 711-722, 736-765, 802, 805-808, 810-811, 841-844, 851, 853-856, 873, 875-878, 880-881, 911-914, 921, 923-926, 954-955, 960-966, 981-982, 987-993, 995-1001, 1003-1009, 1011-1027, 1029-1035, 1046, 1050-1069, 1072-1089, 1100, 1103-1121, 1123-1143, 1145-1151, 1153-1159, 1162-1175, 1178-1191, 1195-1250, 1253-1259, 1267, 1269-1272, 1302-1647, 1664-1934, 1945-1952, 1964, 2003-2007, 2018-2025, 2036-2043, 2054-2063, 2074-2083, 2094-2103, 2114-2123, 2134-2143, 2154-2163, 2174-2201, 2212-2239, 2268, 2272-2279, 2303-2370, 2392-2447
sparkless/dataframe/grouped/cube.py                                     86     77    10%   30-31, 47-215
sparkless/dataframe/grouped/pivot.py                                   493    347    30%   97-119, 122, 127-184, 205-215, 229-230, 236-237, 243, 249-254, 256-328, 356, 362-397, 420, 422-425, 435, 437-440, 449-450, 467-641, 649-810, 825, 845, 862, 878-882, 896, 916, 933-939, 950-956, 967-973, 984-990, 1001-1007, 1018-1024, 1035-1041
sparkless/dataframe/grouped/rollup.py                                   87     79     9%   29-30, 48-220
sparkless/dataframe/joins/__init__.py                                    2      2     0%   8-10
sparkless/dataframe/joins/operations.py                                146    146     0%   8-396
sparkless/dataframe/lazy.py                                           1222   1047    14%   47-73, 106-108, 120-153, 167-173, 188-258, 271-301, 313-337, 352-388, 402-415, 433-447, 453-489, 495-504, 517-519, 523, 562-563, 581-582, 594-600, 603, 607-611, 617-621, 630-642, 645, 649-655, 668, 692-704, 727-734, 775-829, 839-922, 956, 966, 980-991, 1013, 1016, 1021, 1025, 1028, 1072-1075, 1080, 1085, 1095-1099, 1105, 1112-1123, 1128-1129, 1134-1135, 1157-2251, 2264-2525, 2538-2594, 2609-2837, 2853-2865
sparkless/dataframe/logical_plan.py                                    223     90    60%   23-33, 73, 78-85, 105-112, 120-123, 130, 172-180, 184-201, 205-211, 232, 249-254, 271-294, 310, 317-318, 402-407, 415-416, 425, 430-454
sparkless/dataframe/operations/__init__.py                               2      0   100%
sparkless/dataframe/operations/aggregation_operations.py               128    128     0%   3-313
sparkless/dataframe/operations/join_operations.py                      157    157     0%   3-329
sparkless/dataframe/operations/misc.py                                 516    472     9%   56-77, 103-145, 167-215, 236-250, 267-308, 323-407, 421-501, 518-549, 566-593, 615-630, 643-659, 678-685, 710-742, 770-831, 863-922, 949-986, 1023-1074, 1082-1113, 1117-1135, 1149-1176, 1191-1196, 1216, 1232-1234, 1248-1255, 1266-1267, 1276, 1295-1304, 1323-1324, 1340-1345, 1353, 1366-1369, 1377, 1382, 1391-1392, 1401, 1415-1427
sparkless/dataframe/operations/set_operations.py                       168    149    11%   28-94, 99, 121-145, 160-290, 296-316, 322-339, 344-346
sparkless/dataframe/protocols.py                                        49      0   100%
sparkless/dataframe/rdd.py                                              83     56    33%   26, 34, 42, 53, 61, 69-70, 81, 92-95, 106, 117-125, 136-143, 155-166, 174, 185, 193, 201, 209, 217, 229, 240-243, 254-261, 269, 277
sparkless/dataframe/reader.py                                          187    156    17%   64-67, 81-82, 97-98, 112-113, 127-136, 158-190, 206-259, 266-277, 281-288, 294-306, 311-321, 326-349, 354-374, 377-382, 386-390, 396-402, 406, 410, 414, 429, 444, 461-463
sparkless/dataframe/robin_plan.py                                       78      9    88%   54, 57, 61, 68, 111, 119, 128, 130, 159
sparkless/dataframe/schema/__init__.py                                   3      0   100%
sparkless/dataframe/schema/operations.py                                22      9    59%   23-31, 39-41, 46, 51
sparkless/dataframe/schema/schema_manager.py                           514    312    39%   49-75, 93, 109-111, 128-130, 136-151, 227-258, 284, 288-327, 356, 361, 378-401, 406, 438-474, 482, 484, 486-487, 489, 491, 493, 507, 509-510, 514-517, 523, 527-617, 627-639, 668-670, 692-715, 720-735, 745, 747, 763-764, 768-771, 777, 788-798, 803-839, 843-846, 850-853, 857-875, 879-887, 905-909, 916-919, 922-930, 944, 952-967, 975-978, 989, 991, 993, 995, 997, 1000-1019
sparkless/dataframe/services/__init__.py                                 8      0   100%
sparkless/dataframe/services/aggregation_service.py                     99     68    31%   29-39, 69, 126-154, 174-202, 224-250
sparkless/dataframe/services/assertion_service.py                       17      8    53%   25-27, 33-35, 41-43, 49-51
sparkless/dataframe/services/display_service.py                        126    102    19%   39-101, 120-167, 171-174, 182-186, 195-204, 208-223, 227-232, 238-240, 244-250, 264-267, 280, 292-297
sparkless/dataframe/services/join_service.py                           248    166    33%   114, 129, 168-443, 460, 510-534, 606-628
sparkless/dataframe/services/misc_service.py                           613    565     8%   56-73, 84-124, 159-282, 304-352, 373-400, 417-458, 476-560, 574-654, 669-720, 737-780, 802-817, 830-846, 865-872, 897-929, 955-1016, 1048-1126, 1153-1190, 1227-1277, 1285-1318, 1322-1340, 1354-1381, 1396-1401, 1419, 1435-1437, 1451-1458, 1469-1472, 1481, 1499-1503, 1518, 1529-1534, 1540, 1551-1554, 1562, 1567, 1576-1577, 1586, 1600-1612
sparkless/dataframe/services/schema_service.py                           4      0   100%
sparkless/dataframe/services/transformation_service.py                 349    219    37%   57-60, 70-71, 83, 93, 100, 150, 157, 175-191, 198-202, 224, 246-247, 251-266, 271-275, 283-289, 293, 308-315, 330-460, 476-478, 499, 510, 533-543, 559, 595-624, 643-661, 670-697, 713, 730, 751, 771-775, 779, 783, 811-870, 890-910
sparkless/dataframe/transformations/__init__.py                          2      2     0%   8-10
sparkless/dataframe/transformations/operations.py                      224    224     0%   8-629
sparkless/dataframe/types.py                                             8      8     0%   8-25
sparkless/dataframe/validation/__init__.py                               2      0   100%
sparkless/dataframe/validation/column_validator.py                     171     78    54%   34, 36, 94-115, 137, 141-161, 164-165, 185-198, 218, 245-289, 332, 337, 343, 348, 357, 375, 385-392, 401, 422, 429, 440, 461, 473, 485, 494, 508-517, 533-578
sparkless/dataframe/validation_handler.py                               21      2    90%   75-76
sparkless/dataframe/window_handler.py                                  315    315     0%   8-698
sparkless/dataframe/writer.py                                          395    259    34%   113-115, 129, 159-160, 174-175, 192-194, 205-210, 228-232, 235-238, 248-250, 258, 280-283, 288, 294-296, 308-360, 401-402, 414-418, 434-436, 469-495, 509, 521, 537, 549, 561, 573, 580-586, 590-606, 610-613, 617-622, 627-642, 647-656, 661-670, 675-690, 694-699, 720-753, 782-865, 888-892, 896, 905-917, 942-1022
sparkless/delta.py                                                     308    254    18%   46-51, 61-74, 87-88, 100-116, 121-122, 127, 131-132, 137-152, 156-185, 189, 198, 210, 221-286, 300-341, 345, 348-352, 355-357, 360-368, 373-379, 384-408, 421-430, 434, 438, 441-446, 449-450, 455-456, 459-461, 464-466, 470-514, 517-523, 526-540, 547-551, 563-576, 581-584, 589-593, 601-629, 637-657
sparkless/error_simulation.py                                           89     89     0%   29-338
sparkless/errors.py                                                     28     10    64%   57, 62, 67, 72, 79, 86, 91, 96, 101, 106
sparkless/functions/__init__.py                                         29      4    86%   562-566
sparkless/functions/aggregate.py                                       323    158    51%   64-66, 70, 243-244, 259-260, 299-300, 315-316, 331-332, 370-371, 386-387, 418-420, 439-443, 461-472, 490-501, 516-517, 534-535, 552-553, 570-571, 591-597, 617-623, 640-641, 658-659, 733-734, 751-752, 769-770, 787-788, 803-807, 825-826, 843-844, 857-859, 874-890, 904-912, 930-940, 958-967, 985-994, 1014-1026, 1044-1053, 1071-1080, 1098-1107, 1125-1134, 1152-1161, 1182-1222
sparkless/functions/array.py                                           272    165    39%   56, 78-83, 107, 109, 134-139, 161, 185, 213-219, 245-251, 277-283, 309-315, 346-356, 385-396, 418-421, 440-443, 466, 486-490, 511-514, 538-541, 561-564, 580, 604, 626-629, 644-647, 663, 681, 698-701, 716-719, 737-742, 762-765, 779-782, 794-797, 811-830, 853-883, 900-903, 927-976, 997-1000, 1018-1022, 1040-1043, 1058-1059, 1074-1086, 1098-1100, 1112-1116
sparkless/functions/base.py                                            135     63    53%   72, 121, 128, 137, 150-161, 165-171, 175-184, 188-201, 205-217, 221-233, 250-251, 277, 281, 285, 289, 293, 297, 302, 307, 312, 317, 322
sparkless/functions/bitwise.py                                         108     67    38%   31-34, 50-53, 71, 86-89, 107-110, 125-128, 143-146, 161-168, 183-198, 213-228, 243-258, 276-283, 300-307, 324-331, 347-350, 367-370, 387-390, 405-408, 425-428
sparkless/functions/conditional.py                                     396    279    30%   33-115, 147, 152, 214, 226, 230, 234, 238, 242, 246, 251, 256, 261, 266, 271, 275, 279, 283, 295-300, 304-367, 381-384, 396-412, 426-455, 475, 499, 515, 533-538, 553, 570-603, 622, 637-648, 670, 673, 707-722, 737-752, 767-782, 797-812, 827-842, 854-861, 873-880, 895-908, 923-939, 954-970, 985-1001
sparkless/functions/core/__init__.py                                     6      0   100%
sparkless/functions/core/column.py                                     457    167    63%   43, 53, 93, 97, 102, 108, 113, 119, 125, 131, 147, 155, 163, 194, 199, 216, 224, 251, 255, 259, 263, 306, 331-345, 389, 399, 417-436, 464-466, 470-472, 476-478, 482-484, 492, 500-510, 518-528, 536-546, 554-564, 572-582, 590-600, 609, 696, 702, 706, 713, 731, 740, 744, 748, 751-757, 760, 764, 768, 772, 775-777, 779-781, 783-785, 787-789, 807, 818-825, 829, 836, 838-842, 844-848, 850-854, 856-860, 863-885, 891, 958, 970, 991, 994, 1009, 1030, 1046
sparkless/functions/core/expressions.py                                109     74    32%   28-32, 55, 73, 91-94, 108-115, 127-129, 141-143, 155-157, 169-171, 188-228, 240-247, 259-266, 278-285, 297-304, 320-323
sparkless/functions/core/lambda_parser.py                              146    126    14%   58-134, 142-148, 167-175, 189-247, 260-274, 285-298, 309-314, 327-332, 359-361, 369, 377, 381-385
sparkless/functions/core/literals.py                                   131     76    42%   49, 52, 65-76, 86, 108-110, 117-119, 123-125, 129-131, 135-137, 141-143, 147-149, 153-155, 159-161, 165-167, 171-173, 177-179, 183-185, 189-191, 195-197, 201-203, 207-209, 213, 217, 227-229, 233-240, 244-246, 250-252, 256-258, 262-268, 272-274, 278-280, 284-286, 302, 306-308, 312-314, 318-320
sparkless/functions/core/operations.py                                 106     67    37%   27-29, 33-35, 39-41, 45-47, 51-53, 57-59, 63-65, 69, 73, 77-79, 83-85, 89-91, 95-97, 101-103, 107-109, 122, 126, 130, 134, 145, 150-154, 158, 162, 176-189, 199, 203, 211, 219-221, 225-227, 235-237
sparkless/functions/core/sql_expr_parser.py                            308    166    46%   68-78, 90-101, 149, 151-157, 163-171, 175-183, 188-204, 209-226, 248-253, 279-289, 294-300, 308-314, 322-339, 345-381, 399, 401, 405, 410, 419, 428, 489, 491, 501-507, 520-551
sparkless/functions/crypto.py                                           48     39    19%   49-71, 91-113, 133-155
sparkless/functions/datetime.py                                        474    305    36%   49-52, 69-74, 86-89, 98, 107, 119-125, 137-143, 155-161, 173-179, 188-189, 205-218, 231-237, 262-301, 327-366, 390-429, 455-500, 520-549, 564-580, 595-601, 616-622, 637-646, 658-664, 676-682, 694-700, 712-718, 730-736, 748-754, 775, 783, 813-844, 856-860, 872-876, 889, 905, 921, 937, 954-960, 972-978, 990-994, 1006-1010, 1022-1026, 1039-1048, 1063-1074, 1088, 1107, 1126, 1149-1159, 1179-1191, 1211-1222, 1231-1234, 1248-1253, 1262-1273, 1283-1294, 1317-1320, 1340-1343, 1368-1372, 1393-1396, 1422-1468, 1492-1497, 1518-1537, 1557-1560, 1576-1579, 1600-1603, 1622-1627, 1646-1647, 1664-1665, 1685-1693, 1711-1727, 1745-1761
sparkless/functions/functions.py                                      1547    543    65%   67-77, 92, 133-136, 142-162, 168-187, 193-212, 218-238, 259, 264, 286, 341, 346, 351, 356, 361, 366, 371, 376, 381, 394-396, 401, 408, 415, 422, 427, 432, 437, 442, 447, 452, 457, 462, 467, 472, 483, 490, 497, 502, 507, 523, 533, 543, 548, 555, 593, 598, 605, 627, 637, 642, 652, 657, 664, 695, 726, 731, 736, 741, 755, 760, 765, 785, 790, 795, 800, 805, 810, 817, 822, 827, 832, 837, 842, 847, 852, 857, 862, 867, 872, 877, 882, 892, 902, 907, 912, 917, 922, 927, 932, 985, 990, 1002, 1007, 1012, 1023, 1028, 1038, 1045, 1052, 1059, 1082, 1087, 1092, 1097, 1104, 1109, 1114, 1119, 1128, 1133, 1138, 1143, 1148, 1155, 1162, 1167, 1172, 1182-1183, 1192-1193, 1202-1205, 1219, 1224, 1231, 1238, 1243, 1248, 1284, 1296, 1301, 1311, 1316, 1321, 1326, 1331, 1336, 1341, 1346, 1364-1420, 1425, 1430, 1435, 1442, 1466, 1471, 1476, 1483, 1491, 1496, 1501, 1506, 1511, 1516, 1521, 1533-1538, 1549, 1556, 1563, 1579-1586, 1595-1597, 1706-1713, 1770-1777, 1786-1793, 1798-1803, 1809, 1814, 1819, 1824, 1829, 1841, 1855, 1873, 1880, 1887, 1894, 1904, 1913, 1919, 1924, 1934, 1939, 1946, 1951, 1963, 1973, 1978, 1993, 2005, 2010, 2015, 2020, 2029, 2034, 2040, 2045, 2050, 2055, 2062, 2068, 2073, 2078, 2085, 2092, 2099, 2108, 2114-2138, 2152-2158, 2169, 2174, 2179, 2185, 2190, 2195, 2200, 2205, 2210, 2215, 2220, 2225, 2233, 2242-2243, 2248, 2253, 2259, 2264, 2269, 2279, 2285, 2290, 2297, 2302, 2316-2318, 2326-2328, 2336-2338, 2346-2348, 2353-2355, 2360-2362, 2369-2371, 2378-2380, 2387-2389, 2396-2398, 2404, 2409, 2414, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2464-2466, 2471-2473, 2492-2494, 2503-2505, 2510-2512, 2517-2519, 2525-2527, 2532-2534, 2539-2541, 2546-2548, 2553-2555, 2561-2563, 2568-2570, 2575-2577, 2582-2584, 2589-2591, 2596-2598, 2603-2605, 2634-2687, 2716-2741, 2765-2772, 2789-2791, 2797, 2804, 2809, 2814, 2821, 2828, 2833, 2842, 2847, 2854, 2861, 2866, 2871, 2879, 2884, 2891, 2898, 2905, 2913, 2920, 2927, 2933, 2938, 2945, 2950, 2962, 2975, 2989, 3004, 3016, 3023, 3030, 3037, 3044, 3049, 3054, 3059, 3064, 3069, 3074, 3080, 3085, 3090, 3097, 3102, 3107, 3112, 3117, 3122, 3130, 3135, 3140, 3149, 3155, 3160, 3165, 3170, 3175, 3196-3213
sparkless/functions/json_csv.py                                         41     18    56%   31-34, 51-54, 68, 89, 105-107, 127-130, 144-147, 159-161
sparkless/functions/map.py                                             101     72    29%   51-54, 69-72, 87-90, 107-115, 138-143, 167-222, 243-246, 266-269, 292-298, 324-330, 356-362, 391-400, 423-430
sparkless/functions/math.py                                            320    143    55%   51, 66-70, 82-86, 100, 118, 133, 146, 162, 178, 207, 211, 216, 219, 228, 246-249, 264-267, 284-287, 304-307, 323, 349, 362, 378, 394, 409-414, 427, 452, 476-477, 489-490, 505-506, 518-519, 531-532, 544-545, 567-574, 586-587, 599-600, 612-613, 625-626, 638-639, 651-652, 664-665, 677-679, 696-698, 715-716, 729-730, 745-748, 774, 776, 809-810, 823-824, 836-837, 849-850, 859-862, 871-874, 886-887, 902-907, 921-926, 941-960, 972, 990-1003, 1026-1067
sparkless/functions/metadata.py                                         33     33     0%   8-109
sparkless/functions/ordering.py                                         28     28     0%   7-93
sparkless/functions/pandas_types.py                                      6      0   100%
sparkless/functions/string.py                                          547    278    49%   50, 66, 82, 97-103, 115-121, 134, 150, 166, 184-196, 209-218, 231-237, 250-256, 268-274, 287-296, 309-318, 331-337, 350-356, 370-379, 395, 411-420, 435-450, 462-468, 480-484, 496, 508, 521-534, 550-561, 579, 629, 655, 684, 706, 722, 737-741, 760-769, 792, 795-796, 819, 839, 860, 879, 900-903, 923-926, 941-944, 963, 1004, 1031, 1054-1057, 1075-1078, 1099-1102, 1125, 1147, 1170, 1172, 1202-1223, 1235-1238, 1251, 1265-1268, 1280-1299, 1319, 1329-1332, 1352-1355, 1370-1373, 1391-1394, 1414-1417, 1432-1435, 1451-1457, 1475, 1492-1495, 1508-1514, 1529-1540, 1553-1562, 1575-1584, 1601-1610, 1627-1636, 1649-1655, 1673-1684, 1698-1710, 1725-1731, 1746-1752, 1764-1768, 1781-1792, 1807, 1832-1854, 1872-1879, 1897-1902, 1918-1927, 1939-1940
sparkless/functions/udf.py                                              51     41    20%   41-46, 57-58, 70-90, 119-121, 133-155
sparkless/functions/window_execution.py                                651    582    11%   58-67, 100-101, 115, 129, 143, 157, 171, 185, 201-203, 219, 235-237, 253-255, 269, 283, 297, 311, 325, 339, 350, 361, 377, 390-428, 432-471, 478-553, 557-607, 613-629, 633-694, 698-742, 746-790, 794-845, 849-916, 920-981, 987-1024, 1028-1087, 1092, 1101-1146, 1150-1230, 1234-1260, 1268-1304, 1308-1372, 1376-1420, 1424-1468
sparkless/functions/xml.py                                              65     39    40%   25-28, 50-64, 84-87, 107-110, 131-134, 155-158, 179-182, 203-206, 227-230, 251-254, 275-278
sparkless/optimizer/__init__.py                                          3      0   100%
sparkless/optimizer/optimization_rules.py                              174    144    17%   16-61, 65-66, 71, 83-110, 114-115, 119-142, 150-170, 174-175, 181-184, 192-224, 228, 233, 241-266, 270, 275-278, 286-324, 328, 333, 341-361, 365-366, 371-376
sparkless/optimizer/query_optimizer.py                                 256    185    28%   47-58, 67, 72, 80-125, 129-130, 135, 147-174, 178-179, 183-206, 214-234, 238-239, 245-248, 256-288, 292, 297, 305-330, 334, 339-342, 379-392, 403-408, 413, 418-456, 459-472, 477-504, 508, 512, 518
sparkless/performance_simulation.py                                     91     91     0%   29-329
sparkless/session/__init__.py                                            4      0   100%
sparkless/session/catalog.py                                           258    133    48%   43, 47, 65, 69, 111, 131-133, 150, 170, 173, 178, 187-190, 212, 215, 225, 230-233, 251-253, 267, 272, 275, 278, 281, 299-302, 309-312, 315-318, 338, 341, 344, 349-352, 374, 386-414, 431, 434, 438-443, 463, 466, 470-475, 484, 499, 502, 506-511, 528, 537, 546, 566-575, 606, 617, 630, 633, 636, 640-644, 651, 654, 658-659, 666, 683-716
sparkless/session/config/__init__.py                                     2      0   100%
sparkless/session/config/configuration.py                               54     22    59%   77, 85-86, 94, 102, 110, 118-119, 130, 141, 146, 150, 188, 199-200, 211-212, 224-225, 236-237, 245
sparkless/session/context.py                                            36     10    72%   47, 51, 55, 92, 101, 110, 119, 123, 127, 131
sparkless/session/core/__init__.py                                       4      0   100%
sparkless/session/core/builder.py                                       30      7    77%   31, 54, 68-72, 97
sparkless/session/core/session.py                                      227     76    67%   12-13, 122, 174-177, 182, 187, 202, 237-239, 249-254, 258-260, 273, 277, 287, 293, 306-308, 350, 368, 380, 391, 414, 421-436, 444-446, 468, 479-482, 509-510, 525, 530-536, 544, 553-555, 575-580, 597, 604, 611, 621, 628, 633-643, 652, 661-662, 667
sparkless/session/performance_tracker.py                                39     19    51%   57, 87-109, 117
sparkless/session/services/__init__.py                                   6      0   100%
sparkless/session/services/dataframe_factory.py                        216    123    43%   14-15, 73-78, 87-99, 102-103, 106, 119, 131-170, 182, 190, 204, 206, 211, 218, 255, 271, 281, 296-336, 343, 350, 361-364, 392, 403, 414, 428, 440, 447, 465-472, 490-506, 517-587
sparkless/session/services/lifecycle_manager.py                         21     10    52%   32-34, 42-43, 55-59
sparkless/session/services/mocking_coordinator.py                       32     21    34%   39-57, 69-72, 84-86, 102-104, 109
sparkless/session/services/protocols.py                                 20      0   100%
sparkless/session/services/sql_parameter_binder.py                      29     25    14%   28-51, 62-74
sparkless/session/session.py                                             0      0   100%
sparkless/session/sql/__init__.py                                        5      0   100%
sparkless/session/sql/executor.py                                     1280    623    51%   83-90, 129, 140-143, 149, 179-190, 204-211, 232-239, 281, 284, 289, 310-352, 366-381, 419, 514, 517-520, 544-545, 556-569, 609-612, 616-631, 637-643, 648-652, 654-658, 668, 698-720, 730-733, 751-754, 793-820, 825-841, 851-867, 875-910, 965-1011, 1053-1061, 1081-1129, 1185-1192, 1197-1198, 1221-1243, 1268-1271, 1303, 1310, 1319-1326, 1329-1336, 1344-1346, 1390, 1404-1406, 1408-1410, 1417-1478, 1510, 1517-1519, 1554, 1560, 1565, 1588, 1603, 1611, 1627-1641, 1658, 1680, 1690, 1692, 1700-1705, 1729, 1738-1740, 1760-1761, 1802, 1805, 1807, 1811, 1816-1829, 1839, 1853, 1871-1872, 1906, 1915, 1950-1951, 1967, 2002-2030, 2102, 2108-2190, 2194-2249, 2273, 2299-2302, 2314, 2423-2644, 2667-2751, 2764-2779, 2806-2838, 2860-2867, 2899-2908, 2935-3001
sparkless/session/sql/optimizer.py                                      65     48    26%   41-43, 47, 51, 68, 85-100, 111-114, 127, 142, 155, 168, 181, 192-234, 247-260
sparkless/session/sql/parser.py                                        496    175    65%   45, 49, 263, 271-272, 297, 303, 305, 310-315, 356, 358, 486, 509, 540-548, 562, 564, 596-617, 668-671, 674-677, 726-737, 755-765, 790, 806-833, 892, 915, 928, 993, 1019, 1027, 1046-1047, 1049-1050, 1094, 1101, 1121-1141, 1160-1275, 1291-1323, 1335-1338, 1360-1361
sparkless/session/sql/validation.py                                     85     72    15%   42, 105-126, 137-166, 177-188, 199-216, 227-235, 246-265, 276-279, 292, 306-311, 322-323
sparkless/spark_types.py                                               404    206    49%   60-74, 111, 115, 123, 279-281, 285, 333-334, 337, 343, 350, 354, 368, 372, 384, 396, 420, 432, 439-440, 443, 450-451, 454, 466, 475-477, 480, 489-491, 494, 503-505, 508, 531, 539-544, 570-575, 585-590, 593, 602, 605-606, 610-613, 625-633, 654-656, 660, 664-665, 669, 673, 685, 698, 704-713, 718-733, 738-739, 746, 755-767, 812, 823-826, 834-848, 856, 859-880, 884-888, 892-899, 903-910, 914, 918-943, 955-978, 983-984, 989, 995-997, 1011-1012
sparkless/sql/__init__.py                                               10      0   100%
sparkless/sql/functions.py                                              30     11    63%   62-74, 84-92
sparkless/sql/types.py                                                   2      0   100%
sparkless/sql/utils.py                                                   7      0   100%
sparkless/storage/__init__.py                                           10      0   100%
sparkless/storage/backends/__init__.py                                   0      0   100%
sparkless/storage/backends/file.py                                     206     47    77%   39, 49, 68-69, 93, 96-98, 119, 142, 146, 150, 154-155, 159-161, 225, 238, 242, 246, 250, 254, 258, 262-264, 268, 272, 276, 366, 409-414, 471-482, 495-498, 501, 507, 519, 538
sparkless/storage/backends/memory.py                                   133     84    37%   22-25, 34, 39, 44, 53-61, 72-77, 85, 93, 97, 101, 105, 109-110, 114-115, 139-141, 152, 160-161, 169, 187-188, 199, 208-209, 217, 229-231, 246-249, 258-259, 271-275, 290-295, 310-312, 324-330, 342, 352-370, 381-390, 402-406, 418-423, 430
sparkless/storage/manager.py                                           135     86    36%   40-45, 58, 70, 82, 94-98, 108, 119, 128-130, 138, 142-149, 153-159, 171, 186, 195, 208, 223, 237, 249, 258, 269, 283, 295, 303, 312, 325, 336, 344-349, 353-358, 366-378, 382, 390-400, 411-432
sparkless/storage/models.py                                             67      1    99%   77
sparkless/storage/serialization/__init__.py                              0      0   100%
sparkless/storage/serialization/csv.py                                  46     32    30%   23-30, 42-47, 57-62, 76-92, 104-120
sparkless/storage/serialization/json.py                                 39     25    36%   23-24, 36-41, 51-63, 75-90, 102-118
sparkless/utils/profiling.py                                            96     40    58%   47-48, 58, 61, 71-76, 85, 88-90, 94, 99, 102, 118-135, 161-172, 182, 188
sparkless/window.py                                                     67     17    75%   78, 91, 114, 127, 147-151, 166-170, 182, 186, 229, 234, 239
--------------------------------------------------------------------------------------------------
TOTAL                                                                33879  24175    29%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_abs - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_row_number - AssertionError: DataFrames are not equivalent:
Numerical mismatch in column 'row_num' row 2: mock=2, expected=3, diff=1.0
Numerical mismatch in column 'row_num' row 3: mock=3, expected=2, diff=1.0
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_upper - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_year - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_contains - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_round - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_month - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofmonth - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_position - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_with_select - assert 0 == 2
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 0 columns].count
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_rank - AssertionError: DataFrames are not equivalent:
Numerical mismatch in column 'rank' row 2: mock=1, expected=3, diff=2.0
Numerical mismatch in column 'rank' row 3: mock=1, expected=2, diff=1.0
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_inner_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lower - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_length - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sqrt - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_left_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_size - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_dense_rank - AssertionError: DataFrames are not equivalent:
Numerical mismatch in column 'dense_rank' row 2: mock=1, expected=3, diff=2.0
Numerical mismatch in column 'dense_rank' row 3: mock=1, expected=2, diff=1.0
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substring - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofweek - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_pow - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_sum_over_window - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_log - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_add - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_element_at - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_empty_groups - RuntimeError: not found: Column 'A' not found. Available columns: [group, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lag - AssertionError: DataFrames are not equivalent:
Value mismatch in column 'lag_salary' row 2: mock='IT', expected=55000
Value mismatch in column 'lag_salary' row 3: mock='IT', expected=50000
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_explode - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=9
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_exp - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_sub - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substr_method - RuntimeError: not found: Column 'partial_name' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_order_by - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_format - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_coalesce - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sin - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_distinct - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lead - AssertionError: DataFrames are not equivalent:
Value mismatch in column 'lead_salary' row 0: mock='IT', expected=55000
Null mismatch in column 'lead_salary' row 2: mock='IT', expected=None
Null mismatch in column 'lead_salary' row 3: mock=None, expected=70000
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_to_date - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_cos - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_cume_dist - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_column_astype_method - RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_tan - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnotnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_first_value - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_union - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_concat - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_table - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_last_value - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_when_otherwise - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_sort - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_ceil - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_specific_columns - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_split - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_remove - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_floor - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_percent_rank - AssertionError: DataFrames are not equivalent:
Null mismatch in column 'percent_rank' row 1: mock=nan, expected=0.0
Numerical mismatch in column 'percent_rank' row 2: mock=0.0, expected=1.0, diff=1.0
Numerical mismatch in column 'percent_rank' row 3: mock=0.0, expected=0.5, diff=0.5
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_case_when - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: select' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nvl - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nullif - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_regexp_extract - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_trim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_like - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_filter_on_table_with_comparison_operations - RuntimeError: not found: Column 'active' not found. Available columns: [id, score, status]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_ifnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_ntile - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_multiple_values - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_greatest - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_ltrim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_least - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nanvl - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rtrim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_table - RuntimeError: not found: Column 'Alice' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lpad - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_issue_266 - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_order_by_desc - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rpad - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_string_operations_in_filters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_parity - RuntimeError: not found: Column 'split(StringValue, ,, 3)' not found. Available columns: [Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_multiple_columns - RuntimeError: not found: Column 'Alice' not found. Available columns: [name, age, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_like - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_yyyy_mm_dd_format - RuntimeError: not found: Column 'to_date(date_of_birth, 'yyyy-MM-dd')' not found. Available columns: [id, name, date_of_birth]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_append_data_visible_immediately - AssertionError: Initial table should have 1 row
assert 0 == 1
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 2 columns].count
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_logical_operations_in_filters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rlike - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_1_parity - RuntimeError: not found: Column 'split(Value, ,, 1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_basic_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_mm_slash_dd_slash_yyyy_format - RuntimeError: not found: Column 'to_date(event_date, 'MM/dd/yyyy')' not found. Available columns: [id, event_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_concat_ws - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_multiple_matches_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_without_rsd_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_ascii - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_without_limit_parity - RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_left_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format - RuntimeError: not found: Column 'to_date(event_date, 'dd-MM-yyyy')' not found. Available columns: [id, event_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_delete_from_table - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: orderBy' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_hex - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_float_base_parity - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_minus_one_parity - RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_on_table_with_complex_schema - TypeError: Object of type datetime is not JSON serializable
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_base64 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_without_format_string - RuntimeError: not found: Column 'to_date(date_str)' not found. Available columns: [id, date_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_double_join_empty_aggregated.py::TestDoubleJoinEmptyAggregated::test_columns_preserved_in_double_join_with_empty_aggregated - RuntimeError: not found: Column 'concat(first_name,  , last_name)' not found. Available columns: [patient_id, first_name, last_name, age, age_group, gender, insurance_provider]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_initcap - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_parity - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_multiple_columns_parity - assert 100 == 90
FAILED tests/parity/dataframe/test_select.py::TestSelectParity::test_select_with_alias - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_natural_log_parity - RuntimeError: not found: Column 'Ln' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_soundex - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_from_select - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: not found: Column 'IT' not found. Available columns: [name, age, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_to_date_issue_126.py::TestToDateIssue126::test_issue_126_reproduction - RuntimeError: not found: Column 'to_date(date_of_birth, 'yyyy-MM-dd')' not found. Available columns: [id, name, date_of_birth]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_multiple_fields_parity - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_translate - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_basic_parity - RuntimeError: not found: Column 'format_string('%s-%s', StringValue, IntegerValue)' not found. Available columns: [IntegerValue, Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_different_bases_parity - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_levenshtein - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_and_other_columns_parity - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_multiple_args_parity - RuntimeError: not found: Column 'format_string('%s is %d years old and lives in %s', Name, Age, City)' not found. Available columns: [Age, City, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_crc32 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_xxhash64 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_with_null_parity - RuntimeError: not found: Column 'format_string('%s-%s', Value, Number)' not found. Available columns: [Name, Number, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_get_json_object - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_json_tuple - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_substring_index - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_repeat - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_reverse - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
ERROR tests/parity/dataframe/test_parquet_format_table_append.py
============= 128 failed, 115 passed, 6 skipped, 1 error in 13.49s =============
Running Performance tests (parallel)...
============================= test session starts ==============================
platform darwin -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
cachedir: .pytest_cache
hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
rootdir: /Users/odosmatthews/Documents/coding/sparkless
configfile: pyproject.toml
plugins: anyio-4.11.0, cov-7.0.0, green-light-0.2.0, asyncio-1.2.0, xdist-3.8.0, timeout-2.4.0, hypothesis-6.148.7, alt-pytest-asyncio-0.9.3, async-sqlalchemy-0.2.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
timeout: 300.0s
timeout method: thread
timeout func_only: False
created: 10/10 workers
10 workers [0 items]

scheduling tests via LoadFileScheduling

================================ tests coverage ================================
______________ coverage: platform darwin, python 3.11.13-final-0 _______________

Name                                                                 Stmts   Miss  Cover   Missing
--------------------------------------------------------------------------------------------------
sparkless/__init__.py                                                   24      0   100%
sparkless/_version.py                                                    8      8     0%   8-19
sparkless/backend/__init__.py                                            3      0   100%
sparkless/backend/factory.py                                            72     46    36%   44-55, 78-89, 104-115, 131-157, 174-176, 190-191
sparkless/backend/polars/__init__.py                                     4      4     0%   19-23
sparkless/backend/polars/_over_compat.py                                19     19     0%   8-40
sparkless/backend/polars/executors/__init__.py                           1      1     0%   13
sparkless/backend/polars/export.py                                      36     36     0%   7-114
sparkless/backend/polars/expression_translator.py                     2172   2172     0%   8-5251
sparkless/backend/polars/materializer.py                               852    852     0%   8-1944
sparkless/backend/polars/operation_executor.py                        2047   2047     0%   1-4555
sparkless/backend/polars/parquet_storage.py                             41     41     0%   8-119
sparkless/backend/polars/plan_interpreter.py                           381    381     0%   8-531
sparkless/backend/polars/schema_registry.py                             73     73     0%   8-222
sparkless/backend/polars/schema_utils.py                                31     31     0%   3-69
sparkless/backend/polars/storage.py                                    350    350     0%   8-771
sparkless/backend/polars/translators/__init__.py                         1      1     0%   14
sparkless/backend/polars/translators/arithmetic_translator.py           17     17     0%   8-70
sparkless/backend/polars/translators/string_translator.py              145    145     0%   8-302
sparkless/backend/polars/translators/type_translator.py                107    107     0%   8-190
sparkless/backend/polars/type_mapper.py                                 99     99     0%   8-173
sparkless/backend/polars/window_handler.py                             290    290     0%   7-563
sparkless/backend/protocols.py                                          14      0   100%
sparkless/backend/robin/__init__.py                                      4      0   100%
sparkless/backend/robin/export.py                                       46     34    26%   20-29, 36, 41-50, 55-62, 71-77, 80-85
sparkless/backend/robin/materializer.py                                714    684     4%   40-46, 56-64, 69-82, 88-89, 93, 102-113, 123-195, 205-239, 244-249, 261-693, 717, 720, 723, 726-727, 730-742, 745-762, 765-767, 770-780, 795-813, 818-822, 836-838, 846-1070, 1075
sparkless/backend/robin/plan_executor.py                               191    191     0%   9-264
sparkless/backend/robin/storage.py                                      52     24    54%   23-28, 33, 36, 39, 42, 45, 53, 56, 59, 62, 67, 72, 77, 82, 85, 88, 91, 94, 99, 104
sparkless/compat/__init__.py                                             2      0   100%
sparkless/compat/datetime.py                                            74     53    28%   43, 55-57, 61-67, 73-81, 96-103, 115-122, 128-133, 141-146, 162-182
sparkless/config.py                                                     55     37    33%   28-34, 41-73, 77-81, 87-92, 98-100, 106
sparkless/core/__init__.py                                               9      0   100%
sparkless/core/column_resolver.py                                       33     24    27%   46-76, 105-116, 138-142
sparkless/core/condition_evaluator.py                                  764    730     4%   27-34, 49-56, 71-245, 260-541, 556-576, 591-604, 619-781, 795-1203, 1218-1229, 1245-1274, 1290-1311, 1324-1340, 1353, 1366-1370, 1384-1403
sparkless/core/data_validation.py                                       80     69    14%   39-42, 56-85, 91-113, 128-147, 160-187, 205-206, 220-221
sparkless/core/ddl_adapter.py                                           31     23    26%   52-53, 65-66, 78-79, 91-106, 118-133
sparkless/core/exceptions/__init__.py                                    6      0   100%
sparkless/core/exceptions/analysis.py                                  100     81    19%   37-63, 70-73, 91, 109, 137-162, 170-202, 230-245, 269-272, 302-323
sparkless/core/exceptions/base.py                                       22      9    59%   23-25, 28, 31, 46, 61, 76, 91
sparkless/core/exceptions/execution.py                                  29     13    55%   27, 45, 63, 87-90, 114-117, 135, 153
sparkless/core/exceptions/operation.py                                  87     69    21%   24-34, 49-58, 72-82, 96-106, 120-129, 148-156, 173-183, 197-206
sparkless/core/exceptions/py4j_compat.py                                10     10     0%   8-41
sparkless/core/exceptions/runtime.py                                    41     25    39%   27, 53-57, 75, 101-107, 131-134, 158-161, 187-193
sparkless/core/exceptions/validation.py                                 44     26    41%   27, 45, 63, 81, 107-111, 141-147, 171-174, 202-207
sparkless/core/interfaces/__init__.py                                    5      0   100%
sparkless/core/interfaces/dataframe.py                                 180     56    69%   20, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 98, 103, 110, 115, 120, 125, 130, 136, 142, 151, 156, 161, 166, 171, 176, 181, 190, 195, 200, 205, 212, 217, 222, 227, 232, 241, 246, 251, 256, 261, 266, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320
sparkless/core/interfaces/functions.py                                 186     56    70%   23, 28, 33, 42, 47, 56, 61, 70, 75, 84, 89, 94, 99, 108, 113, 118, 123, 130, 135, 144, 149, 154, 159, 164, 173, 178, 185, 192, 197, 202, 207, 212, 221, 226, 231, 236, 241, 250, 255, 263, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 333, 338, 343, 348
sparkless/core/interfaces/session.py                                   117     34    71%   20, 26, 32, 38, 44, 50, 59, 64, 69, 76, 81, 86, 96, 101, 106, 115, 120, 125, 136, 141, 146, 151, 156, 161, 166, 171, 176, 185, 190, 195, 200, 209, 214, 219
sparkless/core/interfaces/storage.py                                   126     38    70%   29, 34, 39, 44, 54, 59, 64, 69, 76, 83, 90, 97, 102, 106, 110, 114, 120, 126, 136, 142, 148, 153, 158, 163, 168, 173, 186, 192, 198, 204, 210, 215, 220, 229, 234, 239, 248, 253
sparkless/core/protocols.py                                             42      0   100%
sparkless/core/safe_evaluator.py                                       125    116     7%   39-50, 63-67, 83-215
sparkless/core/schema_inference.py                                     107     92    14%   72-134, 157-200, 218-237, 242-251, 256-265, 279-280, 296-309
sparkless/core/type_utils.py                                            86     66    23%   20-21, 49-51, 63-65, 77-79, 91-93, 112-121, 140-144, 164-168, 187-199, 223-259, 278, 290-292, 304
sparkless/core/types/__init__.py                                         4      0   100%
sparkless/core/types/data_types.py                                     139     38    73%   22, 27, 32, 37, 42, 47, 52, 57, 66, 76, 81, 91, 97, 102, 111, 121, 127, 132, 141, 146, 155, 160, 170, 175, 180, 190, 196, 201, 206, 211, 221, 226, 231, 240, 249, 254, 259, 264
sparkless/core/types/metadata.py                                       166     47    72%   18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 73, 79, 85, 91, 97, 103, 108, 113, 118, 128, 134, 140, 145, 150, 160, 166, 172, 177, 182, 187, 197, 203, 209, 215, 220, 225, 230, 239, 244, 249, 254, 259, 268, 273, 278, 283, 288
sparkless/core/types/schema.py                                         121     36    70%   22, 28, 34, 40, 45, 50, 55, 60, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 185, 190, 195, 200, 209, 214, 221, 226
sparkless/data_generation/__init__.py                                    4      4     0%   8-12
sparkless/data_generation/builder.py                                    28     28     0%   8-85
sparkless/data_generation/convenience.py                                 9      9     0%   8-64
sparkless/data_generation/generator.py                                 174    174     0%   8-337
sparkless/dataframe/__init__.py                                          6      0   100%
sparkless/dataframe/aggregations/__init__.py                             2      2     0%   8-10
sparkless/dataframe/aggregations/operations.py                          75     75     0%   8-208
sparkless/dataframe/assertions/__init__.py                               3      3     0%   7-10
sparkless/dataframe/assertions/assertions.py                            26     26     0%   8-88
sparkless/dataframe/assertions/operations.py                            16     16     0%   8-45
sparkless/dataframe/attribute_handler.py                                62     50    19%   30, 54, 77-85, 116-125, 150-154, 175-227
sparkless/dataframe/casting/__init__.py                                  2      2     0%   3-5
sparkless/dataframe/casting/type_converter.py                           95     95     0%   3-180
sparkless/dataframe/collection_handler.py                               29     29     0%   8-81
sparkless/dataframe/condition_handler.py                                52     52     0%   8-180
sparkless/dataframe/dataframe.py                                       513    351    32%   132-175, 179-183, 187-191, 195-199, 203-207, 211-215, 219-224, 228-230, 240-243, 252-265, 276, 280, 293, 305, 311, 317, 321, 325, 329, 333, 339, 345, 359, 365, 369, 373, 377, 381, 390, 394, 404, 408, 412, 420, 424, 428, 432, 436, 440, 445, 449, 453, 457, 463, 469-477, 486, 490, 495-503, 507-508, 518-532, 551, 555-561, 565, 569, 574-583, 596-609, 621, 625, 630, 634, 638, 642, 652, 674, 689-691, 700, 709, 715, 719, 723, 727, 733, 742, 746, 750, 756, 760, 770, 780, 791, 795, 799, 803, 809, 813, 817, 821, 829, 835, 839, 843, 847, 852, 856, 860, 864, 871-879, 887-889, 894, 899, 911-912, 924-929, 932, 936, 955-969, 975, 987-1062, 1078-1097, 1103, 1114-1128, 1139-1174, 1184-1188, 1195, 1201-1206, 1210, 1216, 1225, 1241-1244, 1250, 1258, 1269, 1284, 1292, 1303, 1311, 1323, 1329, 1335, 1342, 1347-1353, 1368-1379, 1383, 1403-1411, 1416, 1420-1460
sparkless/dataframe/display/__init__.py                                  3      3     0%   3-6
sparkless/dataframe/display/formatter.py                                37     37     0%   3-57
sparkless/dataframe/display/operations.py                              118    118     0%   8-274
sparkless/dataframe/evaluation/__init__.py                               2      0   100%
sparkless/dataframe/evaluation/evaluators/__init__.py                    1      1     0%   13
sparkless/dataframe/evaluation/evaluators/conditional_evaluator.py      22     22     0%   7-63
sparkless/dataframe/evaluation/expression_evaluator.py                2615   2380     9%   70-78, 89-113, 117-122, 128-130, 134, 138-181, 193-259, 269-300, 306-416, 422-448, 458-1021, 1027-1066, 1072-1257, 1263-1340, 1347-1385, 1391-1442, 1448-1534, 1539-1555, 1562-1574, 1578-1593, 1597-1612, 1616-1631, 1635-1650, 1661-1666, 1670-1693, 1697, 1701, 1710-1731, 1735, 1944, 1948, 1952-1956, 1960-1964, 1968-1972, 1976-1989, 1993-2000, 2004-2014, 2018-2028, 2032-2034, 2040-2043, 2047-2050, 2054-2061, 2065-2070, 2085-2143, 2147-2152, 2163-2207, 2211-2222, 2226-2234, 2240-2242, 2246-2251, 2255-2257, 2261-2263, 2269, 2273-2279, 2283, 2287-2292, 2296-2298, 2302-2304, 2308, 2312, 2316, 2324, 2328, 2332-2335, 2339-2341, 2345-2350, 2354-2357, 2361-2373, 2380, 2384-2416, 2420-2425, 2429-2451, 2455-2477, 2483-2499, 2503-2534, 2540-2575, 2581-2588, 2592-2612, 2616-2659, 2663-2680, 2684-2697, 2702, 2706-2707, 2711, 2715, 2719, 2725-2734, 2738-2747, 2751-2758, 2764, 2768-2782, 2786-2793, 2797-2811, 2815-2822, 2826-2833, 2837-2844, 2848-2857, 2861-2870, 2874-2883, 2887-2894, 2898-2905, 2909-2916, 2920-2927, 2931-2938, 2944, 2948-2957, 2962, 2967, 2972-3004, 3008-3017, 3023, 3029, 3033-3044, 3050, 3057, 3062, 3068, 3073-3097, 3102, 3107, 3112, 3121-3153, 3157-3201, 3205-3249, 3253-3280, 3285-3306, 3314-3376, 3380-3387, 3391-3411, 3417, 3423, 3427-3542, 3547-3558, 3562-3571, 3575, 3579, 3583, 3587, 3591, 3595, 3599, 3603-3608, 3612-3618, 3622-3627, 3631-3636, 3645, 3659-3693, 3699, 3703-3710, 3714-3725, 3730-3739, 3745-3754, 3760-3765, 3771-3776, 3782-3790, 3796-3804, 3808, 3812-3818, 3822-3833, 3837-3840, 3844-3850, 3854-3856, 3861, 3866-3878, 3882, 3886-3892, 3896-3902, 3908-3918, 3922-3929, 3934, 3938-3940, 3944-3967, 3971-3994, 3999, 4004, 4009, 4014, 4019, 4024, 4028-4040, 4046-4053, 4059-4066, 4070-4079, 4085-4092, 4098-4105, 4111-4118, 4126-4140, 4144-4151, 4155-4162, 4167-4182, 4186-4201, 4221, 4226, 4231, 4237-4248, 4255-4258, 4264-4267, 4273-4278, 4283-4287, 4291-4308, 4314-4329, 4335-4350, 4356-4359, 4363-4365, 4370-4378, 4384-4411, 4416-4425, 4429-4431, 4435-4437, 4442-4461, 4465-4482, 4486-4503, 4507-4524, 4528-4533, 4539-4550, 4554-4565, 4569-4574
sparkless/dataframe/export.py                                           15     15     0%   8-46
sparkless/dataframe/grouped/__init__.py                                  5      0   100%
sparkless/dataframe/grouped/base.py                                   1064   1034     3%   56-58, 72-696, 710-765, 779-1647, 1664-1934, 1945-1952, 1963-1970, 1985, 1996-2007, 2018-2025, 2036-2043, 2054-2063, 2074-2083, 2094-2103, 2114-2123, 2134-2143, 2154-2163, 2174-2201, 2212-2239, 2253-2281, 2303-2370, 2392-2447
sparkless/dataframe/grouped/cube.py                                     86     77    10%   30-31, 47-215
sparkless/dataframe/grouped/pivot.py                                   493    470     5%   36-39, 55-356, 362-397, 403-641, 649-810, 822-831, 842-851, 862, 873-882, 893-902, 913-922, 933-939, 950-956, 967-973, 984-990, 1001-1007, 1018-1024, 1035-1041
sparkless/dataframe/grouped/rollup.py                                   87     79     9%   29-30, 48-220
sparkless/dataframe/joins/__init__.py                                    2      2     0%   8-10
sparkless/dataframe/joins/operations.py                                146    146     0%   8-396
sparkless/dataframe/lazy.py                                           1222   1222     0%   8-2865
sparkless/dataframe/logical_plan.py                                    223    212     5%   21-33, 42-226, 231-233, 238-255, 260-262, 271-294, 304-456
sparkless/dataframe/operations/__init__.py                               2      2     0%   8-10
sparkless/dataframe/operations/aggregation_operations.py               128    128     0%   3-313
sparkless/dataframe/operations/join_operations.py                      157    157     0%   3-329
sparkless/dataframe/operations/misc.py                                 516    516     0%   8-1427
sparkless/dataframe/operations/set_operations.py                       168    168     0%   3-346
sparkless/dataframe/protocols.py                                        49      0   100%
sparkless/dataframe/rdd.py                                              83     56    33%   26, 34, 42, 53, 61, 69-70, 81, 92-95, 106, 117-125, 136-143, 155-166, 174, 185, 193, 201, 209, 217, 229, 240-243, 254-261, 269, 277
sparkless/dataframe/reader.py                                          187    156    17%   64-67, 81-82, 97-98, 112-113, 127-136, 158-190, 206-259, 266-277, 281-288, 294-306, 311-321, 326-349, 354-374, 377-382, 386-390, 396-402, 406, 410, 414, 429, 444, 461-463
sparkless/dataframe/robin_plan.py                                       78     69    12%   53-94, 104-142, 153-162
sparkless/dataframe/schema/__init__.py                                   3      3     0%   3-6
sparkless/dataframe/schema/operations.py                                22     22     0%   8-51
sparkless/dataframe/schema/schema_manager.py                           514    514     0%   3-1019
sparkless/dataframe/services/__init__.py                                 8      8     0%   8-16
sparkless/dataframe/services/aggregation_service.py                     99     99     0%   7-254
sparkless/dataframe/services/assertion_service.py                       17     17     0%   7-51
sparkless/dataframe/services/display_service.py                        126    126     0%   7-297
sparkless/dataframe/services/join_service.py                           248    248     0%   7-628
sparkless/dataframe/services/misc_service.py                           613    613     0%   7-1612
sparkless/dataframe/services/schema_service.py                           4      4     0%   8-24
sparkless/dataframe/services/transformation_service.py                 349    349     0%   7-910
sparkless/dataframe/transformations/__init__.py                          2      2     0%   8-10
sparkless/dataframe/transformations/operations.py                      224    224     0%   8-629
sparkless/dataframe/types.py                                             8      8     0%   8-25
sparkless/dataframe/validation/__init__.py                               2      2     0%   7-9
sparkless/dataframe/validation/column_validator.py                     171    171     0%   9-578
sparkless/dataframe/validation_handler.py                               21     21     0%   9-116
sparkless/dataframe/window_handler.py                                  315    315     0%   8-698
sparkless/dataframe/writer.py                                          395    352    11%   74-79, 93-94, 111-120, 129, 144-145, 159-160, 174-175, 191-442, 469-495, 509, 521, 537, 549, 561, 573, 580-586, 590-606, 610-613, 617-622, 627-642, 647-656, 661-670, 675-690, 694-699, 720-753, 771-865, 886-917, 936-1022
sparkless/delta.py                                                     308    254    18%   46-51, 61-74, 87-88, 100-116, 121-122, 127, 131-132, 137-152, 156-185, 189, 198, 210, 221-286, 300-341, 345, 348-352, 355-357, 360-368, 373-379, 384-408, 421-430, 434, 438, 441-446, 449-450, 455-456, 459-461, 464-466, 470-514, 517-523, 526-540, 547-551, 563-576, 581-584, 589-593, 601-629, 637-657
sparkless/error_simulation.py                                           89     89     0%   29-338
sparkless/errors.py                                                     28     10    64%   57, 62, 67, 72, 79, 86, 91, 96, 101, 106
sparkless/functions/__init__.py                                         29      4    86%   562-566
sparkless/functions/aggregate.py                                       323    215    33%   56-70, 90-100, 115-123, 138-146, 161-169, 184-192, 211-212, 227-228, 243-244, 259-260, 275-283, 299-300, 315-316, 331-332, 347-355, 370-371, 386-387, 402-403, 418-420, 439-443, 461-472, 490-501, 516-517, 534-535, 552-553, 570-571, 591-597, 617-623, 640-641, 658-659, 676-677, 699-716, 733-734, 751-752, 769-770, 787-788, 803-807, 825-826, 843-844, 857-859, 874-890, 904-912, 930-940, 958-967, 985-994, 1014-1026, 1044-1053, 1071-1080, 1098-1107, 1125-1134, 1152-1161, 1182-1222
sparkless/functions/array.py                                           272    185    32%   55-58, 78-83, 106-111, 134-139, 160-163, 184-187, 213-219, 245-251, 277-283, 309-315, 346-356, 385-396, 418-421, 440-443, 465-468, 486-490, 511-514, 538-541, 561-564, 579-585, 603-606, 626-629, 644-647, 662-665, 680-683, 698-701, 716-719, 737-742, 762-765, 779-782, 794-797, 811-830, 853-883, 900-903, 927-976, 997-1000, 1018-1022, 1040-1043, 1058-1059, 1074-1086, 1098-1100, 1112-1116
sparkless/functions/base.py                                            135    103    24%   57-67, 71-89, 94-99, 106-139, 150-161, 165-171, 175-184, 188-201, 205-217, 221-233, 237-239, 250-251, 265, 277, 281, 285, 289, 293, 297, 302, 307, 312, 317, 322
sparkless/functions/bitwise.py                                         108     67    38%   31-34, 50-53, 71, 86-89, 107-110, 125-128, 143-146, 161-168, 183-198, 213-228, 243-258, 276-283, 300-307, 324-331, 347-350, 367-370, 387-390, 405-408, 425-428
sparkless/functions/conditional.py                                     396    320    19%   33-115, 133-142, 147, 152, 164-165, 176-188, 199-200, 214, 226, 230, 234, 238, 242, 246, 251, 256, 261, 266, 271, 275, 279, 283, 295-300, 304-367, 381-384, 396-412, 426-455, 472-486, 498-502, 514-521, 533-538, 551-553, 570-603, 622, 637-648, 661-682, 707-722, 737-752, 767-782, 797-812, 827-842, 854-861, 873-880, 895-908, 923-939, 954-970, 985-1001
sparkless/functions/core/__init__.py                                     6      0   100%
sparkless/functions/core/column.py                                     457    370    19%   39, 43, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 102, 108, 113, 119, 125, 131, 135, 139, 143, 147, 151, 155, 159, 163, 189-195, 199, 203, 209-210, 216, 220, 224, 239, 243, 247, 251, 255, 259, 263, 267, 285, 306, 331-345, 368-377, 382-384, 389, 393-395, 399, 417-436, 440, 444-447, 464-466, 470-472, 476-478, 482-484, 492, 500-510, 518-528, 536-546, 554-564, 572-582, 590-600, 609, 637-677, 687-891, 900-901, 909-959, 964, 969-1016, 1025, 1029-1042, 1046, 1050-1052
sparkless/functions/core/expressions.py                                109     74    32%   28-32, 55, 73, 91-94, 108-115, 127-129, 141-143, 155-157, 169-171, 188-228, 240-247, 259-266, 278-285, 297-304, 320-323
sparkless/functions/core/lambda_parser.py                              146    126    14%   58-134, 142-148, 167-175, 189-247, 260-274, 285-298, 309-314, 327-332, 359-361, 369, 377, 381-385
sparkless/functions/core/literals.py                                   131     87    34%   38-54, 65-76, 81, 86, 99-101, 108-110, 117-119, 123-125, 129-131, 135-137, 141-143, 147-149, 153-155, 159-161, 165-167, 171-173, 177-179, 183-185, 189-191, 195-197, 201-203, 207-209, 213, 217, 227-229, 233-240, 244-246, 250-252, 256-258, 262-268, 272-274, 278-280, 284-286, 302, 306-308, 312-314, 318-320
sparkless/functions/core/operations.py                                 106     67    37%   27-29, 33-35, 39-41, 45-47, 51-53, 57-59, 63-65, 69, 73, 77-79, 83-85, 89-91, 95-97, 101-103, 107-109, 122, 126, 130, 134, 145, 150-154, 158, 162, 176-189, 199, 203, 211, 219-221, 225-227, 235-237
sparkless/functions/core/sql_expr_parser.py                            308    308     0%   9-551
sparkless/functions/crypto.py                                           48     39    19%   49-71, 91-113, 133-155
sparkless/functions/datetime.py                                        474    333    30%   49-52, 69-74, 86-89, 98, 107, 119-125, 137-143, 155-161, 173-179, 188-189, 205-218, 231-237, 262-301, 327-366, 390-429, 455-500, 520-549, 564-580, 595-601, 616-622, 637-646, 658-664, 676-682, 694-700, 712-718, 730-736, 748-754, 772-794, 813-844, 856-860, 872-876, 888-892, 904-908, 920-924, 936-942, 954-960, 972-978, 990-994, 1006-1010, 1022-1026, 1039-1048, 1063-1074, 1087-1093, 1106-1112, 1125-1134, 1149-1159, 1179-1191, 1211-1222, 1231-1234, 1248-1253, 1262-1273, 1283-1294, 1317-1320, 1340-1343, 1368-1372, 1393-1396, 1422-1468, 1492-1497, 1518-1537, 1557-1560, 1576-1579, 1600-1603, 1622-1627, 1646-1647, 1664-1665, 1685-1693, 1711-1727, 1745-1761
sparkless/functions/functions.py                                      1547    688    56%   67-77, 89-92, 107, 117, 133-136, 142-162, 168-187, 193-212, 218-238, 244, 249, 254, 259, 264, 269, 274, 279, 286, 300, 307, 312, 317, 324, 329, 334, 341, 346, 351, 356, 361, 366, 371, 376, 381, 394-396, 401, 408, 415, 422, 427, 432, 437, 442, 447, 452, 457, 462, 467, 472, 483, 490, 497, 502, 507, 512, 523, 533, 543, 548, 555, 564, 569, 574, 581, 588, 593, 598, 605, 610, 615, 622, 627, 632, 637, 642, 647, 652, 657, 664, 669, 674, 680, 685, 690, 695, 700, 705, 710, 721, 726, 731, 736, 741, 748, 755, 760, 765, 770, 775, 780, 785, 790, 795, 800, 805, 810, 817, 822, 827, 832, 837, 842, 847, 852, 857, 862, 867, 872, 877, 882, 887, 892, 902, 907, 912, 917, 922, 927, 932, 937, 942, 948, 953, 958, 963, 968, 975, 980, 985, 990, 996, 1002, 1007, 1012, 1018, 1023, 1028, 1033, 1038, 1045, 1052, 1059, 1064, 1077, 1082, 1087, 1092, 1097, 1104, 1109, 1114, 1119, 1128, 1133, 1138, 1143, 1148, 1155, 1162, 1167, 1172, 1182-1183, 1192-1193, 1202-1205, 1212, 1219, 1224, 1231, 1238, 1243, 1248, 1253, 1258, 1263, 1269, 1274, 1279, 1284, 1293-1296, 1301, 1306, 1311, 1316, 1321, 1326, 1331, 1336, 1341, 1346, 1364-1420, 1425, 1430, 1435, 1442, 1447, 1452, 1457, 1466, 1471, 1476, 1483, 1491, 1496, 1501, 1506, 1511, 1516, 1521, 1533-1538, 1549, 1556, 1563, 1569-1571, 1579-1586, 1595-1597, 1607-1617, 1626-1634, 1643-1651, 1667-1674, 1690-1697, 1706-1713, 1722-1729, 1738-1745, 1754-1761, 1770-1777, 1786-1793, 1798-1803, 1809, 1814, 1819, 1824, 1829, 1834, 1841, 1848, 1855, 1860, 1865, 1873, 1880, 1887, 1894, 1904, 1913, 1919, 1924, 1929, 1934, 1939, 1946, 1951, 1956, 1963, 1968, 1973, 1978, 1983, 1988, 1993, 2000, 2005, 2010, 2015, 2020, 2029, 2034, 2040, 2045, 2050, 2055, 2062, 2068, 2073, 2078, 2085, 2092, 2099, 2108, 2114-2138, 2152-2158, 2169, 2174, 2179, 2185, 2190, 2195, 2200, 2205, 2210, 2215, 2220, 2225, 2233, 2242-2243, 2248, 2253, 2259, 2264, 2269, 2279, 2285, 2290, 2297, 2302, 2307, 2316-2318, 2326-2328, 2336-2338, 2346-2348, 2353-2355, 2360-2362, 2369-2371, 2378-2380, 2387-2389, 2396-2398, 2404, 2409, 2414, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2464-2466, 2471-2473, 2478-2480, 2485-2487, 2492-2494, 2503-2505, 2510-2512, 2517-2519, 2525-2527, 2532-2534, 2539-2541, 2546-2548, 2553-2555, 2561-2563, 2568-2570, 2575-2577, 2582-2584, 2589-2591, 2596-2598, 2603-2605, 2634-2687, 2716-2741, 2765-2772, 2789-2791, 2797, 2804, 2809, 2814, 2821, 2828, 2833, 2842, 2847, 2854, 2861, 2866, 2871, 2879, 2884, 2891, 2898, 2905, 2913, 2920, 2927, 2933, 2938, 2945, 2950, 2962, 2975, 2989, 3004, 3016, 3023, 3030, 3037, 3044, 3049, 3054, 3059, 3064, 3069, 3074, 3080, 3085, 3090, 3097, 3102, 3107, 3112, 3117, 3122, 3130, 3135, 3140, 3149, 3155, 3160, 3165, 3170, 3175, 3196-3213
sparkless/functions/json_csv.py                                         41     41     0%   8-161
sparkless/functions/map.py                                             101     72    29%   51-54, 69-72, 87-90, 107-115, 138-143, 167-222, 243-246, 266-269, 292-298, 324-330, 356-362, 391-400, 423-430
sparkless/functions/math.py                                            320    207    35%   50-54, 66-70, 82-86, 99-105, 117-121, 133, 145-149, 161-165, 177-182, 204-231, 246-249, 264-267, 284-287, 304-307, 322-334, 349, 361-365, 377-381, 393-397, 409-414, 426-439, 451-461, 476-477, 489-490, 505-506, 518-519, 531-532, 544-545, 567-574, 586-587, 599-600, 612-613, 625-626, 638-639, 651-652, 664-665, 677-679, 696-698, 715-716, 729-730, 745-748, 768-792, 809-810, 823-824, 836-837, 849-850, 859-862, 871-874, 886-887, 902-907, 921-926, 941-960, 972, 990-1003, 1026-1067
sparkless/functions/metadata.py                                         33     33     0%   8-109
sparkless/functions/ordering.py                                         28     28     0%   7-93
sparkless/functions/pandas_types.py                                      6      0   100%
sparkless/functions/string.py                                          547    372    32%   49-53, 65-69, 81-85, 97-103, 115-121, 133-137, 149-153, 165-169, 184-196, 209-218, 231-237, 250-256, 268-274, 287-296, 309-318, 331-337, 350-356, 370-379, 395, 411-420, 435-450, 462-468, 480-484, 496, 508, 521-534, 550-561, 578-590, 606-615, 628-641, 654-667, 683-693, 705-709, 721-725, 737-741, 760-769, 791-803, 818-822, 838-844, 859-863, 878-882, 900-903, 923-926, 941-944, 960-971, 1003-1006, 1030-1033, 1054-1057, 1075-1078, 1099-1102, 1124-1127, 1146-1149, 1169-1174, 1202-1223, 1235-1238, 1250-1253, 1265-1268, 1280-1299, 1316-1334, 1352-1355, 1370-1373, 1391-1394, 1414-1417, 1432-1435, 1451-1457, 1474-1477, 1492-1495, 1508-1514, 1529-1540, 1553-1562, 1575-1584, 1601-1610, 1627-1636, 1649-1655, 1673-1684, 1698-1710, 1725-1731, 1746-1752, 1764-1768, 1781-1792, 1807, 1832-1854, 1872-1879, 1897-1902, 1918-1927, 1939-1940
sparkless/functions/udf.py                                              51     41    20%   41-46, 57-58, 70-90, 119-121, 133-155
sparkless/functions/window_execution.py                                651    602     8%   34-85, 89, 100-101, 115, 129, 143, 157, 171, 185, 201-203, 219, 235-237, 253-255, 269, 283, 297, 311, 325, 339, 350, 361, 377, 390-428, 432-471, 478-553, 557-607, 613-629, 633-694, 698-742, 746-790, 794-845, 849-916, 920-981, 987-1024, 1028-1087, 1092, 1101-1146, 1150-1230, 1234-1260, 1268-1304, 1308-1372, 1376-1420, 1424-1468
sparkless/functions/xml.py                                              65     39    40%   25-28, 50-64, 84-87, 107-110, 131-134, 155-158, 179-182, 203-206, 227-230, 251-254, 275-278
sparkless/optimizer/__init__.py                                          3      0   100%
sparkless/optimizer/optimization_rules.py                              174    144    17%   16-61, 65-66, 71, 83-110, 114-115, 119-142, 150-170, 174-175, 181-184, 192-224, 228, 233, 241-266, 270, 275-278, 286-324, 328, 333, 341-361, 365-366, 371-376
sparkless/optimizer/query_optimizer.py                                 256    191    25%   47-58, 67, 72, 80-125, 129-130, 135, 147-174, 178-179, 183-206, 214-234, 238-239, 245-248, 256-288, 292, 297, 305-330, 334, 339-342, 351-371, 379-392, 403-408, 413, 418-456, 459-472, 477-504, 508, 512, 518
sparkless/performance_simulation.py                                     91     66    27%   58-68, 76-78, 86-88, 99-103, 120-136, 144-151, 155, 166-175, 179-181, 185-197, 221-222, 230-231, 239-240, 244-245, 253, 271-280, 296, 313, 329
sparkless/session/__init__.py                                            4      0   100%
sparkless/session/catalog.py                                           258    223    14%   39, 43, 47, 60-61, 65, 69, 98-100, 111, 119, 130-134, 142, 150, 169-190, 211-233, 250-318, 335-352, 374, 386-414, 430-450, 462-487, 498-519, 528, 537, 546, 566-575, 605-661, 666, 683-716
sparkless/session/config/__init__.py                                     2      0   100%
sparkless/session/config/configuration.py                               54     27    50%   46, 68, 77, 85-86, 94, 102, 110, 118-119, 130, 139-142, 146, 150, 188, 199-200, 211-212, 224-225, 236-237, 245
sparkless/session/context.py                                            36     15    58%   33, 41-42, 47, 51, 55, 82-83, 92, 101, 110, 119, 123, 127, 131
sparkless/session/core/__init__.py                                       4      0   100%
sparkless/session/core/builder.py                                       30     18    40%   31, 42-43, 54, 68-72, 81-99
sparkless/session/core/session.py                                      227    156    31%   12-13, 108-166, 174-177, 182, 187, 192, 197, 202, 211, 236-265, 269, 273, 277, 287, 293, 306-308, 331, 349-352, 368, 380, 384-385, 391, 406-490, 509-510, 515-521, 525, 530-536, 544, 553-555, 575-580, 589, 597, 604, 611, 621, 628, 633-643, 648-652, 661-662, 667
sparkless/session/performance_tracker.py                                39     39     0%   8-117
sparkless/session/services/__init__.py                                   6      0   100%
sparkless/session/services/dataframe_factory.py                        216    203     6%   14-15, 72-451, 465-472, 490-506, 517-587
sparkless/session/services/lifecycle_manager.py                         21     15    29%   30-43, 55-59
sparkless/session/services/mocking_coordinator.py                       32     24    25%   21, 39-57, 69-72, 84-86, 101-105, 109
sparkless/session/services/protocols.py                                 20      0   100%
sparkless/session/services/sql_parameter_binder.py                      29     25    14%   28-51, 62-74
sparkless/session/session.py                                             0      0   100%
sparkless/session/sql/__init__.py                                        5      0   100%
sparkless/session/sql/executor.py                                     1280   1244     3%   76-90, 98-101, 115-150, 170-1285, 1296-1348, 1363-1478, 1492-1529, 1544-1665, 1676-1705, 1720-1880, 1894-1988, 2002-2030, 2042-2088, 2100-2407, 2423-2644, 2667-2751, 2764-2779, 2806-2838, 2860-2867, 2899-2908, 2935-3001
sparkless/session/sql/optimizer.py                                      65     48    26%   41-43, 47, 51, 68, 85-100, 111-114, 127, 142, 155, 168, 181, 192-234, 247-260
sparkless/session/sql/parser.py                                        496    472     5%   39-41, 45, 49, 69, 262-272, 283-315, 327-360, 372-375, 387-687, 698-833, 848-892, 906-993, 1010-1069, 1085-1106, 1121-1141, 1160-1275, 1291-1323, 1335-1338, 1349-1374
sparkless/session/sql/validation.py                                     85     72    15%   42, 105-126, 137-166, 177-188, 199-216, 227-235, 246-265, 276-279, 292, 306-311, 322-323
sparkless/spark_types.py                                               404    281    30%   60-74, 98-104, 109-111, 115, 119-123, 127-151, 165, 181, 196, 211, 226, 241, 256, 271, 279-281, 285, 330-346, 350, 354, 362-364, 368, 372, 384, 396, 408, 420, 432, 439-440, 443, 450-451, 454, 466, 475-477, 480, 489-491, 494, 503-505, 508, 525-528, 531, 539-544, 558-590, 593, 596, 599, 602, 605-606, 610-613, 625-633, 644-646, 650, 654-656, 660, 664-665, 669, 673, 685, 698, 704-713, 718-733, 738-739, 744-746, 755-767, 811-848, 852-880, 884-888, 892-899, 903-910, 914, 918-943, 948-978, 982-989, 995-997, 1001-1005, 1008-1012
sparkless/sql/__init__.py                                               10      0   100%
sparkless/sql/functions.py                                              30      9    70%   59, 63-66, 70-72, 84-92
sparkless/sql/types.py                                                   2      0   100%
sparkless/sql/utils.py                                                   7      0   100%
sparkless/storage/__init__.py                                           10      0   100%
sparkless/storage/backends/__init__.py                                   0      0   100%
sparkless/storage/backends/file.py                                     206    142    31%   26-34, 39, 44, 49, 53-56, 64-69, 77-78, 87-101, 112-119, 127, 135-138, 142, 146, 150, 154-155, 159-161, 174-177, 188-191, 202-203, 211-216, 224-232, 238, 242, 246, 250, 254, 258, 262-264, 268, 272, 276, 288-292, 300-301, 312, 321-328, 336, 348-350, 365-368, 377-378, 390-394, 409-414, 429-431, 443-449, 461, 471-482, 493-502, 506-510, 514, 518-520, 526-531, 538
sparkless/storage/backends/memory.py                                   133     88    34%   22-25, 34, 39, 44, 53-61, 72-77, 85, 93, 97, 101, 105, 109-110, 114-115, 127-128, 139-141, 152, 160-161, 169, 177-179, 187-188, 199, 208-209, 217, 229-231, 246-249, 258-259, 271-275, 290-295, 310-312, 324-330, 342, 352-370, 381-390, 402-406, 418-423, 430
sparkless/storage/manager.py                                           135     86    36%   40-45, 58, 70, 82, 94-98, 108, 119, 128-130, 138, 142-149, 153-159, 171, 186, 195, 208, 223, 237, 249, 258, 269, 283, 295, 303, 312, 325, 336, 344-349, 353-358, 366-378, 382, 390-400, 411-432
sparkless/storage/models.py                                             67      1    99%   77
sparkless/storage/serialization/__init__.py                              0      0   100%
sparkless/storage/serialization/csv.py                                  46     32    30%   23-30, 42-47, 57-62, 76-92, 104-120
sparkless/storage/serialization/json.py                                 39     25    36%   23-24, 36-41, 51-63, 75-90, 102-118
sparkless/utils/profiling.py                                            96     43    55%   47-48, 58, 61, 71-76, 85, 88-90, 94, 99, 102, 108, 118-135, 158-172, 182, 188
sparkless/window.py                                                     67     46    31%   57-60, 77-96, 113-132, 147-151, 166-170, 174-189, 219, 229, 234, 239
--------------------------------------------------------------------------------------------------
TOTAL                                                                33879  28994    14%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml
============================ no tests ran in 9.61s =============================
No performance tests found, skipping...
Running documentation tests...
============================= test session starts ==============================
platform darwin -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /Users/odosmatthews/.pyenv/versions/3.11.13/bin/python3
cachedir: .pytest_cache
hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
rootdir: /Users/odosmatthews/Documents/coding/sparkless
configfile: pyproject.toml
plugins: anyio-4.11.0, cov-7.0.0, green-light-0.2.0, asyncio-1.2.0, xdist-3.8.0, timeout-2.4.0, hypothesis-6.148.7, alt-pytest-asyncio-0.9.3, async-sqlalchemy-0.2.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
timeout: 300.0s
timeout method: thread
timeout func_only: False
created: 10/10 workers
10 workers [4 items]

scheduling tests via LoadFileScheduling

tests/documentation/test_examples.py::TestExampleScripts::test_basic_usage_runs 
[gw0] [ 25%] SKIPPED tests/documentation/test_examples.py::TestExampleScripts::test_basic_usage_runs 
tests/documentation/test_examples.py::TestExampleScripts::test_comprehensive_usage_runs 
[gw0] [ 50%] SKIPPED tests/documentation/test_examples.py::TestExampleScripts::test_comprehensive_usage_runs 
tests/documentation/test_examples.py::TestExampleScripts::test_examples_show_v2_features 
[gw0] [ 75%] PASSED tests/documentation/test_examples.py::TestExampleScripts::test_examples_show_v2_features 
tests/documentation/test_examples.py::TestExampleScripts::test_example_outputs_captured 
[gw0] [100%] PASSED tests/documentation/test_examples.py::TestExampleScripts::test_example_outputs_captured 

================================ tests coverage ================================
______________ coverage: platform darwin, python 3.11.13-final-0 _______________

Name                                                                 Stmts   Miss  Cover   Missing
--------------------------------------------------------------------------------------------------
sparkless/__init__.py                                                   24      0   100%
sparkless/_version.py                                                    8      8     0%   8-19
sparkless/backend/__init__.py                                            3      0   100%
sparkless/backend/factory.py                                            72     52    28%   44-55, 78-89, 104-115, 131-157, 174-176, 185-195
sparkless/backend/polars/__init__.py                                     4      4     0%   19-23
sparkless/backend/polars/_over_compat.py                                19     19     0%   8-40
sparkless/backend/polars/executors/__init__.py                           1      1     0%   13
sparkless/backend/polars/export.py                                      36     36     0%   7-114
sparkless/backend/polars/expression_translator.py                     2172   2172     0%   8-5251
sparkless/backend/polars/materializer.py                               852    852     0%   8-1944
sparkless/backend/polars/operation_executor.py                        2047   2047     0%   1-4555
sparkless/backend/polars/parquet_storage.py                             41     41     0%   8-119
sparkless/backend/polars/plan_interpreter.py                           381    381     0%   8-531
sparkless/backend/polars/schema_registry.py                             73     73     0%   8-222
sparkless/backend/polars/schema_utils.py                                31     31     0%   3-69
sparkless/backend/polars/storage.py                                    350    350     0%   8-771
sparkless/backend/polars/translators/__init__.py                         1      1     0%   14
sparkless/backend/polars/translators/arithmetic_translator.py           17     17     0%   8-70
sparkless/backend/polars/translators/string_translator.py              145    145     0%   8-302
sparkless/backend/polars/translators/type_translator.py                107    107     0%   8-190
sparkless/backend/polars/type_mapper.py                                 99     99     0%   8-173
sparkless/backend/polars/window_handler.py                             290    290     0%   7-563
sparkless/backend/protocols.py                                          14      0   100%
sparkless/backend/robin/__init__.py                                      4      0   100%
sparkless/backend/robin/export.py                                       46     34    26%   20-29, 36, 41-50, 55-62, 71-77, 80-85
sparkless/backend/robin/materializer.py                                714    684     4%   40-46, 56-64, 69-82, 88-89, 93, 102-113, 123-195, 205-239, 244-249, 261-693, 717, 720, 723, 726-727, 730-742, 745-762, 765-767, 770-780, 795-813, 818-822, 836-838, 846-1070, 1075
sparkless/backend/robin/plan_executor.py                               191    191     0%   9-264
sparkless/backend/robin/storage.py                                      52     24    54%   23-28, 33, 36, 39, 42, 45, 53, 56, 59, 62, 67, 72, 77, 82, 85, 88, 91, 94, 99, 104
sparkless/compat/__init__.py                                             2      0   100%
sparkless/compat/datetime.py                                            74     53    28%   43, 55-57, 61-67, 73-81, 96-103, 115-122, 128-133, 141-146, 162-182
sparkless/config.py                                                     55     37    33%   28-34, 41-73, 77-81, 87-92, 98-100, 106
sparkless/core/__init__.py                                               9      0   100%
sparkless/core/column_resolver.py                                       33     33     0%   8-142
sparkless/core/condition_evaluator.py                                  764    730     4%   27-34, 49-56, 71-245, 260-541, 556-576, 591-604, 619-781, 795-1203, 1218-1229, 1245-1274, 1290-1311, 1324-1340, 1353, 1366-1370, 1384-1403
sparkless/core/data_validation.py                                       80     69    14%   39-42, 56-85, 91-113, 128-147, 160-187, 205-206, 220-221
sparkless/core/ddl_adapter.py                                           31     23    26%   52-53, 65-66, 78-79, 91-106, 118-133
sparkless/core/exceptions/__init__.py                                    6      0   100%
sparkless/core/exceptions/analysis.py                                  100     81    19%   37-63, 70-73, 91, 109, 137-162, 170-202, 230-245, 269-272, 302-323
sparkless/core/exceptions/base.py                                       22      9    59%   23-25, 28, 31, 46, 61, 76, 91
sparkless/core/exceptions/execution.py                                  29     13    55%   27, 45, 63, 87-90, 114-117, 135, 153
sparkless/core/exceptions/operation.py                                  87     87     0%   8-206
sparkless/core/exceptions/py4j_compat.py                                10     10     0%   8-41
sparkless/core/exceptions/runtime.py                                    41     25    39%   27, 53-57, 75, 101-107, 131-134, 158-161, 187-193
sparkless/core/exceptions/validation.py                                 44     26    41%   27, 45, 63, 81, 107-111, 141-147, 171-174, 202-207
sparkless/core/interfaces/__init__.py                                    5      0   100%
sparkless/core/interfaces/dataframe.py                                 180     56    69%   20, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 98, 103, 110, 115, 120, 125, 130, 136, 142, 151, 156, 161, 166, 171, 176, 181, 190, 195, 200, 205, 212, 217, 222, 227, 232, 241, 246, 251, 256, 261, 266, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320
sparkless/core/interfaces/functions.py                                 186     56    70%   23, 28, 33, 42, 47, 56, 61, 70, 75, 84, 89, 94, 99, 108, 113, 118, 123, 130, 135, 144, 149, 154, 159, 164, 173, 178, 185, 192, 197, 202, 207, 212, 221, 226, 231, 236, 241, 250, 255, 263, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 333, 338, 343, 348
sparkless/core/interfaces/session.py                                   117     34    71%   20, 26, 32, 38, 44, 50, 59, 64, 69, 76, 81, 86, 96, 101, 106, 115, 120, 125, 136, 141, 146, 151, 156, 161, 166, 171, 176, 185, 190, 195, 200, 209, 214, 219
sparkless/core/interfaces/storage.py                                   126     38    70%   29, 34, 39, 44, 54, 59, 64, 69, 76, 83, 90, 97, 102, 106, 110, 114, 120, 126, 136, 142, 148, 153, 158, 163, 168, 173, 186, 192, 198, 204, 210, 215, 220, 229, 234, 239, 248, 253
sparkless/core/protocols.py                                             42      0   100%
sparkless/core/safe_evaluator.py                                       125    116     7%   39-50, 63-67, 83-215
sparkless/core/schema_inference.py                                     107     92    14%   72-134, 157-200, 218-237, 242-251, 256-265, 279-280, 296-309
sparkless/core/type_utils.py                                            86     66    23%   20-21, 49-51, 63-65, 77-79, 91-93, 112-121, 140-144, 164-168, 187-199, 223-259, 278, 290-292, 304
sparkless/core/types/__init__.py                                         4      0   100%
sparkless/core/types/data_types.py                                     139     38    73%   22, 27, 32, 37, 42, 47, 52, 57, 66, 76, 81, 91, 97, 102, 111, 121, 127, 132, 141, 146, 155, 160, 170, 175, 180, 190, 196, 201, 206, 211, 221, 226, 231, 240, 249, 254, 259, 264
sparkless/core/types/metadata.py                                       166     47    72%   18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 73, 79, 85, 91, 97, 103, 108, 113, 118, 128, 134, 140, 145, 150, 160, 166, 172, 177, 182, 187, 197, 203, 209, 215, 220, 225, 230, 239, 244, 249, 254, 259, 268, 273, 278, 283, 288
sparkless/core/types/schema.py                                         121     36    70%   22, 28, 34, 40, 45, 50, 55, 60, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 185, 190, 195, 200, 209, 214, 221, 226
sparkless/data_generation/__init__.py                                    4      4     0%   8-12
sparkless/data_generation/builder.py                                    28     28     0%   8-85
sparkless/data_generation/convenience.py                                 9      9     0%   8-64
sparkless/data_generation/generator.py                                 174    174     0%   8-337
sparkless/dataframe/__init__.py                                          6      0   100%
sparkless/dataframe/aggregations/__init__.py                             2      2     0%   8-10
sparkless/dataframe/aggregations/operations.py                          75     75     0%   8-208
sparkless/dataframe/assertions/__init__.py                               3      3     0%   7-10
sparkless/dataframe/assertions/assertions.py                            26     26     0%   8-88
sparkless/dataframe/assertions/operations.py                            16     16     0%   8-45
sparkless/dataframe/attribute_handler.py                                62     50    19%   30, 54, 77-85, 116-125, 150-154, 175-227
sparkless/dataframe/casting/__init__.py                                  2      2     0%   3-5
sparkless/dataframe/casting/type_converter.py                           95     95     0%   3-180
sparkless/dataframe/collection_handler.py                               29     29     0%   8-81
sparkless/dataframe/condition_handler.py                                52     52     0%   8-180
sparkless/dataframe/dataframe.py                                       513    351    32%   132-175, 179-183, 187-191, 195-199, 203-207, 211-215, 219-224, 228-230, 240-243, 252-265, 276, 280, 293, 305, 311, 317, 321, 325, 329, 333, 339, 345, 359, 365, 369, 373, 377, 381, 390, 394, 404, 408, 412, 420, 424, 428, 432, 436, 440, 445, 449, 453, 457, 463, 469-477, 486, 490, 495-503, 507-508, 518-532, 551, 555-561, 565, 569, 574-583, 596-609, 621, 625, 630, 634, 638, 642, 652, 674, 689-691, 700, 709, 715, 719, 723, 727, 733, 742, 746, 750, 756, 760, 770, 780, 791, 795, 799, 803, 809, 813, 817, 821, 829, 835, 839, 843, 847, 852, 856, 860, 864, 871-879, 887-889, 894, 899, 911-912, 924-929, 932, 936, 955-969, 975, 987-1062, 1078-1097, 1103, 1114-1128, 1139-1174, 1184-1188, 1195, 1201-1206, 1210, 1216, 1225, 1241-1244, 1250, 1258, 1269, 1284, 1292, 1303, 1311, 1323, 1329, 1335, 1342, 1347-1353, 1368-1379, 1383, 1403-1411, 1416, 1420-1460
sparkless/dataframe/display/__init__.py                                  3      3     0%   3-6
sparkless/dataframe/display/formatter.py                                37     37     0%   3-57
sparkless/dataframe/display/operations.py                              118    118     0%   8-274
sparkless/dataframe/evaluation/__init__.py                               2      0   100%
sparkless/dataframe/evaluation/evaluators/__init__.py                    1      1     0%   13
sparkless/dataframe/evaluation/evaluators/conditional_evaluator.py      22     22     0%   7-63
sparkless/dataframe/evaluation/expression_evaluator.py                2615   2380     9%   70-78, 89-113, 117-122, 128-130, 134, 138-181, 193-259, 269-300, 306-416, 422-448, 458-1021, 1027-1066, 1072-1257, 1263-1340, 1347-1385, 1391-1442, 1448-1534, 1539-1555, 1562-1574, 1578-1593, 1597-1612, 1616-1631, 1635-1650, 1661-1666, 1670-1693, 1697, 1701, 1710-1731, 1735, 1944, 1948, 1952-1956, 1960-1964, 1968-1972, 1976-1989, 1993-2000, 2004-2014, 2018-2028, 2032-2034, 2040-2043, 2047-2050, 2054-2061, 2065-2070, 2085-2143, 2147-2152, 2163-2207, 2211-2222, 2226-2234, 2240-2242, 2246-2251, 2255-2257, 2261-2263, 2269, 2273-2279, 2283, 2287-2292, 2296-2298, 2302-2304, 2308, 2312, 2316, 2324, 2328, 2332-2335, 2339-2341, 2345-2350, 2354-2357, 2361-2373, 2380, 2384-2416, 2420-2425, 2429-2451, 2455-2477, 2483-2499, 2503-2534, 2540-2575, 2581-2588, 2592-2612, 2616-2659, 2663-2680, 2684-2697, 2702, 2706-2707, 2711, 2715, 2719, 2725-2734, 2738-2747, 2751-2758, 2764, 2768-2782, 2786-2793, 2797-2811, 2815-2822, 2826-2833, 2837-2844, 2848-2857, 2861-2870, 2874-2883, 2887-2894, 2898-2905, 2909-2916, 2920-2927, 2931-2938, 2944, 2948-2957, 2962, 2967, 2972-3004, 3008-3017, 3023, 3029, 3033-3044, 3050, 3057, 3062, 3068, 3073-3097, 3102, 3107, 3112, 3121-3153, 3157-3201, 3205-3249, 3253-3280, 3285-3306, 3314-3376, 3380-3387, 3391-3411, 3417, 3423, 3427-3542, 3547-3558, 3562-3571, 3575, 3579, 3583, 3587, 3591, 3595, 3599, 3603-3608, 3612-3618, 3622-3627, 3631-3636, 3645, 3659-3693, 3699, 3703-3710, 3714-3725, 3730-3739, 3745-3754, 3760-3765, 3771-3776, 3782-3790, 3796-3804, 3808, 3812-3818, 3822-3833, 3837-3840, 3844-3850, 3854-3856, 3861, 3866-3878, 3882, 3886-3892, 3896-3902, 3908-3918, 3922-3929, 3934, 3938-3940, 3944-3967, 3971-3994, 3999, 4004, 4009, 4014, 4019, 4024, 4028-4040, 4046-4053, 4059-4066, 4070-4079, 4085-4092, 4098-4105, 4111-4118, 4126-4140, 4144-4151, 4155-4162, 4167-4182, 4186-4201, 4221, 4226, 4231, 4237-4248, 4255-4258, 4264-4267, 4273-4278, 4283-4287, 4291-4308, 4314-4329, 4335-4350, 4356-4359, 4363-4365, 4370-4378, 4384-4411, 4416-4425, 4429-4431, 4435-4437, 4442-4461, 4465-4482, 4486-4503, 4507-4524, 4528-4533, 4539-4550, 4554-4565, 4569-4574
sparkless/dataframe/export.py                                           15     15     0%   8-46
sparkless/dataframe/grouped/__init__.py                                  5      0   100%
sparkless/dataframe/grouped/base.py                                   1064   1034     3%   56-58, 72-696, 710-765, 779-1647, 1664-1934, 1945-1952, 1963-1970, 1985, 1996-2007, 2018-2025, 2036-2043, 2054-2063, 2074-2083, 2094-2103, 2114-2123, 2134-2143, 2154-2163, 2174-2201, 2212-2239, 2253-2281, 2303-2370, 2392-2447
sparkless/dataframe/grouped/cube.py                                     86     77    10%   30-31, 47-215
sparkless/dataframe/grouped/pivot.py                                   493    470     5%   36-39, 55-356, 362-397, 403-641, 649-810, 822-831, 842-851, 862, 873-882, 893-902, 913-922, 933-939, 950-956, 967-973, 984-990, 1001-1007, 1018-1024, 1035-1041
sparkless/dataframe/grouped/rollup.py                                   87     79     9%   29-30, 48-220
sparkless/dataframe/joins/__init__.py                                    2      2     0%   8-10
sparkless/dataframe/joins/operations.py                                146    146     0%   8-396
sparkless/dataframe/lazy.py                                           1222   1222     0%   8-2865
sparkless/dataframe/logical_plan.py                                    223    223     0%   9-456
sparkless/dataframe/operations/__init__.py                               2      2     0%   8-10
sparkless/dataframe/operations/aggregation_operations.py               128    128     0%   3-313
sparkless/dataframe/operations/join_operations.py                      157    157     0%   3-329
sparkless/dataframe/operations/misc.py                                 516    516     0%   8-1427
sparkless/dataframe/operations/set_operations.py                       168    168     0%   3-346
sparkless/dataframe/protocols.py                                        49      0   100%
sparkless/dataframe/rdd.py                                              83     56    33%   26, 34, 42, 53, 61, 69-70, 81, 92-95, 106, 117-125, 136-143, 155-166, 174, 185, 193, 201, 209, 217, 229, 240-243, 254-261, 269, 277
sparkless/dataframe/reader.py                                          187    156    17%   64-67, 81-82, 97-98, 112-113, 127-136, 158-190, 206-259, 266-277, 281-288, 294-306, 311-321, 326-349, 354-374, 377-382, 386-390, 396-402, 406, 410, 414, 429, 444, 461-463
sparkless/dataframe/robin_plan.py                                       78     78     0%   10-162
sparkless/dataframe/schema/__init__.py                                   3      3     0%   3-6
sparkless/dataframe/schema/operations.py                                22     22     0%   8-51
sparkless/dataframe/schema/schema_manager.py                           514    514     0%   3-1019
sparkless/dataframe/services/__init__.py                                 8      8     0%   8-16
sparkless/dataframe/services/aggregation_service.py                     99     99     0%   7-254
sparkless/dataframe/services/assertion_service.py                       17     17     0%   7-51
sparkless/dataframe/services/display_service.py                        126    126     0%   7-297
sparkless/dataframe/services/join_service.py                           248    248     0%   7-628
sparkless/dataframe/services/misc_service.py                           613    613     0%   7-1612
sparkless/dataframe/services/schema_service.py                           4      4     0%   8-24
sparkless/dataframe/services/transformation_service.py                 349    349     0%   7-910
sparkless/dataframe/transformations/__init__.py                          2      2     0%   8-10
sparkless/dataframe/transformations/operations.py                      224    224     0%   8-629
sparkless/dataframe/types.py                                             8      8     0%   8-25
sparkless/dataframe/validation/__init__.py                               2      2     0%   7-9
sparkless/dataframe/validation/column_validator.py                     171    171     0%   9-578
sparkless/dataframe/validation_handler.py                               21     21     0%   9-116
sparkless/dataframe/window_handler.py                                  315    315     0%   8-698
sparkless/dataframe/writer.py                                          395    352    11%   74-79, 93-94, 111-120, 129, 144-145, 159-160, 174-175, 191-442, 469-495, 509, 521, 537, 549, 561, 573, 580-586, 590-606, 610-613, 617-622, 627-642, 647-656, 661-670, 675-690, 694-699, 720-753, 771-865, 886-917, 936-1022
sparkless/delta.py                                                     308    254    18%   46-51, 61-74, 87-88, 100-116, 121-122, 127, 131-132, 137-152, 156-185, 189, 198, 210, 221-286, 300-341, 345, 348-352, 355-357, 360-368, 373-379, 384-408, 421-430, 434, 438, 441-446, 449-450, 455-456, 459-461, 464-466, 470-514, 517-523, 526-540, 547-551, 563-576, 581-584, 589-593, 601-629, 637-657
sparkless/error_simulation.py                                           89     89     0%   29-338
sparkless/errors.py                                                     28     10    64%   57, 62, 67, 72, 79, 86, 91, 96, 101, 106
sparkless/functions/__init__.py                                         29      6    79%   560-569
sparkless/functions/aggregate.py                                       323    215    33%   56-70, 90-100, 115-123, 138-146, 161-169, 184-192, 211-212, 227-228, 243-244, 259-260, 275-283, 299-300, 315-316, 331-332, 347-355, 370-371, 386-387, 402-403, 418-420, 439-443, 461-472, 490-501, 516-517, 534-535, 552-553, 570-571, 591-597, 617-623, 640-641, 658-659, 676-677, 699-716, 733-734, 751-752, 769-770, 787-788, 803-807, 825-826, 843-844, 857-859, 874-890, 904-912, 930-940, 958-967, 985-994, 1014-1026, 1044-1053, 1071-1080, 1098-1107, 1125-1134, 1152-1161, 1182-1222
sparkless/functions/array.py                                           272    185    32%   55-58, 78-83, 106-111, 134-139, 160-163, 184-187, 213-219, 245-251, 277-283, 309-315, 346-356, 385-396, 418-421, 440-443, 465-468, 486-490, 511-514, 538-541, 561-564, 579-585, 603-606, 626-629, 644-647, 662-665, 680-683, 698-701, 716-719, 737-742, 762-765, 779-782, 794-797, 811-830, 853-883, 900-903, 927-976, 997-1000, 1018-1022, 1040-1043, 1058-1059, 1074-1086, 1098-1100, 1112-1116
sparkless/functions/base.py                                            135    103    24%   57-67, 71-89, 94-99, 106-139, 150-161, 165-171, 175-184, 188-201, 205-217, 221-233, 237-239, 250-251, 265, 277, 281, 285, 289, 293, 297, 302, 307, 312, 317, 322
sparkless/functions/bitwise.py                                         108     67    38%   31-34, 50-53, 71, 86-89, 107-110, 125-128, 143-146, 161-168, 183-198, 213-228, 243-258, 276-283, 300-307, 324-331, 347-350, 367-370, 387-390, 405-408, 425-428
sparkless/functions/conditional.py                                     396    320    19%   33-115, 133-142, 147, 152, 164-165, 176-188, 199-200, 214, 226, 230, 234, 238, 242, 246, 251, 256, 261, 266, 271, 275, 279, 283, 295-300, 304-367, 381-384, 396-412, 426-455, 472-486, 498-502, 514-521, 533-538, 551-553, 570-603, 622, 637-648, 661-682, 707-722, 737-752, 767-782, 797-812, 827-842, 854-861, 873-880, 895-908, 923-939, 954-970, 985-1001
sparkless/functions/core/__init__.py                                     6      0   100%
sparkless/functions/core/column.py                                     457    370    19%   39, 43, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 102, 108, 113, 119, 125, 131, 135, 139, 143, 147, 151, 155, 159, 163, 189-195, 199, 203, 209-210, 216, 220, 224, 239, 243, 247, 251, 255, 259, 263, 267, 285, 306, 331-345, 368-377, 382-384, 389, 393-395, 399, 417-436, 440, 444-447, 464-466, 470-472, 476-478, 482-484, 492, 500-510, 518-528, 536-546, 554-564, 572-582, 590-600, 609, 637-677, 687-891, 900-901, 909-959, 964, 969-1016, 1025, 1029-1042, 1046, 1050-1052
sparkless/functions/core/expressions.py                                109     74    32%   28-32, 55, 73, 91-94, 108-115, 127-129, 141-143, 155-157, 169-171, 188-228, 240-247, 259-266, 278-285, 297-304, 320-323
sparkless/functions/core/lambda_parser.py                              146    126    14%   58-134, 142-148, 167-175, 189-247, 260-274, 285-298, 309-314, 327-332, 359-361, 369, 377, 381-385
sparkless/functions/core/literals.py                                   131     87    34%   38-54, 65-76, 81, 86, 99-101, 108-110, 117-119, 123-125, 129-131, 135-137, 141-143, 147-149, 153-155, 159-161, 165-167, 171-173, 177-179, 183-185, 189-191, 195-197, 201-203, 207-209, 213, 217, 227-229, 233-240, 244-246, 250-252, 256-258, 262-268, 272-274, 278-280, 284-286, 302, 306-308, 312-314, 318-320
sparkless/functions/core/operations.py                                 106     67    37%   27-29, 33-35, 39-41, 45-47, 51-53, 57-59, 63-65, 69, 73, 77-79, 83-85, 89-91, 95-97, 101-103, 107-109, 122, 126, 130, 134, 145, 150-154, 158, 162, 176-189, 199, 203, 211, 219-221, 225-227, 235-237
sparkless/functions/core/sql_expr_parser.py                            308    308     0%   9-551
sparkless/functions/crypto.py                                           48     39    19%   49-71, 91-113, 133-155
sparkless/functions/datetime.py                                        474    333    30%   49-52, 69-74, 86-89, 98, 107, 119-125, 137-143, 155-161, 173-179, 188-189, 205-218, 231-237, 262-301, 327-366, 390-429, 455-500, 520-549, 564-580, 595-601, 616-622, 637-646, 658-664, 676-682, 694-700, 712-718, 730-736, 748-754, 772-794, 813-844, 856-860, 872-876, 888-892, 904-908, 920-924, 936-942, 954-960, 972-978, 990-994, 1006-1010, 1022-1026, 1039-1048, 1063-1074, 1087-1093, 1106-1112, 1125-1134, 1149-1159, 1179-1191, 1211-1222, 1231-1234, 1248-1253, 1262-1273, 1283-1294, 1317-1320, 1340-1343, 1368-1372, 1393-1396, 1422-1468, 1492-1497, 1518-1537, 1557-1560, 1576-1579, 1600-1603, 1622-1627, 1646-1647, 1664-1665, 1685-1693, 1711-1727, 1745-1761
sparkless/functions/functions.py                                      1547    688    56%   67-77, 89-92, 107, 117, 133-136, 142-162, 168-187, 193-212, 218-238, 244, 249, 254, 259, 264, 269, 274, 279, 286, 300, 307, 312, 317, 324, 329, 334, 341, 346, 351, 356, 361, 366, 371, 376, 381, 394-396, 401, 408, 415, 422, 427, 432, 437, 442, 447, 452, 457, 462, 467, 472, 483, 490, 497, 502, 507, 512, 523, 533, 543, 548, 555, 564, 569, 574, 581, 588, 593, 598, 605, 610, 615, 622, 627, 632, 637, 642, 647, 652, 657, 664, 669, 674, 680, 685, 690, 695, 700, 705, 710, 721, 726, 731, 736, 741, 748, 755, 760, 765, 770, 775, 780, 785, 790, 795, 800, 805, 810, 817, 822, 827, 832, 837, 842, 847, 852, 857, 862, 867, 872, 877, 882, 887, 892, 902, 907, 912, 917, 922, 927, 932, 937, 942, 948, 953, 958, 963, 968, 975, 980, 985, 990, 996, 1002, 1007, 1012, 1018, 1023, 1028, 1033, 1038, 1045, 1052, 1059, 1064, 1077, 1082, 1087, 1092, 1097, 1104, 1109, 1114, 1119, 1128, 1133, 1138, 1143, 1148, 1155, 1162, 1167, 1172, 1182-1183, 1192-1193, 1202-1205, 1212, 1219, 1224, 1231, 1238, 1243, 1248, 1253, 1258, 1263, 1269, 1274, 1279, 1284, 1293-1296, 1301, 1306, 1311, 1316, 1321, 1326, 1331, 1336, 1341, 1346, 1364-1420, 1425, 1430, 1435, 1442, 1447, 1452, 1457, 1466, 1471, 1476, 1483, 1491, 1496, 1501, 1506, 1511, 1516, 1521, 1533-1538, 1549, 1556, 1563, 1569-1571, 1579-1586, 1595-1597, 1607-1617, 1626-1634, 1643-1651, 1667-1674, 1690-1697, 1706-1713, 1722-1729, 1738-1745, 1754-1761, 1770-1777, 1786-1793, 1798-1803, 1809, 1814, 1819, 1824, 1829, 1834, 1841, 1848, 1855, 1860, 1865, 1873, 1880, 1887, 1894, 1904, 1913, 1919, 1924, 1929, 1934, 1939, 1946, 1951, 1956, 1963, 1968, 1973, 1978, 1983, 1988, 1993, 2000, 2005, 2010, 2015, 2020, 2029, 2034, 2040, 2045, 2050, 2055, 2062, 2068, 2073, 2078, 2085, 2092, 2099, 2108, 2114-2138, 2152-2158, 2169, 2174, 2179, 2185, 2190, 2195, 2200, 2205, 2210, 2215, 2220, 2225, 2233, 2242-2243, 2248, 2253, 2259, 2264, 2269, 2279, 2285, 2290, 2297, 2302, 2307, 2316-2318, 2326-2328, 2336-2338, 2346-2348, 2353-2355, 2360-2362, 2369-2371, 2378-2380, 2387-2389, 2396-2398, 2404, 2409, 2414, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2464-2466, 2471-2473, 2478-2480, 2485-2487, 2492-2494, 2503-2505, 2510-2512, 2517-2519, 2525-2527, 2532-2534, 2539-2541, 2546-2548, 2553-2555, 2561-2563, 2568-2570, 2575-2577, 2582-2584, 2589-2591, 2596-2598, 2603-2605, 2634-2687, 2716-2741, 2765-2772, 2789-2791, 2797, 2804, 2809, 2814, 2821, 2828, 2833, 2842, 2847, 2854, 2861, 2866, 2871, 2879, 2884, 2891, 2898, 2905, 2913, 2920, 2927, 2933, 2938, 2945, 2950, 2962, 2975, 2989, 3004, 3016, 3023, 3030, 3037, 3044, 3049, 3054, 3059, 3064, 3069, 3074, 3080, 3085, 3090, 3097, 3102, 3107, 3112, 3117, 3122, 3130, 3135, 3140, 3149, 3155, 3160, 3165, 3170, 3175, 3196-3213
sparkless/functions/json_csv.py                                         41     41     0%   8-161
sparkless/functions/map.py                                             101     72    29%   51-54, 69-72, 87-90, 107-115, 138-143, 167-222, 243-246, 266-269, 292-298, 324-330, 356-362, 391-400, 423-430
sparkless/functions/math.py                                            320    207    35%   50-54, 66-70, 82-86, 99-105, 117-121, 133, 145-149, 161-165, 177-182, 204-231, 246-249, 264-267, 284-287, 304-307, 322-334, 349, 361-365, 377-381, 393-397, 409-414, 426-439, 451-461, 476-477, 489-490, 505-506, 518-519, 531-532, 544-545, 567-574, 586-587, 599-600, 612-613, 625-626, 638-639, 651-652, 664-665, 677-679, 696-698, 715-716, 729-730, 745-748, 768-792, 809-810, 823-824, 836-837, 849-850, 859-862, 871-874, 886-887, 902-907, 921-926, 941-960, 972, 990-1003, 1026-1067
sparkless/functions/metadata.py                                         33     33     0%   8-109
sparkless/functions/ordering.py                                         28     28     0%   7-93
sparkless/functions/pandas_types.py                                      6      0   100%
sparkless/functions/string.py                                          547    372    32%   49-53, 65-69, 81-85, 97-103, 115-121, 133-137, 149-153, 165-169, 184-196, 209-218, 231-237, 250-256, 268-274, 287-296, 309-318, 331-337, 350-356, 370-379, 395, 411-420, 435-450, 462-468, 480-484, 496, 508, 521-534, 550-561, 578-590, 606-615, 628-641, 654-667, 683-693, 705-709, 721-725, 737-741, 760-769, 791-803, 818-822, 838-844, 859-863, 878-882, 900-903, 923-926, 941-944, 960-971, 1003-1006, 1030-1033, 1054-1057, 1075-1078, 1099-1102, 1124-1127, 1146-1149, 1169-1174, 1202-1223, 1235-1238, 1250-1253, 1265-1268, 1280-1299, 1316-1334, 1352-1355, 1370-1373, 1391-1394, 1414-1417, 1432-1435, 1451-1457, 1474-1477, 1492-1495, 1508-1514, 1529-1540, 1553-1562, 1575-1584, 1601-1610, 1627-1636, 1649-1655, 1673-1684, 1698-1710, 1725-1731, 1746-1752, 1764-1768, 1781-1792, 1807, 1832-1854, 1872-1879, 1897-1902, 1918-1927, 1939-1940
sparkless/functions/udf.py                                              51     41    20%   41-46, 57-58, 70-90, 119-121, 133-155
sparkless/functions/window_execution.py                                651    602     8%   34-85, 89, 100-101, 115, 129, 143, 157, 171, 185, 201-203, 219, 235-237, 253-255, 269, 283, 297, 311, 325, 339, 350, 361, 377, 390-428, 432-471, 478-553, 557-607, 613-629, 633-694, 698-742, 746-790, 794-845, 849-916, 920-981, 987-1024, 1028-1087, 1092, 1101-1146, 1150-1230, 1234-1260, 1268-1304, 1308-1372, 1376-1420, 1424-1468
sparkless/functions/xml.py                                              65     39    40%   25-28, 50-64, 84-87, 107-110, 131-134, 155-158, 179-182, 203-206, 227-230, 251-254, 275-278
sparkless/optimizer/__init__.py                                          3      3     0%   8-17
sparkless/optimizer/optimization_rules.py                              174    174     0%   7-376
sparkless/optimizer/query_optimizer.py                                 256    256     0%   8-518
sparkless/performance_simulation.py                                     91     91     0%   29-329
sparkless/session/__init__.py                                            4      0   100%
sparkless/session/catalog.py                                           258    223    14%   39, 43, 47, 60-61, 65, 69, 98-100, 111, 119, 130-134, 142, 150, 169-190, 211-233, 250-318, 335-352, 374, 386-414, 430-450, 462-487, 498-519, 528, 537, 546, 566-575, 605-661, 666, 683-716
sparkless/session/config/__init__.py                                     2      0   100%
sparkless/session/config/configuration.py                               54     27    50%   46, 68, 77, 85-86, 94, 102, 110, 118-119, 130, 139-142, 146, 150, 188, 199-200, 211-212, 224-225, 236-237, 245
sparkless/session/context.py                                            36     15    58%   33, 41-42, 47, 51, 55, 82-83, 92, 101, 110, 119, 123, 127, 131
sparkless/session/core/__init__.py                                       4      0   100%
sparkless/session/core/builder.py                                       30     18    40%   31, 42-43, 54, 68-72, 81-99
sparkless/session/core/session.py                                      227    156    31%   12-13, 108-166, 174-177, 182, 187, 192, 197, 202, 211, 236-265, 269, 273, 277, 287, 293, 306-308, 331, 349-352, 368, 380, 384-385, 391, 406-490, 509-510, 515-521, 525, 530-536, 544, 553-555, 575-580, 589, 597, 604, 611, 621, 628, 633-643, 648-652, 661-662, 667
sparkless/session/performance_tracker.py                                39     39     0%   8-117
sparkless/session/services/__init__.py                                   6      0   100%
sparkless/session/services/dataframe_factory.py                        216    203     6%   14-15, 72-451, 465-472, 490-506, 517-587
sparkless/session/services/lifecycle_manager.py                         21     15    29%   30-43, 55-59
sparkless/session/services/mocking_coordinator.py                       32     24    25%   21, 39-57, 69-72, 84-86, 101-105, 109
sparkless/session/services/protocols.py                                 20      0   100%
sparkless/session/services/sql_parameter_binder.py                      29     25    14%   28-51, 62-74
sparkless/session/session.py                                             0      0   100%
sparkless/session/sql/__init__.py                                        5      0   100%
sparkless/session/sql/executor.py                                     1280   1244     3%   76-90, 98-101, 115-150, 170-1285, 1296-1348, 1363-1478, 1492-1529, 1544-1665, 1676-1705, 1720-1880, 1894-1988, 2002-2030, 2042-2088, 2100-2407, 2423-2644, 2667-2751, 2764-2779, 2806-2838, 2860-2867, 2899-2908, 2935-3001
sparkless/session/sql/optimizer.py                                      65     48    26%   41-43, 47, 51, 68, 85-100, 111-114, 127, 142, 155, 168, 181, 192-234, 247-260
sparkless/session/sql/parser.py                                        496    472     5%   39-41, 45, 49, 69, 262-272, 283-315, 327-360, 372-375, 387-687, 698-833, 848-892, 906-993, 1010-1069, 1085-1106, 1121-1141, 1160-1275, 1291-1323, 1335-1338, 1349-1374
sparkless/session/sql/validation.py                                     85     72    15%   42, 105-126, 137-166, 177-188, 199-216, 227-235, 246-265, 276-279, 292, 306-311, 322-323
sparkless/spark_types.py                                               404    281    30%   60-74, 98-104, 109-111, 115, 119-123, 127-151, 165, 181, 196, 211, 226, 241, 256, 271, 279-281, 285, 330-346, 350, 354, 362-364, 368, 372, 384, 396, 408, 420, 432, 439-440, 443, 450-451, 454, 466, 475-477, 480, 489-491, 494, 503-505, 508, 525-528, 531, 539-544, 558-590, 593, 596, 599, 602, 605-606, 610-613, 625-633, 644-646, 650, 654-656, 660, 664-665, 669, 673, 685, 698, 704-713, 718-733, 738-739, 744-746, 755-767, 811-848, 852-880, 884-888, 892-899, 903-910, 914, 918-943, 948-978, 982-989, 995-997, 1001-1005, 1008-1012
sparkless/sql/__init__.py                                               10      0   100%
sparkless/sql/functions.py                                              30     13    57%   58-74, 84-92
sparkless/sql/types.py                                                   2      0   100%
sparkless/sql/utils.py                                                   7      0   100%
sparkless/storage/__init__.py                                           10      0   100%
sparkless/storage/backends/__init__.py                                   0      0   100%
sparkless/storage/backends/file.py                                     206    142    31%   26-34, 39, 44, 49, 53-56, 64-69, 77-78, 87-101, 112-119, 127, 135-138, 142, 146, 150, 154-155, 159-161, 174-177, 188-191, 202-203, 211-216, 224-232, 238, 242, 246, 250, 254, 258, 262-264, 268, 272, 276, 288-292, 300-301, 312, 321-328, 336, 348-350, 365-368, 377-378, 390-394, 409-414, 429-431, 443-449, 461, 471-482, 493-502, 506-510, 514, 518-520, 526-531, 538
sparkless/storage/backends/memory.py                                   133     88    34%   22-25, 34, 39, 44, 53-61, 72-77, 85, 93, 97, 101, 105, 109-110, 114-115, 127-128, 139-141, 152, 160-161, 169, 177-179, 187-188, 199, 208-209, 217, 229-231, 246-249, 258-259, 271-275, 290-295, 310-312, 324-330, 342, 352-370, 381-390, 402-406, 418-423, 430
sparkless/storage/manager.py                                           135     86    36%   40-45, 58, 70, 82, 94-98, 108, 119, 128-130, 138, 142-149, 153-159, 171, 186, 195, 208, 223, 237, 249, 258, 269, 283, 295, 303, 312, 325, 336, 344-349, 353-358, 366-378, 382, 390-400, 411-432
sparkless/storage/models.py                                             67      1    99%   77
sparkless/storage/serialization/__init__.py                              0      0   100%
sparkless/storage/serialization/csv.py                                  46     32    30%   23-30, 42-47, 57-62, 76-92, 104-120
sparkless/storage/serialization/json.py                                 39     25    36%   23-24, 36-41, 51-63, 75-90, 102-118
sparkless/utils/profiling.py                                            96     43    55%   47-48, 58, 61, 71-76, 85, 88-90, 94, 99, 102, 108, 118-135, 158-172, 182, 188
sparkless/window.py                                                     67     46    31%   57-60, 77-96, 113-132, 147-151, 166-170, 174-189, 219, 229, 234, 239
--------------------------------------------------------------------------------------------------
TOTAL                                                                33879  29176    14%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml
========================= 2 passed, 2 skipped in 6.98s =========================

Test Summary
============
Unit tests: âŒ FAILED
Parity tests: âŒ FAILED
Performance tests: âœ… PASSED
Documentation tests: âœ… PASSED
Total tests: collected

âŒ Test suite FAILED
