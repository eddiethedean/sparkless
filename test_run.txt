============================= test session starts ==============================
created: 10/10 workers
10 workers [2734 items]

sss......s..FF..F..s..FF...FFsF..F.F.Fs.FF.F...FFFFFF.FF.....FF.FF.F.... [  2%]
..FFFF..s..F.F.F....F.......F.F.FF..F..sF..FF.FFF.F.FFF..FF.FFF..FF.F.F. [  5%]
F.FF.F.F..FF.FF.F.FFFFF.FF.FF.FF..FFFF.FF..F.s.FFF.FFFFFF..FFF.F.F..FFFF [  7%]
.F..FFF.FFFF.F...FF.F..F.F.FF.FsFsFs...FFFFF.FFF..FFFFFFFFFFFFFF..FFFFF. [ 10%]
F..FFF..FFFFFFFFFFF.FFF..F..FF.FF.FFF..FF.FF.FF.F.FFF.F.F..FF.F.FFF.FFF. [ 13%]
.F.FFFF..F..F.s.FFFFF.....F.FF.F.F.F....F.FFF.......F.FF..F.F.F.F.F....F [ 15%]
...FFFF...F..F..FF..FFFFF....FF.FF...FF.FF.FFFFF.FFF.FFFFFFFFFFFFFFFFFFF [ 18%]
.FFFFFFFFFFFFFF.FF..FFFF.FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF [ 21%]
FFFFFFFFFFFFFFFF.FFFFFFFF.FF.FFFF..FF...F..FFFFF.F.F..FFF.FFFF.FFFFFFFFF [ 23%]
F.FFF..FFF..FFF..F.FFF.FFF.FFFF.FFFFF.FFFF.F.FFF.FFFFFFF.FFF.FFFFFFFFFFF [ 26%]
FFFFFF.FFFF.F.F.F.FFF.FF.FF.FFFF.F.FFF.FFF.FF.F.FFF.FFF.F.FF.FF..FFF.F.. [ 28%]
.F.F.FF..FFF.FF.F.F..FFF....FFFF..FFFF.FFFFFF.FFF.FFFsFF.FFFF..FFF.FFFFF [ 31%]
FFFFFF.FFFFFFFFFFFFFFFFFF.FFFF.F.FFFFFFFFFFFF.FF.FFF.FFFFF.FFFFFFF.F..FF [ 34%]
.FFFFF.FFF.FFFFFFFFFFFFFFFFFFFFFFFFxFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF [ 36%]
FFF.FFF.F.FFF.F..FFFF.FFFFFF.FFF.FFFF.FFFF.F.FF.FFFF.FFFFFFFFFFFF..F.FFF [ 39%]
FFFFFFFFFF.FFFF.FFFFFFFF.F.FF.FFFFFFF.FFFFFF.FFFFFFFFFFFF.FFFF.FF..FFF.. [ 42%]
sFFF.FF..F..sFFF.F.F..F..FFF.F..F.F..FF.FF.F..F...FFFFFs.FsF.FFFFF..FF.. [ 44%]
FFFFF..F.FF.F.FFF.FFFFF.FF..FFFFFFFFFFFFFFFFFFF.FFF.FFFFF.FFF.FFFFFFFFFF [ 47%]
FFFF.FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF.FFFFFFF.FFFFFF [ 50%]
FFFFFFFF.FFFFFFFFF..F.FFF...F.F.FFFF.F.F..F..FF.F...F...FFFF..FFF..F.sFF [ 52%]
.FF.FFF.FFFF..FFF.FFFF.FFFFFFFFFFFF.F.F..F..F.FF.FF.F........F..FF.F.F.. [ 55%]
.......F..F.F..FFF.....F..FF.FFFFF.FFFFFF..F.FF.F.FFF.F.F.FFF..FFF.FFF.F [ 57%]
FF..FFF.FFF.FF.F.FFFF.FFFFFFF.F.FF..FFFF..F.F.FFFFF.FFFF..FF....FFF.F.F. [ 60%]
F.F..FFFFF.F.FFF.F..FF.FF...F.F..sss.F.F...F.FF..F..FF.F..FF.FF...F.FF.. [ 63%]
...F....FF..FFF........F..F..F.F..sF...........F.F.s.F.....F...F.......F [ 65%]
....F..F..F.F.........F....FF....F...........F..F.....F......F.......... [ 68%]
FF......F..........F.....F...FF.......F.F......FF.F.F..F.........F.F..s. [ 71%]
.....F..F............FF....F...FF.F.......F.FFFFF.sss...FsF..F...sF.F.FF [ 73%]
...FF...FF....F.F....FF.F...F...FFF..F...FF..FF..F..FFFF...FFF.FFF..FF.. [ 76%]
FFF.FF.FFF.FF.FFFF..FF..F...FFFFF...FF.F.F.FFF..FFFFF.FFFFFF.F.F..F.FF.F [ 79%]
FFF.FF....F.FFF...FF....FFF.F.F.F.F..FF.FFFFF.FFF.FF.FFFFF..F.F..F...... [ 81%]
F....FFF.FF.......F....FFF....FF.....F..F...F...F....FF...FFF..F...F.FFF [ 84%]
FFFFFFFFF..FFFFFF.FFFFFFF..FFF.FFF.F.F...FF..F..F.F...FFF...F...FF.F...F [ 86%]
..F.F...FFF.....F.F...FFF.F..F...F........FF.F....F..........F.....F.F.s [ 89%]
.F..F.s..FFs..s.sFssFsF.s..ssFssFs...ssFsFss.sFssFs.ssFs.ssFssFssssFsssF [ 92%]
sssss.sFsFsssFssss.sssFssssssFssFsF.ssssssFsssssFs..ssFsF.s.FF...F...... [ 94%]
..F........F.F...F.s..F..s.Fssss..Fs.sss...s.s...ss..FFFFFFFFFFF.FFF.F.F [ 97%]
..F....F..F..F......F......................s.sssssssssssssssssssss....   [100%]
=================================== FAILURES ===================================
______________________ TestStringFunctionsParity.test_hex ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:207: in test_hex
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________________ TestSQLDMLParity.test_delete_from_table ____________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:148: in test_delete_from_table
    spark.sql("DELETE FROM delete_test WHERE age > 30")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Delete { tables: [], from: WithFromKeyword([TableWithJoins { relation: Table { name: ObjectName([Ident { value: "delete_test", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }]), using: None, selection: Some(BinaryOp { left: Identifier(Ident { value: "age", quote_style: None }), op: Gt, right: Value(Number("30", false)) }), returning: None, order_by: [], limit: None }.
___________________ TestArrayFunctionsParity.test_array_sort ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:100: in test_array_sort
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestIssue139DatetimeValidationCompatibility.test_validation_with_date_column_and_operations _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_139_datetime_validation_compatibility.py:74: in test_validation_with_date_column_and_operations
    count = validation_result.count()
            ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_____________ TestIssue289StructFunction.test_struct_field_access ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:258: in test_struct_field_access
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
____________________ TestSQLDMLParity.test_delete_all_rows _____________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:175: in test_delete_all_rows
    spark.sql("DELETE FROM delete_all")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Delete { tables: [], from: WithFromKeyword([TableWithJoins { relation: Table { name: ObjectName([Ident { value: "delete_all", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }]), using: None, selection: None, returning: None, order_by: [], limit: None }.
____________________ TestStringFunctionsParity.test_base64 _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:216: in test_base64
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestArrayFunctionsParity.test_array_remove __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:109: in test_array_remove
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ TestIssue261Between.test_between_with_string_values ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_261_between.py:180: in test_between_with_string_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'Bob' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue139DatetimeValidationCompatibility.test_validation_with_datetime_comparison _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_139_datetime_validation_compatibility.py:108: in test_validation_with_datetime_comparison
    count = validation_result.count()
            ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
________________ TestIssue289StructFunction.test_nested_struct _________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:293: in test_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
___________________ TestSQLDMLParity.test_insert_from_select ___________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:196: in test_insert_from_select
    spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "target_table", quote_style: None }]), table_alias: None, columns: [], overwrite: false, source: Some(Query { with: None, body: Select(Select { distinct: None, top: None, projection: [UnnamedExpr(Identifier(Ident { value: "name", quote_style: None })), UnnamedExpr(Identifier(Ident { value: "age", quote_style: None }))], into: None, from: [TableWithJoins { relation: Table { name: ObjectName([Ident { value: "source_table", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }], lateral_views: [], selection: Some(BinaryOp { left: Identifier(Ident { value: "dept", quote_style: None }), op: Eq, right: Value(SingleQuotedString("IT")) }), group_by: Expressions([]), cluster_by: [], distribute_by: [], sort_by: [], having: None, named_window: [], qualify: None, value_table_mode: None }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
____________________ TestStringFunctionsParity.test_initcap ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:225: in test_initcap
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________ TestIssue261Between.test_between_in_select_expression _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_261_between.py:237: in test_between_in_select_expression
    assert rows[0]["in_range"] is True
E   assert None is True
_ TestIssue139DatetimeValidationCompatibility.test_validation_with_multiple_datetime_columns _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_139_datetime_validation_compatibility.py:142: in test_validation_with_multiple_datetime_columns
    count = validation_result.count()
            ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_________ TestIssue261Between.test_between_with_per_row_column_bounds __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_261_between.py:278: in test_between_with_per_row_column_bounds
    assert in_range_map[(5, 0, 10)] is True
E   assert None is True
______________ TestIssue289StructFunction.test_struct_with_arrays ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:315: in test_struct_with_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
____________________ TestSQLQueriesParity.test_basic_select ____________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_queries.py:24: in test_basic_select
    result = spark.sql("SELECT id, name, age FROM test_table")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
____________________ TestStringFunctionsParity.test_soundex ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:234: in test_soundex
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
______ TestArrayContainsJoinParity.test_array_contains_join_basic_parity _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array_contains_join_parity.py:36: in test_array_contains_join_basic_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
____ TestIssue202SelectWithList.test_select_star_with_list_does_not_unpack _____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_202_select_with_list.py:144: in test_select_star_with_list_does_not_unpack
    assert result.count() == 2
           ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: duplicate: the name '*' is duplicate
E   
E   It's possible that multiple expressions are returning the same default column name. If this is the case, try renaming the columns with `.alias("new_name")` to avoid duplicate column names.
______________ TestIssue261Between.test_between_with_date_values _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_261_between.py:305: in test_between_with_date_values
    assert date(2024, 1, 1) in days
E   assert datetime.date(2024, 1, 1) in {None}
E    +  where datetime.date(2024, 1, 1) = date(2024, 1, 1)
__________________ TestSQLQueriesParity.test_filtered_select ___________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_queries.py:35: in test_filtered_select
    result = spark.sql("SELECT * FROM test_table WHERE age > 30")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
_ TestArrayContainsJoinParity.test_array_contains_join_multiple_matches_parity _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array_contains_join_parity.py:73: in test_array_contains_join_multiple_matches_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue139DatetimeValidationCompatibility.test_validation_with_datetime_after_column_rename _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_139_datetime_validation_compatibility.py:168: in test_validation_with_datetime_after_column_rename
    .withColumnRenamed("inventory_id", "id")
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:321: in withColumnRenamed
    return self._transformations.withColumnRenamed(existing, new)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/transformation_service.py:552: in withColumnRenamed
    materialized = self._df._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________________ TestStringFunctionsParity.test_translate ___________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:243: in test_translate
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestIssue289StructFunction.test_struct_in_join ________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:340: in test_struct_in_join
    rows = joined.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
______________________ TestSQLQueriesParity.test_group_by ______________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_queries.py:48: in test_group_by
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
________ TestIssue261Between.test_between_in_when_otherwise_expression _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_261_between.py:351: in test_between_in_when_otherwise_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________________ TestStringFunctionsParity.test_levenshtein __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:252: in test_levenshtein
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestArrayContainsJoinParity.test_array_contains_join_left_parity _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array_contains_join_parity.py:110: in test_array_contains_join_left_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___________________ test_string_cast_works_with_to_timestamp ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_145_string_cast.py:55: in test_string_cast_works_with_to_timestamp
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_________ TestIssue289StructFunction.test_struct_with_aliased_columns __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:366: in test_struct_with_aliased_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
____________________ TestSQLQueriesParity.test_aggregation _____________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_queries.py:63: in test_aggregation
    result = spark.sql("SELECT AVG(salary) as avg_salary FROM test_table")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
_____________________ TestStringFunctionsParity.test_crc32 _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:261: in test_crc32
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________ TestIssue289StructFunction.test_struct_multiple_operations __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:390: in test_struct_multiple_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
________________ TestSQLShowDescribeParity.test_show_databases _________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_show_describe.py:16: in test_show_databases
    spark.sql("CREATE DATABASE IF NOT EXISTS show_test_db")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____________________ TestDatetimeFunctionsParity.test_year _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:21: in test_year
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestIssue149ToTimestampString.test_to_timestamp_with_regexp_replace_cast_string _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_149_to_timestamp_string.py:39: in test_to_timestamp_with_regexp_replace_cast_string
    result = df_transformed.collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________________ TestStringFunctionsParity.test_xxhash64 ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:270: in test_xxhash64
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestSQLShowDescribeParity.test_show_tables __________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_show_describe.py:37: in test_show_tables
    result = spark.sql("SHOW TABLES")
             ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got ShowTables { extended: false, full: false, db_name: None, filter: None }.
___ TestIssue149ToTimestampString.test_to_timestamp_with_nested_cast_string ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_149_to_timestamp_string.py:69: in test_to_timestamp_with_nested_cast_string
    result = df_transformed.collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
____________________ TestDatetimeFunctionsParity.test_month ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:30: in test_month
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestStringFunctionsParity.test_get_json_object ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:281: in test_get_json_object
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________ TestIssue289StructFunction.test_struct_empty_dataframe ____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:417: in test_struct_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
___________________ TestSelectParity.test_select_with_alias ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_select.py:29: in test_select_with_alias
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Null mismatch in column 'user_id' row 0: mock=None, expected=1
E   Null mismatch in column 'full_name' row 0: mock=None, expected='Alice'
E   Null mismatch in column 'user_id' row 1: mock=None, expected=2
E   Null mismatch in column 'full_name' row 1: mock=None, expected='Bob'
E   Null mismatch in column 'user_id' row 2: mock=None, expected=3
E   Null mismatch in column 'full_name' row 2: mock=None, expected='Charlie'
E   Null mismatch in column 'user_id' row 3: mock=None, expected=4
E   Null mismatch in column 'full_name' row 3: mock=None, expected='David'
_ TestIssue263IsnanString.test_isnan_on_string_column_filter_does_not_error_and_returns_empty _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_263_isnan_string.py:40: in test_isnan_on_string_column_filter_does_not_error_and_returns_empty
    assert result.collect() == []
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isnan
____________ TestSQLShowDescribeParity.test_show_tables_in_database ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_show_describe.py:49: in test_show_tables_in_database
    spark.sql("CREATE DATABASE IF NOT EXISTS show_db")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________________ test_sort_with_list_of_column_names ______________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_214_sort_with_list.py:36: in test_sort_with_list_of_column_names
    assert rows[0]["dept"] == "HR"
E   AssertionError: assert 'IT' == 'HR'
E     
E     - HR
E     + IT
----------------------------- Captured stdout call -----------------------------
DataFrame[3 rows, 3 columns]

dept name    salary
IT     Alice     50000   
HR     Bob       60000   
IT     Charlie   70000   
_________________ TestDatetimeFunctionsParity.test_dayofmonth __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:39: in test_dayofmonth
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________________ TestStringFunctionsParity.test_json_tuple ___________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:292: in test_json_tuple
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____ TestIssue149ToTimestampString.test_to_timestamp_with_string_operations ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_149_to_timestamp_string.py:97: in test_to_timestamp_with_string_operations
    result = df_transformed.collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
__________________________ test_sort_with_df_columns ___________________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_214_sort_with_list.py:63: in test_sort_with_df_columns
    assert rows[0]["dept"] == "HR"  # HR comes before IT alphabetically
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert 'IT' == 'HR'
E     
E     - HR
E     + IT
----------------------------- Captured stdout call -----------------------------
DataFrame[3 rows, 3 columns]

dept name    salary
IT     Alice     50000   
HR     Bob       60000   
IT     Charlie   70000   
________________ TestSQLShowDescribeParity.test_describe_table _________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_show_describe.py:74: in test_describe_table
    result = spark.sql("DESCRIBE describe_test")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got ExplainTable { describe_alias: Describe, hive_format: None, table_name: ObjectName([Ident { value: "describe_test", quote_style: None }]) }.
___________ TestIssue289StructFunction.test_struct_with_conditional ____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:443: in test_struct_with_conditional
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type CaseWhen is not JSON serializable
__________________ TestDatetimeFunctionsParity.test_dayofweek __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:48: in test_dayofweek
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____ TestIssue263IsnanString.test_isnan_on_numeric_column_true_only_for_nan ____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_263_isnan_string.py:51: in test_isnan_on_numeric_column_true_only_for_nan
    rows = df.select("id", F.isnan(F.col("v")).alias("is_nan")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isnan
________________ TestStringFunctionsParity.test_substring_index ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:301: in test_substring_index
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
______________________ TestSetOperationsParity.test_union ______________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_set_operations.py:31: in test_union
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=3, expected=6
_ TestIssue151ToTimestampValidation.test_to_timestamp_with_validation_rule_not_null _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_151_to_timestamp_validation.py:56: in test_to_timestamp_with_validation_rule_not_null
    result = df_validated.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_______________ TestSQLShowDescribeParity.test_describe_extended _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_show_describe.py:95: in test_describe_extended
    result = spark.sql("DESCRIBE EXTENDED describe_extended_test")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got ExplainTable { describe_alias: Describe, hive_format: Some(Extended), table_name: ObjectName([Ident { value: "describe_extended_test", quote_style: None }]) }.
_________ TestIssue289StructFunction.test_struct_with_string_functions _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:471: in test_struct_with_string_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
__________________ TestDatetimeFunctionsParity.test_date_add ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:57: in test_date_add
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestStringFunctionsParity.test_repeat _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:310: in test_repeat
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________________ TestSetOperationsParity.test_union_all ____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_set_operations.py:49: in test_union_all
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=3, expected=6
________ TestIssue263IsnanString.test_isnan_literal_matches_python_math ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_263_isnan_string.py:67: in test_isnan_literal_matches_python_math
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: failed to parse plan_json: expected value at line 1 column 99
________________ TestSQLShowDescribeParity.test_describe_column ________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_show_describe.py:116: in test_describe_column
    result = spark.sql("DESCRIBE describe_col_test age")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL parse error: sql parser error: Expected end of statement, found: age at Line: 1, Column 28. Hint: only SELECT and CREATE SCHEMA/DATABASE/DROP TABLE are supported.
__________________ TestDatetimeFunctionsParity.test_date_sub ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:66: in test_date_sub
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestIssue151ToTimestampValidation.test_to_timestamp_with_datetime_operations _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_151_to_timestamp_validation.py:85: in test_to_timestamp_with_datetime_operations
    result = df_transformed.collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
____________________ TestStringFunctionsParity.test_reverse ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:319: in test_reverse
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________ TestIssue289StructFunction.test_struct_with_math_operations __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:500: in test_struct_with_math_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_ TestIssue259DatetimeStringComparison.test_date_column_vs_string_column_filter _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_259_datetime_string_comparison.py:54: in test_date_column_vs_string_column_filter
    assert result[0]["date_timestamp"] == date(2026, 1, 1)
E   assert None == datetime.date(2026, 1, 1)
E    +  where datetime.date(2026, 1, 1) = date(2026, 1, 1)
_________________ TestSQLShowDescribeParity.test_show_columns __________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_show_describe.py:146: in test_show_columns
    spark.sql("DROP TABLE IF EXISTS show_cols_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__ TestIssue263IsnanString.test_isnan_on_string_and_numeric_columns_in_select __
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_263_isnan_string.py:89: in test_isnan_on_string_and_numeric_columns_in_select
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isnan
___________ TestIssue288CaseWhenOperators.test_casewhen_subtraction ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:38: in test_casewhen_subtraction
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________ TestDatetimeFunctionsParity.test_date_format _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:75: in test_date_format
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________ TestStructFieldAliasParity.test_struct_field_with_alias_parity ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_struct_field_alias_parity.py:32: in test_struct_field_with_alias_parity
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
______ TestIssue152SQLColumnAliases.test_sql_with_inner_join_and_aliases _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_152_sql_column_aliases.py:42: in test_sql_with_inner_join_and_aliases
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
_ TestStructFieldAliasParity.test_struct_field_with_alias_multiple_fields_parity _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_struct_field_alias_parity.py:59: in test_struct_field_with_alias_multiple_fields_parity
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
________ TestIssue289StructFunction.test_struct_large_number_of_fields _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:530: in test_struct_large_number_of_fields
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_ TestStructFieldAliasParity.test_struct_field_with_alias_and_other_columns_parity _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_struct_field_alias_parity.py:92: in test_struct_field_with_alias_and_other_columns_parity
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
___________________ TestDatetimeFunctionsParity.test_to_date ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_datetime.py:84: in test_to_date
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestTableAppendPersistence.test_append_data_visible_immediately ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_table_append_persistence.py:19: in test_append_data_visible_immediately
    spark.sql("CREATE SCHEMA IF NOT EXISTS test_schema")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_______ TestIssue152SQLColumnAliases.test_sql_with_left_join_and_aliases _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_152_sql_column_aliases.py:83: in test_sql_with_left_join_and_aliases
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
_____________ TestIssue288CaseWhenOperators.test_casewhen_addition _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:74: in test_casewhen_addition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue263IsnanString.test_isnan_in_when_otherwise_expression ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_263_isnan_string.py:121: in test_isnan_in_when_otherwise_expression
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue290UdfMultipleArguments.test_udf_two_arguments ____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:32: in test_udf_two_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestTableAppendPersistence.test_append_to_new_table ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_table_append_persistence.py:53: in test_append_to_new_table
    spark.sql("CREATE SCHEMA IF NOT EXISTS test_schema")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___________ TestToDateWithFormat.test_to_date_with_yyyy_mm_dd_format ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_to_date_format.py:48: in test_to_date_with_yyyy_mm_dd_format
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_ TestIssue259DatetimeStringComparison.test_datetime_column_vs_string_column_filter _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_259_datetime_string_comparison.py:146: in test_datetime_column_vs_string_column_filter
    assert names == {"Early"}
E   AssertionError: assert set() == {'Early'}
E     
E     Extra items in the right set:
E     'Early'
E     
E     Full diff:
E     + set()
E     - {
E     -     'Early',
E     - }
__________ TestIssue288CaseWhenOperators.test_casewhen_multiplication __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:110: in test_casewhen_multiplication
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestFormatStringParity.test_format_string_basic_parity ____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_format_string_parity.py:32: in test_format_string_basic_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
__ TestIssue153ToTimestampReturnsNone.test_to_timestamp_returns_actual_values __
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_153_to_timestamp_returns_none.py:48: in test_to_timestamp_returns_actual_values
    rows = df_transformed.select("date_parsed").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestIssue259DatetimeStringComparison.test_datetime_column_vs_string_column_all_operators _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_259_datetime_string_comparison.py:189: in test_datetime_column_vs_string_column_all_operators
    assert names == set(expected), f"Operator {op} mismatch"
E   AssertionError: Operator > mismatch
E   assert set() == {'Greater'}
E     
E     Extra items in the right set:
E     'Greater'
E     
E     Full diff:
E     + set()
E     - {
E     -     'Greater',
E     - }
_____ TestIssue290UdfMultipleArguments.test_udf_two_arguments_string_names _____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:59: in test_udf_two_arguments_string_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestJoinThenGroupByNoAmbiguity.test_inner_join_then_groupby __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:68: in test_inner_join_then_groupby
    assert result_dict == {(1, "A"): 10, (2, "B"): 20}
E   AssertionError: assert {} == {(1, 'A'): 10, (2, 'B'): 20}
E     
E     Right contains 2 more items:
E     {(1, 'A'): 10, (2, 'B'): 20}
E     
E     Full diff:
E     + {}
E     - {
E     -     (1, 'A'): 10,
E     -     (2, 'B'): 20,
E     - }
__________ TestTableAppendPersistence.test_multiple_append_operations __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_table_append_persistence.py:76: in test_multiple_append_operations
    spark.sql("CREATE SCHEMA IF NOT EXISTS test_schema")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________ TestJoinThenGroupByNoAmbiguity.test_right_join_then_groupby __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:88: in test_right_join_then_groupby
    assert result_dict == {1: 1, 2: 1}
E   assert {} == {1: 1, 2: 1}
E     
E     Right contains 2 more items:
E     {1: 1, 2: 1}
E     
E     Full diff:
E     + {}
E     - {
E     -     1: 1,
E     -     2: 1,
E     - }
_____ TestToDateWithFormat.test_to_date_with_mm_slash_dd_slash_yyyy_format _____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_to_date_format.py:84: in test_to_date_with_mm_slash_dd_slash_yyyy_format
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_____________ TestIssue288CaseWhenOperators.test_casewhen_division _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:146: in test_casewhen_division
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestJoinThenGroupByNoAmbiguity.test_outer_join_then_groupby __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:109: in test_outer_join_then_groupby
    assert result_dict == {1: 1, None: 1, 3: 1}
E   assert {1: 1, 3: 1} == {1: 1, None: 1, 3: 1}
E     
E     Omitting 2 identical items, use -vv to show
E     Right contains 1 more item:
E     {None: 1}
E     
E     Full diff:
E       {
E     -     None: 1,
E           1: 1,
E           3: 1,
E       }
____ TestIssue153ToTimestampReturnsNone.test_to_timestamp_with_clean_string ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_153_to_timestamp_returns_none.py:74: in test_to_timestamp_with_clean_string
    rows = df_transformed.select("date_parsed").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
________ TestFormatStringParity.test_format_string_multiple_args_parity ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_format_string_parity.py:65: in test_format_string_multiple_args_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
__________ TestIssue290UdfMultipleArguments.test_udf_three_arguments ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:82: in test_udf_three_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____ TestJoinThenGroupByNoAmbiguity.test_single_column_join_then_groupby ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:128: in test_single_column_join_then_groupby
    assert result_dict == {1: 100.0, 2: 200.0}
E   assert {1: None, 2: None} == {1: 100.0, 2: 200.0}
E     
E     Differing items:
E     {1: None} != {1: 100.0}
E     {2: None} != {2: 200.0}
E     
E     Full diff:
E       {
E     -     1: 100.0,
E     -     2: 200.0,
E     +     1: None,
E     +     2: None,
E       }
____ TestToDateWithFormat.test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format ____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_to_date_format.py:114: in test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
______ TestJoinThenGroupByNoAmbiguity.test_three_column_join_then_groupby ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:160: in test_three_column_join_then_groupby
    assert result_dict == {(2023, 1, 1): 10, (2023, 1, 2): 20}
E   assert {} == {(2023, 1, 1)...23, 1, 2): 20}
E     
E     Right contains 2 more items:
E     {(2023, 1, 1): 10, (2023, 1, 2): 20}
E     
E     Full diff:
E     + {}
E     - {
E     -     (2023, 1, 1): 10,
E     -     (2023, 1, 2): 20,
E     - }
__________________ TestTransformationsParity.test_drop_column __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_transformations.py:29: in test_drop_column
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
______________ TestIssue288CaseWhenOperators.test_casewhen_modulo ______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:182: in test_casewhen_modulo
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestJoinThenGroupByNoAmbiguity.test_join_then_select_join_keys ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:177: in test_join_then_select_join_keys
    assert result[0]["score"] == 100
E   assert None == 100
_____________ TestDeltaLakeSchemaEvolution.test_type_casting_works _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:100: in test_type_casting_works
    assert df4.select("id_str").collect()[0]["id_str"] == "1"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'id' not found. Available columns: [id_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestFormatStringParity.test_format_string_with_null_parity __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_format_string_parity.py:91: in test_format_string_with_null_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_________ TestIssue290UdfMultipleArguments.test_udf_multiply_arguments _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:103: in test_udf_multiply_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___________ TestToDateWithFormat.test_to_date_without_format_string ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_to_date_format.py:141: in test_to_date_without_format_string
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
___ TestIssue260EqNullSafe.test_eqnullsafe_literal_semantics[None-None-True] ___
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:96: in test_eqnullsafe_literal_semantics
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestJoinThenGroupByNoAmbiguity.test_join_then_orderby_on_join_keys ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:219: in test_join_then_orderby_on_join_keys
    assert len(result) == 3
E   assert 0 == 3
E    +  where 0 = len([])
____________ TestIssue288CaseWhenOperators.test_casewhen_bitwise_or ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:218: in test_casewhen_bitwise_or
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue290UdfMultipleArguments.test_udf_string_concatenation ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:124: in test_udf_string_concatenation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________ TestLogFloatConstantParity.test_log_with_float_base_parity __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_log_float_constant_parity.py:30: in test_log_with_float_base_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
________________ TestToDateIssue126.test_issue_126_reproduction ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_to_date_issue_126.py:54: in test_issue_126_reproduction
    result = df_with_date.collect()
             ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
___ TestDeltaLakeSchemaEvolution.test_null_literal_casting_to_various_types ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:140: in test_null_literal_casting_to_various_types
    rows = df.head(1)
           ^^^^^^^^^^
sparkless/dataframe/dataframe.py:527: in head
    result = self._display.head(n)
             ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/display_service.py:209: in head
    materialized = self._df._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: casting from null to boolean not supported
____ TestIssue260EqNullSafe.test_eqnullsafe_literal_semantics[None-x-False] ____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:96: in test_eqnullsafe_literal_semantics
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestJoinThenGroupByNoAmbiguity.test_join_then_aggregate_with_join_keys ____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:281: in test_join_then_aggregate_with_join_keys
    assert result_dict == {"A": 30, "B": 30}
E   AssertionError: assert {} == {'A': 30, 'B': 30}
E     
E     Right contains 2 more items:
E     {'A': 30, 'B': 30}
E     
E     Full diff:
E     + {}
E     - {
E     -     'A': 30,
E     -     'B': 30,
E     - }
___________ TestIssue288CaseWhenOperators.test_casewhen_bitwise_not ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:251: in test_casewhen_bitwise_not
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ~
_____________ TestIssue290UdfMultipleArguments.test_udf_with_nulls _____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:146: in test_udf_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_ TestIssue160DroppedColumnExecutionPlan.test_dropped_column_in_execution_plan _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_dropped_column_execution_plan.py:103: in test_dropped_column_in_execution_plan
    count = silver_df.count()  # This should not raise an error
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
______ TestWindowOrderByListParity.test_window_orderby_list_basic_parity _______
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_window_orderby_list_parity.py:31: in test_window_orderby_list_basic_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestLogFloatConstantParity.test_log_natural_log_parity ____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_log_float_constant_parity.py:56: in test_log_natural_log_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
__ TestJoinThenGroupByNoAmbiguity.test_join_different_data_types_then_groupby __
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:316: in test_join_different_data_types_then_groupby
    assert len(result) == 1
E   assert 0 == 1
E    +  where 0 = len([])
____ TestIssue260EqNullSafe.test_eqnullsafe_literal_semantics[x-None-False] ____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:96: in test_eqnullsafe_literal_semantics
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestIssue288CaseWhenOperators.test_casewhen_with_literal ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:284: in test_casewhen_with_literal
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________________ TestWindowOperationsParity.test_row_number __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:32: in test_row_number
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_____________ TestIssue290UdfMultipleArguments.test_udf_in_select ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:168: in test_udf_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
____ TestIssue160DroppedColumnExecutionPlan.test_dropped_column_with_cache _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_dropped_column_execution_plan.py:184: in test_dropped_column_with_cache
    count = silver_df.count()  # This should not raise an error
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestWindowOrderByListParity.test_window_orderby_list_multiple_columns_parity _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_window_orderby_list_parity.py:62: in test_window_orderby_list_multiple_columns_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestLogFloatConstantParity.test_log_with_different_bases_parity ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_log_float_constant_parity.py:77: in test_log_with_different_bases_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
_____________________ TestWindowOperationsParity.test_rank _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:45: in test_rank
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
______ TestIssue260EqNullSafe.test_eqnullsafe_literal_semantics[x-x-True] ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:96: in test_eqnullsafe_literal_semantics
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestIssue288CaseWhenOperators.test_casewhen_reverse_operations ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:317: in test_casewhen_reverse_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____ TestDeltaLakeSchemaEvolution.test_schema_merge_with_type_preservation _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:231: in test_schema_merge_with_type_preservation
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_______ TestWindowOrderByListParity.test_window_partitionby_list_parity ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_window_orderby_list_parity.py:92: in test_window_partitionby_list_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________________ TestMathFunctionsParity.test_math_abs _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:21: in test_math_abs
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestJoinThenGroupByNoAmbiguity.test_join_then_drop_other_columns _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_280_join_groupby_ambiguity.py:348: in test_join_then_drop_other_columns
    result = df.groupBy("id").count().collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:2001: in count
    return self.agg(AggregateFunctions.count().alias("count"))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'name' not found. Available columns: [id, score, temp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestWindowOperationsParity.test_dense_rank __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:58: in test_dense_rank
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
____________ TestIssue290UdfMultipleArguments.test_udf_mixed_types _____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:194: in test_udf_mixed_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________________ test_lazy_polars_expression_after_column_drop _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_lazy_polars_expr.py:72: in test_lazy_polars_expression_after_column_drop
    count = df_dropped.count()
            ^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
_____ TestIssue260EqNullSafe.test_eqnullsafe_literal_semantics[x-y-False] ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:96: in test_eqnullsafe_literal_semantics
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__ TestDeltaLakeSchemaEvolution.test_delta_create_or_replace_table_as_select ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:283: in test_delta_create_or_replace_table_as_select
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_______ test_join_with_unmaterialized_withcolumn_on_right_regression_281 _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_281_join_withcolumn_unmaterialized.py:29: in test_join_with_unmaterialized_withcolumn_on_right_regression_281
    assert [
E   AssertionError: assert [('Alice', '1..., None, None)] == [('Alice', '1...B', 'D', 'D')]
E     
E     At index 0 diff: ('Alice', '1', 'A', None, None) != ('Alice', '1', 'A', 'C', 'C')
E     
E     Full diff:
E       [
E           (
E               'Alice',
E               '1',
E               'A',
E     -         'C',
E     -         'C',
E     +         None,
E     +         None,
E           ),
E           (
E               'Bob',
E               '2',
E               'B',
E     -         'D',
E     -         'D',
E     +         None,
E     +         None,
E           ),
E       ]
___________________ TestMathFunctionsParity.test_math_round ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:30: in test_math_round
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________ TestIssue288CaseWhenOperators.test_casewhen_chained_operations ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:357: in test_casewhen_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______________ TestWindowOperationsParity.test_sum_over_window ________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:73: in test_sum_over_window
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
____ TestIssue290UdfMultipleArguments.test_udf_single_argument_still_works _____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:213: in test_udf_single_argument_still_works
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ test_join_with_multiple_unmaterialized_ops_on_right ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_281_join_withcolumn_unmaterialized.py:67: in test_join_with_multiple_unmaterialized_ops_on_right
    assert [
E   AssertionError: assert [('Alice', '1...', 'B', None)] == [('Alice', '1...2', 'B', 'D')]
E     
E     At index 0 diff: ('Alice', '1', 'A', None) != ('Alice', '1', 'A', 'C')
E     
E     Full diff:
E       [
E           (
E               'Alice',
E               '1',
E               'A',
E     -         'C',
E     +         None,
E           ),
E           (
E               'Bob',
E               '2',
E               'B',
E     -         'D',
E     +         None,
E           ),
E       ]
_______________________ test_nested_operations_with_drop _______________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_lazy_polars_expr.py:125: in test_nested_operations_with_drop
    _ = df_with_nested.count()
        ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
____________________ TestMathFunctionsParity.test_math_sqrt ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:39: in test_math_sqrt
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ test_join_with_unmaterialized_select_filter_on_right _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_281_join_withcolumn_unmaterialized.py:104: in test_join_with_unmaterialized_select_filter_on_right
    assert [
E   AssertionError: assert [('Alice', '1..., None, None)] == [('Alice', '1...B', 'D', 'D')]
E     
E     At index 0 diff: ('Alice', '1', 'A', None, None) != ('Alice', '1', 'A', 'C', 'C')
E     
E     Full diff:
E       [
E           (
E               'Alice',
E               '1',
E               'A',
E     -         'C',
E     -         'C',
E     +         None,
E     +         None,
E           ),
E           (
E               'Bob',
E               '2',
E               'B',
E     -         'D',
E     -         'D',
E     +         None,
E     +         None,
E           ),
E       ]
___________ TestDeltaLakeSchemaEvolution.test_immediate_table_access ___________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:322: in test_immediate_table_access
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________________ TestWindowOperationsParity.test_lag ______________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:86: in test_lag
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
____________ TestIssue288CaseWhenOperators.test_casewhen_with_nulls ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:393: in test_casewhen_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue260EqNullSafe.test_eqnullsafe_with_date_types ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:194: in test_eqnullsafe_with_date_types
    assert (d1, d1) in values
E   assert (datetime.date(2025, 1, 1), datetime.date(2025, 1, 1)) in {(None, None)}
_______________ test_join_with_unmaterialized_ops_on_both_sides ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_281_join_withcolumn_unmaterialized.py:135: in test_join_with_unmaterialized_ops_on_both_sides
    assert [
E   AssertionError: assert [('Alice', '1..., None, None)] == [('Alice', '1...B', 'D', 'D')]
E     
E     At index 0 diff: ('Alice', '1', 'A', 'A', None, None) != ('Alice', '1', 'A', 'A', 'C', 'C')
E     
E     Full diff:
E       [
E           (
E               'Alice',
E               '1',
E               'A',
E               'A',
E     -         'C',
E     -         'C',
E     +         None,
E     +         None,
E           ),
E           (
E               'Bob',
E               '2',
E               'B',
E               'B',
E     -         'D',
E     -         'D',
E     +         None,
E     +         None,
E           ),
E       ]
_________________ test_operations_chain_with_intermediate_drop _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_lazy_polars_expr.py:191: in test_operations_chain_with_intermediate_drop
    count = df_chain.count()
            ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________ TestIssue290UdfMultipleArguments.test_udf_four_arguments ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:234: in test_udf_four_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
____________________ TestMathFunctionsParity.test_math_pow _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:48: in test_math_pow
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________ TestIssue260EqNullSafe.test_eqnullsafe_with_datetime_types __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:219: in test_eqnullsafe_with_datetime_types
    assert (dt1, dt1) in values
E   assert (datetime.datetime(2025, 1, 1, 12, 0), datetime.datetime(2025, 1, 1, 12, 0)) in {(None, None)}
_________________ TestCatalogParity.test_set_current_database __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:94: in test_set_current_database
    spark.sql("DROP TABLE IF EXISTS test_current_db2.catalog_test_table")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________________ TestWindowOperationsParity.test_lead _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:99: in test_lead
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
___________ TestDeltaLakeSchemaEvolution.test_basic_schema_evolution ___________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:352: in test_basic_schema_evolution
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____ TestIssue288CaseWhenOperators.test_casewhen_multiple_when_conditions _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:434: in test_casewhen_multiple_when_conditions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________________ TestMathFunctionsParity.test_math_log _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:57: in test_math_log
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______________________ test_write_operation_after_drop ________________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_lazy_polars_expr.py:242: in test_write_operation_after_drop
    df_transformed.write.mode("overwrite").saveAsTable("test_table_160")
sparkless/dataframe/writer.py:370: in saveAsTable
    data = df_to_write.collect()
           ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
______________________ TestCatalogParity.test_list_tables ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:112: in test_list_tables
    spark.sql("DROP TABLE IF EXISTS list_tables_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_______ TestIssue290UdfMultipleArguments.test_udf_with_computed_columns ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:259: in test_udf_with_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________________ TestWindowOperationsParity.test_cume_dist ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:112: in test_cume_dist
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_________ TestIssue260EqNullSafe.test_eqnullsafe_in_select_expression __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:301: in test_eqnullsafe_in_select_expression
    assert equals_map[("x", "x")] is True
E   assert None is True
__________ TestDeltaLakeSchemaEvolution.test_overwrite_schema_option ___________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:383: in test_overwrite_schema_option
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____________________ TestMathFunctionsParity.test_math_exp _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:66: in test_math_exp
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________ TestIssue288CaseWhenOperators.test_casewhen_nested_expressions ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:479: in test_casewhen_nested_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________________ TestCatalogParity.test_list_tables_in_database ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:138: in test_list_tables_in_database
    spark.sql("DROP TABLE IF EXISTS list_db.list_table")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_______________________ test_nested_operations_with_drop _______________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_nested_operations.py:75: in test_nested_operations_with_drop
    count = df_result.count()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
_________________ TestWindowOperationsParity.test_first_value __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:125: in test_first_value
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_________ TestIssue290UdfMultipleArguments.test_udf_decorator_pattern __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:284: in test_udf_decorator_pattern
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestDeltaLakeSchemaEvolution.test_preserve_existing_columns __________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:426: in test_preserve_existing_columns
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____________________ TestMathFunctionsParity.test_math_sin _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:75: in test_math_sin
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________ TestIssue260EqNullSafe.test_eqnullsafe_with_type_coercion ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:358: in test_eqnullsafe_with_type_coercion
    result = df.where(F.col("str_col").eqNullSafe(F.col("int_col"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: cannot compare string with numeric type (i64)
_____________________ TestCatalogParity.test_table_exists ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:153: in test_table_exists
    spark.sql("DROP TABLE IF EXISTS exists_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________________ TestWindowOperationsParity.test_last_value __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:138: in test_last_value
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_________ TestIssue288CaseWhenOperators.test_casewhen_division_by_zero _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:515: in test_casewhen_division_by_zero
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________________ TestMathFunctionsParity.test_math_cos _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:84: in test_math_cos
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________ TestDeltaLakeSchemaEvolution.test_schema_merge_on_overwrite __________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:465: in test_schema_merge_on_overwrite
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________ TestIssue290UdfMultipleArguments.test_udf_empty_dataframe ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:308: in test_udf_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestIssue160ReproduceBug.test_bug_reproduction_with_150_rows _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_reproduce_bug.py:99: in test_bug_reproduction_with_150_rows
    count = silver_df.count()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_________________ TestWindowOperationsParity.test_percent_rank _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:151: in test_percent_rank
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_______________ TestCatalogParity.test_table_exists_in_database ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:177: in test_table_exists_in_database
    spark.sql("DROP TABLE IF EXISTS exists_db.exists_table")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____ TestIssue260EqNullSafe.test_eqnullsafe_chained_with_other_operations _____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_260_eq_null_safe.py:470: in test_eqnullsafe_chained_with_other_operations
    assert row["name_is_null"] is False
E   assert None is False
____________________ TestMathFunctionsParity.test_math_tan _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:93: in test_math_tan
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________ TestIssue288CaseWhenOperators.test_casewhen_modulo_by_zero __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:551: in test_casewhen_modulo_by_zero
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestDeltaLakeSchemaEvolution.test_merge_schema_append _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:510: in test_merge_schema_append
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____________________ TestWindowOperationsParity.test_ntile _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_window.py:164: in test_ntile
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
___________ TestIssue290UdfMultipleArguments.test_udf_five_arguments ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:328: in test_udf_five_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_______________________ TestCatalogParity.test_get_table _______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:195: in test_get_table
    spark.sql("DROP TABLE IF EXISTS get_table_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________ TestIssue160ReproduceBug.test_bug_does_not_occur_with_2_rows _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_reproduce_bug.py:191: in test_bug_does_not_occur_with_2_rows
    count = silver_df.count()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
____________________ TestMathFunctionsParity.test_math_ceil ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:102: in test_math_ceil
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
___________ TestIssue288CaseWhenOperators.test_casewhen_with_floats ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:587: in test_casewhen_with_floats
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue290UdfMultipleArguments.test_udf_with_float_arguments ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:349: in test_udf_with_float_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestDeltaLakeSchemaEvolution.test_merge_schema_bidirectional _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:553: in test_merge_schema_bidirectional
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________________ TestCatalogParity.test_get_table_in_database _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:222: in test_get_table_in_database
    spark.sql("DROP TABLE IF EXISTS get_db.get_table")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___________________ TestMathFunctionsParity.test_math_floor ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:111: in test_math_floor
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________________ test_bug_with_cache_enabled __________________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_160_with_cache_enabled.py:74: in test_bug_with_cache_enabled
    count = silver_df.count()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
______ TestIssue288CaseWhenOperators.test_casewhen_with_zero_and_negative ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:623: in test_casewhen_with_zero_and_negative
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestDeltaLakeSchemaEvolution.test_complete_schema_evolution_scenario _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_delta_lake_schema_evolution.py:598: in test_complete_schema_evolution_scenario
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______________________ TestCatalogParity.test_cache_table ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:236: in test_cache_table
    result = spark.sql("SELECT * FROM cache_test")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'cache_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
__________________ TestMathFunctionsParity.test_math_greatest __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:120: in test_math_greatest
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestIssue290UdfMultipleArguments.test_udf_with_boolean_arguments _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:373: in test_udf_with_boolean_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______ TestIssue163ValidationAfterDrop.test_validation_after_drop_columns ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_163_validation_after_drop.py:55: in test_validation_after_drop_columns
    count = valid_df.count()
            ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_____________________ TestCatalogParity.test_uncache_table _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:257: in test_uncache_table
    result = spark.sql("SELECT * FROM uncache_test")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'uncache_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
___________________ TestMathFunctionsParity.test_math_least ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_math.py:129: in test_math_least
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
______ TestIssue293ExplodeWithColumn.test_explode_outer_with_null_arrays _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:210: in test_explode_outer_with_null_arrays
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___________ TestIssue288CaseWhenOperators.test_casewhen_bitwise_and ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:659: in test_casewhen_bitwise_and
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________ TestIssue290UdfMultipleArguments.test_udf_in_filter ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:395: in test_udf_in_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________________ TestNullHandlingFunctionsParity.test_coalesce _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:21: in test_coalesce
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_______________________ TestCatalogParity.test_is_cached _______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/internal/test_catalog.py:286: in test_is_cached
    spark.sql("DROP TABLE IF EXISTS is_cached_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_ TestIssue295WithColumnRenamedNonexistent.test_withColumnRenamed_after_union __
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_295_withColumnRenamed_nonexistent.py:588: in test_withColumnRenamed_after_union
    assert result.count() == 2
E   assert 1 == 2
E    +  where 1 = count()
E    +    where count = DataFrame[1 rows, 2 columns].count
____ TestIssue288CaseWhenOperators.test_casewhen_complex_nested_operations _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:706: in test_casewhen_complex_nested_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue293ExplodeWithColumn.test_explode_with_multiple_columns _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:239: in test_explode_with_multiple_columns
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_______ TestIssue165ToDateTimestampType.test_to_date_with_timestamp_type _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_165_to_date_timestamp_type.py:47: in test_to_date_with_timestamp_type
    rows = result_df.select("event_date").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_________________ TestNullHandlingFunctionsParity.test_isnull __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:30: in test_isnull
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_____________ TestIssue290UdfMultipleArguments.test_udf_in_orderby _____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:452: in test_udf_in_orderby
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________________ TestNullHandlingFunctionsParity.test_isnotnull ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:39: in test_isnotnull
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
______ TestIssue288CaseWhenOperators.test_casewhen_all_reverse_operators _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:746: in test_casewhen_all_reverse_operators
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue165ToDateTimestampType.test_to_date_with_string_type _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_165_to_date_timestamp_type.py:89: in test_to_date_with_string_type
    rows = result_df.select("event_date").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
________ TestIssue293ExplodeWithColumn.test_explode_chained_operations _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:269: in test_explode_chained_operations
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
__ TestIssue295WithColumnRenamedNonexistent.test_withColumnRenamed_after_drop __
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_295_withColumnRenamed_nonexistent.py:647: in test_withColumnRenamed_after_drop
    result = df.drop("city").withColumnRenamed("Does-Not-Exist", "New-Name")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:321: in withColumnRenamed
    return self._transformations.withColumnRenamed(existing, new)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/transformation_service.py:552: in withColumnRenamed
    materialized = self._df._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'city' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestNullHandlingFunctionsParity.test_when_otherwise ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:48: in test_when_otherwise
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
__ TestIssue290UdfMultipleArguments.test_udf_mixed_string_and_column_objects ___
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:475: in test_udf_mixed_string_and_column_objects
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestIssue165ToDateTimestampType.test_to_date_with_date_type __________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_165_to_date_timestamp_type.py:123: in test_to_date_with_date_type
    rows = result_df.select("event_date_extracted").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
________________ TestSQLAdvancedParity.test_sql_with_inner_join ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:26: in test_sql_with_inner_join
    result = spark.sql("""
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
_ TestIssue295WithColumnRenamedNonexistent.test_withColumnRenamed_complex_nested_operations _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_295_withColumnRenamed_nonexistent.py:711: in test_withColumnRenamed_complex_nested_operations
    assert rows[0]["salary"] == 70000
E   assert 60000 == 70000
___________________ TestNullHandlingFunctionsParity.test_nvl ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:57: in test_nvl
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
____________ TestIssue293ExplodeWithColumn.test_explode_with_floats ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:294: in test_explode_with_floats
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_______ TestIssue288CaseWhenOperators.test_casewhen_operator_precedence ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:831: in test_casewhen_operator_precedence
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________________ TestSQLAdvancedParity.test_sql_with_left_join _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:52: in test_sql_with_left_join
    result = spark.sql("""
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees2' not found. Register it with create_or_replace_temp_view or saveAsTable.
_______ TestIssue290UdfMultipleArguments.test_udf_nested_with_arithmetic _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:502: in test_udf_nested_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestNullHandlingFunctionsParity.test_nullif __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:66: in test_nullif
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_____ TestIssue166UnixTimestamp.test_unix_timestamp_with_timestamp_column ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_166_unix_timestamp.py:48: in test_unix_timestamp_with_timestamp_column
    rows = result_df.select("unix_ts").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_________ TestIssue296UdfDecorator.test_udf_decorator_with_return_type _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:37: in test_udf_decorator_with_return_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___________ TestIssue293ExplodeWithColumn.test_explode_with_booleans ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:321: in test_explode_with_booleans
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________________ TestSQLAdvancedParity.test_sql_with_order_by _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:73: in test_sql_with_order_by
    result = spark.sql("SELECT * FROM order_test ORDER BY age")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'order_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
_________________ TestNullHandlingFunctionsParity.test_ifnull __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:75: in test_ifnull
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____ TestIssue166UnixTimestamp.test_unix_timestamp_with_string_and_format _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_166_unix_timestamp.py:89: in test_unix_timestamp_with_string_and_format
    rows = result_df.select("unix_ts").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: unix_timestamp
________ TestIssue288CaseWhenOperators.test_casewhen_with_large_numbers ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:867: in test_casewhen_with_large_numbers
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue290UdfMultipleArguments.test_udf_with_date_operations ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:528: in test_udf_with_date_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________________ TestSQLAdvancedParity.test_sql_with_limit ___________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:96: in test_sql_with_limit
    result = spark.sql("SELECT * FROM limit_test LIMIT 2")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'limit_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
______ TestIssue135DatetimeFilter.test_to_timestamp_with_filter_isnotnull ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_135_datetime_filter.py:39: in test_to_timestamp_with_filter_isnotnull
    count = validation_result.count()
            ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
__________________ TestNullHandlingFunctionsParity.test_nanvl __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_null_handling.py:84: in test_nanvl
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestIssue296UdfDecorator.test_udf_decorator_without_return_type ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:62: in test_udf_decorator_without_return_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestIssue293ExplodeWithColumn.test_explode_with_mixed_types __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:349: in test_explode_with_mixed_types
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
________ TestOrderByAscendingParity.test_orderby_ascending_true_parity _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_orderby_ascending_parity.py:33: in test_orderby_ascending_true_parity
    assert rows[1]["StringValue"] == "MMM"
E   AssertionError: assert 'ZZZ' == 'MMM'
E     
E     - MMM
E     + ZZZ
_________ TestIssue288CaseWhenOperators.test_casewhen_empty_dataframe __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:898: in test_casewhen_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue290UdfMultipleArguments.test_udf_in_join_condition __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:562: in test_udf_in_join_condition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'id' has more than one occurrence
__________________ TestSQLAdvancedParity.test_sql_with_having __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:112: in test_sql_with_having
    result = spark.sql("""
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'having_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
_______ TestIssue135DatetimeFilter.test_to_timestamp_with_filter_isnull ________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_135_datetime_filter.py:85: in test_to_timestamp_with_filter_isnull
    null_count = null_result.count()
                 ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
________ TestOrderByAscendingParity.test_orderby_ascending_false_parity ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_orderby_ascending_parity.py:57: in test_orderby_ascending_false_parity
    assert rows[0]["StringValue"] == "ZZZ"
E   AssertionError: assert 'AAA' == 'ZZZ'
E     
E     - ZZZ
E     + AAA
________ TestIssue296UdfDecorator.test_udf_decorator_with_integer_type _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:78: in test_udf_decorator_with_integer_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_______ TestIssue166UnixTimestamp.test_unix_timestamp_current_timestamp ________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_166_unix_timestamp.py:115: in test_unix_timestamp_current_timestamp
    rows = result_df.select("unix_ts").collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: unix_timestamp
__________ TestOrderByAscendingParity.test_sort_with_ascending_parity __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_orderby_ascending_parity.py:82: in test_sort_with_ascending_parity
    assert rows[0]["Value"] == 20
E   assert 10 == 20
____ TestIssue293ExplodeWithColumn.test_explode_with_single_element_arrays _____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:380: in test_explode_with_single_element_arrays
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
__________________ TestSQLAdvancedParity.test_sql_with_union ___________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:138: in test_sql_with_union
    result = spark.sql("""
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT (no UNION/EXCEPT/INTERSECT) is supported.
_______ TestIssue290UdfMultipleArguments.test_udf_with_conditional_logic _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:587: in test_udf_with_conditional_logic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______ TestIssue135DatetimeFilter.test_to_timestamp_with_multiple_filters ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_135_datetime_filter.py:122: in test_to_timestamp_with_multiple_filters
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________ TestIssue288CaseWhenOperators.test_casewhen_with_aliases ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:927: in test_casewhen_with_aliases
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestApproxCountDistinctRsdParity.test_approx_count_distinct_rsd_issue_266 ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_approx_count_distinct_rsd_parity.py:34: in test_approx_count_distinct_rsd_issue_266
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue168ValidationAfterDrop.test_validation_after_drop_columns ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_168_validation_after_drop.py:58: in test_validation_after_drop_columns
    count = valid_df.count()
            ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_____ TestIssue296UdfDecorator.test_udf_decorator_with_multiple_arguments ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:99: in test_udf_decorator_with_multiple_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______________ TestSplitLimitParity.test_split_with_limit_parity _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_split_limit_parity.py:32: in test_split_with_limit_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_________________ TestSQLAdvancedParity.test_sql_with_subquery _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:158: in test_sql_with_subquery
    result = spark.sql("""
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'subquery_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
_________ TestIssue293ExplodeWithColumn.test_explode_with_large_arrays _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:414: in test_explode_with_large_arrays
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue135DatetimeFilter.test_to_timestamp_with_multiple_operations_and_filter _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_135_datetime_filter.py:159: in test_to_timestamp_with_multiple_operations_and_filter
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________ TestIssue290UdfMultipleArguments.test_udf_six_arguments ____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:611: in test_udf_six_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____ TestIssue288CaseWhenOperators.test_casewhen_all_arithmetic_operators _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:966: in test_casewhen_all_arithmetic_operators
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue168ValidationAfterDrop.test_validation_after_drop_with_nested_operations _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_168_validation_after_drop.py:98: in test_validation_after_drop_with_nested_operations
    count = valid_df.count()
            ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
________________ TestSQLAdvancedParity.test_sql_with_case_when _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:180: in test_sql_with_case_when
    result = spark.sql("""
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'case_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
____________ TestIssue296UdfDecorator.test_udf_decorator_in_select _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:117: in test_udf_decorator_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestSplitLimitParity.test_split_with_limit_1_parity ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_split_limit_parity.py:56: in test_split_with_limit_1_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_ TestIssue136ColumnRenameValidation.test_column_rename_and_transform_with_filter _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_136_column_rename_validation.py:42: in test_column_rename_and_transform_with_filter
    .withColumnRenamed("record_id", "id")
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:321: in withColumnRenamed
    return self._transformations.withColumnRenamed(existing, new)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/transformation_service.py:552: in withColumnRenamed
    materialized = self._df._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________________ TestSQLAdvancedParity.test_sql_with_like ___________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:205: in test_sql_with_like
    result = spark.sql("SELECT * FROM like_test WHERE name LIKE 'A%'")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'like_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
______ TestIssue290UdfMultipleArguments.test_udf_with_all_null_arguments _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:634: in test_udf_with_all_null_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__ TestApproxCountDistinctRsdParity.test_approx_count_distinct_window_parity ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_approx_count_distinct_rsd_parity.py:107: in test_approx_count_distinct_window_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue288CaseWhenOperators.test_casewhen_mixed_with_columns ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_288_casewhen_operators.py:1012: in test_casewhen_mixed_with_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue293ExplodeWithColumn.test_explode_with_groupby_agg __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:442: in test_explode_with_groupby_agg
    result = df.groupBy("Category").agg(F.sum("ExplodedValue").alias("Total"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue168ValidationAfterDrop.test_validation_after_drop_with_complex_filter _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_168_validation_after_drop.py:145: in test_validation_after_drop_with_complex_filter
    count = valid_df.count()
            ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
____________ TestIssue296UdfDecorator.test_udf_decorator_in_filter _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:138: in test_udf_decorator_in_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________________ TestSQLAdvancedParity.test_sql_with_in_clause _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_advanced.py:221: in test_sql_with_in_clause
    result = spark.sql("SELECT * FROM in_test WHERE age IN (25, 35)")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'in_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
_____________ TestSplitLimitParity.test_split_without_limit_parity _____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_split_limit_parity.py:77: in test_split_without_limit_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_______ TestIssue290UdfMultipleArguments.test_udf_with_string_functions ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:658: in test_udf_with_string_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestIssue289StructFunction.test_struct_basic _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:29: in test_struct_basic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
___________ TestIssue293ExplodeWithColumn.test_explode_with_orderby ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:474: in test_explode_with_orderby
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
__ TestIssue169ToTimestampDropError.test_to_timestamp_drop_materialize_basic ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_169_to_timestamp_drop_error.py:55: in test_to_timestamp_drop_materialize_basic
    count = silver_df.count()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
__ TestIssue136ColumnRenameValidation.test_rename_then_add_column_then_filter __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_136_column_rename_validation.py:115: in test_rename_then_add_column_then_filter
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: cannot compare string with numeric type (f64)
____________________ TestSQLDDLParity.test_create_database _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:24: in test_create_database
    spark.sql("CREATE DATABASE IF NOT EXISTS test_db")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
________ TestIssue296UdfDecorator.test_udf_decorator_with_string_names _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:178: in test_udf_decorator_with_string_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___________ TestIssue289StructFunction.test_struct_with_col_function ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:67: in test_struct_with_col_function
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_________ TestIssue290UdfMultipleArguments.test_udf_chained_operations _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:683: in test_udf_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___________ TestIssue293ExplodeWithColumn.test_explode_with_distinct ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:501: in test_explode_with_distinct
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
_________ TestSplitLimitParity.test_split_with_limit_minus_one_parity __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_split_limit_parity.py:101: in test_split_with_limit_minus_one_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_ TestApproxCountDistinctRsdParity.test_approx_count_distinct_window_without_rsd_parity _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_approx_count_distinct_rsd_parity.py:196: in test_approx_count_distinct_window_without_rsd_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue169ToTimestampDropError.test_to_timestamp_drop_multiple_columns ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_169_to_timestamp_drop_error.py:101: in test_to_timestamp_drop_multiple_columns
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
_____________ TestSQLDDLParity.test_create_database_if_not_exists ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:37: in test_create_database_if_not_exists
    spark.sql("CREATE DATABASE IF NOT EXISTS test_db2")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_ TestIssue137DatetimeValidation.test_datetime_validation_with_age_calculation _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_137_datetime_validation.py:42: in test_datetime_validation_with_age_calculation
    count = validation_result.count()
            ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
________ TestIssue296UdfDecorator.test_udf_decorator_chained_operations ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:203: in test_udf_decorator_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestArrayFunctionsParity.test_array_contains _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:21: in test_array_contains
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestStringFunctionsParity.test_string_upper __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:21: in test_string_upper
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ TestIssue289StructFunction.test_struct_single_column _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:89: in test_struct_single_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_____ TestIssue169ToTimestampDropError.test_to_timestamp_drop_with_select ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_169_to_timestamp_drop_error.py:134: in test_to_timestamp_drop_with_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
____ TestIssue290UdfMultipleArguments.test_udf_with_large_number_of_columns ____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_290_udf_multiple_arguments.py:724: in test_udf_with_large_number_of_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
____________ TestIssue293ExplodeWithColumn.test_explode_with_union _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:533: in test_explode_with_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____________________ TestSQLDDLParity.test_drop_database ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:53: in test_drop_database
    spark.sql("CREATE DATABASE IF NOT EXISTS test_db3")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____ TestIssue137DatetimeValidation.test_datetime_validation_simple_filter _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_137_datetime_validation.py:68: in test_datetime_validation_simple_filter
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
______ TestIssue296UdfDecorator.test_udf_decorator_vs_function_interface _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:229: in test_udf_decorator_vs_function_interface
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestArrayFunctionsParity.test_array_position _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:30: in test_array_position
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
______________ TestIssue289StructFunction.test_struct_with_nulls _______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:111: in test_struct_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_________________ TestStringFunctionsParity.test_string_lower __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:30: in test_string_lower
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____ TestIssue169ToTimestampDropError.test_to_timestamp_drop_with_filter ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_169_to_timestamp_drop_error.py:162: in test_to_timestamp_drop_with_filter
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
______________ TestSQLDDLParity.test_create_table_from_dataframe _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:75: in test_create_table_from_dataframe
    result = spark.sql("SELECT * FROM test_users")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'test_users' not found. Register it with create_or_replace_temp_view or saveAsTable.
__ TestIssue291PowerNegativeExponent.test_power_negative_exponent_exact_issue __
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_negative_exponent.py:19: in test_power_negative_exponent_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must be a JSON object
_________ TestIssue296UdfDecorator.test_udf_decorator_with_null_values _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:252: in test_udf_decorator_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______________________ TestArrayFunctionsParity.test_size ______________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:39: in test_size
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestIssue293ExplodeWithColumn.test_explode_with_computed_column ________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:564: in test_explode_with_computed_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________________ TestStringFunctionsParity.test_string_length _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:39: in test_string_length
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestSQLDDLParity.test_create_table_with_select ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:95: in test_create_table_with_select
    spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: true, transient: false, name: ObjectName([Ident { value: "it_employees", quote_style: None }]), columns: [], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: Some(Query { with: None, body: Select(Select { distinct: None, top: None, projection: [UnnamedExpr(Identifier(Ident { value: "name", quote_style: None })), UnnamedExpr(Identifier(Ident { value: "age", quote_style: None }))], into: None, from: [TableWithJoins { relation: Table { name: ObjectName([Ident { value: "employees", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }], lateral_views: [], selection: Some(BinaryOp { left: Identifier(Ident { value: "dept", quote_style: None }), op: Eq, right: Value(SingleQuotedString("IT")) }), group_by: Expressions([]), cluster_by: [], distribute_by: [], sort_by: [], having: None, named_window: [], qualify: None, value_table_mode: None }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.
_______________ TestIssue289StructFunction.test_struct_in_select _______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:133: in test_struct_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_ TestIssue137DatetimeValidation.test_datetime_validation_with_multiple_conditions _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_137_datetime_validation.py:96: in test_datetime_validation_with_multiple_conditions
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_____ TestIssue170ToDateTimestampType.test_to_date_on_timestamp_type_basic _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_170_to_date_timestamp_type.py:52: in test_to_date_on_timestamp_type_basic
    .agg(F.count("*").alias("total_events"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestIssue291PowerNegativeExponent.test_power_negative_exponent_multiple_values _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_negative_exponent.py:33: in test_power_negative_exponent_multiple_values
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must be a JSON object
___________________ TestArrayFunctionsParity.test_element_at ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:48: in test_element_at
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______________ TestStringFunctionsParity.test_string_substring ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:48: in test_string_substring
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______________________ TestSQLDDLParity.test_drop_table _______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:118: in test_drop_table
    spark.sql("DROP TABLE IF EXISTS temp_table")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____ TestIssue296UdfDecorator.test_udf_decorator_with_different_data_types _____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:291: in test_udf_decorator_with_different_data_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________ TestIssue293ExplodeWithColumn.test_explode_with_when_otherwise ________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:594: in test_explode_with_when_otherwise
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___ TestIssue170ToDateTimestampType.test_to_date_on_timestamp_type_with_drop ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_170_to_date_timestamp_type.py:91: in test_to_date_on_timestamp_type_with_drop
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
____________ TestIssue289StructFunction.test_struct_multiple_types _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:154: in test_struct_multiple_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_______ TestIssue138ColumnDropReference.test_drop_column_after_transform _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_138_column_drop_reference.py:43: in test_drop_column_after_transform
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
____________________ TestArrayFunctionsParity.test_explode _____________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:57: in test_explode
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=9
__________________ TestSQLDDLParity.test_drop_table_if_exists __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:126: in test_drop_table_if_exists
    spark.sql("DROP TABLE IF EXISTS non_existent_table")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___ TestIssue291PowerNegativeExponent.test_power_negative_exponent_in_select ___
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_negative_exponent.py:48: in test_power_negative_exponent_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must be a JSON object
___ TestIssue296UdfDecorator.test_udf_decorator_multiple_udfs_same_dataframe ___
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:377: in test_udf_decorator_multiple_udfs_same_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestStringFunctionsParity.test_string_substr_method ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:62: in test_string_substr_method
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
___________ TestIssue289StructFunction.test_struct_with_expressions ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:183: in test_struct_with_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
__ TestIssue170ToDateTimestampType.test_to_date_on_timestamp_type_with_select __
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_170_to_date_timestamp_type.py:121: in test_to_date_on_timestamp_type_with_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_________________ TestArrayFunctionsParity.test_array_distinct _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:73: in test_array_distinct
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_____________ TestIssue293ExplodeWithColumn.test_explode_with_cast _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:624: in test_explode_with_cast
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____________________ TestSQLDDLParity.test_create_schema ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:138: in test_create_schema
    spark.sql("CREATE SCHEMA IF NOT EXISTS test_schema")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______ TestIssue296UdfDecorator.test_udf_decorator_with_computed_columns _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:404: in test_udf_decorator_with_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__ TestIssue138ColumnDropReference.test_drop_multiple_columns_after_transform __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_138_column_drop_reference.py:83: in test_drop_multiple_columns_after_transform
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___ TestIssue291PowerNegativeExponent.test_power_negative_exponent_with_show ___
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_negative_exponent.py:60: in test_power_negative_exponent_with_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must be a JSON object
___________________ TestArrayFunctionsParity.test_array_join ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:82: in test_array_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__ TestIssue170ToDateTimestampType.test_to_date_on_timestamp_type_with_filter __
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_170_to_date_timestamp_type.py:149: in test_to_date_on_timestamp_type_with_filter
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_____________ TestIssue289StructFunction.test_struct_with_literals _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_289_struct_function.py:207: in test_struct_with_literals
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_____________ TestStringFunctionsParity.test_column_astype_method ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:84: in test_column_astype_method
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
__________________ TestSQLDDLParity.test_set_current_database __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:151: in test_set_current_database
    spark.sql("CREATE DATABASE IF NOT EXISTS test_current_db")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______ TestIssue293ExplodeWithColumn.test_explode_with_string_operations _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:652: in test_explode_with_string_operations
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________ TestIssue296UdfDecorator.test_udf_decorator_empty_dataframe __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:427: in test_udf_decorator_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________________ TestArrayFunctionsParity.test_array_union ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_array.py:91: in test_array_union
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_________________ TestStringFunctionsParity.test_string_concat _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:99: in test_string_concat
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________ TestIssue138ColumnDropReference.test_drop_then_select _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_138_column_drop_reference.py:115: in test_drop_then_select
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestIssue173ValidationDuringMaterialization.test_validation_during_materialization_with_dropped_columns _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_173_validation_during_materialization.py:66: in test_validation_during_materialization_with_dropped_columns
    count = valid_df.count()
            ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestIssue291PowerNegativeExponent.test_unary_minus_standalone_in_withcolumn __
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_negative_exponent.py:73: in test_unary_minus_standalone_in_withcolumn
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must be a JSON object
_______________ TestSQLDDLParity.test_table_in_specific_database _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_ddl.py:171: in test_table_in_specific_database
    spark.sql("CREATE DATABASE IF NOT EXISTS test_db_specific")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________ TestIssue296UdfDecorator.test_udf_decorator_with_date_type __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:448: in test_udf_decorator_with_date_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______ TestIssue293ExplodeWithColumn.test_explode_with_multiple_explodes _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:681: in test_explode_with_multiple_explodes
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_______ TestIssue291PowerOperatorFloatColumn.test_power_with_conditional _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:697: in test_power_with_conditional
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________ TestStringFunctionsParity.test_string_split __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:108: in test_string_split
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________ TestIssue138ColumnDropReference.test_drop_then_filter _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_138_column_drop_reference.py:140: in test_drop_then_filter
    count = result.count()
            ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestIssue297JoinDifferentCaseSelect.test_groupby_after_select_with_ambiguous_column _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:251: in test_groupby_after_select_with_ambiguous_column
    .agg(
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "bonus"]; PROJECT */2 COLUMNS; SELECTION: None
___________________ TestSQLDMLParity.test_insert_into_table ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:29: in test_insert_into_table
    spark.sql("INSERT INTO insert_test VALUES ('Bob', 30)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "insert_test", quote_style: None }]), table_alias: None, columns: [], overwrite: false, source: Some(Query { with: None, body: Values(Values { explicit_row: false, rows: [[Value(SingleQuotedString("Bob")), Value(Number("30", false))]] }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
_____________ TestStringFunctionsParity.test_string_regexp_extract _____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:117: in test_string_regexp_extract
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestIssue296UdfDecorator.test_udf_decorator_with_timestamp_type ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:466: in test_udf_decorator_with_timestamp_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_ TestIssue297JoinDifferentCaseSelect.test_single_match_preserves_original_name _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:285: in test_single_match_preserves_original_name
    assert row[df.select("name").columns[0]] == "Alice"
E   AssertionError: assert None == 'Alice'
_ TestIssue139DatetimeValidationCompatibility.test_validation_with_datetime_column _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_139_datetime_validation_compatibility.py:42: in test_validation_with_datetime_column
    count = validation_result.count()
            ^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_____________ TestIssue293ExplodeWithColumn.test_explode_with_join _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:717: in test_explode_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
________ TestIssue291PowerOperatorFloatColumn.test_column_power_number _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:115: in test_column_power_number
    assert row_value_2["Squared"] == 4  # 2 ** 2
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert '4' == 4
______________ TestSQLDMLParity.test_insert_into_specific_columns ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:49: in test_insert_into_specific_columns
    spark.sql("INSERT INTO insert_specific (name, age) VALUES ('Bob', 30)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "insert_specific", quote_style: None }]), table_alias: None, columns: [Ident { value: "name", quote_style: None }, Ident { value: "age", quote_style: None }], overwrite: false, source: Some(Query { with: None, body: Values(Values { explicit_row: false, rows: [[Value(SingleQuotedString("Bob")), Value(Number("30", false))]] }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
__________________ TestStringFunctionsParity.test_string_trim __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:126: in test_string_trim
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestIssue297JoinDifferentCaseSelect.test_multiple_matches_uses_requested_name _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:300: in test_multiple_matches_uses_requested_name
    result = df.select("NaMe").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME"]; PROJECT */1 COLUMNS; SELECTION: None
_________ TestIssue296UdfDecorator.test_udf_decorator_with_array_type __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:482: in test_udf_decorator_with_array_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestSQLDMLParity.test_insert_multiple_values _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:70: in test_insert_multiple_values
    spark.sql("INSERT INTO insert_multi VALUES ('Bob', 30), ('Charlie', 35)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "insert_multi", quote_style: None }]), table_alias: None, columns: [], overwrite: false, source: Some(Query { with: None, body: Values(Values { explicit_row: false, rows: [[Value(SingleQuotedString("Bob")), Value(Number("30", false))], [Value(SingleQuotedString("Charlie")), Value(Number("35", false))]] }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
_________ TestIssue335WindowOrderByList.test_window_orderby_list_basic _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:29: in test_window_orderby_list_basic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestStringConcatenationCacheEdgeCases.test_string_concat_with_select _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_188_string_concat_cache.py:155: in test_string_concat_with_select
    df3_cached = df3.cache()
                 ^^^^^^^^^^^
sparkless/dataframe/dataframe.py:600: in cache
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'col1' not found. Available columns: [concat]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestIssue293ExplodeWithColumn.test_explode_outer_with_empty_arrays ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:745: in test_explode_outer_with_empty_arrays
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________________ TestStringFunctionsParity.test_string_ltrim __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:135: in test_string_ltrim
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
______________________ TestSQLDMLParity.test_update_table ______________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:95: in test_update_table
    spark.sql("UPDATE update_test SET age = 26 WHERE name = 'Alice'")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Update { table: TableWithJoins { relation: Table { name: ObjectName([Ident { value: "update_test", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }, assignments: [Assignment { id: [Ident { value: "age", quote_style: None }], value: Value(Number("26", false)) }], from: None, selection: Some(BinaryOp { left: Identifier(Ident { value: "name", quote_style: None }), op: Eq, right: Value(SingleQuotedString("Alice")) }), returning: None }.
__________ TestIssue297JoinDifferentCaseSelect.test_empty_dataframes ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:340: in test_empty_dataframes
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
___________ TestIssue291PowerOperatorFloatColumn.test_power_in_union ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:839: in test_power_in_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: type String is incompatible with expected type Float64
_________ TestIssue296UdfDecorator.test_udf_decorator_three_arguments __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:498: in test_udf_decorator_three_arguments
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________ TestIssue291PowerOperatorFloatColumn.test_power_in_select ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:221: in test_power_in_select
    assert rows[0]["Power"] == 8.0  # 2.0 ** 3
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 8.0
_____ TestIssue335WindowOrderByList.test_window_orderby_list_single_column _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:54: in test_window_orderby_list_single_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________ TestStringFunctionsParity.test_string_rtrim __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:144: in test_string_rtrim
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestStringConcatenationCacheEdgeCases.test_string_concat_chained_operations __
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_188_string_concat_cache.py:177: in test_string_concat_chained_operations
    df2_cached = df2.cache()
                 ^^^^^^^^^^^
sparkless/dataframe/dataframe.py:600: in cache
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
__________ TestIssue291PowerOperatorFloatColumn.test_power_with_alias __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:868: in test_power_with_alias
    assert abs(rows[0]["TwoToPower"] - 4.0) < 0.01
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for -: 'NoneType' and 'float'
________________ TestSQLDMLParity.test_update_multiple_columns _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/sql/test_dml.py:121: in test_update_multiple_columns
    spark.sql("UPDATE update_multi SET age = 26, dept = 'HR' WHERE name = 'Alice'")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Update { table: TableWithJoins { relation: Table { name: ObjectName([Ident { value: "update_multi", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }, assignments: [Assignment { id: [Ident { value: "age", quote_style: None }], value: Value(Number("26", false)) }, Assignment { id: [Ident { value: "dept", quote_style: None }], value: Value(SingleQuotedString("HR")) }], from: None, selection: Some(BinaryOp { left: Identifier(Ident { value: "name", quote_style: None }), op: Eq, right: Value(SingleQuotedString("Alice")) }), returning: None }.
____________ TestIssue293ExplodeWithColumn.test_explode_with_alias _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:772: in test_explode_with_alias
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___ TestStringConcatenationCacheEdgeCases.test_string_concat_without_caching ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_188_string_concat_cache.py:202: in test_string_concat_without_caching
    assert result["concat"] == "ab", (
E   AssertionError: String concatenation should work normally without caching
E   assert None == 'ab'
____ TestIssue297JoinDifferentCaseSelect.test_null_values_in_joined_columns ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:367: in test_null_values_in_joined_columns
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
__________________ TestStringFunctionsParity.test_string_lpad __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:153: in test_string_lpad
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
____________ TestIssue296UdfDecorator.test_udf_decorator_with_join _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:517: in test_udf_decorator_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___ TestIssue335WindowOrderByList.test_window_orderby_list_multiple_columns ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:76: in test_window_orderby_list_multiple_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestStringConcatenationCacheEdgeCases.test_concat_function_with_caching ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_188_string_concat_cache.py:214: in test_concat_function_with_caching
    df2_cached = df2.cache()
                 ^^^^^^^^^^^
sparkless/dataframe/dataframe.py:600: in cache
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
_________ TestIssue293ExplodeWithColumn.test_explode_with_filter_after _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:800: in test_explode_with_filter_after
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______ TestIssue297JoinDifferentCaseSelect.test_different_case_variations ______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:387: in test_different_case_variations
    result = df.select(case_variant).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME"]; PROJECT */1 COLUMNS; SELECTION: None
__________________ TestStringFunctionsParity.test_string_rpad __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:162: in test_string_rpad
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________________ TestIssue328SplitLimit.test_split_with_limit_1 ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:75: in test_split_with_limit_1
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
____________ TestIssue296UdfDecorator.test_udf_decorator_with_union ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:540: in test_udf_decorator_with_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________ TestIssue335WindowOrderByList.test_window_partitionby_list __________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:101: in test_window_partitionby_list
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue291PowerOperatorFloatColumn.test_power_in_multiple_withcolumns ____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:956: in test_power_in_multiple_withcolumns
    assert row_value_2["Power2"] == 4
E   AssertionError: assert '4' == 4
______ TestIssue297JoinDifferentCaseSelect.test_with_column_after_select _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:410: in test_with_column_after_select
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
__________________ TestStringFunctionsParity.test_string_like __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:171: in test_string_like
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
________ TestIssue293ExplodeWithColumn.test_explode_with_filter_before _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:828: in test_explode_with_filter_before
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______ TestIssue291PowerOperatorFloatColumn.test_power_negative_exponent _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:347: in test_power_negative_exponent
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must be a JSON object
________________ TestIssue328SplitLimit.test_split_with_limit_2 ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:101: in test_split_with_limit_2
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
__________ TestIssue296UdfDecorator.test_udf_decorator_with_distinct ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:564: in test_udf_decorator_with_distinct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestIssue335WindowOrderByList.test_window_both_list ______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:128: in test_window_both_list
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________ TestIssue292RlikeLookaround.test_rlike_negative_lookahead ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:38: in test_rlike_negative_lookahead
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_________________ TestStringFunctionsParity.test_string_rlike __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:180: in test_string_rlike
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
__________ TestIssue297JoinDifferentCaseSelect.test_drop_after_select __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:432: in test_drop_after_select
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
_________ TestIssue331ArrayContainsJoin.test_array_contains_join_basic _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:33: in test_array_contains_join_basic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
________ TestIssue293ExplodeWithColumn.test_explode_with_select_subset _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:857: in test_explode_with_select_subset
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
__ TestIssue335WindowOrderByList.test_window_orderby_list_with_column_objects __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:152: in test_window_orderby_list_with_column_objects
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________________ TestStringFunctionsParity.test_concat_ws ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:189: in test_concat_ws
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______________ TestIssue328SplitLimit.test_split_without_limit ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:129: in test_split_without_limit
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
___________ TestIssue296UdfDecorator.test_udf_decorator_with_orderby ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:589: in test_udf_decorator_with_orderby
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestIssue331ArrayContainsJoin.test_array_contains_join_inner _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:67: in test_array_contains_join_inner
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
__________ TestIssue292RlikeLookaround.test_rlike_positive_lookahead ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:66: in test_rlike_positive_lookahead
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
______________ TestIssue326FormatString.test_format_string_basic _______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:45: in test_format_string_basic
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_______ TestIssue328SplitLimit.test_split_with_limit_larger_than_splits ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:159: in test_split_with_limit_larger_than_splits
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_____________________ TestStringFunctionsParity.test_ascii _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/functions/test_string.py:198: in test_ascii
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_ TestIssue335WindowOrderByList.test_window_orderby_list_mixed_strings_and_columns _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:173: in test_window_orderby_list_mixed_strings_and_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue293ExplodeWithColumn.test_explode_with_count _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:885: in test_explode_with_count
    result = df.groupBy("Name").agg(F.count("ExplodedValue").alias("Count"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____ TestIssue291PowerOperatorFloatColumn.test_power_fractional_exponent ______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:497: in test_power_fractional_exponent
    assert abs(row_value_4["SquareRoot"] - 2.0) < 0.01  # 4.0 ** 0.5 = 2.0
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: unsupported operand type(s) for -: 'str' and 'float'
_____ TestIssue296UdfDecorator.test_udf_decorator_with_special_characters ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:618: in test_udf_decorator_with_special_characters
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestIssue331ArrayContainsJoin.test_array_contains_join_left __________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:95: in test_array_contains_join_left
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________ TestIssue326FormatString.test_format_string_multiple_columns _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:88: in test_format_string_multiple_columns
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
______________ TestIssue292RlikeLookaround.test_rlike_lookbehind _______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:93: in test_rlike_lookbehind
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
____________ TestIssue328SplitLimit.test_split_with_limit_minus_one ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:188: in test_split_with_limit_minus_one
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_ TestIssue335WindowOrderByList.test_window_orderby_list_backward_compatibility _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:194: in test_window_orderby_list_backward_compatibility
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue294HourMinuteSecondStringTimestamps.test_hour_minute_second_from_string_timestamps _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_294_hour_minute_second_string_timestamps.py:48: in test_hour_minute_second_from_string_timestamps
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_multiple_orderby_columns _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1716: in test_window_function_comparison_with_multiple_orderby_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue296UdfDecorator.test_udf_decorator_with_unicode ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:640: in test_udf_decorator_with_unicode
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestIssue326FormatString.test_format_string_with_null_values _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:121: in test_format_string_with_null_values
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
___ TestIssue331ArrayContainsJoin.test_array_contains_join_multiple_matches ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:124: in test_array_contains_join_multiple_matches
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
__________ TestIssue292RlikeLookaround.test_rlike_negative_lookbehind __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:119: in test_rlike_negative_lookbehind
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_______ TestIssue291PowerOperatorFloatColumn.test_power_string_coercion ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:571: in test_power_string_coercion
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: `pow` operation not supported for dtype `str` as exponent
______________ TestIssue328SplitLimit.test_split_with_null_values ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:217: in test_split_with_null_values
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
______ TestIssue296UdfDecorator.test_udf_decorator_with_very_long_strings ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:658: in test_udf_decorator_with_very_long_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_ TestIssue294HourMinuteSecondStringTimestamps.test_hour_minute_second_with_different_timezone_formats _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_294_hour_minute_second_string_timestamps.py:113: in test_hour_minute_second_with_different_timezone_formats
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_chained_filters _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1749: in test_window_function_comparison_with_chained_filters
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue335WindowOrderByList.test_window_orderby_list_with_desc _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:215: in test_window_orderby_list_with_desc
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue326FormatString.test_format_string_in_select _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:158: in test_format_string_in_select
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
__________ TestIssue291PowerOperatorFloatColumn.test_power_in_orderby __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_291_power_operator_float_column.py:602: in test_power_in_orderby
    assert rows[0]["Value"] == 4
E   assert 2 == 4
__________ TestIssue292RlikeLookaround.test_rlike_complex_lookaround ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:146: in test_rlike_complex_lookaround
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
______ TestIssue331ArrayContainsJoin.test_array_contains_join_no_matches _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:156: in test_array_contains_join_no_matches
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______ TestIssue296UdfDecorator.test_udf_decorator_with_conditional_logic ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:686: in test_udf_decorator_with_conditional_logic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestIssue328SplitLimit.test_split_with_empty_string ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:247: in test_split_with_empty_string
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_window_function_in_value _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1781: in test_window_function_comparison_with_window_function_in_value
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue294HourMinuteSecondStringTimestamps.test_hour_minute_second_with_different_formats _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_294_hour_minute_second_string_timestamps.py:154: in test_hour_minute_second_with_different_formats
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
___ TestIssue335WindowOrderByList.test_window_orderby_list_with_rows_between ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:245: in test_window_orderby_list_with_rows_between
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue326FormatString.test_format_string_different_format_specifiers ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:196: in test_format_string_different_format_specifiers
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
___________ TestIssue292RlikeLookaround.test_regexp_alias_lookaround ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:172: in test_regexp_alias_lookaround
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
______ TestIssue331ArrayContainsJoin.test_array_contains_join_null_arrays ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:187: in test_array_contains_join_null_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____ TestIssue296UdfDecorator.test_udf_decorator_with_exception_handling ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:713: in test_udf_decorator_with_exception_handling
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestIssue328SplitLimit.test_split_in_select __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:276: in test_split_in_select
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_ TestIssue294HourMinuteSecondStringTimestamps.test_hour_minute_second_in_select _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_294_hour_minute_second_string_timestamps.py:209: in test_hour_minute_second_in_select
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_direct_filter _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:425: in test_window_function_comparison_direct_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue335WindowOrderByList.test_window_orderby_list_empty_list_error ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:267: in test_window_orderby_list_empty_list_error
    result.collect()  # Should raise error, but if it doesn't, that's also acceptable
    ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'

During handling of the above exception, another exception occurred:
tests/test_issue_335_window_orderby_list.py:270: in test_window_orderby_list_empty_list_error
    assert "At least one column" in str(e) or "must be specified" in str(e)
E   assert ('At least one column' in "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'" or 'must be specified' in "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'")
E    +  where "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'" = str(ValueError("Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'"))
E    +  and   "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'" = str(ValueError("Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'"))
__________ TestIssue326FormatString.test_format_string_empty_strings ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:231: in test_format_string_empty_strings
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
________ TestIssue292RlikeLookaround.test_regexp_like_alias_lookaround _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:198: in test_regexp_like_alias_lookaround
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_______ TestIssue331ArrayContainsJoin.test_array_contains_join_null_ids ________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:218: in test_array_contains_join_null_ids
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___________ TestIssue296UdfDecorator.test_udf_decorator_nested_calls ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:734: in test_udf_decorator_nested_calls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
____________ TestIssue328SplitLimit.test_split_multi_char_delimiter ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:304: in test_split_multi_char_delimiter
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_ TestIssue294HourMinuteSecondStringTimestamps.test_hour_minute_second_with_filter _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_294_hour_minute_second_string_timestamps.py:249: in test_hour_minute_second_with_filter
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_window_function __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:288: in test_window_orderby_list_with_window_function
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue326FormatString.test_format_string_many_columns ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:279: in test_format_string_many_columns
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_eqNullSafe _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:450: in test_window_function_comparison_with_eqNullSafe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue296UdfDecorator.test_udf_decorator_with_float_precision _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:750: in test_udf_decorator_with_float_precision
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________ TestIssue292RlikeLookaround.test_rlike_without_lookaround ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:225: in test_rlike_without_lookaround
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
__________ TestIssue328SplitLimit.test_split_special_regex_characters __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:331: in test_split_special_regex_characters
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_________ TestIssue331ArrayContainsJoin.test_array_contains_join_right _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:247: in test_array_contains_join_right
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
________ TestIssue335WindowOrderByList.test_window_static_orderby_list _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:310: in test_window_static_orderby_list
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue294HourMinuteSecondStringTimestamps.test_hour_minute_second_with_null_values _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_294_hour_minute_second_string_timestamps.py:283: in test_hour_minute_second_with_null_values
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
________ TestIssue326FormatString.test_format_string_numeric_edge_cases ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:318: in test_format_string_numeric_edge_cases
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
________ TestIssue296UdfDecorator.test_udf_decorator_with_boolean_logic ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:772: in test_udf_decorator_with_boolean_logic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_isnotnull _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:477: in test_window_function_comparison_with_isnotnull
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue331ArrayContainsJoin.test_array_contains_join_outer _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:278: in test_array_contains_join_outer
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______ TestIssue292RlikeLookaround.test_rlike_case_insensitive_lookaround ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:252: in test_rlike_case_insensitive_lookaround
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
____________ TestIssue328SplitLimit.test_split_whitespace_delimiter ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:358: in test_split_whitespace_delimiter
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
______ TestIssue335WindowOrderByList.test_window_static_partitionby_list _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:331: in test_window_static_partitionby_list
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue294HourMinuteSecondStringTimestamps.test_hour_minute_second_in_groupby_agg _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_294_hour_minute_second_string_timestamps.py:326: in test_hour_minute_second_in_groupby_agg
    .agg(F.avg("hour").alias("avg_hour"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
_______ TestIssue296UdfDecorator.test_udf_decorator_with_drop_operation ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:790: in test_udf_decorator_with_drop_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'city' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestIssue326FormatString.test_format_string_unicode ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:354: in test_format_string_unicode
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_null_values _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:509: in test_window_function_comparison_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue331ArrayContainsJoin.test_array_contains_join_with_select ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:309: in test_array_contains_join_with_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'array_contains(IDs, ID)' not found. Available columns: [Name, Dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__ TestIssue335WindowOrderByList.test_window_orderby_list_with_desc_asc_mixed __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:357: in test_window_orderby_list_with_desc_asc_mixed
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue328SplitLimit.test_split_consecutive_delimiters ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:384: in test_split_consecutive_delimiters
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
__________ TestIssue292RlikeLookaround.test_rlike_multiple_lookaheads __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:282: in test_rlike_multiple_lookaheads
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
______ TestIssue296UdfDecorator.test_udf_decorator_multiple_chained_udfs _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:819: in test_udf_decorator_multiple_chained_udfs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___ TestIssue326FormatString.test_format_string_special_characters_in_format ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:387: in test_format_string_special_characters_in_format
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
______ TestIssue331ArrayContainsJoin.test_array_contains_join_with_filter ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:338: in test_array_contains_join_with_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_empty_dataframe _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:529: in test_window_function_comparison_with_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestIssue335WindowOrderByList.test_window_orderby_list_with_range_between ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:392: in test_window_orderby_list_with_range_between
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue328SplitLimit.test_split_delimiter_not_found _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:410: in test_split_delimiter_not_found
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_________ TestIssue292RlikeLookaround.test_rlike_lookaround_with_nulls _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:308: in test_rlike_lookaround_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_________ TestIssue337GroupedDataMean.test_grouped_data_mean_with_join _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:535: in test_grouped_data_mean_with_join
    assert alice_row["Type"] == "A"
E   AssertionError: assert None == 'A'
_______ TestIssue296UdfDecorator.test_udf_decorator_with_all_null_inputs _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:849: in test_udf_decorator_with_all_null_inputs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestIssue326FormatString.test_format_string_all_null _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:429: in test_format_string_all_null
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_ TestIssue331ArrayContainsJoin.test_array_contains_join_column_name_conflicts _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:363: in test_array_contains_join_column_name_conflicts
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_single_row _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:548: in test_window_function_comparison_with_single_row
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________ TestIssue328SplitLimit.test_split_limit_zero _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:435: in test_split_limit_zero
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
____________ TestIssue292RlikeLookaround.test_rlike_empty_dataframe ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:336: in test_rlike_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_____ TestIssue296UdfDecorator.test_udf_decorator_with_mixed_types_in_udf ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:883: in test_udf_decorator_with_mixed_types_in_udf
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
____ TestIssue335WindowOrderByList.test_window_orderby_list_with_dense_rank ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:419: in test_window_orderby_list_with_dense_rank
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue331ArrayContainsJoin.test_array_contains_join_empty_dataframes ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:401: in test_array_contains_join_empty_dataframes
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Dept' has more than one occurrence
___________ TestIssue326FormatString.test_format_string_mixed_types ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:467: in test_format_string_mixed_types
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_______________ TestIssue292RlikeLookaround.test_rlike_in_select _______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:362: in test_rlike_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue331ArrayContainsJoin.test_array_contains_join_backward_compatibility _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:429: in test_array_contains_join_backward_compatibility
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_large_dataset _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:571: in test_window_function_comparison_with_large_dataset
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________ TestIssue328SplitLimit.test_split_unicode_characters _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:464: in test_split_unicode_characters
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
___ TestIssue335WindowOrderByList.test_window_orderby_list_with_percent_rank ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:447: in test_window_orderby_list_with_percent_rank
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue337GroupedDataMean.test_grouped_data_mean_with_drop _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:648: in test_grouped_data_mean_with_drop
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'Name' not found. Available columns: [avg(Value)]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestIssue296UdfDecorator.test_udf_decorator_with_complex_aggregation _____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:917: in test_udf_decorator_with_complex_aggregation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________ TestIssue326FormatString.test_format_string_format_specifiers _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:500: in test_format_string_format_specifiers
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
__ TestIssue295WithColumnRenamedNonexistent.test_withColumnRenamed_after_join __
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_295_withColumnRenamed_nonexistent.py:407: in test_withColumnRenamed_after_join
    assert result.count() == 2
E   assert 0 == 2
E    +  where 0 = count()
E    +    where count = DataFrame[0 rows, 3 columns].count
________ TestIssue337GroupedDataMean.test_grouped_data_mean_with_alias _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:678: in test_grouped_data_mean_with_alias
    assert alice_row["MeanValue"] == 5.5
E   assert None == 5.5
_____ TestIssue331ArrayContainsJoin.test_array_contains_join_empty_arrays ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:453: in test_array_contains_join_empty_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______________ TestIssue328SplitLimit.test_split_very_long_string ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:492: in test_split_very_long_string
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
_____________ TestIssue292RlikeLookaround.test_rlike_in_withcolumn _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:388: in test_rlike_in_withcolumn
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_multiple_window_functions _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:601: in test_window_function_comparison_with_multiple_window_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue296UdfDecorator.test_udf_decorator_idempotent_behavior ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_296_udf_decorator.py:941: in test_udf_decorator_idempotent_behavior
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____ TestIssue335WindowOrderByList.test_window_orderby_list_with_lag_lead _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:476: in test_window_orderby_list_with_lag_lead
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue326FormatString.test_format_string_precision_formatting _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:533: in test_format_string_precision_formatting
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_ TestIssue295WithColumnRenamedNonexistent.test_withColumnRenamed_after_orderby _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_295_withColumnRenamed_nonexistent.py:487: in test_withColumnRenamed_after_orderby
    assert rows[0]["age"] == 20  # Should be sorted
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert 25 == 20
______ TestIssue337GroupedDataMean.test_grouped_data_mean_with_case_when _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:702: in test_grouped_data_mean_with_case_when
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue331ArrayContainsJoin.test_array_contains_join_duplicate_values ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:484: in test_array_contains_join_duplicate_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______________ TestIssue328SplitLimit.test_split_empty_delimiter _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:521: in test_split_empty_delimiter
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
__________ TestIssue292RlikeLookaround.test_rlike_chained_operations ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:418: in test_rlike_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_first_last_value _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:504: in test_window_orderby_list_with_first_last_value
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue297JoinDifferentCaseSelect.test_join_different_case_select_third_case _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:37: in test_join_different_case_select_third_case
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "Value2"]; PROJECT */2 COLUMNS; SELECTION: None
___________ TestIssue326FormatString.test_format_string_long_strings ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_326_format_string.py:561: in test_format_string_long_strings
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_select _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:667: in test_window_function_comparison_with_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue337GroupedDataMean.test_grouped_data_mean_with_coalesce _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:732: in test_grouped_data_mean_with_coalesce
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: coalesce
___________ TestIssue327OrderByAscending.test_orderby_ascending_true ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:33: in test_orderby_ascending_true
    assert rows[1]["StringValue"] == "MMM"
E   AssertionError: assert 'ZZZ' == 'MMM'
E     
E     - MMM
E     + ZZZ
_____ TestIssue331ArrayContainsJoin.test_array_contains_join_string_arrays _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:511: in test_array_contains_join_string_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
________ TestIssue328SplitLimit.test_split_leading_trailing_delimiters _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:546: in test_split_leading_trailing_delimiters
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
________ TestIssue292RlikeLookaround.test_rlike_lookahead_with_anchors _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:449: in test_rlike_lookahead_with_anchors
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_________ TestIssue337GroupedDataMean.test_grouped_data_mean_with_cast _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:761: in test_grouped_data_mean_with_cast
    assert alice_row["MeanInt"] == 5  # 5.5 cast to int = 5
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 5
__________ TestIssue327OrderByAscending.test_orderby_ascending_false ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:54: in test_orderby_ascending_false
    assert rows[0]["StringValue"] == "ZZZ"
E   AssertionError: assert 'AAA' == 'ZZZ'
E     
E     - ZZZ
E     + AAA
____________ TestIssue367ArrayEmpty.test_array_empty_multiple_times ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:141: in test_array_empty_multiple_times
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_ TestIssue297JoinDifferentCaseSelect.test_join_different_case_select_left_column _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:67: in test_join_different_case_select_left_column
    result = df.select("NaMe", "value").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "value"]; PROJECT */2 COLUMNS; SELECTION: None
______ TestIssue335WindowOrderByList.test_window_orderby_list_with_ntile _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:529: in test_window_orderby_list_with_ntile
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_orderby _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:693: in test_window_function_comparison_with_orderby
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue327OrderByAscending.test_orderby_default_ascending __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:77: in test_orderby_default_ascending
    assert rows[1]["StringValue"] == "MMM"
E   AssertionError: assert 'ZZZ' == 'MMM'
E     
E     - MMM
E     + ZZZ
_____ TestIssue297JoinDifferentCaseSelect.test_join_same_case_no_ambiguity _____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:90: in test_join_same_case_no_ambiguity
    assert result[0]["value2"] == 2
E   assert None == 2
_________ TestIssue327OrderByAscending.test_orderby_numeric_ascending __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:98: in test_orderby_numeric_ascending
    assert rows[0]["Value"] == 5
E   assert 10 == 5
_____ TestIssue331ArrayContainsJoin.test_array_contains_join_float_arrays ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:542: in test_array_contains_join_float_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue337GroupedDataMean.test_grouped_data_mean_with_multiple_aggregations _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:810: in test_grouped_data_mean_with_multiple_aggregations
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
___________ TestIssue328SplitLimit.test_split_different_limit_values ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:577: in test_split_different_limit_values
    rows = result_df.collect()
           ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
___________ TestIssue292RlikeLookaround.test_rlike_nested_lookahead ____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:476: in test_rlike_nested_lookahead
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
______ TestIssue367ArrayEmpty.test_array_empty_with_different_data_types _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:153: in test_array_empty_with_different_data_types
    assert df1.withColumn("arr", F.array()).collect()[0]["arr"] == []
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_________ TestIssue327OrderByAscending.test_orderby_numeric_descending _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:120: in test_orderby_numeric_descending
    assert rows[0]["Value"] == 20
E   assert 10 == 20
____ TestIssue335WindowOrderByList.test_window_orderby_list_with_cume_dist _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:554: in test_window_orderby_list_with_cume_dist
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue297JoinDifferentCaseSelect.test_different_join_types _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:117: in test_different_join_types
    inner_result = inner_df.collect()
                   ^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
_____ TestIssue327OrderByAscending.test_orderby_multiple_columns_ascending _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:144: in test_orderby_multiple_columns_ascending
    assert rows[0]["Value"] == 5
E   assert 10 == 5
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_groupby _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:722: in test_window_function_comparison_with_groupby
    .agg(F.max("Score").alias("MaxScore"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue337GroupedDataMean.test_grouped_data_mean_with_window_functions ___
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:839: in test_grouped_data_mean_with_window_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue331ArrayContainsJoin.test_array_contains_join_large_arrays ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:573: in test_array_contains_join_large_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
____ TestIssue327OrderByAscending.test_orderby_multiple_columns_descending _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:169: in test_orderby_multiple_columns_descending
    assert rows[0]["Category"] == "B"
E   AssertionError: assert 'A' == 'B'
E     
E     - B
E     + A
_____________ TestIssue328SplitLimit.test_split_in_filter_context ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:610: in test_split_in_filter_context
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: element_at
________ TestIssue292RlikeLookaround.test_rlike_lookbehind_with_digits _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:503: in test_rlike_lookbehind_with_digits
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
__ TestIssue335WindowOrderByList.test_window_orderby_list_chained_operations ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:585: in test_window_orderby_list_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue367ArrayEmpty.test_array_empty_with_computed_columns _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:173: in test_array_empty_with_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_________ TestIssue327OrderByAscending.test_orderby_with_column_object _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:194: in test_orderby_with_column_object
    assert rows[0]["Value"] == 20
E   assert 10 == 20
_____ TestIssue297JoinDifferentCaseSelect.test_multiple_ambiguous_columns ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:172: in test_multiple_ambiguous_columns
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["AGE", "CITY", "NAME"]; PROJECT */3 COLUMNS; SELECTION: None
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_join _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:757: in test_window_function_comparison_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue327OrderByAscending.test_sort_with_ascending_parameter ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:216: in test_sort_with_ascending_parameter
    assert rows[0]["StringValue"] == "ZZZ"
E   AssertionError: assert 'AAA' == 'ZZZ'
E     
E     - ZZZ
E     + AAA
___ TestIssue331ArrayContainsJoin.test_array_contains_join_with_where_clause ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:602: in test_array_contains_join_with_where_clause
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
____________ TestIssue329LogFloatConstant.test_log_with_float_base _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:45: in test_log_with_float_base
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
_____ TestIssue292RlikeLookaround.test_rlike_combined_lookahead_lookbehind _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:530: in test_rlike_combined_lookahead_lookbehind
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
__________ TestIssue327OrderByAscending.test_orderby_with_null_values __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:240: in test_orderby_with_null_values
    assert rows[1]["Value"] == 20
E   assert None == 20
___ TestIssue297JoinDifferentCaseSelect.test_chained_operations_after_select ___
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_297_join_different_case_select.py:210: in test_chained_operations_after_select
    result = df.collect()
             ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: NaMe
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
_______________ TestIssue367ArrayEmpty.test_array_empty_in_join ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:187: in test_array_empty_in_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_____ TestIssue335WindowOrderByList.test_window_orderby_list_with_groupby ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:609: in test_window_orderby_list_with_groupby
    .agg(F.max("Rank").alias("MaxRank"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue327OrderByAscending.test_orderby_backward_compatibility _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:262: in test_orderby_backward_compatibility
    assert rows[0]["Value"] == 5
E   assert 10 == 5
_ TestIssue337GroupedDataMean.test_grouped_data_mean_with_complex_chained_operations _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:932: in test_grouped_data_mean_with_complex_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'avg(Value)' not found. Available columns: [Name, Type, MeanValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_union _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:785: in test_window_function_comparison_with_union
    combined = result1.unionByName(result2, allowMissingColumns=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:420: in unionByName
    return self._joins.unionByName(other, allowMissingColumns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/join_service.py:281: in unionByName
    self_materialized = LazyEvaluationEngine.materialize(self._df)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________ TestIssue329LogFloatConstant.test_log_with_int_base ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:75: in test_log_with_int_base
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
___ TestIssue331ArrayContainsJoin.test_array_contains_join_with_aggregation ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:632: in test_array_contains_join_with_aggregation
    .agg(F.count("Name").alias("Count"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue292RlikeLookaround.test_rlike_negative_lookahead_multiple_conditions _
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:558: in test_rlike_negative_lookahead_multiple_conditions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_______ TestIssue335WindowOrderByList.test_window_orderby_list_with_join _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:641: in test_window_orderby_list_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue339ColumnSubscript.test_column_subscript_with_comparison _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:368: in test_column_subscript_with_comparison
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
____________ TestIssue367ArrayEmpty.test_array_empty_two_equivalent ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:204: in test_array_empty_two_equivalent
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
____ TestIssue337GroupedDataMean.test_grouped_data_mean_with_nested_select _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:959: in test_grouped_data_mean_with_nested_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'avg(Value)' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_distinct _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:816: in test_window_function_comparison_with_distinct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue327OrderByAscending.test_orderby_mixed_nulls_and_values _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:353: in test_orderby_mixed_nulls_and_values
    assert rows_asc[0]["Value"] == 5
E   assert None == 5
_ TestIssue331ArrayContainsJoin.test_array_contains_join_with_window_functions _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:670: in test_array_contains_join_with_window_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______________ TestIssue329LogFloatConstant.test_log_natural_log _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:101: in test_log_natural_log
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
_____________ TestIssue368FDataFrame.test_f_dataframe_union_reduce _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_368_f_dataframe.py:53: in test_f_dataframe_union_reduce
    assert names == ["Alice", "Bob", "Charlie", "Disco"]
E   AssertionError: assert ['Alice', 'Bob'] == ['Alice', 'Bo...lie', 'Disco']
E     
E     Right contains 2 more items, first extra item: 'Charlie'
E     
E     Full diff:
E       [
E           'Alice',
E           'Bob',
E     -     'Charlie',
E     -     'Disco',
E       ]
__________ TestIssue327OrderByAscending.test_orderby_negative_numbers __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:390: in test_orderby_negative_numbers
    assert rows_asc[1]["Value"] == -5
E   assert 5 == -5
____ TestIssue292RlikeLookaround.test_rlike_lookahead_with_word_boundaries _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:587: in test_rlike_lookahead_with_word_boundaries
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
______ TestIssue335WindowOrderByList.test_window_orderby_list_with_union _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:667: in test_window_orderby_list_with_union
    combined = result1.unionByName(result2, allowMissingColumns=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:420: in unionByName
    return self._joins.unionByName(other, allowMissingColumns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/join_service.py:281: in unionByName
    self_materialized = LazyEvaluationEngine.materialize(self._df)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue337GroupedDataMean.test_grouped_data_mean_with_column_alias_in_groupBy _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_337_grouped_data_mean.py:1011: in test_grouped_data_mean_with_column_alias_in_groupBy
    assert len(rows) == 2
E   assert 1 == 2
E    +  where 1 = len([Row(Person=None, avg(Value)=5.333333333333333)])
______ TestIssue339ColumnSubscript.test_column_subscript_with_arithmetic _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:393: in test_column_subscript_with_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
___________ TestIssue327OrderByAscending.test_orderby_floating_point ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:422: in test_orderby_floating_point
    assert rows_asc[0]["Value"] == 5.1
E   assert 10.5 == 5.1
__________ TestIssue368FDataFrame.test_f_dataframe_union_multiple_dfs __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_368_f_dataframe.py:80: in test_f_dataframe_union_multiple_dfs
    assert len(rows) == 4
E   assert 1 == 4
E    +  where 1 = len([Row(id=1, val=a)])
______ TestIssue331ArrayContainsJoin.test_array_contains_join_with_union _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:704: in test_array_contains_join_with_union
    combined = result1.unionByName(result2, allowMissingColumns=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:420: in unionByName
    return self._joins.unionByName(other, allowMissingColumns)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/join_service.py:281: in unionByName
    self_materialized = LazyEvaluationEngine.materialize(self._df)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_limit _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:842: in test_window_function_comparison_with_limit
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________ TestIssue329LogFloatConstant.test_log_with_different_bases __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:130: in test_log_with_different_bases
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
___________ TestIssue327OrderByAscending.test_orderby_boolean_column ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:447: in test_orderby_boolean_column
    assert rows_asc[0]["Active"] is False
E   assert True is False
__________ TestIssue327OrderByAscending.test_orderby_unicode_strings ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:489: in test_orderby_unicode_strings
    assert values[i] <= values[i + 1]
E   AssertionError: assert '' <= 'caf'
___ TestIssue335WindowOrderByList.test_window_orderby_list_with_select_expr ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:691: in test_window_orderby_list_with_select_expr
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue292RlikeLookaround.test_rlike_lookbehind_with_fixed_width ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:618: in test_rlike_lookbehind_with_fixed_width
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
________ TestIssue339ColumnSubscript.test_column_subscript_single_field ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:42: in test_column_subscript_single_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_________ TestIssue327OrderByAscending.test_orderby_special_characters _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:511: in test_orderby_special_characters
    assert rows_asc[0]["Value"] == "A B"
E   AssertionError: assert 'A-B' == 'A B'
E     
E     - A B
E     + A-B
_____ TestIssue331ArrayContainsJoin.test_array_contains_join_with_distinct _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:737: in test_array_contains_join_with_distinct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'array_contains(IDs, ID)' not found. Available columns: [Name, Dept, ID, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue339ColumnSubscript.test_column_subscript_with_multiple_struct_columns _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:482: in test_column_subscript_with_multiple_struct_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'Struct1'
_________ TestIssue327OrderByAscending.test_orderby_very_long_strings __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:538: in test_orderby_very_long_strings
    assert rows_asc[0]["Value"] == long_string1
E   AssertionError: assert 'CCCCCCCCCCCC...CCCCCCCCCCCCC' == 'AAAAAAAAAAAA...AAAAAAAAAAAAA'
E     
E     - AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
E     + CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_chained_operations _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:871: in test_window_function_comparison_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue329LogFloatConstant.test_log_with_column_base ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:161: in test_log_with_column_base
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
______ TestIssue292RlikeLookaround.test_rlike_lookahead_with_alternation _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:645: in test_rlike_lookahead_with_alternation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_withcolumn_renamed _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:710: in test_window_orderby_list_with_withcolumn_renamed
    result = df.withColumn("Rank", F.row_number().over(w)).withColumnRenamed(
sparkless/dataframe/dataframe.py:321: in withColumnRenamed
    return self._transformations.withColumnRenamed(existing, new)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/transformation_service.py:552: in withColumnRenamed
    materialized = self._df._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue339ColumnSubscript.test_column_subscript_multiple_fields _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:68: in test_column_subscript_multiple_fields
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
______ TestIssue369IsinNegation.test_negation_isin_string_column_int_list ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_369_isin_negation.py:25: in test_negation_isin_string_column_int_list
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
____ TestIssue339ColumnSubscript.test_column_subscript_with_computed_column ____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:507: in test_column_subscript_with_computed_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
______ TestIssue331ArrayContainsJoin.test_array_contains_join_with_limit _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:767: in test_array_contains_join_with_limit
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________ TestIssue327OrderByAscending.test_orderby_chained_operations _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:562: in test_orderby_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'Category' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestIssue339ColumnSubscript.test_column_subscript_in_select __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:98: in test_column_subscript_in_select
    assert alice_row["E1"] == 1
E   assert None == 1
____________ TestIssue329LogFloatConstant.test_log_with_null_values ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:189: in test_log_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_nested_select _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:901: in test_window_function_comparison_with_nested_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue292RlikeLookaround.test_rlike_lookahead_with_capture_groups _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:674: in test_rlike_lookahead_with_capture_groups
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_____ TestIssue335WindowOrderByList.test_window_orderby_list_with_distinct _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:738: in test_window_orderby_list_with_distinct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue327OrderByAscending.test_orderby_multiple_orderby_calls _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:592: in test_orderby_multiple_orderby_calls
    assert rows[0]["Value"] == 20
E   assert 10 == 20
_______________ TestIssue369IsinNegation.test_negation_isin_show _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_369_isin_negation.py:41: in test_negation_isin_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
____ TestIssue339ColumnSubscript.test_column_subscript_deeply_nested_struct ____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:542: in test_column_subscript_deeply_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'Level1'
_____________ TestIssue327OrderByAscending.test_orderby_with_limit _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:615: in test_orderby_with_limit
    assert rows[0]["Value"] == 20
E   assert 10 == 20
_ TestIssue331ArrayContainsJoin.test_array_contains_join_multiple_conditions_same_df _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:794: in test_array_contains_join_multiple_conditions_same_df
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________ TestIssue339ColumnSubscript.test_column_subscript_in_filter __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:115: in test_column_subscript_in_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_____________ TestIssue329LogFloatConstant.test_log_in_with_column _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:217: in test_log_in_with_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_case_when_chain _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:928: in test_window_function_comparison_with_case_when_chain
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue292RlikeLookaround.test_rlike_multiple_negative_lookaheads ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:704: in test_rlike_multiple_negative_lookaheads
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_orderby_dataframe _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:761: in test_window_orderby_list_with_orderby_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue327OrderByAscending.test_orderby_three_columns ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:680: in test_orderby_three_columns
    assert rows[0]["A"] == 1 and rows[0]["B"] == 1 and rows[0]["C"] == 1
E   assert (1 == 1 and 1 == 1 and 3 == 1)
_________ TestIssue339ColumnSubscript.test_column_subscript_with_union _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:573: in test_column_subscript_with_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
__ TestIssue369IsinNegation.test_isin_without_negation_string_column_int_list __
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_369_isin_negation.py:57: in test_isin_without_negation_string_column_int_list
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
__ TestIssue331ArrayContainsJoin.test_array_contains_join_with_nested_select ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:830: in test_array_contains_join_with_nested_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'array_contains(IDs, ID)' not found. Available columns: [Name, Department, MatchedID]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestIssue327OrderByAscending.test_orderby_duplicate_values __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_327_orderby_ascending.py:705: in test_orderby_duplicate_values
    assert rows[0]["Value"] == 5
E   assert 10 == 5
____ TestIssue339ColumnSubscript.test_column_subscript_equals_dot_notation _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:137: in test_column_subscript_equals_dot_notation
    rows_subscript = result_subscript.collect()
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_______________ TestIssue329LogFloatConstant.test_log_edge_cases _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_329_log_float_constant.py:246: in test_log_edge_cases
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: log
______ TestIssue335WindowOrderByList.test_window_orderby_list_with_limit _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:783: in test_window_orderby_list_with_limit
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________ TestIssue330StructFieldAlias.test_struct_field_with_alias ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:29: in test_struct_field_with_alias
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_coalesce _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:958: in test_window_function_comparison_with_coalesce
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue292RlikeLookaround.test_rlike_lookbehind_with_character_classes ___
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:737: in test_rlike_lookbehind_with_character_classes
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_______ TestIssue339ColumnSubscript.test_column_subscript_with_distinct ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:597: in test_column_subscript_with_distinct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'StructVal' not found. Available columns: [Name, Extract-E1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__ TestIssue330StructFieldAlias.test_struct_field_with_alias_multiple_fields ___
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:52: in test_struct_field_with_alias_multiple_fields
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
____ TestIssue331ArrayContainsJoin.test_array_contains_join_with_case_when _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:863: in test_array_contains_join_with_case_when
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________ TestIssue369IsinNegation.test_negation_isin_string_to_string _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_369_isin_negation.py:73: in test_negation_isin_string_to_string
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
_____ TestIssue339ColumnSubscript.test_column_subscript_with_nested_struct _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:167: in test_column_subscript_with_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'Outer'
_________________ TestIssue328SplitLimit.test_split_with_limit _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_328_split_limit.py:45: in test_split_with_limit
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: split
______ TestIssue335WindowOrderByList.test_window_orderby_list_with_filter ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:805: in test_window_orderby_list_with_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue330StructFieldAlias.test_struct_field_with_alias_in_withcolumn ____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:73: in test_struct_field_with_alias_in_withcolumn
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructValue'
__ TestIssue292RlikeLookaround.test_rlike_lookahead_with_non_capturing_groups __
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:764: in test_rlike_lookahead_with_non_capturing_groups
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_cast _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:985: in test_window_function_comparison_with_cast
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue339ColumnSubscript.test_column_subscript_with_cast __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:623: in test_column_subscript_with_cast
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_ TestIssue330StructFieldAlias.test_struct_field_with_alias_and_other_columns __
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:101: in test_struct_field_with_alias_and_other_columns
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
_____ TestIssue331ArrayContainsJoin.test_array_contains_join_with_coalesce _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:896: in test_array_contains_join_with_coalesce
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_______ TestIssue370FilterInString.test_filter_values_in_string_literal ________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_370_filter_in_string.py:21: in test_filter_values_in_string_literal
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
____ TestIssue330StructFieldAlias.test_struct_field_with_alias_null_values _____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:121: in test_struct_field_with_alias_null_values
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
_________ TestIssue339ColumnSubscript.test_column_subscript_with_alias _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:189: in test_column_subscript_with_alias
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
___________ TestIssue392WindowSumPeers.test_sum_single_row_partition ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:129: in test_sum_single_row_partition
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_aggregation_functions _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:831: in test_window_orderby_list_with_aggregation_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue330StructFieldAlias.test_struct_field_with_alias_nested_struct ____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:155: in test_struct_field_with_alias_nested_struct
    assert rows[0]["E2-Extract"] == "A"
E   AssertionError: assert None == 'A'
____ TestIssue339ColumnSubscript.test_column_subscript_with_window_function ____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:656: in test_column_subscript_with_window_function
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_avg _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1012: in test_window_function_comparison_with_avg
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue292RlikeLookaround.test_rlike_complex_nested_lookaround _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:793: in test_rlike_complex_nested_lookaround
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_______ TestIssue331ArrayContainsJoin.test_array_contains_join_with_cast _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_331_array_contains_join.py:926: in test_array_contains_join_with_cast
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______ TestIssue339ColumnSubscript.test_column_subscript_with_null_struct ______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:211: in test_column_subscript_with_null_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_______ TestIssue370FilterInString.test_filter_values_in_numeric_literal _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_370_filter_in_string.py:34: in test_filter_values_in_numeric_literal
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
___________ TestIssue392WindowSumPeers.test_sum_three_rows_all_peers ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:146: in test_sum_three_rows_all_peers
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue330StructFieldAlias.test_struct_field_without_alias_still_works ___
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:172: in test_struct_field_without_alias_still_works
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'StructValue' not found. Available columns: [StructValue.E1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__ TestIssue335WindowOrderByList.test_window_orderby_list_with_count_distinct __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:854: in test_window_orderby_list_with_count_distinct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue330StructFieldAlias.test_struct_field_with_alias_chained_operations _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:200: in test_struct_field_with_alias_chained_operations
    assert len(rows) == 1
E   assert 0 == 1
E    +  where 0 = len([])
_ TestIssue339ColumnSubscript.test_column_subscript_with_multiple_aggregations _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:681: in test_column_subscript_with_multiple_aggregations
    .agg(
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
________ TestIssue292RlikeLookaround.test_rlike_lookahead_with_unicode _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:820: in test_rlike_lookahead_with_unicode
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_max _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1040: in test_window_function_comparison_with_max
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue339ColumnSubscript.test_column_subscript_with_null_field _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:234: in test_column_subscript_with_null_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
____________ TestIssue370FilterInString.test_filter_in_string_show _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_370_filter_in_string.py:47: in test_filter_in_string_show
    df1.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
___________ TestIssue392WindowSumPeers.test_sum_with_nulls_excluded ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:164: in test_sum_with_nulls_excluded
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_stddev_variance __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:880: in test_window_orderby_list_with_stddev_variance
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____ TestIssue330StructFieldAlias.test_struct_field_with_alias_mixed_nulls _____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:307: in test_struct_field_with_alias_mixed_nulls
    assert rows[0]["E1-Extract"] == 1
E   assert None == 1
_______ TestIssue339ColumnSubscript.test_column_subscript_with_coalesce ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:717: in test_column_subscript_with_coalesce
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
______ TestIssue332CastAliasSelect.test_cast_alias_select_with_withcolumn ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_332_cast_alias_select.py:122: in test_cast_alias_select_with_withcolumn
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'Value' not found. Available columns: [Name, ValueDouble]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_min _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1068: in test_window_function_comparison_with_min
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue330StructFieldAlias.test_struct_field_with_alias_different_data_types _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:342: in test_struct_field_with_alias_different_data_types
    assert rows[0]["IntField"] == 1
E   assert None == 1
___ TestIssue292RlikeLookaround.test_rlike_lookbehind_multiple_fixed_widths ____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:853: in test_rlike_lookbehind_multiple_fixed_widths
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
________ TestIssue339ColumnSubscript.test_column_subscript_with_orderBy ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:259: in test_column_subscript_with_orderBy
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
___ TestIssue335WindowOrderByList.test_window_orderby_list_with_null_values ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:905: in test_window_orderby_list_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestIssue330StructFieldAlias.test_struct_field_with_alias_case_sensitivity __
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:370: in test_struct_field_with_alias_case_sensitivity
    assert rows[0]["UpperE1"] == 1
E   assert None == 1
_ TestIssue392WindowSumPeers.test_sum_order_by_multiple_cols_subset_of_partition_by _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:182: in test_sum_order_by_multiple_cols_subset_of_partition_by
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue330StructFieldAlias.test_struct_field_with_alias_special_characters _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:398: in test_struct_field_with_alias_special_characters
    assert rows[0]["FieldAlias"] == 2
E   assert None == 2
_______ TestIssue332CastAliasSelect.test_cast_alias_select_with_orderby ________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_332_cast_alias_select.py:204: in test_cast_alias_select_with_orderby
    assert rows[0]["Name"] == "Bob"
E   AssertionError: assert 'Alice' == 'Bob'
E     
E     - Bob
E     + Alice
_ TestIssue339ColumnSubscript.test_column_subscript_with_when_otherwise_nested _
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:749: in test_column_subscript_with_when_otherwise_nested
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
______ TestIssue292RlikeLookaround.test_rlike_lookahead_in_groupby_filter ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:883: in test_rlike_lookahead_in_groupby_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_________ TestIssue370FilterInString.test_filter_in_multiple_literals __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_370_filter_in_string.py:73: in test_filter_in_multiple_literals
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_count _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1096: in test_window_function_comparison_with_count
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue339ColumnSubscript.test_column_subscript_with_groupBy ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:284: in test_column_subscript_with_groupBy
    .agg(F.count("*").alias("count"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_empty_partition __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:927: in test_window_orderby_list_with_empty_partition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue330StructFieldAlias.test_struct_field_with_alias_with_join ______
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:425: in test_struct_field_with_alias_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'ID' not found. Available columns: [Name, E1-Extract]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestIssue392WindowSumPeers.test_sum_no_order_by_partition_total ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:203: in test_sum_no_order_by_partition_total
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue330StructFieldAlias.test_struct_field_with_alias_with_union _____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:455: in test_struct_field_with_alias_with_union
    assert len(rows) == 2
E   assert 1 == 2
E    +  where 1 = len([Row(Name=Alice, E1-Extract=None)])
___ TestIssue339ColumnSubscript.test_column_subscript_with_string_operations ___
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:776: in test_column_subscript_with_string_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_________ TestIssue339ColumnSubscript.test_column_subscript_with_join __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:321: in test_column_subscript_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
__________ TestIssue371CastDecimal.test_with_column_cast_decimal_10_0 __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:32: in test_with_column_cast_decimal_10_0
    df1.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'DecimalValue'
__ TestIssue292RlikeLookaround.test_rlike_lookahead_performance_large_dataset __
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:910: in test_rlike_lookahead_performance_large_dataset
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_ntile _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1123: in test_window_function_comparison_with_ntile
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____ TestIssue330StructFieldAlias.test_struct_field_with_alias_with_groupby ____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:489: in test_struct_field_with_alias_with_groupby
    assert totals["A"] == 3  # 1 + 2
    ^^^^^^^^^^^^^^^^^^^^^^^
E   assert 0 == 3
_ TestIssue335WindowOrderByList.test_window_orderby_list_with_single_row_partition _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:948: in test_window_orderby_list_with_single_row_partition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue332CastAliasSelect.test_cast_alias_select_complex_nested_operations _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_332_cast_alias_select.py:389: in test_cast_alias_select_complex_nested_operations
    assert rows[0]["Name"] == "Bob"
E   AssertionError: assert 'Alice' == 'Bob'
E     
E     - Bob
E     + Alice
___ TestIssue393SumStringColumn.test_sum_string_column_partition_by_order_by ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:36: in test_sum_string_column_partition_by_order_by
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue339ColumnSubscript.test_column_subscript_with_limit _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:803: in test_column_subscript_with_limit
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_______ TestIssue339ColumnSubscript.test_column_subscript_with_case_when _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:345: in test_column_subscript_with_case_when
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
_____________ TestIssue371CastDecimal.test_cast_decimal_lowercase ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:47: in test_cast_decimal_lowercase
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd'
____ TestIssue335WindowOrderByList.test_window_orderby_list_with_large_list ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_335_window_orderby_list.py:988: in test_window_orderby_list_with_large_list
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_cume_dist _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1151: in test_window_function_comparison_with_cume_dist
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue330StructFieldAlias.test_struct_field_with_alias_with_window_function _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:518: in test_struct_field_with_alias_with_window_function
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue292RlikeLookaround.test_rlike_lookahead_with_special_characters ___
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:938: in test_rlike_lookahead_with_special_characters
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_________ TestIssue332CastAliasSelect.test_cast_alias_select_with_join _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_332_cast_alias_select.py:420: in test_cast_alias_select_with_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'ID' not found. Available columns: [Name, AvgValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestIssue393SumStringColumn.test_avg_string_column ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:54: in test_avg_string_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue339ColumnSubscript.test_column_subscript_chained_operations _____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_339_column_subscript.py:831: in test_column_subscript_chained_operations
    .agg(F.avg("Sum").alias("AvgSum"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
________ TestIssue332CastAliasSelect.test_cast_alias_select_with_union _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_332_cast_alias_select.py:461: in test_cast_alias_select_with_union
    assert len(rows) == 2
E   assert 1 == 2
E    +  where 1 = len([Row(Name=Alice, AvgValue=1.5)])
__ TestIssue330StructFieldAlias.test_struct_field_with_alias_multiple_selects __
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_330_struct_field_alias.py:542: in test_struct_field_with_alias_multiple_selects
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'E1-Extract' not found. Available columns: [FinalE1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_first_value _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1179: in test_window_function_comparison_with_first_value
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________ TestIssue371CastDecimal.test_cast_decimal_in_select ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:57: in test_cast_decimal_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'a' not found. Available columns: [dec]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestIssue292RlikeLookaround.test_rlike_lookahead_case_sensitivity _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:968: in test_rlike_lookahead_case_sensitivity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
___ TestIssue336WindowFunctionComparison.test_window_function_gt_comparison ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:32: in test_window_function_gt_comparison
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue332CastAliasSelect.test_cast_alias_select_with_window_function ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_332_cast_alias_select.py:491: in test_cast_alias_select_with_window_function
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue393SumStringColumn.test_sum_string_column_running_sum ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:70: in test_sum_string_column_running_sum
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue360InputFileName.test_input_file_name_returns_string_column _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:27: in test_input_file_name_returns_string_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
________________ TestIssue358GetField.test_getfield_array_index ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_358_getfield.py:39: in test_getfield_array_index
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______________ TestIssue396ToDateCast.test_to_date_cast_with_show ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:65: in test_to_date_cast_with_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_last_value _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1207: in test_window_function_comparison_with_last_value
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestIssue292RlikeLookaround.test_rlike_lookbehind_with_escaped_characters ___
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:996: in test_rlike_lookbehind_with_escaped_characters
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_____ TestIssue371CastDecimal.test_cast_decimal_different_precision_scale ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:70: in test_cast_decimal_different_precision_scale
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd5_2'
___ TestIssue336WindowFunctionComparison.test_window_function_lt_comparison ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:56: in test_window_function_lt_comparison
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______________ TestIssue396ToDateCast.test_to_date_cast_in_select ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:83: in test_to_date_cast_in_select
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_________ TestIssue393SumStringColumn.test_sum_string_column_with_show _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:88: in test_sum_string_column_with_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue358GetField.test_getfield_equivalent_to_getitem ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_358_getfield.py:58: in test_getfield_equivalent_to_getitem
    rows_gf = df_getfield.collect()
              ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____ TestIssue360InputFileName.test_input_file_name_exact_issue_scenario ______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:46: in test_input_file_name_exact_issue_scenario
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
________ TestIssue332CastAliasSelect.test_cast_alias_select_with_limit _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_332_cast_alias_select.py:581: in test_cast_alias_select_with_limit
    assert rows[0]["Name"] == "Charlie"
E   AssertionError: assert 'Alice' == 'Charlie'
E     
E     - Charlie
E     + Alice
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_countDistinct _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1236: in test_window_function_comparison_with_countDistinct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue292RlikeLookaround.test_rlike_lookahead_with_quantified_groups ____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:1023: in test_rlike_lookahead_with_quantified_groups
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
____________ TestIssue371CastDecimal.test_cast_decimal_after_filter ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:88: in test_cast_decimal_after_filter
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'dec'
___ TestIssue336WindowFunctionComparison.test_window_function_ge_comparison ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:82: in test_window_function_ge_comparison
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue358GetField.test_getfield_struct_field_by_name ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_358_getfield.py:102: in test_getfield_struct_field_by_name
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_____________ TestIssue396ToDateCast.test_to_date_cast_with_nulls ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:102: in test_to_date_cast_with_nulls
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
________ TestIssue393SumStringColumn.test_sum_string_column_with_nulls _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:106: in test_sum_string_column_with_nulls
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________ TestIssue360InputFileName.test_input_file_name_select_only __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:59: in test_input_file_name_select_only
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_string_values _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1264: in test_window_function_comparison_with_string_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestIssue292RlikeLookaround.test_rlike_negative_lookahead_with_boundaries ___
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_292_rlike_lookaround.py:1050: in test_rlike_negative_lookahead_with_boundaries
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
_ TestIssue413UnionCreateDataFrame.test_union_createDataFrame_tuple_column_names _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:35: in test_union_createDataFrame_tuple_column_names
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(id=1, age=25, name=alice), Row(id=2, age=30, name=bob)])
_____________ TestIssue371CastDecimal.test_cast_decimal_with_nulls _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:100: in test_cast_decimal_with_nulls
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'dec'
___ TestIssue336WindowFunctionComparison.test_window_function_le_comparison ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:108: in test_window_function_le_comparison
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue358GetField.test_getfield_nested_array_access ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_358_getfield.py:125: in test_getfield_nested_array_access
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: array element type 'array<long>' not supported
__________ TestIssue396ToDateCast.test_to_date_cast_different_format ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:117: in test_to_date_cast_different_format
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_ TestIssue393SumStringColumn.test_sum_string_column_no_partition_running_sum __
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:124: in test_sum_string_column_no_partition_running_sum
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue360InputFileNameRobust.test_input_file_name_empty_dataframe _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:78: in test_input_file_name_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_float_values _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1295: in test_window_function_comparison_with_float_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue293ExplodeWithColumn.test_explode_in_withcolumn ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:42: in test_explode_in_withcolumn
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______________ TestIssue371CastDecimal.test_cast_float_to_decimal ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:113: in test_cast_float_to_decimal
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'dec'
___ TestIssue336WindowFunctionComparison.test_window_function_eq_comparison ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:134: in test_window_function_eq_comparison
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______________ TestIssue358GetField.test_getfield_negative_index _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_358_getfield.py:148: in test_getfield_negative_index
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue413UnionCreateDataFrame.test_union_different_column_order_by_position _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:58: in test_union_different_column_order_by_position
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
_____________ TestIssue396ToDateCast.test_to_date_cast_then_filter _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:135: in test_to_date_cast_then_filter
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
____ TestIssue393SumStringColumn.test_avg_string_column_multiple_partitions ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:143: in test_avg_string_column_multiple_partitions
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue360InputFileNameRobust.test_input_file_name_single_row ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:88: in test_input_file_name_single_row
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
_____________ TestIssue293ExplodeWithColumn.test_explode_in_select _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:89: in test_explode_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______________ TestIssue358GetField.test_getfield_chained_access _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_358_getfield.py:170: in test_getfield_chained_access
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: array element type 'array<long>' not supported
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_complex_filter _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1350: in test_window_function_comparison_with_complex_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue336WindowFunctionComparison.test_window_function_ne_comparison ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:160: in test_window_function_ne_comparison
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue371CastDecimal.test_cast_decimal_show_then_collect __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:127: in test_cast_decimal_show_then_collect
    df1.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd'
_____ TestIssue413UnionCreateDataFrame.test_union_chained_three_dataframes _____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:73: in test_union_chained_three_dataframes
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "a" and "col1"
_________ TestIssue396ToDateCast.test_to_date_cast_integer_type_column _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:154: in test_to_date_cast_integer_type_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_______ TestIssue393SumStringColumn.test_sum_string_column_decimal_like ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:163: in test_sum_string_column_decimal_like
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue360InputFileNameRobust.test_input_file_name_after_filter _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:100: in test_input_file_name_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
___________ TestIssue293ExplodeWithColumn.test_explode_with_integers ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:120: in test_explode_with_integers
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_multiple_partitions _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1377: in test_window_function_comparison_with_multiple_partitions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_filter _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:185: in test_window_function_comparison_with_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue371CastDecimal.test_cast_decimal_single_digit_precision _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_371_cast_decimal.py:141: in test_cast_decimal_single_digit_precision
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd'
_______ TestIssue413UnionCreateDataFrame.test_union_empty_dataframe_left _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:91: in test_union_empty_dataframe_left
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
______ TestIssue360InputFileNameRobust.test_input_file_name_after_select _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:111: in test_input_file_name_after_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
___ TestIssue393SumStringColumn.test_sum_string_column_single_row_partition ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:174: in test_sum_string_column_single_row_partition
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue293ExplodeWithColumn.test_explode_with_empty_arrays _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:152: in test_explode_with_empty_arrays
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_no_partition _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1405: in test_window_function_comparison_with_no_partition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_multiple_conditions _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:211: in test_window_function_comparison_with_multiple_conditions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestIssue413UnionCreateDataFrame.test_union_empty_dataframe_right _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:108: in test_union_empty_dataframe_right
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "a"
_______ TestIssue393SumStringColumn.test_sum_string_column_select_after ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_393_sum_string_column.py:193: in test_sum_string_column_select_after
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue293ExplodeWithColumn.test_explode_with_null_arrays __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_293_explode_withcolumn.py:181: in test_explode_with_null_arrays
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
____ TestIssue360InputFileNameRobust.test_input_file_name_preserves_schema _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:124: in test_input_file_name_preserves_schema
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_rowsBetween _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1442: in test_window_function_comparison_with_rowsBetween
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_rank _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:237: in test_window_function_comparison_with_rank
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue413UnionCreateDataFrame.test_union_both_empty ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:130: in test_union_both_empty
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
______ TestIssue439ArrayDistinct.test_array_distinct_with_nulls_in_array _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:156: in test_array_distinct_with_nulls_in_array
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____________ TestIssue394LikeInExpr.test_filter_like_exact_issue ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:24: in test_filter_like_exact_issue
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
________ TestIssue360InputFileNameRobust.test_input_file_name_with_show ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:134: in test_input_file_name_with_show
    result.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_rangeBetween _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1475: in test_window_function_comparison_with_rangeBetween
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_dense_rank _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:265: in test_window_function_comparison_with_dense_rank
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue413UnionCreateDataFrame.test_union_with_nulls ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:146: in test_union_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
____ TestIssue439ArrayDistinct.test_array_distinct_null_array_returns_null _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:178: in test_array_distinct_null_array_returns_null
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array_distinct
___ TestIssue360InputFileNameRobust.test_input_file_name_all_rows_same_type ____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:143: in test_input_file_name_all_rows_same_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
___________ TestIssue394LikeInExpr.test_filter_not_like_exact_issue ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:37: in test_filter_not_like_exact_issue
    rows = df2.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_negative_values _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1503: in test_window_function_comparison_with_negative_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_percent_rank _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:304: in test_window_function_comparison_with_percent_rank
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________ TestIssue413UnionCreateDataFrame.test_unionAll_alias _____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:165: in test_unionAll_alias
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
__ TestIssue439ArrayDistinct.test_array_distinct_float_arrays_preserves_type ___
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:187: in test_array_distinct_float_arrays_preserves_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
____ TestIssue360InputFileNameRobust.test_input_file_name_multiple_columns _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:159: in test_input_file_name_multiple_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
______________ TestIssue394LikeInExpr.test_filter_like_with_show _______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:50: in test_filter_like_with_show
    df1.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_zero_values _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1531: in test_window_function_comparison_with_zero_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_lag _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:332: in test_window_function_comparison_with_lag
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________ TestIssue413UnionCreateDataFrame.test_union_single_column ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:176: in test_union_single_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "other"
________ TestIssue398WithFieldWindow.test_withfield_window_exact_issue _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:49: in test_withfield_window_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
__________ TestIssue360InputFileNameRobust.test_input_file_name_alias __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_360_input_file_name.py:170: in test_input_file_name_alias
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
_________ TestIssue439ArrayDistinct.test_array_distinct_boolean_arrays _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:203: in test_array_distinct_boolean_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_lead _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:364: in test_window_function_comparison_with_lead
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue394LikeInExpr.test_filter_like_prefix_pattern ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:65: in test_filter_like_prefix_pattern
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_duplicate_scores _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1559: in test_window_function_comparison_with_duplicate_scores
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue413UnionCreateDataFrame.test_union_many_columns_different_names ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:188: in test_union_many_columns_different_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "c1" and "a"
_______________ TestIssue373RoundString.test_round_string_column _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:39: in test_round_string_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_sum _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:396: in test_window_function_comparison_with_sum
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue394LikeInExpr.test_filter_like_underscore_wildcard __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:79: in test_filter_like_underscore_wildcard
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
_______ TestIssue439ArrayDistinct.test_array_distinct_all_duplicates_int _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:217: in test_array_distinct_all_duplicates_int
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_______ TestIssue398WithFieldWindow.test_withfield_window_select_struct ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:74: in test_withfield_window_select_struct
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_all_null_partition _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1602: in test_window_function_comparison_with_all_null_partition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue413UnionCreateDataFrame.test_union_then_select ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:200: in test_union_then_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: field not found: id
___________ TestIssue373RoundString.test_round_string_with_decimals ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:58: in test_round_string_with_decimals
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
_____ TestIssue419FilterInOrParseException.test_filter_in_or_empty_result ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:149: in test_filter_in_or_empty_result
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_mixed_types _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1629: in test_window_function_comparison_with_mixed_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____ TestIssue439ArrayDistinct.test_array_distinct_all_duplicates_string ______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:230: in test_array_distinct_all_duplicates_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
__________ TestIssue394LikeInExpr.test_filter_not_like_multiple_rows ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:93: in test_filter_not_like_multiple_rows
    rows = df2.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
____________ TestIssue398WithFieldWindow.test_withfield_row_number _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:97: in test_withfield_row_number
    rows = df.select("id", F.col("s.rn")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
__________ TestIssue413UnionCreateDataFrame.test_union_then_order_by ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:211: in test_union_then_order_by
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
__________ TestIssue373RoundString.test_round_string_negative_numbers __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:75: in test_round_string_negative_numbers
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
____________________ test_alias_cast_column_with_underscore ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:154: in test_alias_cast_column_with_underscore
    assert rows[0]["mc_int"] == 42
E   assert None == 42
___ TestIssue419FilterInOrParseException.test_filter_in_multiple_strings_or ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:162: in test_filter_in_multiple_strings_or
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_desc_ordering _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1656: in test_window_function_comparison_with_desc_ordering
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______________ TestIssue394LikeInExpr.test_expr_like_standalone _______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:109: in test_expr_like_standalone
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
__________ TestIssue439ArrayDistinct.test_array_distinct_zero_values ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:243: in test_array_distinct_zero_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
________ TestIssue373RoundString.test_round_string_scientific_notation _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:92: in test_round_string_scientific_notation
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
___________ TestIssue413UnionCreateDataFrame.test_union_then_filter ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:222: in test_union_then_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "a"
________________ TestIssue398WithFieldWindow.test_withfield_sum ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:122: in test_withfield_sum
    rows = df.select("g", F.col("s.total")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
______________________ test_alias_cast_then_select_subset ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:168: in test_alias_cast_then_select_subset
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'B' not found. Available columns: [A, C]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestIssue419FilterInOrParseException.test_filter_in_or_with_show _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:176: in test_filter_in_or_with_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_ TestIssue336WindowFunctionComparison.test_window_function_comparison_with_asc_ordering _
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_336_window_function_comparison.py:1684: in test_window_function_comparison_with_asc_ordering
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ TestIssue394LikeInExpr.test_filter_like_suffix_pattern ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:125: in test_filter_like_suffix_pattern
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
__________________________ test_alias_cast_long_type ___________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:182: in test_alias_cast_long_type
    assert rows[0]["lng"] == 9999999999
E   assert None == 9999999999
_________________________ test_datetime_less_than_date _________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_431_date_datetime_comparison.py:152: in test_datetime_less_than_date
    assert rows[0]["dt"] == datetime.datetime(2023, 6, 15, 10, 0, 0)
E   AssertionError: assert None == datetime.datetime(2023, 6, 15, 10, 0)
E    +  where datetime.datetime(2023, 6, 15, 10, 0) = <class 'datetime.datetime'>(2023, 6, 15, 10, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
______ TestIssue439ArrayDistinct.test_array_distinct_chained_with_filter _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:266: in test_array_distinct_chained_with_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___________ TestIssue366AliasPosexplode.test_posexplode_alias_select ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:68: in test_posexplode_alias_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
__________ TestIssue373RoundString.test_round_string_with_whitespace ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:109: in test_round_string_with_whitespace
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
___________________ test_alias_cast_mixed_with_plain_select ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:199: in test_alias_cast_mixed_with_plain_select
    assert rows[0]["score_int"] == 100
E   assert None == 100
____________________________ test_date_ne_datetime _____________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_431_date_datetime_comparison.py:175: in test_date_ne_datetime
    assert rows[0]["dt"] == datetime.datetime(2024, 1, 1, 12, 0, 0)
E   AssertionError: assert None == datetime.datetime(2024, 1, 1, 12, 0)
E    +  where datetime.datetime(2024, 1, 1, 12, 0) = <class 'datetime.datetime'>(2024, 1, 1, 12, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
________________ TestIssue398WithFieldWindow.test_withfield_avg ________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:139: in test_withfield_avg
    rows = df.select("g", F.col("s.avg_v")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
______________ TestIssue413UnionCreateDataFrame.test_union_count _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_413_union_createDataFrame.py:233: in test_union_count
    assert result.count() == 3
           ^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
_ TestIssue420WhenComparisonWithNone.test_when_comparison_with_none_exact_issue _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_420_when_comparison_with_none.py:31: in test_when_comparison_with_none_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________ TestIssue394LikeInExpr.test_filter_like_and_combined _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:140: in test_filter_like_and_combined
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
__________ TestIssue373RoundString.test_round_string_integer_strings ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:126: in test_round_string_integer_strings
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
________ TestIssue439ArrayDistinct.test_array_distinct_unicode_strings _________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:284: in test_array_distinct_unicode_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______ TestIssue366AliasPosexplode.test_posexplode_alias_two_names_select ______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:87: in test_posexplode_alias_two_names_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_______________ test_concat_literal_cast_string_exact_issue_436 ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:33: in test_concat_literal_cast_string_exact_issue_436
    df.show(truncate=False)
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
_ TestIssue414RowNumberOverDescending.test_row_number_over_partition_order_desc _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:39: in test_row_number_over_partition_order_desc
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestIssue420WhenComparisonWithNone.test_when_comparison_with_none_and_show __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_420_when_comparison_with_none.py:48: in test_when_comparison_with_none_and_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestIssue398WithFieldWindow.test_withfield_window_with_nulls_in_partition ___
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:159: in test_withfield_window_with_nulls_in_partition
    rows = df.select("g", F.col("s.cnt")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
_______ TestIssue373RoundString.test_round_mixed_string_numeric_columns ________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:144: in test_round_mixed_string_numeric_columns
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
_____________ TestIssue394LikeInExpr.test_filter_like_or_combined ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:154: in test_filter_like_or_combined
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
__ TestIssue366AliasPosexplode.test_posexplode_alias_two_names_no_type_error ___
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:113: in test_posexplode_alias_two_names_no_type_error
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
______ TestIssue439ArrayDistinct.test_array_distinct_multiple_rows_mixed _______
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:315: in test_array_distinct_multiple_rows_mixed
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____________________ test_concat_literal_col_cast_string ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:49: in test_concat_literal_col_cast_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
_ TestIssue414RowNumberOverDescending.test_row_number_over_order_desc_no_partition _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:60: in test_row_number_over_order_desc_no_partition
    result = df.select(F.row_number().over(window).alias("rn"), "value").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestIssue421JoinColumnNames.test_join_different_column_names_exact_issue ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:55: in test_join_different_column_names_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
________________ TestIssue373RoundString.test_round_string_zero ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_373_round_string.py:161: in test_round_string_zero
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
______ TestIssue398WithFieldWindow.test_withfield_multiple_window_fields _______
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:180: in test_withfield_multiple_window_fields
    rows = df.select(F.col("s.cnt"), F.col("s.tot")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
_____________ TestIssue394LikeInExpr.test_filter_like_empty_result _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:163: in test_filter_like_empty_result
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
_____________________ test_cast_datetime_to_timestamp_noop _____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:26: in test_cast_datetime_to_timestamp_noop
    assert rows[0]["DateTime"] == datetime.datetime(2023, 1, 1, 12, 0, 0)
E   AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
E    +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
_____________________ test_create_map_list_exact_issue_440 _____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:34: in test_create_map_list_exact_issue_440
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
__ TestIssue366AliasPosexplode.test_posexplode_alias_two_names_single_element __
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:125: in test_posexplode_alias_two_names_single_element
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_____________________ test_concat_all_literals_still_works _____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:59: in test_concat_all_literals_still_works
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
_________________________ test_cast_date_to_date_noop __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:42: in test_cast_date_to_date_noop
    assert rows[0]["Date"] == datetime.date(2024, 1, 1)
E   AssertionError: assert None == datetime.date(2024, 1, 1)
E    +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
E    +    where <class 'datetime.date'> = datetime.date
__ TestIssue421JoinColumnNames.test_join_different_column_names_reverse_order __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:69: in test_join_different_column_names_reverse_order
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
_ TestIssue414RowNumberOverDescending.test_row_number_over_partition_order_asc _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:77: in test_row_number_over_partition_order_asc
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestIssue394LikeInExpr.test_filter_like_multiple_underscores _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:177: in test_filter_like_multiple_underscores
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
_________ TestIssue374JoinAliasedColumns.test_join_aliased_column_refs _________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_374_join_aliased_columns.py:62: in test_join_aliased_column_refs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'sm.brand_id = b.code' not found. Available columns: [brand_uuid, sm.taxonomy_id, sm.confidence]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________________ test_create_map_list_literals_only ______________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:52: in test_create_map_list_literals_only
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
___ TestIssue366AliasPosexplode.test_posexplode_alias_two_names_empty_array ____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:140: in test_posexplode_alias_two_names_empty_array
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_____________________ test_concat_all_columns_still_works ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:69: in test_concat_all_columns_still_works
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
________ TestIssue398WithFieldWindow.test_withfield_window_then_filter _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:205: in test_withfield_window_then_filter
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
__________________ test_cast_string_to_timestamp_still_works ___________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:87: in test_cast_string_to_timestamp_still_works
    assert rows[0]["s"] == datetime.datetime(2024, 1, 15, 10, 30, 0)
E   AssertionError: assert None == datetime.datetime(2024, 1, 15, 10, 30)
E    +  where datetime.datetime(2024, 1, 15, 10, 30) = <class 'datetime.datetime'>(2024, 1, 15, 10, 30, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
__ TestIssue421JoinColumnNames.test_join_different_column_names_left_no_match __
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:84: in test_join_different_column_names_left_no_match
    rows = sorted(df.collect(), key=lambda r: _val(r, "Name") or "")
                  ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
___ TestIssue414RowNumberOverDescending.test_row_number_with_column_pattern ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:94: in test_row_number_with_column_pattern
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue394LikeInExpr.test_expr_not_like_in_with_column ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:192: in test_expr_not_like_in_with_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
_______ TestIssue374JoinAliasedColumns.test_join_multiple_aliased_tables _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_374_join_aliased_columns.py:101: in test_join_multiple_aliased_tables
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'u.dept_id = d.dept_id' not found. Available columns: [u.name, d.dept_name, l.city]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ test_cast_string_to_date_still_works _____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:97: in test_cast_string_to_date_still_works
    assert rows[0]["s"] == datetime.date(2024, 1, 15)
E   AssertionError: assert None == datetime.date(2024, 1, 15)
E    +  where datetime.date(2024, 1, 15) = <class 'datetime.date'>(2024, 1, 15)
E    +    where <class 'datetime.date'> = datetime.date
______ TestIssue366AliasPosexplode.test_posexplode_outer_alias_two_names _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:160: in test_posexplode_outer_alias_two_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode_outer
______________________ test_concat_expression_cast_string ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:87: in test_concat_expression_cast_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
__________________ test_cast_datetime_to_timestamp_with_nulls __________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:116: in test_cast_datetime_to_timestamp_with_nulls
    assert rows[0]["dt"] == datetime.datetime(2023, 1, 1, 12, 0, 0)
E   AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
E    +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
______ TestIssue421JoinColumnNames.test_join_different_column_names_inner ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:101: in test_join_different_column_names_inner
    rows = sorted(df.collect(), key=lambda r: _val(r, "id_l"))
                  ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'id_r' has more than one occurrence
_________________ test_create_map_list_mixed_literals_columns __________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:65: in test_create_map_list_mixed_literals_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
__ TestIssue398WithFieldWindow.test_withfield_chain_three_with_window_middle ___
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_398_withfield_window.py:225: in test_withfield_chain_three_with_window_middle
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type WindowFunction is not JSON serializable
____ TestIssue414RowNumberOverDescending.test_sum_over_partition_order_desc ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:111: in test_sum_over_partition_order_desc
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____ TestIssue374JoinAliasedColumns.test_join_aliased_column_without_prefix ____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_374_join_aliased_columns.py:129: in test_join_aliased_column_without_prefix
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 't1.id = t2.id' not found. Available columns: [id, val, data]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestIssue394LikeInExpr.test_filter_like_with_nulls ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:208: in test_filter_like_with_nulls
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
______________________ test_cast_date_to_date_with_nulls _______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:134: in test_cast_date_to_date_with_nulls
    assert rows[0]["d"] == datetime.date(2024, 1, 1)
E   AssertionError: assert None == datetime.date(2024, 1, 1)
E    +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
E    +    where <class 'datetime.date'> = datetime.date
__________ TestIssue366AliasPosexplode.test_explode_alias_single_name __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:185: in test_explode_alias_single_name
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
______________________ test_concat_cast_string_with_nulls ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:110: in test_concat_cast_string_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
__________ TestIssue374JoinAliasedColumns.test_join_aliased_self_join __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_374_join_aliased_columns.py:159: in test_join_aliased_self_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'e.manager_id = m.id' not found. Available columns: [employee, manager]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestIssue421JoinColumnNames.test_join_different_column_names_right ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:112: in test_join_different_column_names_right
    rows = sorted(df.collect(), key=lambda r: _val(r, "b") or 0)
                  ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'b' has more than one occurrence
___ TestIssue406AggregateCastDecimalDrop.test_groupby_agg_cast_decimal_drop ____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_406_aggregate_cast_decimal_drop.py:43: in test_groupby_agg_cast_decimal_drop
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'Name' not found. Available columns: [CAST(sum(Value) AS DECIMALTYPE(38, 6))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ test_cast_date_to_timestamp_midnight _____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:146: in test_cast_date_to_timestamp_midnight
    assert rows[0]["ts"] == datetime.datetime(2024, 3, 15, 0, 0, 0)
E   AssertionError: assert None == datetime.datetime(2024, 3, 15, 0, 0)
E    +  where datetime.datetime(2024, 3, 15, 0, 0) = <class 'datetime.datetime'>(2024, 3, 15, 0, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
____ TestIssue414RowNumberOverDescending.test_lag_over_partition_order_desc ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:131: in test_lag_over_partition_order_desc
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestIssue394LikeInExpr.test_filter_like_middle_wildcard ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_394_like_in_expr.py:223: in test_filter_like_middle_wildcard
    rows = df1.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: like
________________ test_create_map_list_map_lookup_key_not_found _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:83: in test_create_map_list_map_lookup_key_not_found
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
___________ TestIssue366AliasPosexplode.test_posexplode_empty_array ____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:202: in test_posexplode_empty_array
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
__________________ test_cast_datetime_to_date_truncates_time ___________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:156: in test_cast_datetime_to_date_truncates_time
    assert rows[0]["d"] == datetime.date(2024, 5, 10)
E   AssertionError: assert None == datetime.date(2024, 5, 10)
E    +  where datetime.date(2024, 5, 10) = <class 'datetime.date'>(2024, 5, 10)
E    +    where <class 'datetime.date'> = datetime.date
____________________ test_concat_multiple_cast_expressions _____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:132: in test_concat_multiple_cast_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
___ TestIssue374JoinAliasedColumns.test_join_complex_condition_with_aliases ____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_374_join_aliased_columns.py:197: in test_join_complex_condition_with_aliases
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column '(o.customer_id = c.customer_id & (o.amount > 30))' not found. Available columns: [o.order_id, c.name, o.amount]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue406AggregateCastDecimalDrop.test_agg_cast_decimal_drop_different_precision_scale _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_406_aggregate_cast_decimal_drop.py:65: in test_agg_cast_decimal_drop_different_precision_scale
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'k' not found. Available columns: [CAST(sum(v) AS DECIMALTYPE(10, 2)), CAST(count(v) AS DECIMALTYPE(5, 0))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______ TestIssue421JoinColumnNames.test_join_different_column_names_outer ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:133: in test_join_different_column_names_outer
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'right_id' has more than one occurrence
___ TestIssue414RowNumberOverDescending.test_first_over_partition_order_desc ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:150: in test_first_over_partition_order_desc
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue395FilterAndStringExpr.test_filter_and_string_equality_exact_issue __
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:22: in test_filter_and_string_equality_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
________________________ test_create_map_list_in_select ________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:97: in test_create_map_list_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
__________ TestIssue366AliasPosexplode.test_posexplode_nested_arrays ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:221: in test_posexplode_nested_arrays
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
______ TestIssue392WindowSumPeers.test_sum_order_by_same_as_partition_by _______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:41: in test_sum_order_by_same_as_partition_by
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________________ test_concat_abs_cast_string __________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:144: in test_concat_abs_cast_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
___________________ test_cast_date_only_string_to_timestamp ____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:164: in test_cast_date_only_string_to_timestamp
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: conversion from `str` to `datetime[s]` failed in column 's' for 1 out of 1 values: ["2024-01-15"]
E   
E   You might want to try:
E   - setting `strict=False` to set values that cannot be converted to `null`
E   - using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string
__ TestIssue406AggregateCastDecimalDrop.test_agg_cast_decimal_drop_with_nulls __
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_406_aggregate_cast_decimal_drop.py:92: in test_agg_cast_decimal_drop_with_nulls
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'name' not found. Available columns: [CAST(sum(val) AS DECIMALTYPE(38, 2))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__ TestIssue395FilterAndStringExpr.test_filter_and_string_equality_with_show ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:35: in test_filter_and_string_equality_with_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
________ TestIssue414RowNumberOverDescending.test_mixed_order_asc_desc _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:168: in test_mixed_order_asc_desc
    result = df.select(F.row_number().over(w).alias("rn"), "grp", "val").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____ TestIssue421JoinColumnNames.test_join_different_column_names_with_show ____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:157: in test_join_different_column_names_with_show
    df.show()  # No exception
    ^^^^^^^^^
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
_______________________ test_create_map_list_then_filter _______________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:111: in test_create_map_list_then_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_______ TestIssue366AliasPosexplode.test_posexplode_outer_null_handling ________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_366_alias_posexplode.py:239: in test_posexplode_outer_null_handling
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode_outer
__________________________ test_cast_select_with_cast __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:181: in test_cast_select_with_cast
    assert rows[0]["DateTime"] == datetime.datetime(2023, 1, 1, 12, 0, 0)
E   AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
E    +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
________________________ test_concat_length_cast_string ________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:158: in test_concat_length_cast_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
_____ TestIssue392WindowSumPeers.test_sum_order_by_subset_of_partition_by ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:61: in test_sum_order_by_subset_of_partition_by
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue406AggregateCastDecimalDrop.test_avg_cast_decimal_drop ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_406_aggregate_cast_decimal_drop.py:115: in test_avg_cast_decimal_drop
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'g' not found. Available columns: [CAST(avg(x) AS DECIMALTYPE(10, 2))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_ TestIssue395FilterAndStringExpr.test_filter_and_is_null_workaround_still_works _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:48: in test_filter_and_is_null_workaround_still_works
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
______ TestIssue414RowNumberOverDescending.test_single_row_per_partition _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:189: in test_single_row_per_partition
    result = df.select(F.row_number().over(w).alias("rn"), "id", "value").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestIssue367ArrayEmpty.test_array_no_args_returns_empty_array _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:22: in test_array_no_args_returns_empty_array
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___ TestIssue421JoinColumnNames.test_join_different_column_names_with_select ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:173: in test_join_different_column_names_with_select
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'Key = Name' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________________ test_create_map_list_with_null_value_in_map __________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:130: in test_create_map_list_with_null_value_in_map
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_______________________ test_cast_with_datatype_objects ________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:220: in test_cast_with_datatype_objects
    assert rows[0]["dt"] == datetime.datetime(2023, 1, 1, 12, 0, 0)
E   AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
E    +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
___________________________ test_concat_filter_after ___________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:182: in test_concat_filter_after
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
_ TestIssue392WindowSumPeers.test_sum_order_by_differs_from_partition_running_sum _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:82: in test_sum_order_by_differs_from_partition_running_sum
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______________________________ test_cast_leap_day ______________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_432_cast_datetime_date_noop.py:237: in test_cast_leap_day
    assert rows[0]["d"] == datetime.date(2024, 2, 29)
E   AssertionError: assert None == datetime.date(2024, 2, 29)
E    +  where datetime.date(2024, 2, 29) = <class 'datetime.date'>(2024, 2, 29)
E    +    where <class 'datetime.date'> = datetime.date
_____ TestIssue406AggregateCastDecimalDrop.test_min_max_cast_decimal_drop ______
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_406_aggregate_cast_decimal_drop.py:136: in test_min_max_cast_decimal_drop
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'k' not found. Available columns: [CAST(min(v) AS DECIMALTYPE(5, 0)), CAST(max(v) AS DECIMALTYPE(5, 0))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________ TestIssue421JoinColumnNames.test_join_dot_notation_still_works ________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:188: in test_join_dot_notation_still_works
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
____ TestIssue414RowNumberOverDescending.test_avg_over_partition_order_desc ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_414_row_number_over_descending.py:204: in test_avg_over_partition_order_desc
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______ TestIssue367ArrayEmpty.test_array_empty_list_returns_empty_array _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:34: in test_array_empty_list_returns_empty_array
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
____________________ test_create_map_list_numeric_like_keys ____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:144: in test_create_map_list_numeric_like_keys
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
________________________ test_concat_float_cast_string _________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:194: in test_concat_float_cast_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
____________________ test_orderby_with_list_of_column_names ____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:21: in test_orderby_with_list_of_column_names
    assert result[0]["a"] == 1 and result[0]["b"] == 1 and result[0]["c"] == 4
E   assert (1 == 1 and 2 == 1)
_ TestIssue421JoinColumnNames.test_join_same_column_name_string_key_still_works _
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_421_join_column_names.py:200: in test_join_same_column_name_string_key_still_works
    assert len(rows) == 1
E   assert 0 == 1
E    +  where 0 = len([])
______ TestIssue395FilterAndStringExpr.test_filter_and_string_and_is_null ______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:74: in test_filter_and_string_and_is_null
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
_____ TestIssue392WindowSumPeers.test_avg_order_by_subset_of_partition_by ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:101: in test_avg_order_by_subset_of_partition_by
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestIssue406AggregateCastDecimalDrop.test_agg_cast_decimal_drop_then_show_and_collect _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_406_aggregate_cast_decimal_drop.py:157: in test_agg_cast_decimal_drop_then_show_and_collect
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'id' not found. Available columns: [CAST(sum(amt) AS DECIMALTYPE(38, 2))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________________ test_filter_regexp_exact_issue_433 ______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_433_regexp_in_expr.py:24: in test_filter_regexp_exact_issue_433
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
_____________________ test_orderby_with_single_column_list _____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:34: in test_orderby_with_single_column_list
    assert result[0]["a"] == 1
E   assert 2 == 1
_______________________ test_create_map_list_single_pair _______________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:156: in test_create_map_list_single_pair
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
_________________ TestIssue367ArrayEmpty.test_array_empty_show _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:46: in test_array_empty_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
______ TestIssue422FillnaFloat.test_fillna_float_subset_calculated_column ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_422_fillna_float.py:39: in test_fillna_float_subset_calculated_column
    df = df.fillna(0.0, subset=["V3"])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:674: in fillna
    return self._misc.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/misc_service.py:224: in fillna
    new_row = row.copy()
              ^^^^^^^^
sparkless/spark_types.py:1000: in __getattr__
    raise AttributeError(
E   AttributeError: 'Row' object has no attribute 'copy'
______________________ test_concat_with_column_alias_cast ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_436_concat_cast_string.py:213: in test_concat_with_column_alias_cast
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
_________________________ test_orderby_desc_with_list __________________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:48: in test_orderby_desc_with_list
    assert result[0]["a"] == 2 and result[0]["b"] == 0
E   assert (1 == 2)
______ TestIssue392WindowSumPeers.test_sum_order_by_col_desc_still_subset ______
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_392_window_sum_peers.py:118: in test_sum_order_by_col_desc_still_subset
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______________________ test_filter_rlike_same_as_regexp _______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_433_regexp_in_expr.py:42: in test_filter_rlike_same_as_regexp
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
_ TestIssue406AggregateCastDecimalDrop.test_single_group_agg_cast_decimal_drop _
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_406_aggregate_cast_decimal_drop.py:174: in test_single_group_agg_cast_decimal_drop
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'x' not found. Available columns: [CAST(sum(y) AS DECIMALTYPE(10, 0))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_________ TestIssue395FilterAndStringExpr.test_filter_or_with_is_null __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:102: in test_filter_or_with_is_null
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_null
_________________________ test_orderby_with_df_columns _________________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:65: in test_orderby_with_df_columns
    assert result[0]["dept"] == "HR"
E   AssertionError: assert 'IT' == 'HR'
E     
E     - HR
E     + IT
______________ TestIssue367ArrayEmpty.test_array_empty_in_select _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:59: in test_array_empty_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
________________________ test_create_map_list_six_pairs ________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_440_create_map_list.py:177: in test_create_map_list_six_pairs
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_______________________ test_orderby_with_string_columns _______________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:84: in test_orderby_with_string_columns
    assert result[0]["dept"] == "A" and result[0]["name"] == "Alice"
E   AssertionError: assert ('Z' == 'A'
E     
E     - A
E     + Z)
_________________________ test_expr_regexp_with_column _________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_433_regexp_in_expr.py:59: in test_expr_regexp_with_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
__________ TestIssue407StddevWindow.test_stddev_over_window_partition __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_407_stddev_window.py:31: in test_stddev_over_window_partition
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________________ test_distinct_after_select_with_array _____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_448_drop_duplicates_list_column.py:236: in test_distinct_after_select_with_array
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_______________________ test_orderby_with_three_columns ________________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:102: in test_orderby_with_three_columns
    assert (result[0]["a"], result[0]["b"], result[0]["c"]) == (1, 1, 1)
E   assert (3, 2, 1) == (1, 1, 1)
E     
E     At index 0 diff: 3 != 1
E     
E     Full diff:
E       (
E     -     1,
E     ?     ^
E     +     3,
E     ?     ^
E     -     1,
E     ?     ^
E     +     2,
E     ?     ^
E           1,
E       )
______ TestIssue367ArrayEmpty.test_array_empty_list_and_array_equivalent _______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:76: in test_array_empty_list_and_array_equivalent
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
__________ test_map_column_subscript_with_column_key_exact_issue_441 ___________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:33: in test_map_column_subscript_with_column_key_exact_issue_441
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'MapValue'
_ TestIssue395FilterAndStringExpr.test_filter_and_string_equality_empty_result _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:130: in test_filter_and_string_equality_empty_result
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
___________________________ test_orderby_then_limit ____________________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:116: in test_orderby_then_limit
    assert result[0]["x"] == 1
E   assert 3 == 1
________________________ test_expr_regexp_single_match _________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_433_regexp_in_expr.py:73: in test_expr_regexp_single_match
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
_____ TestIssue407StddevWindow.test_stddev_over_window_multiple_partitions _____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_407_stddev_window.py:57: in test_stddev_over_window_multiple_partitions
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________ TestIssue367ArrayEmpty.test_array_empty_after_filter _____________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:96: in test_array_empty_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________________ test_map_column_subscript_key_not_found ____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:52: in test_map_column_subscript_key_not_found
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
___________________________ test_orderby_then_select ___________________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:140: in test_orderby_then_select
    assert result[0]["a"] == 1 and result[0]["b"] == 10
E   assert (3 == 1)
_______ TestIssue395FilterAndStringExpr.test_expr_and_string_with_column _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:160: in test_expr_and_string_with_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
__________________________ test_expr_regexp_no_match ___________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_433_regexp_in_expr.py:83: in test_expr_regexp_no_match
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
____________ TestIssue407StddevWindow.test_stddev_samp_over_window _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_407_stddev_window.py:84: in test_stddev_samp_over_window
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______________ TestIssue367ArrayEmpty.test_array_empty_in_union _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_367_array_empty.py:112: in test_array_empty_in_union
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________________ test_orderby_with_explicit_list_variable ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_415_orderby_list.py:154: in test_orderby_with_explicit_list_variable
    assert result[0]["x"] == 1
E   assert 2 == 1
_____________________ test_map_column_subscript_in_select ______________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:64: in test_map_column_subscript_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
____ TestIssue422FillnaFloat.test_fillna_float_multiple_calculated_columns _____
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_422_fillna_float.py:176: in test_fillna_float_multiple_calculated_columns
    df = df.fillna(0.0, subset=["ratio", "sum"])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:674: in fillna
    return self._misc.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/misc_service.py:224: in fillna
    new_row = row.copy()
              ^^^^^^^^
sparkless/spark_types.py:1000: in __getattr__
    raise AttributeError(
E   AttributeError: 'Row' object has no attribute 'copy'
____________________ test_expr_ltrim_rtrim_exact_issue_434 _____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:24: in test_expr_ltrim_rtrim_exact_issue_434
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
_________ TestIssue395FilterAndStringExpr.test_filter_and_select_after _________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:175: in test_filter_and_select_after
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
_____________ TestIssue407StddevWindow.test_stddev_pop_over_window _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_407_stddev_window.py:105: in test_stddev_pop_over_window
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__________________________ test_distinct_then_filter ___________________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_448_drop_duplicates_list_column.py:335: in test_distinct_then_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____________________ test_robust_join_compound_condition ______________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:181: in test_robust_join_compound_condition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column '(o.customer_id = c.customer_id & (o.amount > 30))' not found. Available columns: [o.order_id, o.amount, c.name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestIssue422FillnaFloat.test_fillna_float_after_filter ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_422_fillna_float.py:200: in test_fillna_float_after_filter
    df = df.fillna(0.0, subset=["div"])
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:674: in fillna
    return self._misc.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/misc_service.py:224: in fillna
    new_row = row.copy()
              ^^^^^^^^
sparkless/spark_types.py:1000: in __getattr__
    raise AttributeError(
E   AttributeError: 'Row' object has no attribute 'copy'
_ TestIssue419FilterInOrParseException.test_filter_in_or_with_integer_literal_exact_issue _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:24: in test_filter_in_or_with_integer_literal_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_____________________________ test_expr_ltrim_only _____________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:38: in test_expr_ltrim_only
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
____________________ test_map_column_subscript_then_filter _____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:109: in test_map_column_subscript_then_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
___ TestIssue395FilterAndStringExpr.test_filter_is_null_and_string_equality ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_395_filter_and_string_expr.py:189: in test_filter_is_null_and_string_equality
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
_________ TestIssue407StddevWindow.test_stddev_over_window_with_nulls __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_407_stddev_window.py:132: in test_stddev_over_window_with_nulls
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______________________ test_filter_then_drop_duplicates _______________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_448_drop_duplicates_list_column.py:351: in test_filter_then_drop_duplicates
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
______ TestIssue438LeftsemiJoin.test_leftsemi_join_excludes_right_columns ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_438_leftsemi_join.py:28: in test_leftsemi_join_excludes_right_columns
    assert len(rows) == 1
E   assert 0 == 1
E    +  where 0 = len([])
_____________________ test_robust_sql_where_table_prefixed _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:207: in test_robust_sql_where_table_prefixed
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/test_issues_376_382_robust.py:223: in test_robust_sql_where_table_prefixed
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____ TestIssue438LeftsemiJoin.test_left_semi_join_excludes_right_columns ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_438_leftsemi_join.py:44: in test_left_semi_join_excludes_right_columns
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
_______ TestIssue396ToDateCast.test_to_date_cast_string_type_exact_issue _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:29: in test_to_date_cast_string_type_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_____________________________ test_expr_rtrim_only _____________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:48: in test_expr_rtrim_only
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rtrim
_______________ test_map_column_subscript_null_key_returns_null ________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:128: in test_map_column_subscript_null_key_returns_null
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
__ TestIssue407StddevWindow.test_stddev_single_row_per_partition_returns_none __
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_407_stddev_window.py:150: in test_stddev_single_row_per_partition_returns_none
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ test_drop_duplicates_struct_column_after_materialization_exact_issue_451 ___
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_451_drop_duplicates_struct_column.py:44: in test_drop_duplicates_struct_column_after_materialization_exact_issue_451
    df.count()  # force materialization - required to trigger the bug
    ^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_ TestIssue419FilterInOrParseException.test_filter_in_or_string_literal_type_coercion_exact_issue _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:48: in test_filter_in_or_string_literal_type_coercion_exact_issue
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
___________________ test_robust_sql_group_by_table_prefixed ____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:244: in test_robust_sql_group_by_table_prefixed
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/test_issues_376_382_robust.py:258: in test_robust_sql_group_by_table_prefixed
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___________ TestIssue396ToDateCast.test_to_date_cast_string_literal ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_396_to_date_cast.py:46: in test_to_date_cast_string_literal
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
______ TestIssue438LeftsemiJoin.test_leftsemi_join_with_column_expression ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_438_leftsemi_join.py:62: in test_leftsemi_join_with_column_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'id = id' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ test_map_column_subscript_coalesce_default __________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:145: in test_map_column_subscript_coalesce_default
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
___________________ test_expr_nested_ltrim_rtrim_with_column ___________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:60: in test_expr_nested_ltrim_rtrim_with_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
____ TestIssue407StddevWindow.test_stddev_over_window_then_select_and_show _____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_407_stddev_window.py:170: in test_stddev_over_window_then_select_and_show
    df.show()
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________ test_posexplode_without_alias_no_type_error __________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_429_posexplode_no_alias.py:35: in test_posexplode_without_alias_no_type_error
    result.show()  # Previously failed here
    ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:470: in show
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
________________ test_robust_sql_three_joins_select_third_table ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:283: in test_robust_sql_three_joins_select_third_table
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/test_issues_376_382_robust.py:310: in test_robust_sql_three_joins_select_third_table
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________ test_drop_duplicates_struct_column_before_materialization ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_451_drop_duplicates_struct_column.py:73: in test_drop_duplicates_struct_column_before_materialization
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
_ TestIssue419FilterInOrParseException.test_filter_in_or_workaround_still_works _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:62: in test_filter_in_or_workaround_still_works
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
______ TestIssue438LeftsemiJoin.test_leftanti_join_excludes_right_columns ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_438_leftsemi_join.py:79: in test_leftanti_join_excludes_right_columns
    assert len(rows) == 2  # K=1 and K=3 not in right
    ^^^^^^^^^^^^^^^^^^^^^
E   assert 0 == 2
E    +  where 0 = len([])
_______________________________ test_quickstart ________________________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_notebooks.py:72: in test_quickstart
    assert high_value_orders.count() == 3
E   assert 0 == 3
E    +  where 0 = count()
E    +    where count = DataFrame[0 rows, 6 columns].count
----------------------------- Captured stdout call -----------------------------
Testing Quickstart Tutorial...
 Session created: test_test_quickstart
 Created DataFrame with 5 orders
_________________ test_map_column_subscript_multiple_in_select _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:164: in test_map_column_subscript_multiple_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_________________________ test_expr_rtrim_ltrim_order __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:71: in test_expr_rtrim_ltrim_order
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rtrim
__________ TestIssue438LeftsemiJoin.test_leftsemi_join_multiple_keys ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_438_leftsemi_join.py:99: in test_leftsemi_join_multiple_keys
    assert len(rows) == 1
E   assert 0 == 1
E    +  where 0 = len([])
__________________________ test_dataframe_operations ___________________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_notebooks.py:185: in test_dataframe_operations
    assert joined.count() == 5
E   assert 0 == 5
E    +  where 0 = count()
E    +    where count = DataFrame[0 rows, 7 columns].count
----------------------------- Captured stdout call -----------------------------
Testing DataFrame Operations Tutorial...
 Select works
 Filter works
______________ test_distinct_struct_column_after_materialization _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_451_drop_duplicates_struct_column.py:92: in test_distinct_struct_column_after_materialization
    df.count()  # materialize
    ^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
__ TestIssue419FilterInOrParseException.test_filter_in_or_with_string_column ___
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:76: in test_filter_in_or_with_string_column
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_______________________ test_expr_trim_with_ltrim_rtrim ________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:81: in test_expr_trim_with_ltrim_rtrim
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: trim
___________________ test_map_column_subscript_orderby_result ___________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:183: in test_map_column_subscript_orderby_result
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
________________ test_drop_duplicates_subset_with_struct_column ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_451_drop_duplicates_struct_column.py:112: in test_drop_duplicates_subset_with_struct_column
    df.count()
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
____________ TestIssue438LeftsemiJoin.test_leftsemi_join_all_match _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_438_leftsemi_join.py:122: in test_leftsemi_join_all_match
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
____ TestIssue419FilterInOrParseException.test_filter_in_multiple_values_or ____
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:91: in test_filter_in_multiple_values_or
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_________________ test_posexplode_without_alias_single_element _________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_429_posexplode_no_alias.py:115: in test_posexplode_without_alias_single_element
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
______________________ test_expr_ltrim_rtrim_with_filter _______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:99: in test_expr_ltrim_rtrim_with_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
___________________ test_map_column_subscript_when_otherwise ___________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:205: in test_map_column_subscript_when_otherwise
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
______ TestIssue419FilterInOrParseException.test_filter_in_and_condition _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:105: in test_filter_in_and_condition
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
__________________ test_alias_cast_withcolumn_exact_issue_453 __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:29: in test_alias_cast_withcolumn_exact_issue_453
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'y_int' not found. Available columns: [x, y, y_as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestIssue438LeftsemiJoin.test_leftsemi_join_then_select ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_438_leftsemi_join.py:143: in test_leftsemi_join_then_select
    assert len(rows) == 1
E   assert 0 == 1
E    +  where 0 = len([])
____________ TestCaseWhenCast.test_casewhen_cast_to_long_issue_243 _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:56: in test_casewhen_cast_to_long_issue_243
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_______________________ test_expr_ltrim_rtrim_with_nulls _______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:118: in test_expr_ltrim_rtrim_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
________________ test_map_column_subscript_chained_with_columns ________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:219: in test_map_column_subscript_chained_with_columns
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
_ TestIssue439ArrayDistinct.test_array_distinct_integer_arrays_preserves_type __
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:39: in test_array_distinct_integer_arrays_preserves_type
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
________ TestCaseSensitivityConfiguration.test_default_case_insensitive ________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:23: in test_default_case_insensitive
    assert result[0]["Name"] == "Alice"
E   AssertionError: assert None == 'Alice'
_________________ test_alias_cast_withcolumn_multiple_columns __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:47: in test_alias_cast_withcolumn_multiple_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'a_aliased' not found. Available columns: [a, b, a_int, b_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestIssue419FilterInOrParseException.test_filter_multiple_in_or ________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:120: in test_filter_multiple_in_or
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
__________ TestCaseSensitivityConfiguration.test_case_sensitive_mode ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:32: in test_case_sensitive_mode
    assert spark.conf.is_case_sensitive() is True
E   assert False is True
E    +  where False = is_case_sensitive()
E    +    where is_case_sensitive = Configuration(9 settings).is_case_sensitive
E    +      where Configuration(9 settings) = <sparkless.session.core.session.SparkSession object at 0x10d833b90>.conf
__ TestToTimestampCompatibility.test_to_timestamp_timestamp_type_pass_through __
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:48: in test_to_timestamp_timestamp_type_pass_through
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
______________________ test_alias_cast_select_still_works ______________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:65: in test_alias_cast_select_still_works
    assert _row_val(rows[0], "y_int") == 2
E   AssertionError: assert None == 2
E    +  where None = _row_val(Row(y_int=None), 'y_int')
________________ TestCaseWhenCast.test_casewhen_cast_to_string _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:90: in test_casewhen_cast_to_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
________ TestCaseSensitivityConfiguration.test_case_insensitive_select _________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:58: in test_case_insensitive_select
    assert result1[0]["Name"] == result2[0]["Name"] == result3[0]["Name"] == "Alice"
E   AssertionError: assert None == 'Alice'
____________ test_posexplode_alias_two_names_returns_exploded_rows _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:28: in test_posexplode_alias_two_names_returns_exploded_rows
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_________________________ test_expr_ltrim_empty_string _________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:130: in test_expr_ltrim_empty_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
_____________ test_map_column_subscript_create_map_with_column_key _____________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_441_map_column_subscript.py:238: in test_map_column_subscript_create_map_with_column_key
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_________ TestIssue439ArrayDistinct.test_array_distinct_string_arrays __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:71: in test_array_distinct_string_arrays
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
____ TestToTimestampCompatibility.test_to_timestamp_string_type_with_format ____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:68: in test_to_timestamp_string_type_with_format
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_____ TestIssue419FilterInOrParseException.test_filter_in_float_column_or ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_419_filter_in_or_parse_exception.py:135: in test_filter_in_float_column_or
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
____________________ test_alias_cast_withcolumn_then_select ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:78: in test_alias_cast_withcolumn_then_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'y_renamed' not found. Available columns: [x, y_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestCaseWhenCast.test_casewhen_cast_to_int __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:122: in test_casewhen_cast_to_int
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_____________________ test_posexplode_alias_no_none_values _____________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:55: in test_posexplode_alias_no_none_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_________ TestCaseSensitivityConfiguration.test_case_insensitive_join __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:101: in test_case_insensitive_join
    result = df1.join(df2, on="id", how="inner").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: not found: ID
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
_________________________ test_expr_rtrim_empty_string _________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:140: in test_expr_rtrim_empty_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: rtrim
________ TestIssue439ArrayDistinct.test_array_distinct_with_column_expr ________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:97: in test_array_distinct_with_column_expr
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array_distinct
__ TestToTimestampCompatibility.test_to_timestamp_string_type_without_format ___
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:84: in test_to_timestamp_string_type_without_format
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestCaseSensitivityConfiguration.test_case_sensitive_mode_exact_match_required _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:117: in test_case_sensitive_mode_exact_match_required
    with pytest.raises(Exception):
E   Failed: DID NOT RAISE <class 'Exception'>
____________________ test_alias_cast_withcolumn_string_type ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:96: in test_alias_cast_withcolumn_string_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'n' not found. Available columns: [num, num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestColumnSubstr.test_substr_zero_start ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:383: in test_substr_zero_start
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_________________ test_posexplode_alias_chained_filter_orderby _________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:79: in test_posexplode_alias_chained_filter_orderby
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
________________ TestCaseWhenCast.test_casewhen_cast_to_double _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:145: in test_casewhen_cast_to_double
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestToTimestampCompatibility.test_to_timestamp_integer_type_unix_timestamp __
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:101: in test_to_timestamp_integer_type_unix_timestamp
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_________________________ test_expr_triple_nested_trim _________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:150: in test_expr_triple_nested_trim
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: trim
_ TestCaseSensitivityConfiguration.test_case_sensitive_withColumn_fails_with_wrong_case _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:152: in test_case_sensitive_withColumn_fails_with_wrong_case
    result = df.withColumn("key_upper", F.upper(F.col("key"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
__________ TestIssue439ArrayDistinct.test_array_distinct_empty_array ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:118: in test_array_distinct_empty_array
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_ TestCaseSensitivityConfiguration.test_case_sensitive_filter_fails_with_wrong_case _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:172: in test_case_sensitive_filter_fails_with_wrong_case
    with pytest.raises(Exception):
E   Failed: DID NOT RAISE <class 'Exception'>
_ TestCaseSensitivityConfiguration.test_case_sensitive_select_fails_with_wrong_case _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:201: in test_case_sensitive_select_fails_with_wrong_case
    with pytest.raises(Exception):
E   Failed: DID NOT RAISE <class 'Exception'>
____________________ test_alias_cast_withcolumn_double_type ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:109: in test_alias_cast_withcolumn_double_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'str_val' not found. Available columns: [s, dbl]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ TestColumnSubstr.test_substr_with_alias ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:400: in test_substr_with_alias
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
___ TestToTimestampCompatibility.test_to_timestamp_long_type_unix_timestamp ____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:118: in test_to_timestamp_long_type_unix_timestamp
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestCaseSensitivityConfiguration.test_case_sensitive_groupBy_fails_with_wrong_case _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:231: in test_case_sensitive_groupBy_fails_with_wrong_case
    with pytest.raises(Exception):
E   Failed: DID NOT RAISE <class 'Exception'>
____________ TestCaseWhenCast.test_casewhen_cast_with_multiple_when ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:179: in test_casewhen_cast_with_multiple_when
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______________________ test_posexplode_alias_empty_array _______________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:105: in test_posexplode_alias_empty_array
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_________________ test_expr_ltrim_rtrim_column_with_underscore _________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:160: in test_expr_ltrim_rtrim_column_with_underscore
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
_________ TestIssue439ArrayDistinct.test_array_distinct_single_element _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_439_array_distinct.py:135: in test_array_distinct_single_element
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____ TestToTimestampCompatibility.test_to_timestamp_date_type_conversion ______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:133: in test_to_timestamp_date_type_conversion
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
_ TestCaseSensitivityConfiguration.test_case_sensitive_join_fails_with_wrong_case _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:261: in test_case_sensitive_join_fails_with_wrong_case
    result = df1.join(df2, df1["ID"] == df2["id"], "inner").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Dept' has more than one occurrence
_____________________ test_alias_cast_withcolumn_long_type _____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:122: in test_alias_cast_withcolumn_long_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'l' not found. Available columns: [s, lng]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnSubstr.test_substr_pyspark_parity_comprehensive ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:443: in test_substr_pyspark_parity_comprehensive
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_ TestCaseSensitivityConfiguration.test_case_sensitive_attribute_access_requires_exact_case _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:287: in test_case_sensitive_attribute_access_requires_exact_case
    with pytest.raises(Exception):
E   Failed: DID NOT RAISE <class 'Exception'>
_____________________ test_posexplode_alias_single_element _____________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:123: in test_posexplode_alias_single_element
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_____________ TestCaseWhenCast.test_casewhen_cast_with_null_values _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:202: in test_casewhen_cast_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________________ test_expr_ltrim_inside_upper _________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:170: in test_expr_ltrim_inside_upper
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
_______________ test_between_string_column_in_select_expression ________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_445_between_string_column_numeric_bounds.py:154: in test_between_string_column_in_select_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: cannot compare string with numeric type (i32)
_ TestCaseSensitivityConfiguration.test_case_sensitive_sql_queries_require_exact_case _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:324: in test_case_sensitive_sql_queries_require_exact_case
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
__ TestToTimestampCompatibility.test_to_timestamp_double_type_unix_timestamp ___
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:152: in test_to_timestamp_double_type_unix_timestamp
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________________ TestColumnAstype.test_astype_with_alias ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:423: in test_astype_with_alias
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_as_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ test_alias_cast_withcolumn_with_nulls _____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:135: in test_alias_cast_withcolumn_with_nulls
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'a_aliased' not found. Available columns: [a, a_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestCaseWhenCast.test_casewhen_cast_in_select _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:224: in test_casewhen_cast_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________________ test_expr_filter_with_ltrim __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:186: in test_expr_filter_with_ltrim
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
_____________________ test_posexplode_alias_mixed_columns ______________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:134: in test_posexplode_alias_mixed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
___________________ TestColumnSubstr.test_substr_in_groupBy ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:469: in test_substr_in_groupBy
    result = df_with_first_char.groupBy("first_char").agg(
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
___ TestCaseSensitivityConfiguration.test_case_sensitive_issue_264_scenario ____
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:352: in test_case_sensitive_issue_264_scenario
    result = df.withColumn("key_upper", F.upper(F.col("key"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
_____ TestToTimestampCompatibility.test_to_timestamp_after_regexp_replace ______
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_to_timestamp_compatibility.py:224: in test_to_timestamp_after_regexp_replace
    rows = df_parsed.collect()
           ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
_____________ TestColumnAstype.test_astype_on_complex_expressions ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:448: in test_astype_on_complex_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'a' not found. Available columns: [result_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ test_alias_cast_withcolumn_then_filter ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:158: in test_alias_cast_withcolumn_then_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'v' not found. Available columns: [name, val, val_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestCaseSensitivityConfiguration.test_ambiguity_detection ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/integration/test_case_sensitivity.py:400: in test_ambiguity_detection
    assert (
E   AssertionError: assert 'Bob' == 'Alice'
E     
E     - Alice
E     + Bob
___________ TestCaseWhenCast.test_casewhen_cast_with_datatype_object ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:246: in test_casewhen_cast_with_datatype_object
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______________ test_posexplode_outer_alias_returns_exploded_rows _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:151: in test_posexplode_outer_alias_returns_exploded_rows
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode_outer
__________ TestColumnSubstr.test_substr_chained_with_other_operations __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:493: in test_substr_chained_with_other_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
____________________ test_expr_ltrim_rtrim_case_insensitive ____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:196: in test_expr_ltrim_rtrim_case_insensitive
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
___________ TestChainedArithmetic.test_reverse_operations_in_orderby ___________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_chained_arithmetic.py:563: in test_reverse_operations_in_orderby
    assert rows[0]["value"] == 1.0  # 2 * 1.0 = 2.0
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert 3.0 == 1.0
_________ TestTypeStrictness.test_to_timestamp_accepts_multiple_types __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_type_strictness.py:35: in test_to_timestamp_accepts_multiple_types
    rows = result_str.collect()
           ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
___________________ test_between_string_column_then_orderby ____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_445_between_string_column_numeric_bounds.py:230: in test_between_string_column_then_orderby
    assert [r["val"] for r in rows] == ["3", "5", "8"]
E   AssertionError: assert ['8', '3', '5'] == ['3', '5', '8']
E     
E     At index 0 diff: '8' != '3'
E     
E     Full diff:
E       [
E     +     '8',
E           '3',
E           '5',
E     -     '8',
E       ]
______________ TestColumnAstype.test_astype_invalid_string_to_int ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:468: in test_astype_invalid_string_to_int
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'text' not found. Available columns: [as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ test_alias_cast_withcolumn_column_with_underscore _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:172: in test_alias_cast_withcolumn_column_with_underscore
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'mc' not found. Available columns: [my_column, mc_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________ TestColumnSubstr.test_substr_very_long_string _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:511: in test_substr_very_long_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
______________________ test_posexplode_alias_string_array ______________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:167: in test_posexplode_alias_string_array
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
___________ TestWindowFunctionCast.test_window_function_cast_to_long ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:281: in test_window_function_cast_to_long
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________________ test_expr_multiple_columns_ltrim_rtrim ____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:209: in test_expr_multiple_columns_ltrim_rtrim
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
_________________ test_between_string_column_in_when_otherwise _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_445_between_string_column_numeric_bounds.py:250: in test_between_string_column_in_when_otherwise
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________________ test_alias_cast_withcolumn_mixed_with_plain __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:187: in test_alias_cast_withcolumn_mixed_with_plain
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 's' not found. Available columns: [id, name, score, score_int, doubled]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestColumnAstype.test_astype_double_to_int __________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:491: in test_astype_double_to_int
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'double_val' not found. Available columns: [as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestWindowFunctionCast.test_window_function_cast_to_string __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:312: in test_window_function_cast_to_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______ TestChainedArithmetic.test_reverse_operations_with_when_otherwise _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_chained_arithmetic.py:612: in test_reverse_operations_with_when_otherwise
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
______________ TestColumnSubstr.test_substr_start_exceeds_length _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:527: in test_substr_start_exceeds_length
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_____________________ test_posexplode_alias_column_object ______________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:177: in test_posexplode_alias_column_object
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
_______________________ test_expr_ltrim_whitespace_only ________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_434_ltrim_rtrim_in_expr.py:220: in test_expr_ltrim_whitespace_only
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
____________________ test_between_string_column_not_between ____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_445_between_string_column_numeric_bounds.py:269: in test_between_string_column_not_between
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
________________ TestColumnAstype.test_astype_string_to_boolean ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:519: in test_astype_string_to_boolean
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'bool_str' not found. Available columns: [as_bool]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestChainedArithmetic.test_reverse_operations_with_cast ____________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_chained_arithmetic.py:630: in test_reverse_operations_with_cast
    assert rows[0]["result"] == 5  # (2 * 2.5) = 5.0, cast to int = 5
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 5
______________ test_alias_cast_withcolumn_replace_existing_column ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:203: in test_alias_cast_withcolumn_replace_existing_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'a_as_int' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ test_alias_cast_select_exact_issue_435 ____________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:31: in test_alias_cast_select_exact_issue_435
    assert rows[0]["Name"] == "Alice" and rows[0]["ValueNew"] == 123
E   AssertionError: assert ('Alice' == 'Alice'
E     
E       Alice and None == 123)
----------------------------- Captured stdout call -----------------------------
DataFrame[2 rows, 2 columns]

Name  ValueNew
Alice   None      
Bob     None      
______________________ test_posexplode_alias_show_no_none ______________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_430_posexplode_alias_execution.py:192: in test_posexplode_alias_show_no_none
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
__________ TestColumnSubstr.test_substr_negative_start_exceeds_length __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:545: in test_substr_negative_start_exceeds_length
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
__________ TestWindowFunctionCast.test_window_function_cast_to_double __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:343: in test_window_function_cast_to_double
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________________ TestColumnAstype.test_astype_in_orderBy ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:555: in test_astype_in_orderBy
    assert num_strs == ["2", "10", "100"] or num_strs == [
E   AssertionError: assert (['10', '2', '100'] == ['2', '10', '100']
E     
E     At index 0 diff: '10' != '2'
E     
E     Full diff:
E       [
E     +     '10',
E           '2',
E     -     '10',
E           '100',
E       ] or ['10', '2', '100'] == ['2', '100', '10']
E     
E     At index 0 diff: '10' != '2'
E     
E     Full diff:
E       [
E     +     '10',
E           '2',
E           '100',
E     -     '10',
E       ])
_____________________ test_alias_without_cast_still_works ______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:45: in test_alias_without_cast_still_works
    assert rows[0]["B_renamed"] == 2
E   assert None == 2
_________________________ test_date_less_than_datetime _________________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_431_date_datetime_comparison.py:43: in test_date_less_than_datetime
    assert rows[0]["Date"] == datetime.date(2024, 1, 1)
E   AssertionError: assert None == datetime.date(2024, 1, 1)
E    +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
E    +    where <class 'datetime.date'> = datetime.date
__________________ test_alias_cast_withcolumn_chain_three_ops __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:221: in test_alias_cast_withcolumn_chain_three_ops
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'x_a' not found. Available columns: [x, y, z, x_int, y_int, z_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________________ test_cast_without_alias_still_works ______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:57: in test_cast_without_alias_still_works
    assert rows[0]["s"] == 123
E   assert None == 123
_______ TestWindowFunctionCast.test_window_function_cast_with_partition ________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:375: in test_window_function_cast_with_partition
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_ TestDoubleJoinEmptyAggregated.test_columns_preserved_in_double_join_with_empty_aggregated _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_double_join_empty_aggregated.py:144: in test_columns_preserved_in_double_join_with_empty_aggregated
    rows = result3.collect()
           ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
____________________________ test_date_eq_datetime _____________________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_431_date_datetime_comparison.py:83: in test_date_eq_datetime
    assert rows[0]["dt"] == datetime.datetime(2024, 1, 1, 0, 0, 0)
E   AssertionError: assert None == datetime.datetime(2024, 1, 1, 0, 0)
E    +  where datetime.datetime(2024, 1, 1, 0, 0) = <class 'datetime.datetime'>(2024, 1, 1, 0, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
_________________________ test_alias_cast_string_type __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:69: in test_alias_cast_string_type
    assert rows[0]["num_str"] == "123"
E   AssertionError: assert None == '123'
________________ TestColumnAstype.test_astype_multiple_chained _________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:603: in test_astype_multiple_chained
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ test_alias_cast_withcolumn_after_filter ____________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:240: in test_alias_cast_withcolumn_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'v' not found. Available columns: [id, val, val_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________________ test_date_lte_datetime ____________________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_431_date_datetime_comparison.py:106: in test_date_lte_datetime
    assert rows[0]["dt"] == datetime.datetime(2024, 1, 1, 0, 0, 0)
E   AssertionError: assert None == datetime.datetime(2024, 1, 1, 0, 0)
E    +  where datetime.datetime(2024, 1, 1, 0, 0) = <class 'datetime.datetime'>(2024, 1, 1, 0, 0, 0)
E    +    where <class 'datetime.datetime'> = datetime.datetime
_______________________ test_alias_cast_multiple_columns _______________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:85: in test_alias_cast_multiple_columns
    assert rows[0]["A_int"] == 1 and rows[0]["B_int"] == 2 and rows[0]["C_int"] == 3
E   assert (None == 1)
__________ TestFillnaSubset.test_fillna_subset_with_select_operation ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_fillna_subset.py:682: in test_fillna_subset_with_select_operation
    result = df.select("col1", "col2").fillna("FILLED", subset=["col1"])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:674: in fillna
    return self._misc.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/misc_service.py:224: in fillna
    new_row = row.copy()
              ^^^^^^^^
sparkless/spark_types.py:1000: in __getattr__
    raise AttributeError(
E   AttributeError: 'Row' object has no attribute 'copy'
__________ TestWindowFunctionCast.test_window_function_cast_with_sum ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:402: in test_window_function_cast_with_sum
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________________________ test_date_gte_datetime ____________________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_431_date_datetime_comparison.py:129: in test_date_gte_datetime
    assert rows[0]["d"] == datetime.date(2024, 6, 15)
E   AssertionError: assert None == datetime.date(2024, 6, 15)
E    +  where datetime.date(2024, 6, 15) = <class 'datetime.date'>(2024, 6, 15)
E    +    where <class 'datetime.date'> = datetime.date
_________________________ test_alias_cast_double_type __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:100: in test_alias_cast_double_type
    assert rows[0]["dbl"] == 3.14
E   assert None == 3.14
____________ TestColumnAstype.test_astype_on_all_column_operations _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:624: in test_astype_on_all_column_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
__________________ test_alias_cast_withcolumn_empty_dataframe __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_453_alias_cast_withcolumn.py:254: in test_alias_cast_withcolumn_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'a_alias' not found. Available columns: [a, a_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________________ test_alias_cast_with_nulls __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:118: in test_alias_cast_with_nulls
    assert rows[0]["a_int"] == 1
E   assert None == 1
__________ TestWindowFunctionCast.test_window_function_cast_in_select __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:422: in test_window_function_cast_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
__ TestChainedArithmetic.test_reverse_operations_with_select_multiple_columns __
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_chained_arithmetic.py:751: in test_reverse_operations_with_select_multiple_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'col' not found. Available columns: [double, add, sub]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________________ test_robust_round_string_with_whitespace ___________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:64: in test_robust_round_string_with_whitespace
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
_________________ TestColumnAstype.test_astype_date_variations _________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:643: in test_astype_date_variations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'date_str' not found. Available columns: [date_col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestFilterParity.test_filter_on_table_with_complex_schema ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_filter.py:102: in test_filter_on_table_with_complex_schema
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________________________ test_alias_cast_then_filter __________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issue_435_alias_cast_select.py:139: in test_alias_cast_then_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'val_int' not found. Available columns: [name, col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestWindowFunctionCast.test_window_function_cast_with_datatype_object _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_casewhen_windowfunction_cast.py:443: in test_window_function_cast_with_datatype_object
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
____________ test_robust_round_string_with_decimals_and_whitespace _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:77: in test_robust_round_string_with_decimals_and_whitespace
    rows = df.collect()
           ^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: round
________________ TestColumnAstype.test_astype_zero_and_negative ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:673: in test_astype_zero_and_negative
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [as_string, as_bool]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____ TestIsInstanceOrdering.test_filter_on_table_with_comparison_operations ____
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_filter_isinstance_ordering.py:73: in test_filter_on_table_with_comparison_operations
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________ TestIsInstanceOrdering.test_arithmetic_operations_in_filters _________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_filter_isinstance_ordering.py:157: in test_arithmetic_operations_in_filters
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________________ test_robust_select_table_prefixed_after_join _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:96: in test_robust_select_table_prefixed_after_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 't1.id = t2.id' not found. Available columns: [t1.id, t2.label]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________ TestColumnAstype.test_astype_float_string_conversions _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:714: in test_astype_float_string_conversions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'double_val' not found. Available columns: [double_str, str_double]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestColumnAstype.test_basic_astype_string ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:54: in test_basic_astype_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______ TestIsInstanceOrdering.test_complex_nested_operations_in_filters _______
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_filter_isinstance_ordering.py:191: in test_complex_nested_operations_in_filters
    spark.sql(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______________ test_robust_self_join_manager_column_and_row_count ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/test_issues_376_382_robust.py:124: in test_robust_self_join_manager_column_and_row_count
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/test_issues_376_382_robust.py:155: in test_robust_self_join_manager_column_and_row_count
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______________ TestColumnAstype.test_astype_empty_string_handling ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:735: in test_astype_empty_string_handling
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'text' not found. Available columns: [as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestColumnAstype.test_basic_astype_int ____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:74: in test_basic_astype_int
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num_str' not found. Available columns: [num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestJoinTypeCoercionParity.test_pyspark_parity_multiple_keys_complex _____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:674: in test_pyspark_parity_multiple_keys_complex
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
___________ TestIsInstanceOrdering.test_string_operations_in_filters ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_filter_isinstance_ordering.py:216: in test_string_operations_in_filters
    assert result1.count() == 1, "Should return 1 row where name starts with 'A'"
           ^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: startswith
__ TestJoinTypeCoercionParity.test_pyspark_parity_type_promotion_int32_int64 ___
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:703: in test_pyspark_parity_type_promotion_int32_int64
    assert len(rows) == 1
E   assert 0 == 1
E    +  where 0 = len([])
_______________ TestColumnAstype.test_astype_on_column_operation _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:95: in test_astype_on_column_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
____________ TestColumnAstype.test_astype_equals_cast_comprehensive ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:777: in test_astype_equals_cast_comprehensive
    rows_astype = result_astype.collect()
                  ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestIsInstanceOrdering.test_logical_operations_in_filters ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_filter_isinstance_ordering.py:258: in test_logical_operations_in_filters
    assert result3.count() == 2, "Should return 2 rows where NOT (a == 20)"
           ^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:575: in count
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: !
_ TestJoinTypeCoercionParity.test_pyspark_parity_left_on_right_on_different_names _
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:717: in test_pyspark_parity_left_on_right_on_different_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'code' has more than one occurrence
________________ TestColumnAstype.test_astype_issue_239_example ________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:119: in test_astype_issue_239_example
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
______________ TestColumnAstype.test_astype_after_when_otherwise _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:808: in test_astype_after_when_otherwise
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'value' not found. Available columns: [doubled_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestJoinTypeCoercionParity.test_pyspark_parity_mixed_numeric_strings _____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:751: in test_pyspark_parity_mixed_numeric_strings
    assert len(rows) == 4
E   assert 0 == 4
E    +  where 0 = len([])
__ TestJoinTypeCoercionParity.test_pyspark_parity_scientific_notation_strings __
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:769: in test_pyspark_parity_scientific_notation_strings
    assert len(rows) == 1
E   assert 0 == 1
E    +  where 0 = len([])
______________ TestColumnAstype.test_astype_with_datatype_object _______________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:137: in test_astype_with_datatype_object
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestColumnAstype.test_astype_substring_date_pyspark_parity __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:830: in test_astype_substring_date_pyspark_parity
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
_______________ TestJoinTypeCoercion.test_join_int64_with_string _______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:54: in test_join_int64_with_string
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
___________________ TestColumnAstype.test_astype_equals_cast ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:157: in test_astype_equals_cast
    rows_astype = result_astype.collect()
                  ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
____________________ TestColumnAstype.test_astype_long_type ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:851: in test_astype_long_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [as_long]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestJoinTypeCoercion.test_join_string_with_int64 _______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:92: in test_join_string_with_int64
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
________________________ TestJoinParity.test_inner_join ________________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_join.py:35: in test_inner_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______________ TestJoinTypeCoercion.test_join_int32_with_string _______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:131: in test_join_int32_with_string
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
____________________ TestColumnAstype.test_astype_in_select ____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:185: in test_astype_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'text' not found. Available columns: [num, num_str, text_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestChainedArithmetic.test_reverse_operations_in_select ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_chained_arithmetic.py:273: in test_reverse_operations_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'col' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
________________________ TestJoinParity.test_left_join _________________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_join.py:59: in test_left_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_______________ TestColumnAstype.test_astype_string_type_aliases _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:869: in test_astype_string_type_aliases
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [as_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestJoinTypeCoercion.test_join_float_with_string _______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:167: in test_join_float_with_string
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
________________________ TestJoinParity.test_right_join ________________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_join.py:83: in test_right_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=4
_______________ TestJoinTypeCoercion.test_join_int32_with_int64 ________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:203: in test_join_int32_with_int64
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
______________________ TestColumnSubstr.test_basic_substr ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:49: in test_basic_substr
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
________________________ TestJoinParity.test_outer_join ________________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_join.py:107: in test_outer_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=5
____________________ TestColumnAstype.test_astype_with_null ____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:244: in test_astype_with_null
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____________ TestJoinTypeCoercion.test_join_with_left_on_right_on _____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:228: in test_join_with_left_on_right_on
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'key_right' has more than one occurrence
______________ TestColumnSubstr.test_substr_from_second_position _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:69: in test_substr_from_second_position
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
____________ TestUnionTypeCoercionEdgeCases.test_union_zero_values _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:508: in test_union_zero_values
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=0, value=A), Row(key=0, value=B)])
________________________ TestJoinParity.test_semi_join _________________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_join.py:153: in test_semi_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=3
_______ TestJoinTypeCoercion.test_join_multiple_keys_with_type_mismatch ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:255: in test_join_multiple_keys_with_type_mismatch
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
_____________________ TestColumnAstype.test_astype_double ______________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:263: in test_astype_double
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_double]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___________ TestUnionTypeCoercionEdgeCases.test_union_large_numbers ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:534: in test_union_large_numbers
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=2147483647, value=A), Row(key=9223372036854775807, value=B)])
_________ TestJoinTypeCoercion.test_join_type_coercion_parity_pyspark __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:287: in test_join_type_coercion_parity_pyspark
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
________________________ TestJoinParity.test_anti_join _________________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/parity/dataframe/test_join.py:176: in test_anti_join
    self.assert_parity(result, expected)
tests/fixtures/parity_base.py:57: in assert_parity
    assert_dataframes_equal(
tests/tools/comparison_utils.py:798: in assert_dataframes_equal
    raise AssertionError(f"{error_msg}:\n{error_details}")
E   AssertionError: DataFrames are not equivalent:
E   Row count mismatch: mock=0, expected=1
___________ TestStringArithmetic.test_string_arithmetic_with_orderby ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_string_arithmetic.py:630: in test_string_arithmetic_with_orderby
    assert rows[0]["string_1"] == "10"  # 10/10 = 1.0
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert '30' == '10'
E     
E     - 10
E     + 30
________________ TestColumnSubstr.test_substr_issue_238_example ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:88: in test_substr_issue_238_example
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
__________________ TestNaFillRobust.test_na_fill_with_filter ___________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_na_fill_robust.py:118: in test_na_fill_with_filter
    result = df.filter(F.col("score") > 80).na.fill("UNKNOWN", subset=["name"])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/attribute_handler.py:54: in fill
    return self._df.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:674: in fillna
    return self._misc.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/misc_service.py:224: in fillna
    new_row = row.copy()
              ^^^^^^^^
sparkless/spark_types.py:1000: in __getattr__
    raise AttributeError(
E   AttributeError: 'Row' object has no attribute 'copy'
_________ TestJoinTypeCoercion.test_join_left_outer_with_type_mismatch _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:346: in test_join_left_outer_with_type_mismatch
    assert 1234 in key_values
E   AssertionError: assert 1234 in {'1234', '4567', '9999'}
_________ TestUnionTypeCoercionEdgeCases.test_union_decimal_precision __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:560: in test_union_decimal_precision
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1.123456789, value=A), Row(key=2.987654321, value=B)])
_____________________ TestColumnAstype.test_astype_boolean _____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:286: in test_astype_boolean
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'value' not found. Available columns: [value_bool]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________________ TestColumnSubstr.test_substr_start_at_one ___________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:106: in test_substr_start_at_one
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
______ TestJoinTypeCoercionParity.test_pyspark_parity_int64_string_inner _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:374: in test_pyspark_parity_int64_string_inner
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
____ TestUnionTypeCoercionEdgeCases.test_union_scientific_notation_strings _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:580: in test_union_scientific_notation_strings
    assert len(rows) == 2
E   assert 1 == 2
E    +  where 1 = len([Row(key=123.0, value=A)])
______________ TestUnionTypeCoercion.test_union_int64_with_string ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:47: in test_union_int64_with_string
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
__________________ TestNaFillRobust.test_na_fill_with_select ___________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_na_fill_robust.py:146: in test_na_fill_with_select
    result = df.select("col1", "col2").na.fill("FILLED", subset=["col1"])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/attribute_handler.py:54: in fill
    return self._df.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:674: in fillna
    return self._misc.fillna(value, subset)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/misc_service.py:224: in fillna
    new_row = row.copy()
              ^^^^^^^^
sparkless/spark_types.py:1000: in __getattr__
    raise AttributeError(
E   AttributeError: 'Row' object has no attribute 'copy'
______________________ TestNaFill.test_na_fill_after_join ______________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_na_fill.py:151: in test_na_fill_after_join
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
______ TestJoinTypeCoercionParity.test_pyspark_parity_string_int64_inner _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:400: in test_pyspark_parity_string_int64_inner
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
_______________ TestColumnAstype.test_astype_chained_operations ________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:310: in test_astype_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [doubled_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestColumnSubstr.test_substr_start_beyond_length _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:124: in test_substr_start_beyond_length
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_______ TestUnionTypeCoercionEdgeCases.test_union_multiple_numeric_types _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:618: in test_union_multiple_numeric_types
    rows = result2.collect()
           ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
________ TestJoinTypeCoercionParity.test_pyspark_parity_all_join_types _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:445: in test_pyspark_parity_all_join_types
    assert len(inner_rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
______________ TestUnionTypeCoercion.test_union_string_with_int64 ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:77: in test_union_string_with_int64
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
___________________ TestColumnAstype.test_astype_on_literal ____________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:331: in test_astype_on_literal
    assert rows[0]["lit_str"] == "123"
E   AssertionError: assert None == '123'
____ TestJoinTypeCoercionParity.test_pyspark_parity_double_precision_string ____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:562: in test_pyspark_parity_double_precision_string
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
______________ TestUnionTypeCoercion.test_union_int32_with_string ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:113: in test_union_int32_with_string
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=100, value=A), Row(key=200, value=B)])
____________________ TestColumnSubstr.test_substr_with_null ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:144: in test_substr_with_null
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_______ TestApproxCountDistinctRsd.test_approx_count_distinct_in_window ________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_approx_count_distinct_rsd.py:119: in test_approx_count_distinct_in_window
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___________ TestUnionTypeCoercionEdgeCases.test_union_chained_unions ___________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:636: in test_union_chained_unions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
______ TestJoinTypeCoercionParity.test_pyspark_parity_int_float_coercion _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:592: in test_pyspark_parity_int_float_coercion
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
________________ TestColumnAstype.test_astype_date_from_string _________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:345: in test_astype_date_from_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'date_str' not found. Available columns: [date_col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
______________ TestUnionTypeCoercion.test_union_float_with_string ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:147: in test_union_float_with_string
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1.5, value=A), Row(key=2.5, value=B)])
___ TestApproxCountDistinctRsd.test_approx_count_distinct_window_without_rsd ___
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_approx_count_distinct_rsd.py:141: in test_approx_count_distinct_window_without_rsd
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
___ TestJoinTypeCoercionParity.test_pyspark_parity_null_values_in_join_keys ____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:624: in test_pyspark_parity_null_values_in_join_keys
    assert len(rows) >= 2  # At least the non-null matches
    ^^^^^^^^^^^^^^^^^^^^^
E   assert 0 >= 2
E    +  where 0 = len([])
___________________ TestColumnSubstr.test_substr_length_zero ___________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:162: in test_substr_length_zero
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
______________ TestColumnOrderingNulls.test_desc_nulls_last_basic ______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:56: in test_desc_nulls_last_basic
    assert rows[0]["value"] == "D"
E   AssertionError: assert 'A' == 'D'
E     
E     - D
E     + A
______________ TestUnionTypeCoercion.test_union_int32_with_int64 _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:181: in test_union_int32_with_int64
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1234, value=A), Row(key=4567, value=B)])
__________ TestUnionTypeCoercionEdgeCases.test_union_all_null_columns __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:699: in test_union_all_null_columns
    assert len(rows) == 2
E   assert 1 == 2
E    +  where 1 = len([Row(key=None, value=A)])
________________ TestColumnAstype.test_astype_substring_to_date ________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:367: in test_astype_substring_to_date
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
____ TestJoinTypeCoercionParity.test_pyspark_parity_invalid_numeric_strings ____
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_join_type_coercion.py:649: in test_pyspark_parity_invalid_numeric_strings
    assert len(rows) == 2
E   assert 0 == 2
E    +  where 0 = len([])
________________ TestColumnOrderingNulls.test_desc_nulls_first _________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:81: in test_desc_nulls_first
    assert rows[0]["value"] is None
E   AssertionError: assert 'A' is None
_______________ TestUnionTypeCoercion.test_union_int_with_float ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:213: in test_union_int_with_float
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=100.0, value=A), Row(key=200.0, value=B)])
___________ TestWithField.test_withfield_nested_struct_field_access ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1166: in test_withfield_nested_struct_field_access
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_______ TestUnionTypeCoercionEdgeCases.test_union_mixed_nulls_and_values _______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:718: in test_union_mixed_nulls_and_values
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1, value=A), Row(key=None, value=B)])
____________ TestColumnSubstr.test_substr_length_exceeds_remaining _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:178: in test_substr_length_exceeds_remaining
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
___________________ TestNaFillRobust.test_na_fill_with_union ___________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_na_fill_robust.py:389: in test_na_fill_with_union
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(id=1, name=UNKNOWN, value=10), Row(id=2, name=Alice, value=20)])
_________________ TestColumnOrderingNulls.test_asc_nulls_last __________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:108: in test_asc_nulls_last
    assert rows[2]["value"] == "C"
E   AssertionError: assert None == 'C'
__________ TestUnionTypeCoercion.test_union_issue_242_exact_scenario ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:235: in test_union_issue_242_exact_scenario
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
_________________ TestColumnAstype.test_astype_multiple_types __________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_astype.py:388: in test_astype_multiple_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'value' not found. Available columns: [as_int, as_double, as_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_______________ TestColumnOrderingNulls.test_very_large_numbers ________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:531: in test_very_large_numbers
    assert rows[1]["value"] == 0
E   assert None == 0
_________ TestWithField.test_withfield_nested_struct_string_expression _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1227: in test_withfield_nested_struct_string_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________________ TestColumnOrderingNulls.test_asc_nulls_first _________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:131: in test_asc_nulls_first
    assert rows[0]["value"] is None
E   AssertionError: assert 'A' is None
_________ TestUnionTypeCoercionParity.test_pyspark_parity_int64_string _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:271: in test_pyspark_parity_int64_string
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
__________ TestUnionTypeCoercionEdgeCases.test_union_three_dataframes __________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:746: in test_union_three_dataframes
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: type Float64 is incompatible with expected type String
____________________ TestColumnSubstr.test_substr_in_select ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:202: in test_substr_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_________ TestColumnOrderingNulls.test_all_four_methods_comprehensive __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:552: in test_all_four_methods_comprehensive
    assert rows1[1]["value"] == "M"
E   AssertionError: assert 'A' == 'M'
E     
E     - M
E     + A
_____________ TestWithField.test_withfield_with_complex_expression _____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:597: in test_withfield_with_complex_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
____________ TestColumnOrderingNulls.test_desc_nulls_last_integers _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:156: in test_desc_nulls_last_integers
    assert rows[0]["age"] == 35
E   assert 25 == 35
____________ TestStringArithmetic.test_string_arithmetic_in_select _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_string_arithmetic.py:424: in test_string_arithmetic_in_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'string_1' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
___ TestUnionTypeCoercionParityRobust.test_pyspark_parity_exact_output_match ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:774: in test_pyspark_parity_exact_output_match
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
_____________ TestWithField.test_withfield_multiple_nested_structs _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1282: in test_withfield_multiple_nested_structs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________ TestUnionTypeCoercionParity.test_pyspark_parity_string_int64 _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:319: in test_pyspark_parity_string_int64
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
__________________ TestColumnSubstr.test_substr_in_withColumn __________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:224: in test_substr_in_withColumn
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
____________ TestColumnOrderingNulls.test_desc_nulls_last_no_nulls _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:198: in test_desc_nulls_last_no_nulls
    assert rows[0]["value"] == "C"
E   AssertionError: assert 'A' == 'C'
E     
E     - C
E     + A
_ TestUnionTypeCoercionParityRobust.test_pyspark_parity_float_string_decimal_values _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:852: in test_pyspark_parity_float_string_decimal_values
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1.5, value=A), Row(key=2.7, value=B)])
______________ TestColumnOrderingNulls.test_three_column_ordering ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:634: in test_three_column_ordering
    assert rows[2]["col1"] == "B"
E   AssertionError: assert None == 'B'
_ TestUnionTypeCoercionParity.test_pyspark_parity_multiple_numeric_string_columns _
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:341: in test_pyspark_parity_multiple_numeric_string_columns
    assert len(rows) == 2
E   assert 1 == 2
E    +  where 1 = len([Row(key=1, other=A, value=10)])
___________ TestWithField.test_withfield_with_conditional_expression ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:635: in test_withfield_with_conditional_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type CaseWhen is not JSON serializable
____________ TestWithField.test_withfield_very_deeply_nested_struct ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1362: in test_withfield_very_deeply_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________ TestColumnOrderingNulls.test_desc_nulls_last_multiple_nulls __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:221: in test_desc_nulls_last_multiple_nulls
    assert rows[0]["value"] == "C"
E   AssertionError: assert 'A' == 'C'
E     
E     - C
E     + A
_________ TestUnionTypeCoercionParity.test_pyspark_parity_null_values __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:361: in test_pyspark_parity_null_values
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1, value=A), Row(key=None, value=B)])
__________ TestColumnOrderingNulls.test_string_comparison_edge_cases ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:657: in test_string_comparison_edge_cases
    assert rows[-1]["value"] is None
E   AssertionError: assert 'A' is None
____________________ TestColumnSubstr.test_substr_in_filter ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:244: in test_substr_in_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_ TestUnionTypeCoercionParityRobust.test_pyspark_parity_multiple_columns_comprehensive _
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:923: in test_pyspark_parity_multiple_columns_comprehensive
    assert len(rows) == 2
E   assert 1 == 2
E    +  where 1 = len([Row(col1=1, col2=10.5, col3=A, col4=100)])
_______ TestStringArithmetic.test_string_arithmetic_with_when_otherwise ________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_string_arithmetic.py:489: in test_string_arithmetic_with_when_otherwise
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
_________ TestColumnOrderingNulls.test_asc_nulls_first_multiple_nulls __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:246: in test_asc_nulls_first_multiple_nulls
    assert rows[0]["value"] is None
E   AssertionError: assert 'A' is None
____________ TestColumnOrderingNulls.test_complex_ordering_scenario ____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:690: in test_complex_ordering_scenario
    assert rows[0]["dept"] == "HR"
E   AssertionError: assert 'IT' == 'HR'
E     
E     - HR
E     + IT
_______________ TestWithField.test_withfield_with_cast_operation _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:678: in test_withfield_with_cast_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
___________________ TestColumnSubstr.test_substr_in_orderBy ____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:266: in test_substr_in_orderBy
    assert rows[0]["name"] == "Alice"  # 'A'
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert 'Charlie' == 'Alice'
E     
E     - Alice
E     + Charlie
_________ TestUnionTypeCoercionEdgeCases.test_union_double_with_string _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:424: in test_union_double_with_string
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=123.456, value=A), Row(key=789.012, value=B)])
___ TestUnionTypeCoercionParityRobust.test_pyspark_parity_order_preservation ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:955: in test_pyspark_parity_order_preservation
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
________ TestStringArithmetic.test_string_arithmetic_chained_with_cast _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_string_arithmetic.py:507: in test_string_arithmetic_chained_with_cast
    assert rows[0]["result"] == 5  # 10.5 / 2 = 5.25, cast to int = 5
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert None == 5
____ TestIssue189StringFunctionsRobust.test_xxhash64_known_values_and_null _____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:131: in test_xxhash64_known_values_and_null
    rows = df.select(F.xxhash64("s").alias("h")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: xxhash64
________ TestColumnOrderingNulls.test_desc_nulls_last_with_sort_method _________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:271: in test_desc_nulls_last_with_sort_method
    assert rows[0]["value"] == "D"
E   AssertionError: assert 'A' == 'D'
E     
E     - D
E     + A
_________ TestColumnOrderingNulls.test_ordering_with_duplicate_values __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:717: in test_ordering_with_duplicate_values
    assert rows[0]["value"] == "B"
E   AssertionError: assert 'A' == 'B'
E     
E     - B
E     + A
_____________ TestWithField.test_withfield_nested_struct_with_null _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1418: in test_withfield_nested_struct_with_null
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________ TestUnionTypeCoercionEdgeCases.test_union_float_with_double __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:457: in test_union_float_with_double
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=1.5, value=A), Row(key=2.5, value=B)])
___________ TestWithField.test_withfield_replace_with_different_type ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:711: in test_withfield_replace_with_different_type
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
__________ TestColumnOrderingNulls.test_ordering_with_identical_nulls __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:751: in test_ordering_with_identical_nulls
    assert rows[0]["col2"] is None  # nulls first in col2
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   assert 1 is None
____________ TestColumnSubstr.test_substr_equals_substring_function ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:284: in test_substr_equals_substring_function
    rows_substr = result_substr.collect()
                  ^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_ TestIssue189StringFunctionsRobust.test_get_json_object_missing_path_and_invalid_json _
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:150: in test_get_json_object_missing_path_and_invalid_json
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: get_json_object
_____ TestUnionTypeCoercionParityRobust.test_pyspark_parity_large_dataset ______
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:1056: in test_pyspark_parity_large_dataset
    assert len(rows) == 20
E   assert 10 == 20
E    +  where 10 = len([Row(key=0, value=A0), Row(key=1, value=A1), Row(key=2, value=A2), Row(key=3, value=A3), Row(key=4, value=A4), Row(key=5, value=A5), ...])
__________ TestUnionTypeCoercionEdgeCases.test_union_negative_numbers __________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_union_type_coercion.py:477: in test_union_negative_numbers
    assert len(rows) == 4
E   assert 2 == 4
E    +  where 2 = len([Row(key=-1, value=A), Row(key=-2, value=B)])
____________ TestColumnOrderingNulls.test_multiple_columns_ordering ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:341: in test_multiple_columns_ordering
    assert rows[2]["category"] == "B"
E   AssertionError: assert None == 'B'
____________ TestWithField.test_withfield_nested_struct_arithmetic _____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1470: in test_withfield_nested_struct_arithmetic
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
____________ TestColumnOrderingNulls.test_mixed_data_types_ordering ____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:788: in test_mixed_data_types_ordering
    assert rows[1]["name"] == "Bob"
E   AssertionError: assert None == 'Bob'
______________ TestColumnOrderingNulls.test_desc_nulls_last_float ______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:364: in test_desc_nulls_last_float
    assert abs(rows[0]["score"] - 4.67) < 0.01
E   assert 1.5299999999999998 < 0.01
E    +  where 1.5299999999999998 = abs((3.14 - 4.67))
___________ TestWithField.test_withfield_multiple_fields_in_sequence ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:738: in test_withfield_multiple_fields_in_sequence
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_______________ TestColumnSubstr.test_substr_chained_operations ________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:304: in test_substr_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_________ TestColumnOrderingParity.test_pyspark_desc_nulls_last_parity _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:821: in test_pyspark_desc_nulls_last_parity
    assert rows[1]["value"] == "M"
E   AssertionError: assert 'A' == 'M'
E     
E     - M
E     + A
_ TestIssue189StringFunctionsRobust.test_json_tuple_missing_fields_and_invalid_json _
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:178: in test_json_tuple_missing_fields_and_invalid_json
    out = df.select(F.json_tuple("j", "name", "age")).collect()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: json_tuple
________ TestColumnOrderingNulls.test_desc_nulls_last_negative_numbers _________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:389: in test_desc_nulls_last_negative_numbers
    assert rows[0]["temp"] == 10
E   assert -5 == 10
__________________ TestWithField.test_withfield_add_new_field __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:70: in test_withfield_add_new_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
________ TestColumnOrderingParity.test_pyspark_desc_nulls_first_parity _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:857: in test_pyspark_desc_nulls_first_parity
    assert rows[0]["value"] is None
E   AssertionError: assert 'Z' is None
____________ TestWithField.test_withfield_nested_struct_conditional ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1518: in test_withfield_nested_struct_conditional
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:51: in execute_plan_via_robin
    plan_json = json.dumps(list(logical_plan))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/__init__.py:231: in dumps
    return _default_encoder.encode(obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:258: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
../../../.pyenv/versions/3.11.13/lib/python3.11/json/encoder.py:180: in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
E   TypeError: Object of type CaseWhen is not JSON serializable
________________ TestWithField.test_withfield_with_null_literal ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:769: in test_withfield_with_null_literal
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
__________________ TestColumnSubstr.test_substr_empty_string ___________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:322: in test_substr_empty_string
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
_ TestIssue189StringFunctionsRobust.test_regexp_extract_all_multiple_matches_and_nulls _
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:217: in test_regexp_extract_all_multiple_matches_and_nulls
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract_all
_________ TestColumnOrderingParity.test_pyspark_asc_nulls_last_parity __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:888: in test_pyspark_asc_nulls_last_parity
    assert rows[0]["value"] == "A"
E   AssertionError: assert 'Z' == 'A'
E     
E     - A
E     + Z
______________ TestUDFBasicOperations.test_udf_string_return_type ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:22: in test_udf_string_return_type
    result = df.withColumn("upper_text", upper_udf(F.col("text"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
____________________ TestUDFEdgeCases.test_udf_empty_string ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:344: in test_udf_empty_string
    result = df.withColumn("length", length_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestWithField.test_withfield_nested_struct_with_outer_column _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1567: in test_withfield_nested_struct_with_outer_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
________________ TestWithField.test_withfield_with_array_field _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:798: in test_withfield_with_array_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_____________ TestWithField.test_withfield_replace_existing_field ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:125: in test_withfield_replace_existing_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________ TestColumnOrderingParity.test_pyspark_asc_nulls_first_parity _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:913: in test_pyspark_asc_nulls_first_parity
    assert rows[0]["value"] is None
E   AssertionError: assert 'Z' is None
_____________________ TestColumnSubstr.test_substr_unicode _____________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:340: in test_substr_unicode
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
__________ TestColumnOrderingNulls.test_nulls_at_beginning_middle_end __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:448: in test_nulls_at_beginning_middle_end
    assert rows1[0]["value"] == "B"
E   AssertionError: assert None == 'B'
_____________ TestUDFBasicOperations.test_udf_integer_return_type ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:37: in test_udf_integer_return_type
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________________ test_regexp_extract_all_basic_groups _____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_regexp_extract_all_189.py:19: in test_regexp_extract_all_basic_groups
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract_all
__________ TestColumnOrderingParity.test_pyspark_multi_column_parity ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:951: in test_pyspark_multi_column_parity
    assert rows[0]["col2"] is None
E   assert 2 is None
_____________________ TestUDFEdgeCases.test_udf_zero_value _____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:359: in test_udf_zero_value
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_______________ TestColumnOrderingNulls.test_unicode_characters ________________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:482: in test_unicode_characters
    assert rows[3]["value"] is None
E   AssertionError: assert '' is None
________ TestWithField.test_withfield_nested_struct_chained_operations _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1636: in test_withfield_nested_struct_chained_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_____________ TestWithField.test_withfield_with_column_expression ______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:169: in test_withfield_with_column_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________________ TestColumnSubstr.test_substr_negative_start __________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_column_substr.py:369: in test_substr_negative_start
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
______________ TestWithField.test_withfield_combined_with_filter _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:828: in test_withfield_combined_with_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
________ TestColumnOrderingParity.test_pyspark_integer_ordering_parity _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:981: in test_pyspark_integer_ordering_parity
    assert rows[1]["value"] == 0
E   assert -5 == 0
______________ TestUDFBasicOperations.test_udf_double_return_type ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:52: in test_udf_double_return_type
    result = df.withColumn("doubled", double_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestUDFComplexScenarios.test_udf_chained_operations ______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:383: in test_udf_chained_operations
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestColumnOrderingParity.test_pyspark_float_ordering_parity __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_column_ordering.py:1004: in test_pyspark_float_ordering_parity
    assert abs(rows[0]["value"] - 3.14) < 0.01
E   assert 1.6400000000000001 < 0.01
E    +  where 1.6400000000000001 = abs((1.5 - 3.14))
______ TestWithField.test_withfield_nested_struct_reference_other_nested _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1689: in test_withfield_nested_struct_reference_other_nested
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
______________ TestWithField.test_withfield_combined_with_select _______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:867: in test_withfield_combined_with_select
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
____________ TestWithField.test_withfield_with_computed_expression _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:210: in test_withfield_with_computed_expression
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_____________ TestUDFBasicOperations.test_udf_boolean_return_type ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:67: in test_udf_boolean_return_type
    result = df.withColumn("is_adult", is_adult_udf(F.col("age"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________________ TestUDFComplexScenarios.test_udf_with_literal _________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:405: in test_udf_with_literal
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_______ TestDateTruncPolarsBackend.test_date_trunc_month_on_date_column ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_date_trunc_polars_backend.py:43: in test_date_trunc_month_on_date_column
    rows = df_truncated.collect()
           ^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
_________________ TestUDFMultiArgument.test_udf_two_arguments __________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:96: in test_udf_two_arguments
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________ TestUDFComplexScenarios.test_udf_multiple_columns_same_udf __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:421: in test_udf_multiple_columns_same_udf
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestIssue189StringFunctionsRobust.test_translate_edge_cases __________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:37: in test_translate_edge_cases
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: translate
________________ TestWithField.test_withfield_all_null_structs _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:912: in test_withfield_all_null_structs
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: withField
________________ TestWithField.test_withfield_multiple_chained _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:254: in test_withfield_multiple_chained
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
___________ TestDateTruncRobust.test_date_trunc_timestamp_core_units ___________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_date_trunc_robust.py:53: in test_date_trunc_timestamp_core_units
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: date_trunc
________________ TestUDFMultiArgument.test_udf_three_arguments _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:120: in test_udf_three_arguments
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestUDFComplexScenarios.test_udf_in_orderBy __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:445: in test_udf_in_orderBy
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______ TestIssue189StringFunctionsRobust.test_substring_index_edge_cases _______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:73: in test_substring_index_edge_cases
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: substring_index
___________________ TestWithField.test_withfield_null_struct ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:292: in test_withfield_null_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________________ TestWithField.test_withfield_empty_dataframe _________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:937: in test_withfield_empty_dataframe
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: withField
__________________ TestUDFMultiArgument.test_udf_mixed_types ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:146: in test_udf_mixed_types
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
____________ TestUDFWithDifferentDataTypes.test_udf_with_long_type _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:466: in test_udf_with_long_type
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______________ TestDateTruncRobust.test_date_trunc_on_date_column ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_date_trunc_robust.py:106: in test_date_trunc_on_date_column
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: date_trunc
____________ TestComplexMergeBasic.test_merge_multiple_when_matched ____________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:72: in test_merge_multiple_when_matched
    spark.sql("CREATE TABLE test_db.target2 (id INT, value INT, status STRING)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target2", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "status", quote_style: None }, data_type: String(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:102: in test_merge_multiple_when_matched
    spark.sql("DROP TABLE IF EXISTS test_db.target2")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__ TestIssue189StringFunctionsRobust.test_levenshtein_nulls_and_empty_strings __
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:107: in test_levenshtein_nulls_and_empty_strings
    rows = df.select(F.levenshtein("a", "b").alias("d")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: levenshtein
______________________ test_create_table_as_select_basic _______________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_create_table_as_select.py:31: in test_create_table_as_select_basic
    spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: true, transient: false, name: ObjectName([Ident { value: "it_employees_ctas", quote_style: None }]), columns: [], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: Some(Query { with: None, body: Select(Select { distinct: None, top: None, projection: [UnnamedExpr(Identifier(Ident { value: "name", quote_style: None })), UnnamedExpr(Identifier(Ident { value: "age", quote_style: None }))], into: None, from: [TableWithJoins { relation: Table { name: ObjectName([Ident { value: "employees_ctas", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }], lateral_views: [], selection: Some(BinaryOp { left: Identifier(Ident { value: "dept", quote_style: None }), op: Eq, right: Value(SingleQuotedString("IT")) }), group_by: Expressions([]), cluster_by: [], distribute_by: [], sort_by: [], having: None, named_window: [], qualify: None, value_table_mode: None }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_create_table_as_select.py:45: in test_create_table_as_select_basic
    spark.sql("DROP TABLE IF EXISTS employees_ctas")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_______________ TestUDFInDifferentOperations.test_udf_in_select ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:169: in test_udf_in_select
    .collect()
     ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________________ TestWithField.test_withfield_issue_235_example ________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:333: in test_withfield_issue_235_example
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
__________ TestWithField.test_withfield_reference_other_struct_field ___________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:977: in test_withfield_reference_other_struct_field
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________________________ test_robin_sql_simple_select _________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/robin/test_robin_sql.py:25: in test_robin_sql_simple_select
    out = spark.sql("SELECT id, v FROM t_robin_sql WHERE v >= 20 ORDER BY id").collect()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 't_robin_sql' not found. Register it with create_or_replace_temp_view or saveAsTable.
______________ TestComplexMergeBasic.test_merge_first_clause_wins ______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:108: in test_merge_first_clause_wins
    spark.sql("CREATE TABLE test_db.target3 (id INT, value INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target3", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:128: in test_merge_first_clause_wins
    spark.sql("DROP TABLE IF EXISTS test_db.target3")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____________ TestUDFWithDifferentDataTypes.test_udf_with_float_type ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:484: in test_udf_with_float_type
    result = df.withColumn("doubled", double_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______ TestDescribeDetail.test_describe_detail_matches_delta_table_detail ______
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:138: in test_describe_detail_matches_delta_table_detail
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_parity")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________ TestDateTruncRobust.test_date_trunc_preserves_nulls ______________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_date_trunc_robust.py:131: in test_date_trunc_preserves_nulls
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: date_trunc
_________________________ test_robin_sql_group_by_agg __________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/robin/test_robin_sql.py:42: in test_robin_sql_group_by_agg
    out = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 't_robin_agg' not found. Register it with create_or_replace_temp_view or saveAsTable.
______________________________ test_cte_with_join ______________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_cte_robust.py:33: in test_cte_with_join
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:63: in test_cte_with_join
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
________ TestIssue189StringFunctionsRobust.test_soundex_null_and_empty _________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:116: in test_soundex_null_and_empty
    rows = df.select(F.soundex("s").alias("sx")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: soundex
_____________ TestUDFInDifferentOperations.test_udf_in_withColumn ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:183: in test_udf_in_withColumn
    result = df.withColumn("name_upper", upper_udf(F.col("name"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________________ TestUDFCustomName.test_udf_with_custom_name __________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:505: in test_udf_with_custom_name
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________ TestDescribeDetail.test_describe_detail_partition_columns ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:209: in test_describe_detail_partition_columns
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_partitioned")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____ TestMergeNotMatchedBySource.test_merge_delete_not_matched_by_source ______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:139: in test_merge_delete_not_matched_by_source
    spark.sql("CREATE TABLE test_db.target3 (id INT, value INT, org_id STRING)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target3", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "org_id", quote_style: None }, data_type: String(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:173: in test_merge_delete_not_matched_by_source
    spark.sql("DROP TABLE IF EXISTS test_db.target3")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______________ TestWithField.test_withfield_different_data_types _______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:387: in test_withfield_different_data_types
    rows = result_int.collect()
           ^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
______________ TestWithField.test_withfield_with_string_functions ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1008: in test_withfield_with_string_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
___________ TestComplexMergeBasic.test_merge_with_matched_condition ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:27: in test_merge_with_matched_condition
    spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "updated_at", quote_style: None }, data_type: String(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:63: in test_merge_with_matched_condition
    spark.sql("DROP TABLE IF EXISTS test_db.target")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________ TestDescribeDetail.test_describe_detail_empty_table ______________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:233: in test_describe_detail_empty_table
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_empty")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________________________ test_cte_with_multiple_joins _________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_cte_robust.py:88: in test_cte_with_multiple_joins
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:110: in test_cte_with_multiple_joins
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_______________ TestUDFInDifferentOperations.test_udf_in_filter ________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:204: in test_udf_in_filter
    result = df.filter(is_adult_udf(F.col("age"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_________ TestUDFRegression279.test_udf_with_withColumn_regression_279 _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:529: in test_udf_with_withColumn_regression_279
    rows = df2.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______ TestIssue189StringFunctionsRobust.test_crc32_known_values_and_null ______
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_issue_189_string_functions_robust.py:123: in test_crc32_known_values_and_null
    rows = df.select(F.crc32("s").alias("c")).collect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: crc32
__ TestMergeNotMatchedBySource.test_merge_not_matched_by_source_no_condition ___
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:179: in test_merge_not_matched_by_source_no_condition
    spark.sql("CREATE TABLE test_db.target4 (id INT, value INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target4", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:202: in test_merge_not_matched_by_source_no_condition
    spark.sql("DROP TABLE IF EXISTS test_db.target4")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______ TestDescribeDetail.test_describe_detail_special_characters_in_name ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:492: in test_describe_detail_special_characters_in_name
    spark_with_delta.sql(f"DROP TABLE IF EXISTS {table_name}")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________ TestDescribeDetail.test_describe_detail_nonexistent_table ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:271: in test_describe_detail_nonexistent_table
    spark_with_delta.sql("DROP TABLE IF EXISTS test_nonexistent_detail")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________ TestWithField.test_withfield_chained_multiple_times ______________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1037: in test_withfield_chained_multiple_times
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: withField
___________________ test_udf_with_withColumn_regression_279 ____________________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_regression_279.py:19: in test_udf_with_withColumn_regression_279
    rows = df2.collect()
           ^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________________ TestWithField.test_withfield_nested_struct __________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:444: in test_withfield_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
___________________________ test_cte_with_left_join ____________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_cte_robust.py:130: in test_cte_with_left_join
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:147: in test_cte_with_left_join
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________ TestUDFInDifferentOperations.test_udf_in_groupBy_aggregation _________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:229: in test_udf_in_groupBy_aggregation
    .agg(F.sum("value_doubled").alias("total_doubled"))
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
________ TestMergeComplexExpressions.test_merge_with_expression_in_set _________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:213: in test_merge_with_expression_in_set
    spark.sql("CREATE TABLE test_db.target4 (id INT, value INT, version INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target4", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "version", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:234: in test_merge_with_expression_in_set
    spark.sql("DROP TABLE IF EXISTS test_db.target4")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___________ TestDescribeDetail.test_describe_detail_multiple_writes ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:289: in test_describe_detail_multiple_writes
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_multiple")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________ TestDescribeDetail.test_describe_detail_large_table ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:510: in test_describe_detail_large_table
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_large")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___________ TestWithField.test_withfield_with_arithmetic_operations ____________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1068: in test_withfield_with_arithmetic_operations
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
__________________________ test_cte_with_where_clause __________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_cte_robust.py:166: in test_cte_with_where_clause
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:191: in test_cte_with_where_clause
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________________ TestUDFNullHandling.test_udf_with_null_input _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:259: in test_udf_with_null_input
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
______ TestMergeComplexExpressions.test_merge_with_arithmetic_expression _______
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:240: in test_merge_with_arithmetic_expression
    spark.sql("CREATE TABLE test_db.target5 (id INT, count INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target5", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "count", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:258: in test_merge_with_arithmetic_expression
    spark.sql("DROP TABLE IF EXISTS test_db.target5")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________________ TestWithField.test_withfield_empty_struct ___________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:471: in test_withfield_empty_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_________ TestDescribeDetail.test_describe_detail_different_data_types _________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:530: in test_describe_detail_different_data_types
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_types")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
____________ TestDescribeDetail.test_describe_detail_complex_schema ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:326: in test_describe_detail_complex_schema
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_complex")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
________________ TestUDFNullHandling.test_udf_with_null_return _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:277: in test_udf_with_null_return
    result = df.withColumn("result", safe_divide_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
__________ TestWithField.test_withfield_preserves_all_existing_fields __________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:1105: in test_withfield_preserves_all_existing_fields
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
_____________________ test_cte_with_aggregation_after_join _____________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_cte_robust.py:210: in test_cte_with_aggregation_after_join
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:234: in test_cte_with_aggregation_after_join
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___________________________ test_sql_in_clause_basic ___________________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_in_clause.py:11: in test_sql_in_clause_basic
    result = spark.sql("SELECT * FROM in_unit_test WHERE age IN (25, 35)")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'in_unit_test' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_in_clause.py:16: in test_sql_in_clause_basic
    spark.sql("DROP TABLE IF EXISTS in_unit_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________ TestDescribeDetail.test_describe_detail_all_required_columns _________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:374: in test_describe_detail_all_required_columns
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_columns")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
________________ TestWithField.test_withfield_replace_then_add _________________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:510: in test_withfield_replace_then_add
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
___________________ TestMergeInsertAll.test_merge_insert_all ___________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:269: in test_merge_insert_all
    spark.sql("CREATE TABLE test_db.target5 (id INT, value INT, name STRING)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target5", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "name", quote_style: None }, data_type: String(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:296: in test_merge_insert_all
    spark.sql("DROP TABLE IF EXISTS test_db.target5")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________________ TestUDFEdgeCases.test_udf_empty_dataframe ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:300: in test_udf_empty_dataframe
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___________________________ test_cte_with_self_join ____________________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_cte_robust.py:247: in test_cte_with_self_join
    result = spark.sql(
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_cte_robust.py:268: in test_cte_with_self_join
    spark.sql("DROP TABLE IF EXISTS employees")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________________ test_sql_like_simple_prefix_pattern ______________________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_like_clause.py:9: in test_sql_like_simple_prefix_pattern
    result = spark.sql("SELECT * FROM like_unit_test WHERE name LIKE 'A%'")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: Table or view 'like_unit_test' not found. Register it with create_or_replace_temp_view or saveAsTable.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_like_clause.py:14: in test_sql_like_simple_prefix_pattern
    spark.sql("DROP TABLE IF EXISTS like_unit_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________ TestDescribeDetail.test_describe_detail_multiple_partitions __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:409: in test_describe_detail_multiple_partitions
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_multi_partition")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
___________________________ test_update_table_basic ____________________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_update.py:28: in test_update_table_basic
    spark.sql("UPDATE update_test SET age = 26 WHERE name = 'Alice'")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Update { table: TableWithJoins { relation: Table { name: ObjectName([Ident { value: "update_test", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }, assignments: [Assignment { id: [Ident { value: "age", quote_style: None }], value: Value(Number("26", false)) }], from: None, selection: Some(BinaryOp { left: Identifier(Ident { value: "name", quote_style: None }), op: Eq, right: Value(SingleQuotedString("Alice")) }), returning: None }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_update.py:40: in test_update_table_basic
    spark.sql("DROP TABLE IF EXISTS update_test")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________________ TestUDFEdgeCases.test_udf_single_row _____________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:313: in test_udf_single_row
    result = df.withColumn("upper", upper_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
_____________ TestMergeInsertAll.test_merge_insert_only_unmatched ______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:302: in test_merge_insert_only_unmatched
    spark.sql("CREATE TABLE test_db.target6 (id INT, value INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target6", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:328: in test_merge_insert_only_unmatched
    spark.sql("DROP TABLE IF EXISTS test_db.target6")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
________________ TestDescribeDetail.test_describe_detail_basic _________________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:51: in test_describe_detail_basic
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_basic")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
______________ TestWithField.test_withfield_deeply_nested_struct _______________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/dataframe/test_withfield.py:560: in test_withfield_deeply_nested_struct
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: struct value must be object or array
___________ TestDescribeDetail.test_describe_detail_table_properties ___________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:434: in test_describe_detail_table_properties
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_properties")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________ TestDescribeDetail.test_describe_detail_with_schema ______________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:73: in test_describe_detail_with_schema
    spark_with_delta.sql("CREATE DATABASE IF NOT EXISTS test_schema_detail")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________________ TestUDFEdgeCases.test_udf_large_dataframe ___________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/functions/test_udf_comprehensive.py:328: in test_udf_large_dataframe
    result = df.withColumn("squared", square_udf(F.col("value"))).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
___________________ TestMergeEdgeCases.test_merge_no_matches ___________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:339: in test_merge_no_matches
    spark.sql("CREATE TABLE test_db.target7 (id INT, value INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target7", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:363: in test_merge_no_matches
    spark.sql("DROP TABLE IF EXISTS test_db.target7")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_________ TestDescribeDetail.test_describe_detail_overwrite_operation __________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:464: in test_describe_detail_overwrite_operation
    spark_with_delta.sql("DROP TABLE IF EXISTS test_detail_overwrite")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
________ TestDescribeDetail.test_describe_detail_non_delta_table_raises ________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_describe_detail.py:91: in test_describe_detail_non_delta_table_raises
    spark_with_delta.sql("DROP TABLE IF EXISTS test_non_delta")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
__________________ TestMergeEdgeCases.test_merge_empty_source __________________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:369: in test_merge_empty_source
    spark.sql("CREATE TABLE test_db.target8 (id INT, value INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target8", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:388: in test_merge_empty_source
    spark.sql("DROP TABLE IF EXISTS test_db.target8")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_ TestArrayParameterFormats.test_array_with_special_characters_in_column_names _
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:461: in test_array_with_special_characters_in_column_names
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_____ TestArrayTypeRobust.test_array_type_elementtype_with_union_operation _____
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/spark_types/test_array_type_robust.py:382: in test_array_type_elementtype_with_union_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___________ TestArrayParameterFormats.test_array_with_column_objects ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:64: in test_array_with_column_objects
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
____________ TestArrayParameterFormats.test_array_with_null_values _____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:202: in test_array_with_null_values
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
______________ TestMergeEdgeCases.test_merge_all_matched_deleted _______________
[gw4] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/session/test_sql_complex_merge.py:394: in test_merge_all_matched_deleted
    spark.sql("CREATE TABLE test_db.target9 (id INT, value INT)")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:318: in _real_sql
    rows = robin_native.execute_sql_via_robin(query)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/native.py:64: in execute_sql_via_robin
    result = _native.sql(query)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^
E   ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: false, transient: false, name: ObjectName([Ident { value: "test_db", quote_style: None }, Ident { value: "target9", quote_style: None }]), columns: [ColumnDef { name: Ident { value: "id", quote_style: None }, data_type: Int(None), collation: None, options: [] }, ColumnDef { name: Ident { value: "value", quote_style: None }, data_type: Int(None), collation: None, options: [] }], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: None, without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.

During handling of the above exception, another exception occurred:
tests/unit/session/test_sql_complex_merge.py:413: in test_merge_all_matched_deleted
    spark.sql("DROP TABLE IF EXISTS test_db.target9")
sparkless/session/core/session.py:294: in sql
    return self._sql_impl(query, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:319: in _real_sql
    df = self._real_createDataFrame(rows)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/session/core/session.py:205: in _real_createDataFrame
    df = self._dataframe_factory.create_dataframe(
sparkless/session/services/dataframe_factory.py:204: in create_dataframe
    raise ValueError("can not infer schema from empty dataset")
E   ValueError: can not infer schema from empty dataset
_____________ TestArrayParameterFormats.test_array_preserves_order _____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:472: in test_array_preserves_order
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________ TestArrayParameterFormats.test_array_in_groupby_context ____________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:333: in test_array_in_groupby_context
    result = df_with_array.groupBy("dept").agg(F.count("name").alias("count"))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/grouped/base.py:152: in agg
    self.df = self.df._materialize_if_lazy()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_______ TestArrayParameterFormats.test_array_with_list_of_column_objects _______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:79: in test_array_with_list_of_column_objects
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
__________ TestArrayParameterFormats.test_array_with_all_null_columns __________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:226: in test_array_with_all_null_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________ TestArrayParameterFormats.test_array_with_empty_strings ____________
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:482: in test_array_with_empty_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_________________ TestArrayParameterFormats.test_array_in_join _________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:348: in test_array_in_join
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
__________ TestArrayParameterFormats.test_array_all_formats_together ___________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:99: in test_array_all_formats_together
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________ TestArrayParameterFormats.test_array_with_numeric_types ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:244: in test_array_with_numeric_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_____ TestArrayParameterFormats.test_array_with_zero_and_negative_numbers ______
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:491: in test_array_with_zero_and_negative_numbers
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
__________ TestArrayParameterFormats.test_array_with_window_functions __________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:369: in test_array_with_window_functions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
____________ TestArrayParameterFormats.test_array_with_mixed_types _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:124: in test_array_with_mixed_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________ TestArrayParameterFormats.test_array_with_boolean_types ____________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:256: in test_array_with_boolean_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
______ TestArrayParameterFormats.test_array_all_formats_with_mixed_types _______
[gw0] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:515: in test_array_all_formats_with_mixed_types
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
______ TestArrayParameterFormats.test_array_with_large_number_of_columns _______
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:385: in test_array_with_large_number_of_columns
    rows1 = result1.collect()
            ^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________ TestArrayParameterFormats.test_array_with_single_column ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:139: in test_array_with_single_column
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
____ TestArrayTypeRobust.test_array_type_elementtype_with_select_operation _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/spark_types/test_array_type_robust.py:268: in test_array_type_elementtype_with_select_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_____ TestArrayParameterFormats.test_array_with_mixed_types_comprehensive ______
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:282: in test_array_with_mixed_types_comprehensive
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
________ TestArrayParameterFormats.test_array_with_computed_expressions ________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:400: in test_array_with_computed_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
___________ TestArrayParameterFormats.test_array_with_three_columns ____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:154: in test_array_with_three_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
____ TestArrayTypeRobust.test_array_type_elementtype_with_filter_operation _____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/spark_types/test_array_type_robust.py:296: in test_array_type_elementtype_with_filter_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
___________ TestArrayParameterFormats.test_array_in_select_statement ___________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:297: in test_array_in_select_statement
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
_________ TestArrayParameterFormats.test_array_with_nested_expressions _________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:422: in test_array_with_nested_expressions
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
__________ TestArrayParameterFormats.test_array_with_computed_columns __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:167: in test_array_with_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
______________ TestArrayParameterFormats.test_array_after_filter _______________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:316: in test_array_after_filter
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
____ TestArrayTypeRobust.test_array_type_elementtype_with_explode_operation ____
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/spark_types/test_array_type_robust.py:320: in test_array_type_elementtype_with_explode_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
___________ TestArrayParameterFormats.test_array_with_string_columns ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:34: in test_array_with_string_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
________________ TestArrayParameterFormats.test_array_in_union _________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:439: in test_array_in_union
    rows1 = df1_with_array.collect()
            ^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
______ TestArrayParameterFormats.test_array_with_list_of_computed_columns ______
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:178: in test_array_with_list_of_computed_columns
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
__________ TestArrayParameterFormats.test_array_with_list_of_strings ___________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_array_parameter_formats.py:49: in test_array_with_list_of_strings
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: array
__ TestArrayTypeRobust.test_array_type_elementtype_with_withcolumn_operation ___
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/spark_types/test_array_type_robust.py:341: in test_array_type_elementtype_with_withcolumn_operation
    rows = result.collect()
           ^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: array column value must be null or array
_________________ TestDataFrameFirst.test_first_after_orderby __________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_first_method.py:72: in test_first_after_orderby
    assert result["name"] == "Alice"
E   AssertionError: assert 'Charlie' == 'Alice'
E     
E     - Alice
E     + Charlie
___________________ TestDataFrameFirst.test_first_after_join ___________________
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_first_method.py:156: in test_first_after_join
    assert result is not None
E   assert None is not None
_________ TestIssue270TupleDataFrame.test_tuple_data_union_operations __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issue_270_tuple_dataframe.py:482: in test_tuple_data_union_operations
    assert unioned2.count() == 4
E   assert 2 == 4
E    +  where 2 = count()
E    +    where count = DataFrame[2 rows, 2 columns].count
_________ TestDataFrameFirst.test_first_after_multiple_transformations _________
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_first_method.py:238: in test_first_after_multiple_transformations
    .first()
     ^^^^^^^
sparkless/dataframe/dataframe.py:551: in first
    return self._display.first()
           ^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/services/display_service.py:293: in first
    materialized = self._df._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'age' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
__________ TestIssue270TupleDataFrame.test_tuple_data_join_operations __________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issue_270_tuple_dataframe.py:510: in test_tuple_data_join_operations
    assert joined.count() == 2
E   assert 0 == 2
E    +  where 0 = count()
E    +    where count = DataFrame[0 rows, 3 columns].count
_____________ TestIssue226IsinWithValues.test_isin_with_empty_list _____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:286: in test_isin_with_empty_list
    result = df.filter(F.col("value").isin([])).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
_____________ TestIssue226IsinWithValues.test_isin_with_star_args ______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:257: in test_isin_with_star_args
    result = df.filter(F.col("value").isin(2, 3)).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
______________ TestIssue227GetItem.test_getItem_with_array_index _______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:323: in test_getItem_with_array_index
    result = df.select(F.col("arr").getItem(0).alias("first")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
________________ TestIssue227GetItem.test_getItem_out_of_bounds ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:362: in test_getItem_out_of_bounds
    result = df.select(F.col("arr").getItem(10).alias("val")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_without_lookaround __
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:419: in test_regexp_extract_without_lookaround
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
__________ TestIssue225StringToNumericCoercion.test_numeric_eq_string __________
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:208: in test_numeric_eq_string
    result = df.filter(F.col("value") == "150").collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: cannot compare string with numeric type (i64)
___ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_with_lookbehind ___
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:393: in test_regexp_extract_with_lookbehind
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
________________ TestIssue226IsinWithValues.test_isin_with_list ________________
[gw9] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:247: in test_isin_with_list
    result = df.filter(F.col("value").isin([2, 3])).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
____________ TestIssue226IsinWithValues.test_isin_with_single_value ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:294: in test_isin_with_single_value
    result = df.filter(F.col("value").isin(2)).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
______________ TestIssue226IsinWithValues.test_isin_with_strings _______________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:266: in test_isin_with_strings
    result = df.filter(F.col("name").isin("Alice", "Bob")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
____ TestIssue230CaseInsensitiveColumnMatching.test_select_case_insensitive ____
[gw8] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:532: in test_select_case_insensitive
    assert result[0].Name == "Alice"  # Output uses original column name "Name"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: assert None == 'Alice'
E    +  where None = Row(Name=None).Name
______________ TestIssue227GetItem.test_getItem_with_split_result ______________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:335: in test_getItem_with_split_result
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_______________ TestIssue227GetItem.test_getItem_negative_index ________________
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:375: in test_getItem_negative_index
    result = df.select(F.col("arr").getItem(-1).alias("val")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
_ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_with_complex_lookaround _
[gw5] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:433: in test_regexp_extract_with_complex_lookaround
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
___ TestIssue228RegexLookAheadLookBehind.test_regexp_extract_with_lookahead ____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:406: in test_regexp_extract_with_lookahead
    ).collect()
      ^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
___________ TestIssue226IsinWithValues.test_isin_with_column_method ____________
[gw1] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:304: in test_isin_with_column_method
    result = df.filter(F.col("value").isin(2, 3)).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
____________ TestIssue226IsinWithValues.test_isin_with_mixed_types _____________
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:278: in test_isin_with_mixed_types
    result = df.filter(F.col("value").isin(1, 2)).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
________________ TestIssue227GetItem.test_getItem_with_map_key _________________
[gw2] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:350: in test_getItem_with_map_key
    result = df.select(F.col("map").getItem("key1").alias("val")).collect()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
___ TestIssue230CaseInsensitiveColumnMatching.test_orderBy_case_insensitive ____
[gw6] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:592: in test_orderBy_case_insensitive
    assert result[0].Age == 25
E   assert 30 == 25
E    +  where 30 = Row(Age=30, Name=Bob).Age
_____ TestIssue230CaseInsensitiveColumnMatching.test_drop_case_insensitive _____
[gw3] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:630: in test_drop_case_insensitive
    result = result_df.collect()
             ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: Robin execute_plan failed: session/df: not found: Column 'name' not found. Available columns: [Age, City]. Check spelling and case sensitivity (spark.sql.caseSensitive).
_____ TestIssue230CaseInsensitiveColumnMatching.test_join_case_insensitive _____
[gw7] darwin -- Python 3.11.13 /Users/odosmatthews/Documents/coding/sparkless/.venv/bin/python
tests/unit/test_issues_225_231.py:694: in test_join_case_insensitive
    result = result_df.collect()
             ^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:496: in collect
    materialized = self._materialize_if_lazy()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/dataframe.py:926: in _materialize_if_lazy
    result = cast("SupportsDataFrameOps", lazy_engine.materialize(self))
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/dataframe/lazy.py:484: in materialize
    rows = execute_via_robin(df.data, final_schema, df)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sparkless/robin/execution.py:46: in execute_via_robin
    result_rows: List[Dict[str, Any]] = _native.execute_plan_via_robin(
sparkless/robin/native.py:53: in execute_plan_via_robin
    result = _native._execute_plan(list(data), list(schema), plan_json)  # type: ignore[attr-defined]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   ValueError: collect_as_json_rows failed: not found: ID
E   
E   Resolved plan until failure:
E   
E   	---> FAILED HERE RESOLVING 'join' <---
E   DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.11.13-final-0 _______________

Name                                                                 Stmts   Miss  Cover   Missing
--------------------------------------------------------------------------------------------------
sparkless/__init__.py                                                   24      0   100%
sparkless/_version.py                                                    8      4    50%   10-12, 16-19
sparkless/compat/__init__.py                                             2      0   100%
sparkless/compat/datetime.py                                            74     53    28%   43, 55-57, 61-67, 73-81, 96-103, 115-122, 128-133, 141-146, 162-182
sparkless/config.py                                                     47     10    79%   31-43, 54, 63, 65, 91
sparkless/core/__init__.py                                               9      0   100%
sparkless/core/column_resolver.py                                       33      1    97%   71
sparkless/core/condition_evaluator.py                                  764    730     4%   27-34, 49-56, 71-245, 260-541, 556-576, 591-604, 619-781, 795-1203, 1218-1229, 1245-1274, 1290-1311, 1324-1340, 1353, 1366-1370, 1384-1403
sparkless/core/data_validation.py                                       80     41    49%   56-85, 91-113, 129, 136-137, 177-185, 205-206, 220-221
sparkless/core/ddl_adapter.py                                           31      8    74%   94, 98-106
sparkless/core/exceptions/__init__.py                                    6      0   100%
sparkless/core/exceptions/analysis.py                                  100     57    43%   51, 57, 91, 109, 142, 145-154, 170-202, 230-245, 269-272, 302-323
sparkless/core/exceptions/base.py                                       22      4    82%   31, 61, 76, 91
sparkless/core/exceptions/execution.py                                  29     13    55%   27, 45, 63, 87-90, 114-117, 135, 153
sparkless/core/exceptions/operation.py                                  87     64    26%   24-34, 49-58, 72-82, 96-106, 120-129, 152, 173-183, 197-206
sparkless/core/exceptions/py4j_compat.py                                10     10     0%   8-41
sparkless/core/exceptions/runtime.py                                    41     24    41%   53-57, 75, 101-107, 131-134, 158-161, 187-193
sparkless/core/exceptions/validation.py                                 44     24    45%   63, 81, 107-111, 141-147, 171-174, 202-207
sparkless/core/interfaces/__init__.py                                    5      0   100%
sparkless/core/interfaces/dataframe.py                                 180     56    69%   20, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 98, 103, 110, 115, 120, 125, 130, 136, 142, 151, 156, 161, 166, 171, 176, 181, 190, 195, 200, 205, 212, 217, 222, 227, 232, 241, 246, 251, 256, 261, 266, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320
sparkless/core/interfaces/functions.py                                 186     56    70%   23, 28, 33, 42, 47, 56, 61, 70, 75, 84, 89, 94, 99, 108, 113, 118, 123, 130, 135, 144, 149, 154, 159, 164, 173, 178, 185, 192, 197, 202, 207, 212, 221, 226, 231, 236, 241, 250, 255, 263, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 333, 338, 343, 348
sparkless/core/interfaces/session.py                                   117     34    71%   20, 26, 32, 38, 44, 50, 59, 64, 69, 76, 81, 86, 96, 101, 106, 115, 120, 125, 136, 141, 146, 151, 156, 161, 166, 171, 176, 185, 190, 195, 200, 209, 214, 219
sparkless/core/interfaces/storage.py                                   126     38    70%   29, 34, 39, 44, 54, 59, 64, 69, 76, 83, 90, 97, 102, 106, 110, 114, 120, 126, 136, 142, 148, 153, 158, 163, 168, 173, 186, 192, 198, 204, 210, 215, 220, 229, 234, 239, 248, 253
sparkless/core/protocols.py                                             42      0   100%
sparkless/core/safe_evaluator.py                                       125    116     7%   39-50, 63-67, 83-215
sparkless/core/schema_inference.py                                     106     25    76%   74, 132, 199, 218-237, 242-251, 256-265, 279-280, 297, 307
sparkless/core/type_utils.py                                            86     51    41%   20-21, 91-93, 117, 140-144, 164-168, 187-199, 223-259, 278, 290-292, 304
sparkless/core/types/__init__.py                                         4      0   100%
sparkless/core/types/data_types.py                                     139     38    73%   22, 27, 32, 37, 42, 47, 52, 57, 66, 76, 81, 91, 97, 102, 111, 121, 127, 132, 141, 146, 155, 160, 170, 175, 180, 190, 196, 201, 206, 211, 221, 226, 231, 240, 249, 254, 259, 264
sparkless/core/types/metadata.py                                       166     47    72%   18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 73, 79, 85, 91, 97, 103, 108, 113, 118, 128, 134, 140, 145, 150, 160, 166, 172, 177, 182, 187, 197, 203, 209, 215, 220, 225, 230, 239, 244, 249, 254, 259, 268, 273, 278, 283, 288
sparkless/core/types/schema.py                                         121     36    70%   22, 28, 34, 40, 45, 50, 55, 60, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 185, 190, 195, 200, 209, 214, 221, 226
sparkless/data_generation/__init__.py                                    4      4     0%   8-12
sparkless/data_generation/builder.py                                    28     28     0%   8-85
sparkless/data_generation/convenience.py                                 9      9     0%   8-64
sparkless/data_generation/generator.py                                 174    174     0%   8-337
sparkless/dataframe/__init__.py                                          6      0   100%
sparkless/dataframe/aggregations/__init__.py                             2      2     0%   8-10
sparkless/dataframe/aggregations/operations.py                          75     75     0%   8-208
sparkless/dataframe/assertions/__init__.py                               3      3     0%   7-10
sparkless/dataframe/assertions/assertions.py                            26     26     0%   8-88
sparkless/dataframe/assertions/operations.py                            16     16     0%   8-45
sparkless/dataframe/attribute_handler.py                                62      8    87%   176, 190-196, 223-224
sparkless/dataframe/casting/__init__.py                                  2      0   100%
sparkless/dataframe/casting/type_converter.py                           95     63    34%   54, 56-58, 62-64, 66, 69-92, 95-110, 132-153, 158-180
sparkless/dataframe/collection_handler.py                               29      9    69%   27-29, 36, 47-53, 81
sparkless/dataframe/condition_handler.py                                52     34    35%   58-64, 80, 109-122, 136-180
sparkless/dataframe/dataframe.py                                       513    158    69%   187-191, 219-224, 243, 262-265, 317, 377, 381, 394, 432, 440, 486, 490, 507-508, 524, 532, 555-561, 565, 569, 621, 625, 630, 634, 638, 642, 700, 709, 715, 719, 723, 727, 733, 742, 746, 750, 756, 760, 770, 780, 791, 803, 809, 813, 817, 821, 829, 835, 839, 843, 847, 852, 856, 860, 864, 875, 894, 960-969, 997, 1002, 1078-1097, 1103, 1152-1153, 1161-1162, 1201-1206, 1210, 1216, 1225, 1250, 1258, 1269, 1284, 1292, 1303, 1311, 1323, 1329, 1335, 1347-1353, 1368-1379, 1383, 1403-1411, 1420-1460
sparkless/dataframe/display/__init__.py                                  3      3     0%   3-6
sparkless/dataframe/display/formatter.py                                37     37     0%   3-57
sparkless/dataframe/display/operations.py                              118    118     0%   8-274
sparkless/dataframe/evaluation/__init__.py                               2      0   100%
sparkless/dataframe/evaluation/evaluators/__init__.py                    1      0   100%
sparkless/dataframe/evaluation/evaluators/conditional_evaluator.py      22      6    73%   42, 45, 57-63
sparkless/dataframe/evaluation/expression_evaluator.py                2614   2314    11%   97, 109, 112, 118-123, 129-131, 135, 146-147, 151, 155, 161-182, 194-260, 281-301, 308, 318-320, 323, 331-344, 351-394, 401, 407-417, 424, 433, 438-449, 459-1022, 1028-1067, 1073-1258, 1264-1341, 1348-1386, 1392-1443, 1449-1535, 1540-1556, 1563-1575, 1579-1594, 1598-1613, 1617-1632, 1636-1651, 1665, 1667, 1673, 1680, 1685, 1687, 1689-1694, 1945, 1949, 1953-1957, 1961-1965, 1969-1973, 1977-1990, 1994-2001, 2005-2015, 2019-2029, 2033-2035, 2041-2044, 2048-2051, 2055-2062, 2066-2071, 2086-2144, 2148-2153, 2164-2208, 2212-2223, 2227-2235, 2241-2243, 2247-2252, 2256-2258, 2262-2264, 2270, 2274-2280, 2284, 2288-2293, 2297-2299, 2303-2305, 2309, 2313, 2317, 2325, 2329, 2333-2336, 2340-2342, 2346-2351, 2355-2358, 2362-2374, 2381, 2385-2417, 2421-2426, 2430-2452, 2456-2478, 2484-2500, 2504-2535, 2541-2576, 2582-2589, 2593-2613, 2617-2660, 2664-2681, 2685-2698, 2703, 2707-2708, 2712, 2716, 2720, 2726-2735, 2739-2748, 2752-2759, 2765, 2769-2783, 2787-2794, 2798-2812, 2816-2823, 2827-2834, 2838-2845, 2849-2858, 2862-2871, 2875-2884, 2888-2895, 2899-2906, 2910-2917, 2921-2928, 2932-2939, 2945, 2949-2958, 2963, 2968, 2973-3005, 3009-3018, 3024, 3030, 3034-3045, 3051, 3058, 3063, 3069, 3074-3093, 3098, 3103, 3108, 3117-3149, 3153-3197, 3201-3245, 3249-3276, 3281-3302, 3310-3372, 3376-3383, 3387-3407, 3413, 3419, 3423-3538, 3543-3554, 3558-3567, 3571, 3575, 3579, 3583, 3587, 3591, 3595, 3599-3604, 3608-3614, 3618-3623, 3627-3632, 3641, 3655-3689, 3695, 3699-3706, 3710-3721, 3726-3735, 3741-3750, 3756-3761, 3767-3772, 3778-3786, 3792-3800, 3804, 3808-3814, 3818-3829, 3833-3836, 3840-3846, 3850-3852, 3857, 3862-3874, 3878, 3882-3888, 3892-3898, 3904-3914, 3918-3925, 3930, 3934-3936, 3940-3963, 3967-3990, 3995, 4000, 4005, 4010, 4015, 4020, 4024-4036, 4042-4049, 4055-4062, 4066-4075, 4081-4088, 4094-4101, 4107-4114, 4122-4136, 4140-4147, 4151-4158, 4163-4178, 4182-4197, 4217, 4222, 4227, 4233-4244, 4251-4254, 4260-4263, 4269-4274, 4279-4283, 4287-4304, 4310-4325, 4331-4346, 4352-4355, 4359-4361, 4366-4374, 4380-4407, 4412-4421, 4425-4427, 4431-4433, 4438-4457, 4461-4478, 4482-4499, 4503-4520, 4524-4529, 4535-4546, 4550-4561, 4565-4570
sparkless/dataframe/export.py                                           15     15     0%   8-46
sparkless/dataframe/grouped/__init__.py                                  5      0   100%
sparkless/dataframe/grouped/base.py                                   1064    602    43%   95, 103, 111-113, 115-117, 122-144, 181, 188, 192-196, 271, 302-307, 314-322, 328, 360, 367, 372-389, 419, 439-442, 465-466, 583-600, 609-624, 673-689, 711-722, 736-765, 802, 807-808, 810-811, 841-844, 851, 855-856, 873, 875-878, 880-881, 911-914, 921, 925-926, 954-955, 981-982, 995-1001, 1003-1009, 1027, 1050-1069, 1072-1089, 1103-1121, 1123-1143, 1145-1151, 1153-1159, 1162-1175, 1178-1191, 1195-1250, 1253-1259, 1267, 1271-1272, 1302-1647, 1709, 1715, 1720-1729, 1750, 1756, 1763, 1781, 1815, 1833-1841, 1843-1853, 1855-1865, 1867-1877, 1879-1889, 1894-1900, 1902-1908, 1911-1916, 1918-1924, 1926-1932, 1945-1952, 2003-2007, 2018-2025, 2036-2043, 2054-2063, 2074-2083, 2094-2103, 2114-2123, 2134-2143, 2154-2163, 2174-2201, 2212-2239, 2268, 2272-2279, 2303-2370, 2392-2447
sparkless/dataframe/grouped/cube.py                                     86     22    74%   68-74, 87-96, 123-129, 142-151, 166, 201-209
sparkless/dataframe/grouped/pivot.py                                   493    238    52%   101, 113-119, 142-174, 181-184, 205-215, 236-237, 254, 273-274, 279, 285-289, 291-328, 356, 362-397, 420, 422-425, 435, 437-440, 449-450, 486-492, 498, 531-544, 546-555, 565-641, 649-810, 825, 845, 878-882, 896, 916
sparkless/dataframe/grouped/rollup.py                                   87     22    75%   73-79, 90-99, 128-134, 147-156, 171, 206-214
sparkless/dataframe/joins/__init__.py                                    2      2     0%   8-10
sparkless/dataframe/joins/operations.py                                146    146     0%   8-396
sparkless/dataframe/lazy.py                                           1090   1024     6%   61-63, 75-108, 122-128, 143-213, 226-256, 268-292, 307-343, 357-370, 388-402, 408-444, 450-459, 472-474, 534-588, 598-681, 693-726, 739-750, 769-788, 803-904, 916-2009, 2022-2283, 2296-2352, 2367-2595, 2611-2623
sparkless/dataframe/logical_plan.py                                    276     57    79%   28, 34-35, 41-42, 82-83, 86-87, 92-93, 99-100, 120, 131, 152-159, 178-181, 231, 252, 258, 284, 309-320, 338, 342-343, 345-346, 360, 383-384, 391-393, 402-403, 468-473, 481-482, 491, 506-507, 520
sparkless/dataframe/operations/__init__.py                               2      0   100%
sparkless/dataframe/operations/aggregation_operations.py               128    128     0%   3-313
sparkless/dataframe/operations/join_operations.py                      157    157     0%   3-329
sparkless/dataframe/operations/misc.py                                 516    472     9%   56-77, 103-145, 167-215, 236-250, 267-308, 323-407, 421-501, 518-549, 566-593, 615-630, 643-659, 678-685, 710-742, 770-831, 863-922, 949-986, 1023-1074, 1082-1113, 1117-1135, 1149-1176, 1191-1196, 1216, 1232-1234, 1248-1255, 1266-1267, 1276, 1295-1304, 1323-1324, 1340-1345, 1353, 1366-1369, 1377, 1382, 1391-1392, 1401, 1415-1427
sparkless/dataframe/operations/set_operations.py                       168    140    17%   29-95, 100, 141, 161-291, 297-317, 323-340, 345-347
sparkless/dataframe/protocols.py                                        49      0   100%
sparkless/dataframe/rdd.py                                              83     40    52%   69-70, 118-120, 136-143, 155-166, 174, 185, 193, 201, 209, 217, 229, 240-243, 254-261, 269, 277
sparkless/dataframe/reader.py                                          194    108    44%   128-137, 163-181, 187, 193, 204, 221-274, 284-292, 296-303, 311, 314, 320-325, 331-366, 370-374, 378-381, 396, 415, 423-424, 435, 443, 458, 473, 490-492
sparkless/dataframe/schema/__init__.py                                   3      0   100%
sparkless/dataframe/schema/operations.py                                22      9    59%   23-31, 39-41, 46, 51
sparkless/dataframe/schema/schema_manager.py                           514    190    63%   49-75, 93, 136-151, 258, 293-304, 310-324, 361, 406, 453-465, 469-474, 482, 491, 493, 509-510, 514-517, 530, 563, 573, 591, 692-715, 722, 724, 728, 745, 747, 763-764, 768-771, 777, 788-798, 803-839, 843-846, 850-853, 857-875, 879-887, 905-909, 922-930, 960-964, 975-978, 997, 1009-1019
sparkless/dataframe/services/__init__.py                                 8      0   100%
sparkless/dataframe/services/aggregation_service.py                     99     26    74%   37, 133, 148, 181, 196, 224-250
sparkless/dataframe/services/assertion_service.py                       17      8    53%   25-27, 33-35, 41-43, 49-51
sparkless/dataframe/services/display_service.py                        126     63    50%   40-50, 78, 94, 101, 120-167, 171-174, 182-186, 195-204, 220, 223, 227-232, 238-240, 244-250, 264-267, 280
sparkless/dataframe/services/join_service.py                           248     47    81%   115, 130, 193, 204, 207, 227, 233, 239, 263-264, 292-294, 314, 328, 338, 383, 392-393, 418, 427-429, 461, 511-535, 607-629
sparkless/dataframe/services/misc_service.py                           613    464    24%   57, 67-73, 166, 251, 264-268, 304-352, 373-400, 417-458, 476-560, 574-654, 669-720, 737-780, 802-817, 830-846, 865-872, 897-929, 955-1016, 1048-1126, 1153-1190, 1227-1277, 1285-1318, 1322-1340, 1355-1357, 1419, 1435-1437, 1451-1458, 1469-1472, 1481, 1499-1503, 1518, 1529-1534, 1540, 1551-1554, 1562, 1567, 1576-1577, 1586, 1600-1612
sparkless/dataframe/services/schema_service.py                           4      0   100%
sparkless/dataframe/services/transformation_service.py                 349     82    77%   93, 100, 150, 175-191, 246-247, 259-263, 283-289, 293, 315, 368, 372, 377, 385-386, 401-441, 448-452, 456-458, 510, 533-543, 678-680, 772-774, 779, 783, 890-910
sparkless/dataframe/transformations/__init__.py                          2      2     0%   8-10
sparkless/dataframe/transformations/operations.py                      245    245     0%   8-659
sparkless/dataframe/types.py                                             8      8     0%   8-25
sparkless/dataframe/validation/__init__.py                               2      0   100%
sparkless/dataframe/validation/column_validator.py                     171     36    79%   101, 110-112, 137, 150-151, 185-198, 218, 247-279, 289, 337, 348, 401, 473, 485, 514, 541-558, 569-571
sparkless/dataframe/validation_handler.py                               21      2    90%   75-76
sparkless/dataframe/window_handler.py                                  315    315     0%   8-698
sparkless/dataframe/writer.py                                          405    295    27%   95-96, 115-117, 131, 146-147, 161-162, 176-177, 194-196, 207-212, 230-234, 237-240, 247-252, 260, 269, 274-362, 400-444, 471-503, 517, 529, 545, 557, 569, 581, 588-594, 598-614, 618-621, 627-636, 640-645, 648-655, 658-661, 664-680, 685-700, 704-711, 715-720, 741-774, 803-886, 909-913, 917, 927, 933-938, 963-1043
sparkless/delta.py                                                     308    254    18%   46-51, 61-74, 87-88, 100-116, 121-122, 127, 131-132, 137-152, 156-185, 189, 198, 210, 221-286, 300-341, 345, 348-352, 355-357, 360-368, 373-379, 384-408, 421-430, 434, 438, 441-446, 449-450, 455-456, 459-461, 464-466, 470-514, 517-523, 526-540, 547-551, 563-576, 581-584, 589-593, 601-629, 637-657
sparkless/error_simulation.py                                           89     89     0%   29-338
sparkless/errors.py                                                     28     10    64%   57, 62, 67, 72, 79, 86, 91, 96, 101, 106
sparkless/functions/__init__.py                                         29      4    86%   562-566
sparkless/functions/aggregate.py                                       323    146    55%   65-66, 299-300, 315-316, 331-332, 370-371, 386-387, 439-443, 461-472, 490-501, 516-517, 534-535, 552-553, 570-571, 591-597, 617-623, 640-641, 658-659, 769-770, 787-788, 803-807, 825-826, 843-844, 857-859, 874-890, 904-912, 930-940, 958-967, 985-994, 1014-1026, 1044-1053, 1071-1080, 1098-1107, 1125-1134, 1152-1161, 1182-1222
sparkless/functions/array.py                                           272    132    51%   78-83, 107, 109, 134-139, 161, 185, 213-219, 245-251, 277-283, 309-315, 346-356, 385-396, 418-421, 440-443, 466, 486-490, 511-514, 538-541, 561-564, 580, 626-629, 644-647, 698-701, 716-719, 737-742, 811-830, 853-883, 900-903, 964, 997-1000, 1018-1022, 1040-1043, 1058-1059, 1074-1086, 1098-1100, 1112-1116
sparkless/functions/base.py                                            135     56    59%   121, 137, 150-161, 165-171, 175-184, 188-201, 205-217, 221-233, 281, 289, 293, 297, 302, 312, 317, 322
sparkless/functions/bitwise.py                                         108     67    38%   31-34, 50-53, 71, 86-89, 107-110, 125-128, 143-146, 161-168, 183-198, 213-228, 243-258, 276-283, 300-307, 324-331, 347-350, 367-370, 387-390, 405-408, 425-428
sparkless/functions/conditional.py                                     396    260    34%   33-115, 147, 152, 295-300, 304-367, 381-384, 396-412, 426-455, 475, 499, 515, 534, 553, 570-603, 622, 637-648, 670, 673, 707-722, 737-752, 767-782, 797-812, 827-842, 854-861, 873-880, 895-908, 923-939, 954-970, 985-1001
sparkless/functions/core/__init__.py                                     6      0   100%
sparkless/functions/core/column.py                                     457     94    79%   43, 224, 336, 389, 399, 470-472, 476-478, 482-484, 492, 500-510, 518-528, 536-546, 554-564, 572-582, 590-600, 609, 706, 740, 744, 748, 752-754, 756, 760, 764, 768, 772, 776, 780, 784, 788, 807, 818-825, 829, 836, 838-842, 844-848, 850-854, 856-860, 880, 958, 991, 994
sparkless/functions/core/expressions.py                                109     74    32%   28-32, 55, 73, 91-94, 108-115, 127-129, 141-143, 155-157, 169-171, 188-228, 240-247, 259-266, 278-285, 297-304, 320-323
sparkless/functions/core/lambda_parser.py                              146    126    14%   58-134, 142-148, 167-175, 189-247, 260-274, 285-298, 309-314, 327-332, 359-361, 369, 377, 381-385
sparkless/functions/core/literals.py                                   131     66    50%   65-76, 86, 108-110, 117-119, 123-125, 129-131, 135-137, 141-143, 147-149, 153-155, 159-161, 171-173, 177-179, 183-185, 189-191, 195-197, 201-203, 207-209, 213, 217, 227-229, 233-240, 244-246, 250-252, 256-258, 272-274, 278-280, 306-308, 312-314, 318-320
sparkless/functions/core/operations.py                                 106     67    37%   27-29, 33-35, 39-41, 45-47, 51-53, 57-59, 63-65, 69, 73, 77-79, 83-85, 89-91, 95-97, 101-103, 107-109, 122, 126, 130, 134, 145, 150-154, 158, 162, 176-189, 199, 203, 211, 219-221, 225-227, 235-237
sparkless/functions/core/sql_expr_parser.py                            308     73    76%   70, 75-78, 107-157, 200-204, 209-226, 248-253, 328, 339, 353, 356-358, 375-381, 399, 401, 405, 419, 428
sparkless/functions/crypto.py                                           48     39    19%   49-71, 91-113, 133-155
sparkless/functions/datetime.py                                        474    254    46%   52, 98, 107, 119-125, 137-143, 155-161, 173-179, 188-189, 205-218, 231-237, 262-301, 327-366, 390-429, 455-500, 520-549, 564-580, 595-601, 616-622, 637-646, 658-664, 676-682, 694-700, 712-718, 730-736, 748-754, 783, 823, 836, 872-876, 889, 905, 921, 937, 954-960, 972-978, 990-994, 1039-1048, 1063-1074, 1088, 1107, 1126, 1149-1159, 1179-1191, 1211-1222, 1231-1234, 1248-1253, 1262-1273, 1283-1294, 1317-1320, 1340-1343, 1368-1372, 1424, 1429, 1435, 1439, 1442-1445, 1451, 1492-1497, 1524, 1529, 1535, 1557-1560, 1576-1579, 1600-1603, 1622-1627, 1646-1647, 1664-1665, 1685-1693, 1711-1727, 1745-1761
sparkless/functions/functions.py                                      1547    450    71%   67-77, 133-136, 142-162, 168-187, 193-212, 218-238, 259, 264, 341, 346, 351, 356, 361, 366, 371, 376, 381, 394-396, 401, 408, 415, 422, 427, 432, 437, 442, 447, 452, 457, 462, 467, 472, 483, 490, 497, 502, 507, 523, 533, 543, 548, 593, 598, 605, 627, 637, 642, 652, 657, 664, 695, 726, 731, 736, 741, 755, 760, 765, 785, 790, 795, 800, 805, 810, 817, 822, 827, 832, 837, 842, 847, 852, 857, 862, 867, 872, 877, 882, 892, 902, 907, 912, 917, 922, 927, 932, 1002, 1007, 1012, 1023, 1028, 1045, 1052, 1059, 1092, 1097, 1104, 1109, 1114, 1119, 1128, 1133, 1138, 1143, 1148, 1155, 1162, 1167, 1172, 1202-1205, 1224, 1231, 1238, 1248, 1296, 1301, 1311, 1316, 1321, 1326, 1331, 1336, 1341, 1346, 1378-1420, 1435, 1442, 1466, 1483, 1496, 1501, 1506, 1511, 1516, 1521, 1533-1538, 1549, 1556, 1563, 1579-1586, 1595-1597, 1706-1713, 1814, 1819, 1824, 1829, 1841, 1855, 1873, 1880, 1887, 1894, 1904, 1913, 1919, 1924, 1934, 1939, 1946, 1951, 1963, 1973, 1978, 1993, 2020, 2029, 2034, 2040, 2045, 2050, 2055, 2062, 2073, 2078, 2085, 2092, 2099, 2108, 2115, 2128-2129, 2152-2158, 2169, 2174, 2179, 2185, 2190, 2195, 2200, 2205, 2210, 2215, 2220, 2225, 2233, 2242-2243, 2248, 2253, 2259, 2264, 2269, 2279, 2285, 2290, 2297, 2302, 2316-2318, 2326-2328, 2336-2338, 2346-2348, 2353-2355, 2360-2362, 2369-2371, 2378-2380, 2387-2389, 2396-2398, 2404, 2409, 2414, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2464-2466, 2471-2473, 2492-2494, 2503-2505, 2510-2512, 2517-2519, 2532-2534, 2539-2541, 2546-2548, 2553-2555, 2568-2570, 2575-2577, 2582-2584, 2589-2591, 2596-2598, 2603-2605, 2661, 2716-2741, 2765-2772, 2789-2791, 2797, 2804, 2809, 2814, 2821, 2828, 2833, 2842, 2847, 2854, 2861, 2866, 2871, 2879, 2884, 2891, 2898, 2905, 2913, 2920, 2927, 2933, 2938, 2945, 2950, 2962, 2975, 2989, 3004, 3016, 3023, 3030, 3037, 3044, 3049, 3054, 3059, 3064, 3069, 3074, 3080, 3085, 3090, 3097, 3102, 3107, 3112, 3117, 3122, 3130, 3135, 3140, 3149, 3155, 3160, 3165, 3170, 3175, 3196-3213
sparkless/functions/json_csv.py                                         41     16    61%   31-34, 51-54, 105-107, 127-130, 144-147, 159-161
sparkless/functions/map.py                                             101     55    46%   51-54, 69-72, 87-90, 107-115, 138-143, 172-173, 182-183, 195, 204-207, 219, 243-246, 266-269, 292-298, 324-330, 356-362, 391-400, 423-430
sparkless/functions/math.py                                            320    139    57%   51, 66-70, 82-86, 118, 133, 146, 178, 207, 211, 216, 219, 246-249, 264-267, 284-287, 304-307, 349, 362, 378, 394, 409-414, 427, 452, 476-477, 489-490, 505-506, 518-519, 531-532, 544-545, 567-574, 586-587, 599-600, 612-613, 625-626, 638-639, 651-652, 664-665, 677-679, 696-698, 715-716, 729-730, 745-748, 774, 776, 809-810, 823-824, 836-837, 849-850, 859-862, 871-874, 886-887, 902-907, 921-926, 941-960, 972, 990-1003, 1026-1067
sparkless/functions/metadata.py                                         33     13    61%   32, 45, 59, 71, 87-90, 102-109
sparkless/functions/ordering.py                                         28     12    57%   39-42, 56-59, 73-76, 90-93
sparkless/functions/pandas_types.py                                      6      0   100%
sparkless/functions/string.py                                          547    257    53%   66, 82, 97-103, 115-121, 134, 150, 166, 184-196, 209-218, 231-237, 250-256, 268-274, 287-296, 309-318, 332, 350-356, 370-379, 395, 411-420, 435-450, 462-468, 480-484, 496, 508, 521-534, 551, 579, 629, 655, 706, 722, 737-741, 792, 795-796, 819, 839, 860, 900-903, 923-926, 941-944, 963, 1004, 1054-1057, 1075-1078, 1099-1102, 1125, 1147, 1202-1223, 1235-1238, 1251, 1265-1268, 1280-1299, 1329-1332, 1352-1355, 1370-1373, 1391-1394, 1414-1417, 1432-1435, 1451-1457, 1492-1495, 1508-1514, 1529-1540, 1553-1562, 1575-1584, 1601-1610, 1627-1636, 1650, 1673-1684, 1698-1710, 1725-1731, 1746-1752, 1764-1768, 1781-1792, 1807, 1832-1854, 1872-1879, 1897-1902, 1918-1927, 1939-1940
sparkless/functions/udf.py                                              51      1    98%   138
sparkless/functions/window_execution.py                                651    570    12%   58-67, 129, 143, 157, 171, 185, 201-203, 219, 235-237, 253-255, 390-428, 432-471, 478-553, 557-607, 613-629, 633-694, 698-742, 746-790, 794-845, 849-916, 920-981, 987-1024, 1028-1087, 1092, 1101-1146, 1150-1230, 1234-1260, 1268-1304, 1308-1372, 1376-1420, 1424-1468
sparkless/functions/xml.py                                              65     39    40%   25-28, 50-64, 84-87, 107-110, 131-134, 155-158, 179-182, 203-206, 227-230, 251-254, 275-278
sparkless/optimizer/__init__.py                                          3      0   100%
sparkless/optimizer/optimization_rules.py                              174     20    89%   17, 84, 132-140, 151, 162, 193, 242, 264, 278, 287, 299, 342, 376
sparkless/optimizer/query_optimizer.py                                 256    179    30%   48, 50, 52, 54, 56, 58, 67, 72, 80-125, 129-130, 135, 147-174, 178-179, 183-206, 214-234, 238-239, 245-248, 256-288, 292, 297, 305-330, 334, 339-342, 379-392, 403-408, 413, 418-456, 459-472, 477-504, 508, 512, 518
sparkless/performance_simulation.py                                     91      1    99%   150
sparkless/polars_utils/__init__.py                                       3      0   100%
sparkless/polars_utils/schema_utils.py                                  31     24    23%   16-18, 22-30, 35-47
sparkless/polars_utils/type_mapper.py                                   99     85    14%   44-93, 101, 107, 110-150
sparkless/robin/__init__.py                                              2      0   100%
sparkless/robin/execution.py                                            13      0   100%
sparkless/robin/native.py                                               29      9    69%   27, 74-76, 85-87, 101-102
sparkless/robin/plan_adapter.py                                        127     12    91%   105, 162, 172, 178-180, 207, 219-220, 230-231, 269
sparkless/session/__init__.py                                            4      0   100%
sparkless/session/catalog.py                                           258    136    47%   43, 47, 65, 69, 111, 131-133, 142, 150, 170, 173, 177-180, 187-190, 212, 215, 225, 230-233, 251-253, 267, 272, 275, 278, 281, 299-302, 309-312, 315-318, 338, 341, 344, 349-352, 374, 386-414, 431, 434, 438-443, 463, 466, 470-475, 484, 499, 502, 506-511, 528, 537, 546, 566-575, 606, 617, 630, 633, 636, 640-644, 651, 654, 658-659, 666, 683-716
sparkless/session/config/__init__.py                                     2      0   100%
sparkless/session/config/configuration.py                               54     19    65%   85-86, 94, 102, 110, 118-119, 130, 141, 188, 199-200, 211-212, 224-225, 236-237, 245
sparkless/session/context.py                                            36     10    72%   47, 51, 55, 92, 101, 110, 119, 123, 127, 131
sparkless/session/core/__init__.py                                       4      0   100%
sparkless/session/core/builder.py                                       25      2    92%   52, 69
sparkless/session/core/session.py                                      225     97    57%   12-13, 137-140, 150, 200-202, 212-217, 221-223, 236, 240, 250, 256, 269-271, 313, 320, 336, 348, 352-353, 359, 374-458, 477-478, 512, 521-523, 546-548, 565, 572, 579, 589, 596, 601-611, 616-620, 629-630, 635
sparkless/session/performance_tracker.py                                39     19    51%   57, 87-109, 117
sparkless/session/services/__init__.py                                   6      0   100%
sparkless/session/services/dataframe_factory.py                        218     85    61%   14-15, 77-78, 97-99, 102-103, 106, 119, 152, 163-164, 190, 206, 211, 218, 255, 271, 281, 313, 323, 343, 350, 361-364, 403, 428, 440, 447, 465-474, 492-508, 519-589
sparkless/session/services/lifecycle_manager.py                         21      9    57%   33-34, 42-43, 55-59
sparkless/session/services/mocking_coordinator.py                       32     23    28%   39-57, 69-72, 84-86, 101-105, 109
sparkless/session/services/protocols.py                                 20      0   100%
sparkless/session/services/sql_parameter_binder.py                      29     25    14%   28-51, 62-74
sparkless/session/session.py                                             0      0   100%
sparkless/session/sql/__init__.py                                        5      0   100%
sparkless/session/sql/executor.py                                     1280   1241     3%   76-90, 115-150, 170-1285, 1296-1348, 1363-1478, 1492-1529, 1544-1665, 1676-1705, 1720-1880, 1894-1988, 2002-2030, 2042-2088, 2100-2407, 2423-2644, 2667-2751, 2764-2779, 2806-2838, 2860-2867, 2899-2908, 2935-3001
sparkless/session/sql/optimizer.py                                      65      0   100%
sparkless/session/sql/parser.py                                        496    361    27%   45, 49, 263, 271-272, 287, 289, 291, 293, 295, 298-315, 342, 344, 346, 348, 350, 352, 354, 357-358, 387-687, 698-833, 848-892, 906-993, 1010-1069, 1085-1106, 1121-1141, 1265, 1271, 1338, 1349-1374
sparkless/session/sql/validation.py                                     85      0   100%
sparkless/spark_types.py                                               412    163    60%   60-74, 111, 115, 123, 350, 368, 420, 432, 439-440, 443, 450-451, 454, 466, 475-477, 480, 489-491, 494, 503-505, 508, 539-544, 570-575, 585-590, 593, 605-606, 625-633, 644-646, 654-656, 660, 664-665, 669, 673, 685, 698, 704-713, 718-733, 738-739, 755-757, 771, 773, 777, 834-837, 855, 857, 870-891, 897-899, 903-910, 916-921, 929-954, 968-989, 994-995, 1022-1023
sparkless/sql/__init__.py                                               10      0   100%
sparkless/sql/functions.py                                              30      5    83%   70-72, 84-92
sparkless/sql/types.py                                                   2      0   100%
sparkless/sql/utils.py                                                   7      0   100%
sparkless/storage/__init__.py                                            9      0   100%
sparkless/storage/backends/__init__.py                                   0      0   100%
sparkless/storage/backends/file.py                                     199    137    31%   26-34, 39, 44, 49, 53-56, 64-69, 77-78, 87-101, 112-119, 127, 135-138, 142, 146, 150, 154-155, 159-161, 174-177, 188-191, 202-203, 211-216, 224-232, 238, 242, 246, 250, 254, 258, 262-264, 268, 272, 276, 288-291, 299-300, 311, 320-327, 335, 347-349, 364-367, 376-377, 389-393, 408-413, 428-430, 442-448, 460, 470-481, 492-501, 505-509, 515-520, 527
sparkless/storage/backends/memory.py                                   139     41    71%   34, 44, 54, 57-59, 72-77, 93, 97, 101, 105, 109-110, 114-115, 160-161, 256, 267-268, 299-304, 319-321, 351, 392-395, 398, 411-415, 427-432
sparkless/storage/manager.py                                           135     87    36%   39-44, 57, 69, 83-85, 97-101, 111, 122, 131-133, 141, 145-152, 156-162, 174, 189, 198, 211, 226, 240, 252, 261, 272, 286, 298, 306, 315, 328, 339, 347-352, 356-361, 369-381, 385, 393-403, 414-435
sparkless/storage/models.py                                             67      1    99%   77
sparkless/storage/serialization/__init__.py                              0      0   100%
sparkless/storage/serialization/csv.py                                  46     32    30%   23-30, 42-47, 57-62, 76-92, 104-120
sparkless/storage/serialization/json.py                                 39     25    36%   23-24, 36-41, 51-63, 75-90, 102-118
sparkless/utils/profiling.py                                            96     40    58%   47-48, 58, 61, 71-76, 85, 88-90, 94, 99, 102, 118-135, 161-172, 182, 188
sparkless/window.py                                                     67      8    88%   78, 91, 114, 127, 148, 167, 234, 239
--------------------------------------------------------------------------------------------------
TOTAL                                                                26293  15851    40%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_hex - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_delete_from_table - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Delete { tables: [], from: WithFromKeyword([TableWithJoins { relation: Table { name: ObjectName([Ident { value: "delete_test", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }]), using: None, selection: Some(BinaryOp { left: Identifier(Ident { value: "age", quote_style: None }), op: Gt, right: Value(Number("30", false)) }), returning: None, order_by: [], limit: None }.
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_sort - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_date_column_and_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_field_access - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_delete_all_rows - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Delete { tables: [], from: WithFromKeyword([TableWithJoins { relation: Table { name: ObjectName([Ident { value: "delete_all", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }]), using: None, selection: None, returning: None, order_by: [], limit: None }.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_base64 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_remove - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_string_values - ValueError: Robin execute_plan failed: session/df: not found: Column 'Bob' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_datetime_comparison - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_nested_struct - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_from_select - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "target_table", quote_style: None }]), table_alias: None, columns: [], overwrite: false, source: Some(Query { with: None, body: Select(Select { distinct: None, top: None, projection: [UnnamedExpr(Identifier(Ident { value: "name", quote_style: None })), UnnamedExpr(Identifier(Ident { value: "age", quote_style: None }))], into: None, from: [TableWithJoins { relation: Table { name: ObjectName([Ident { value: "source_table", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }], lateral_views: [], selection: Some(BinaryOp { left: Identifier(Ident { value: "dept", quote_style: None }), op: Eq, right: Value(SingleQuotedString("IT")) }), group_by: Expressions([]), cluster_by: [], distribute_by: [], sort_by: [], having: None, named_window: [], qualify: None, value_table_mode: None }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_initcap - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_in_select_expression - assert None is True
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_multiple_datetime_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_per_row_column_bounds - assert None is True
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_basic_select - ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_soundex - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_basic_parity - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_202_select_with_list.py::TestIssue202SelectWithList::test_select_star_with_list_does_not_unpack - ValueError: collect_as_json_rows failed: duplicate: the name '*' is duplicate

It's possible that multiple expressions are returning the same default column name. If this is the case, try renaming the columns with `.alias("new_name")` to avoid duplicate column names.
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_date_values - assert datetime.date(2024, 1, 1) in {None}
 +  where datetime.date(2024, 1, 1) = date(2024, 1, 1)
FAILED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_filtered_select - ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_multiple_matches_parity - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_datetime_after_column_rename - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_translate - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_in_join - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_group_by - ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_in_when_otherwise_expression - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_levenshtein - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_left_parity - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_145_string_cast.py::test_string_cast_works_with_to_timestamp - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_aliased_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/sql/test_queries.py::TestSQLQueriesParity::test_aggregation - ValueError: Robin SQL failed: Table or view 'test_table' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_crc32 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_multiple_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_databases - ValueError: can not infer schema from empty dataset
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_year - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_149_to_timestamp_string.py::TestIssue149ToTimestampString::test_to_timestamp_with_regexp_replace_cast_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_xxhash64 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_tables - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got ShowTables { extended: false, full: false, db_name: None, filter: None }.
FAILED tests/test_issue_149_to_timestamp_string.py::TestIssue149ToTimestampString::test_to_timestamp_with_nested_cast_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_month - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_get_json_object - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_empty_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/dataframe/test_select.py::TestSelectParity::test_select_with_alias - AssertionError: DataFrames are not equivalent:
Null mismatch in column 'user_id' row 0: mock=None, expected=1
Null mismatch in column 'full_name' row 0: mock=None, expected='Alice'
Null mismatch in column 'user_id' row 1: mock=None, expected=2
Null mismatch in column 'full_name' row 1: mock=None, expected='Bob'
Null mismatch in column 'user_id' row 2: mock=None, expected=3
Null mismatch in column 'full_name' row 2: mock=None, expected='Charlie'
Null mismatch in column 'user_id' row 3: mock=None, expected=4
Null mismatch in column 'full_name' row 3: mock=None, expected='David'
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_on_string_column_filter_does_not_error_and_returns_empty - ValueError: Robin execute_plan failed: expression: unsupported expression op: isnan
FAILED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_tables_in_database - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_214_sort_with_list.py::test_sort_with_list_of_column_names - AssertionError: assert 'IT' == 'HR'
  
  - HR
  + IT
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofmonth - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_json_tuple - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_149_to_timestamp_string.py::TestIssue149ToTimestampString::test_to_timestamp_with_string_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_214_sort_with_list.py::test_sort_with_df_columns - AssertionError: assert 'IT' == 'HR'
  
  - HR
  + IT
FAILED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_table - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got ExplainTable { describe_alias: Describe, hive_format: None, table_name: ObjectName([Ident { value: "describe_test", quote_style: None }]) }.
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_conditional - TypeError: Object of type CaseWhen is not JSON serializable
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofweek - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_on_numeric_column_true_only_for_nan - ValueError: Robin execute_plan failed: expression: unsupported expression op: isnan
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_substring_index - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_union - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=3, expected=6
FAILED tests/test_issue_151_to_timestamp_validation.py::TestIssue151ToTimestampValidation::test_to_timestamp_with_validation_rule_not_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_extended - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got ExplainTable { describe_alias: Describe, hive_format: Some(Extended), table_name: ObjectName([Ident { value: "describe_extended_test", quote_style: None }]) }.
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_string_functions - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_add - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_repeat - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_set_operations.py::TestSetOperationsParity::test_union_all - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=3, expected=6
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_literal_matches_python_math - ValueError: failed to parse plan_json: expected value at line 1 column 99
FAILED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_describe_column - ValueError: Robin SQL failed: SQL parse error: sql parser error: Expected end of statement, found: age at Line: 1, Column 28. Hint: only SELECT and CREATE SCHEMA/DATABASE/DROP TABLE are supported.
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_sub - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_151_to_timestamp_validation.py::TestIssue151ToTimestampValidation::test_to_timestamp_with_datetime_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_reverse - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_math_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_filter - assert None == datetime.date(2026, 1, 1)
 +  where datetime.date(2026, 1, 1) = date(2026, 1, 1)
FAILED tests/parity/sql/test_show_describe.py::TestSQLShowDescribeParity::test_show_columns - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_on_string_and_numeric_columns_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: isnan
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_subtraction - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_format - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_parity - assert None == 1
FAILED tests/test_issue_152_sql_column_aliases.py::TestIssue152SQLColumnAliases::test_sql_with_inner_join_and_aliases - ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_multiple_fields_parity - assert None == 1
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_large_number_of_fields - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_and_other_columns_parity - assert None == 1
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_to_date - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_append_data_visible_immediately - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_152_sql_column_aliases.py::TestIssue152SQLColumnAliases::test_sql_with_left_join_and_aliases - ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_addition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_in_when_otherwise_expression - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_two_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_append_to_new_table - ValueError: can not infer schema from empty dataset
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_yyyy_mm_dd_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_datetime_column_vs_string_column_filter - AssertionError: assert set() == {'Early'}
  
  Extra items in the right set:
  'Early'
  
  Full diff:
  + set()
  - {
  -     'Early',
  - }
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_multiplication - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_basic_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_153_to_timestamp_returns_none.py::TestIssue153ToTimestampReturnsNone::test_to_timestamp_returns_actual_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_datetime_column_vs_string_column_all_operators - AssertionError: Operator > mismatch
assert set() == {'Greater'}
  
  Extra items in the right set:
  'Greater'
  
  Full diff:
  + set()
  - {
  -     'Greater',
  - }
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_two_arguments_string_names - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_inner_join_then_groupby - AssertionError: assert {} == {(1, 'A'): 10, (2, 'B'): 20}
  
  Right contains 2 more items:
  {(1, 'A'): 10, (2, 'B'): 20}
  
  Full diff:
  + {}
  - {
  -     (1, 'A'): 10,
  -     (2, 'B'): 20,
  - }
FAILED tests/parity/dataframe/test_table_append_persistence.py::TestTableAppendPersistence::test_multiple_append_operations - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_right_join_then_groupby - assert {} == {1: 1, 2: 1}
  
  Right contains 2 more items:
  {1: 1, 2: 1}
  
  Full diff:
  + {}
  - {
  -     1: 1,
  -     2: 1,
  - }
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_mm_slash_dd_slash_yyyy_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_division - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_outer_join_then_groupby - assert {1: 1, 3: 1} == {1: 1, None: 1, 3: 1}
  
  Omitting 2 identical items, use -vv to show
  Right contains 1 more item:
  {None: 1}
  
  Full diff:
    {
  -     None: 1,
        1: 1,
        3: 1,
    }
FAILED tests/test_issue_153_to_timestamp_returns_none.py::TestIssue153ToTimestampReturnsNone::test_to_timestamp_with_clean_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_multiple_args_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_three_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_single_column_join_then_groupby - assert {1: None, 2: None} == {1: 100.0, 2: 200.0}
  
  Differing items:
  {1: None} != {1: 100.0}
  {2: None} != {2: 200.0}
  
  Full diff:
    {
  -     1: 100.0,
  -     2: 200.0,
  +     1: None,
  +     2: None,
    }
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_three_column_join_then_groupby - assert {} == {(2023, 1, 1)...23, 1, 2): 20}
  
  Right contains 2 more items:
  {(2023, 1, 1): 10, (2023, 1, 2): 20}
  
  Full diff:
  + {}
  - {
  -     (2023, 1, 1): 10,
  -     (2023, 1, 2): 20,
  - }
FAILED tests/parity/dataframe/test_transformations.py::TestTransformationsParity::test_drop_column - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_modulo - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_join_then_select_join_keys - assert None == 100
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_type_casting_works - ValueError: Robin execute_plan failed: session/df: not found: Column 'id' not found. Available columns: [id_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_with_null_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_multiply_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_without_format_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[None-None-True] - ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_join_then_orderby_on_join_keys - assert 0 == 3
 +  where 0 = len([])
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_bitwise_or - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_string_concatenation - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_float_base_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/parity/functions/test_to_date_issue_126.py::TestToDateIssue126::test_issue_126_reproduction - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_null_literal_casting_to_various_types - ValueError: collect_as_json_rows failed: casting from null to boolean not supported
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[None-x-False] - ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_join_then_aggregate_with_join_keys - AssertionError: assert {} == {'A': 30, 'B': 30}
  
  Right contains 2 more items:
  {'A': 30, 'B': 30}
  
  Full diff:
  + {}
  - {
  -     'A': 30,
  -     'B': 30,
  - }
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_bitwise_not - ValueError: Robin execute_plan failed: expression: unsupported expression op: ~
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_160_dropped_column_execution_plan.py::TestIssue160DroppedColumnExecutionPlan::test_dropped_column_in_execution_plan - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_basic_parity - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_natural_log_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_join_different_data_types_then_groupby - assert 0 == 1
 +  where 0 = len([])
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[x-None-False] - ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_literal - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_row_number - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_160_dropped_column_execution_plan.py::TestIssue160DroppedColumnExecutionPlan::test_dropped_column_with_cache - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_multiple_columns_parity - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_different_bases_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_rank - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[x-x-True] - ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_reverse_operations - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_schema_merge_with_type_preservation - ValueError: can not infer schema from empty dataset
FAILED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_partitionby_list_parity - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_abs - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_join_then_drop_other_columns - ValueError: Robin execute_plan failed: session/df: not found: Column 'name' not found. Available columns: [id, score, temp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_dense_rank - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_mixed_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_160_lazy_polars_expr.py::test_lazy_polars_expression_after_column_drop - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[x-y-False] - ValueError: Robin execute_plan failed: session/df: not found: Column 'left' not found. Available columns: [equals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_delta_create_or_replace_table_as_select - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_281_join_withcolumn_unmaterialized.py::test_join_with_unmaterialized_withcolumn_on_right_regression_281 - AssertionError: assert [('Alice', '1..., None, None)] == [('Alice', '1...B', 'D', 'D')]
  
  At index 0 diff: ('Alice', '1', 'A', None, None) != ('Alice', '1', 'A', 'C', 'C')
  
  Full diff:
    [
        (
            'Alice',
            '1',
            'A',
  -         'C',
  -         'C',
  +         None,
  +         None,
        ),
        (
            'Bob',
            '2',
            'B',
  -         'D',
  -         'D',
  +         None,
  +         None,
        ),
    ]
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_round - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_chained_operations - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_sum_over_window - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_single_argument_still_works - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_281_join_withcolumn_unmaterialized.py::test_join_with_multiple_unmaterialized_ops_on_right - AssertionError: assert [('Alice', '1...', 'B', None)] == [('Alice', '1...2', 'B', 'D')]
  
  At index 0 diff: ('Alice', '1', 'A', None) != ('Alice', '1', 'A', 'C')
  
  Full diff:
    [
        (
            'Alice',
            '1',
            'A',
  -         'C',
  +         None,
        ),
        (
            'Bob',
            '2',
            'B',
  -         'D',
  +         None,
        ),
    ]
FAILED tests/test_issue_160_lazy_polars_expr.py::test_nested_operations_with_drop - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sqrt - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_281_join_withcolumn_unmaterialized.py::test_join_with_unmaterialized_select_filter_on_right - AssertionError: assert [('Alice', '1..., None, None)] == [('Alice', '1...B', 'D', 'D')]
  
  At index 0 diff: ('Alice', '1', 'A', None, None) != ('Alice', '1', 'A', 'C', 'C')
  
  Full diff:
    [
        (
            'Alice',
            '1',
            'A',
  -         'C',
  -         'C',
  +         None,
  +         None,
        ),
        (
            'Bob',
            '2',
            'B',
  -         'D',
  -         'D',
  +         None,
  +         None,
        ),
    ]
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_immediate_table_access - ValueError: can not infer schema from empty dataset
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lag - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_nulls - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_date_types - assert (datetime.date(2025, 1, 1), datetime.date(2025, 1, 1)) in {(None, None)}
FAILED tests/test_issue_281_join_withcolumn_unmaterialized.py::test_join_with_unmaterialized_ops_on_both_sides - AssertionError: assert [('Alice', '1..., None, None)] == [('Alice', '1...B', 'D', 'D')]
  
  At index 0 diff: ('Alice', '1', 'A', 'A', None, None) != ('Alice', '1', 'A', 'A', 'C', 'C')
  
  Full diff:
    [
        (
            'Alice',
            '1',
            'A',
            'A',
  -         'C',
  -         'C',
  +         None,
  +         None,
        ),
        (
            'Bob',
            '2',
            'B',
            'B',
  -         'D',
  -         'D',
  +         None,
  +         None,
        ),
    ]
FAILED tests/test_issue_160_lazy_polars_expr.py::test_operations_chain_with_intermediate_drop - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_four_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_pow - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_datetime_types - assert (datetime.datetime(2025, 1, 1, 12, 0), datetime.datetime(2025, 1, 1, 12, 0)) in {(None, None)}
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_set_current_database - ValueError: can not infer schema from empty dataset
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lead - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_basic_schema_evolution - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_multiple_when_conditions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_log - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_160_lazy_polars_expr.py::test_write_operation_after_drop - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_tables - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_computed_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_cume_dist - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_in_select_expression - assert None is True
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_overwrite_schema_option - ValueError: can not infer schema from empty dataset
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_exp - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_nested_expressions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_list_tables_in_database - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_160_nested_operations.py::test_nested_operations_with_drop - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_first_value - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_decorator_pattern - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_preserve_existing_columns - ValueError: can not infer schema from empty dataset
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sin - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_type_coercion - ValueError: collect_as_json_rows failed: cannot compare string with numeric type (i64)
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_table_exists - ValueError: can not infer schema from empty dataset
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_last_value - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_division_by_zero - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_cos - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_schema_merge_on_overwrite - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_empty_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_160_reproduce_bug.py::TestIssue160ReproduceBug::test_bug_reproduction_with_150_rows - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_percent_rank - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_table_exists_in_database - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_chained_with_other_operations - assert None is False
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_tan - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_modulo_by_zero - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_merge_schema_append - ValueError: can not infer schema from empty dataset
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_ntile - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_five_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_get_table - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_160_reproduce_bug.py::TestIssue160ReproduceBug::test_bug_does_not_occur_with_2_rows - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_ceil - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_floats - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_float_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_merge_schema_bidirectional - ValueError: can not infer schema from empty dataset
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_get_table_in_database - ValueError: can not infer schema from empty dataset
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_floor - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_160_with_cache_enabled.py::test_bug_with_cache_enabled - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_zero_and_negative - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_complete_schema_evolution_scenario - ValueError: can not infer schema from empty dataset
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_cache_table - ValueError: Robin SQL failed: Table or view 'cache_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_greatest - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_boolean_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_163_validation_after_drop.py::TestIssue163ValidationAfterDrop::test_validation_after_drop_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_uncache_table - ValueError: Robin SQL failed: Table or view 'uncache_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_least - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_outer_with_null_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_bitwise_and - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_coalesce - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/internal/test_catalog.py::TestCatalogParity::test_is_cached - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_295_withColumnRenamed_nonexistent.py::TestIssue295WithColumnRenamedNonexistent::test_withColumnRenamed_after_union - assert 1 == 2
 +  where 1 = count()
 +    where count = DataFrame[1 rows, 2 columns].count
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_complex_nested_operations - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_multiple_columns - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_165_to_date_timestamp_type.py::TestIssue165ToDateTimestampType::test_to_date_with_timestamp_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_orderby - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnotnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_all_reverse_operators - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_165_to_date_timestamp_type.py::TestIssue165ToDateTimestampType::test_to_date_with_string_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_chained_operations - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_295_withColumnRenamed_nonexistent.py::TestIssue295WithColumnRenamedNonexistent::test_withColumnRenamed_after_drop - ValueError: Robin execute_plan failed: session/df: not found: Column 'city' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_when_otherwise - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_mixed_string_and_column_objects - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_165_to_date_timestamp_type.py::TestIssue165ToDateTimestampType::test_to_date_with_date_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_inner_join - ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_295_withColumnRenamed_nonexistent.py::TestIssue295WithColumnRenamedNonexistent::test_withColumnRenamed_complex_nested_operations - assert 60000 == 70000
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nvl - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_floats - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_operator_precedence - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_left_join - ValueError: Robin SQL failed: Table or view 'employees2' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_nested_with_arithmetic - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nullif - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_166_unix_timestamp.py::TestIssue166UnixTimestamp::test_unix_timestamp_with_timestamp_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_return_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_booleans - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_order_by - ValueError: Robin SQL failed: Table or view 'order_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_ifnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_166_unix_timestamp.py::TestIssue166UnixTimestamp::test_unix_timestamp_with_string_and_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: unix_timestamp
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_large_numbers - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_date_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_limit - ValueError: Robin SQL failed: Table or view 'limit_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_filter_isnotnull - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nanvl - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_without_return_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_mixed_types - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_orderby_ascending_true_parity - AssertionError: assert 'ZZZ' == 'MMM'
  
  - MMM
  + ZZZ
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_empty_dataframe - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_join_condition - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'id' has more than one occurrence
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_having - ValueError: Robin SQL failed: Table or view 'having_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_filter_isnull - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_orderby_ascending_false_parity - AssertionError: assert 'AAA' == 'ZZZ'
  
  - ZZZ
  + AAA
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_integer_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_166_unix_timestamp.py::TestIssue166UnixTimestamp::test_unix_timestamp_current_timestamp - ValueError: Robin execute_plan failed: expression: unsupported expression op: unix_timestamp
FAILED tests/parity/functions/test_orderby_ascending_parity.py::TestOrderByAscendingParity::test_sort_with_ascending_parity - assert 10 == 20
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_single_element_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_union - ValueError: Robin SQL failed: SQL: only SELECT (no UNION/EXCEPT/INTERSECT) is supported.
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_conditional_logic - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_multiple_filters - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_aliases - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_issue_266 - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_168_validation_after_drop.py::TestIssue168ValidationAfterDrop::test_validation_after_drop_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_multiple_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_subquery - ValueError: Robin SQL failed: Table or view 'subquery_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_large_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_multiple_operations_and_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_six_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_all_arithmetic_operators - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_168_validation_after_drop.py::TestIssue168ValidationAfterDrop::test_validation_after_drop_with_nested_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_case_when - ValueError: Robin SQL failed: Table or view 'case_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_1_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_136_column_rename_validation.py::TestIssue136ColumnRenameValidation::test_column_rename_and_transform_with_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_like - ValueError: Robin SQL failed: Table or view 'like_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_all_null_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_parity - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_mixed_with_columns - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_groupby_agg - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_168_validation_after_drop.py::TestIssue168ValidationAfterDrop::test_validation_after_drop_with_complex_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_in_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_in_clause - ValueError: Robin SQL failed: Table or view 'in_test' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_without_limit_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_string_functions - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_basic - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_orderby - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_materialize_basic - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/test_issue_136_column_rename_validation.py::TestIssue136ColumnRenameValidation::test_rename_then_add_column_then_filter - ValueError: collect_as_json_rows failed: cannot compare string with numeric type (f64)
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_database - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_string_names - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_col_function - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_chained_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_distinct - ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_minus_one_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_without_rsd_parity - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_multiple_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_database_if_not_exists - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_137_datetime_validation.py::TestIssue137DatetimeValidation::test_datetime_validation_with_age_calculation - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_chained_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_contains - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_upper - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_single_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_with_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_large_number_of_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_union - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_database - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_137_datetime_validation.py::TestIssue137DatetimeValidation::test_datetime_validation_simple_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_vs_function_interface - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_position - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lower - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_with_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_from_dataframe - ValueError: Robin SQL failed: Table or view 'test_users' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_exact_issue - ValueError: Robin execute_plan failed: expression: expression must be a JSON object
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_null_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_size - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_computed_column - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_length - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_with_select - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got CreateTable { or_replace: false, temporary: false, external: false, global: None, if_not_exists: true, transient: false, name: ObjectName([Ident { value: "it_employees", quote_style: None }]), columns: [], constraints: [], hive_distribution: NONE, hive_formats: Some(HiveFormat { row_format: None, serde_properties: None, storage: None, location: None }), table_properties: [], with_options: [], file_format: None, location: None, query: Some(Query { with: None, body: Select(Select { distinct: None, top: None, projection: [UnnamedExpr(Identifier(Ident { value: "name", quote_style: None })), UnnamedExpr(Identifier(Ident { value: "age", quote_style: None }))], into: None, from: [TableWithJoins { relation: Table { name: ObjectName([Ident { value: "employees", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }], lateral_views: [], selection: Some(BinaryOp { left: Identifier(Ident { value: "dept", quote_style: None }), op: Eq, right: Value(SingleQuotedString("IT")) }), group_by: Expressions([]), cluster_by: [], distribute_by: [], sort_by: [], having: None, named_window: [], qualify: None, value_table_mode: None }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), without_rowid: false, like: None, clone: None, engine: None, comment: None, auto_increment_offset: None, default_charset: None, collation: None, on_commit: None, on_cluster: None, order_by: None, partition_by: None, cluster_by: None, options: None, strict: false }.
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_137_datetime_validation.py::TestIssue137DatetimeValidation::test_datetime_validation_with_multiple_conditions - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_basic - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_multiple_values - ValueError: Robin execute_plan failed: expression: expression must be a JSON object
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_element_at - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substring - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_table - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_different_data_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_when_otherwise - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_with_drop - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_multiple_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_column_after_transform - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_explode - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=9
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_drop_table_if_exists - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_in_select - ValueError: Robin execute_plan failed: expression: expression must be a JSON object
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_multiple_udfs_same_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substr_method - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_expressions - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_with_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_distinct - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_cast - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_schema - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_computed_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_multiple_columns_after_transform - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_with_show - ValueError: Robin execute_plan failed: expression: expression must be a JSON object
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_with_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_literals - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_column_astype_method - ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_set_current_database - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_string_operations - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_empty_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_union - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_concat - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_then_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_173_validation_during_materialization.py::TestIssue173ValidationDuringMaterialization::test_validation_during_materialization_with_dropped_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_unary_minus_standalone_in_withcolumn - ValueError: Robin execute_plan failed: expression: expression must be a JSON object
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_table_in_specific_database - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_date_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_multiple_explodes - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_with_conditional - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_split - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_then_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_groupby_after_select_with_ambiguous_column - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "bonus"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_table - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "insert_test", quote_style: None }]), table_alias: None, columns: [], overwrite: false, source: Some(Query { with: None, body: Values(Values { explicit_row: false, rows: [[Value(SingleQuotedString("Bob")), Value(Number("30", false))]] }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_regexp_extract - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_timestamp_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_single_match_preserves_original_name - AssertionError: assert None == 'Alice'
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_datetime_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_join - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_column_power_number - AssertionError: assert '4' == 4
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_into_specific_columns - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "insert_specific", quote_style: None }]), table_alias: None, columns: [Ident { value: "name", quote_style: None }, Ident { value: "age", quote_style: None }], overwrite: false, source: Some(Query { with: None, body: Values(Values { explicit_row: false, rows: [[Value(SingleQuotedString("Bob")), Value(Number("30", false))]] }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_trim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_multiple_matches_uses_requested_name - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME"]; PROJECT */1 COLUMNS; SELECTION: None
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_array_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_multiple_values - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Insert { or: None, ignore: false, into: true, table_name: ObjectName([Ident { value: "insert_multi", quote_style: None }]), table_alias: None, columns: [], overwrite: false, source: Some(Query { with: None, body: Values(Values { explicit_row: false, rows: [[Value(SingleQuotedString("Bob")), Value(Number("30", false))], [Value(SingleQuotedString("Charlie")), Value(Number("35", false))]] }), order_by: [], limit: None, limit_by: [], offset: None, fetch: None, locks: [], for_clause: None }), partitioned: None, after_columns: [], table: false, on: None, returning: None, replace_into: false, priority: None, insert_alias: None }.
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_basic - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_188_string_concat_cache.py::TestStringConcatenationCacheEdgeCases::test_string_concat_with_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'col1' not found. Available columns: [concat]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_outer_with_empty_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_ltrim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_table - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Update { table: TableWithJoins { relation: Table { name: ObjectName([Ident { value: "update_test", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }, assignments: [Assignment { id: [Ident { value: "age", quote_style: None }], value: Value(Number("26", false)) }], from: None, selection: Some(BinaryOp { left: Identifier(Ident { value: "name", quote_style: None }), op: Eq, right: Value(SingleQuotedString("Alice")) }), returning: None }.
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_empty_dataframes - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_union - ValueError: collect_as_json_rows failed: type String is incompatible with expected type Float64
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_three_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_select - assert None == 8.0
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_single_column - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rtrim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_188_string_concat_cache.py::TestStringConcatenationCacheEdgeCases::test_string_concat_chained_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_with_alias - TypeError: unsupported operand type(s) for -: 'NoneType' and 'float'
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_multiple_columns - ValueError: Robin SQL failed: SQL: only SELECT, CREATE SCHEMA/DATABASE, and DROP TABLE/VIEW are supported, got Update { table: TableWithJoins { relation: Table { name: ObjectName([Ident { value: "update_multi", quote_style: None }]), alias: None, args: None, with_hints: [], version: None, partitions: [] }, joins: [] }, assignments: [Assignment { id: [Ident { value: "age", quote_style: None }], value: Value(Number("26", false)) }, Assignment { id: [Ident { value: "dept", quote_style: None }], value: Value(SingleQuotedString("HR")) }], from: None, selection: Some(BinaryOp { left: Identifier(Ident { value: "name", quote_style: None }), op: Eq, right: Value(SingleQuotedString("Alice")) }), returning: None }.
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_alias - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_188_string_concat_cache.py::TestStringConcatenationCacheEdgeCases::test_string_concat_without_caching - AssertionError: String concatenation should work normally without caching
assert None == 'ab'
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_null_values_in_joined_columns - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lpad - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_join - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_multiple_columns - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_188_string_concat_cache.py::TestStringConcatenationCacheEdgeCases::test_concat_function_with_caching - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_filter_after - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_different_case_variations - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME"]; PROJECT */1 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rpad - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_1 - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_union - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_partitionby_list - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_multiple_withcolumns - AssertionError: assert '4' == 4
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_with_column_after_select - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_like - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_filter_before - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_negative_exponent - ValueError: Robin execute_plan failed: expression: expression must be a JSON object
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_2 - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_distinct - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_both_list - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookahead - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rlike - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_drop_after_select - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_basic - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_select_subset - ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_column_objects - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_concat_ws - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_without_limit - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_orderby - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_inner - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_positive_lookahead - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_basic - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_larger_than_splits - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_ascii - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_mixed_strings_and_columns - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_count - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_fractional_exponent - TypeError: unsupported operand type(s) for -: 'str' and 'float'
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_special_characters - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_left - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_multiple_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_minus_one - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_backward_compatibility - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_from_string_timestamps - ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_orderby_columns - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_unicode - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_with_null_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_multiple_matches - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookbehind - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_string_coercion - ValueError: collect_as_json_rows failed: `pow` operation not supported for dtype `str` as exponent
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_null_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_very_long_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_different_timezone_formats - ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_chained_filters - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_desc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_orderby - assert 2 == 4
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_complex_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_no_matches - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_conditional_logic - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_empty_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_window_function_in_value - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_different_formats - ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_rows_between - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_different_format_specifiers - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_regexp_alias_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_null_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_exception_handling - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_direct_filter - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_empty_list_error - assert ('At least one column' in "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'" or 'must be specified' in "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'")
 +  where "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'" = str(ValueError("Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'"))
 +  and   "Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'" = str(ValueError("Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'"))
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_empty_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_regexp_like_alias_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_null_ids - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_nested_calls - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_multi_char_delimiter - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_window_function - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_many_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_eqNullSafe - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_float_precision - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_without_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_special_regex_characters - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_right - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_static_orderby_list - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_null_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_numeric_edge_cases - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_boolean_logic - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_isnotnull - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_outer - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_case_insensitive_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_whitespace_delimiter - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_static_partitionby_list - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_in_groupby_agg - ValueError: Robin execute_plan failed: expression: unsupported expression op: hour
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_drop_operation - ValueError: Robin execute_plan failed: session/df: not found: Column 'city' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_unicode - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_null_values - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'array_contains(IDs, ID)' not found. Available columns: [Name, Dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_desc_asc_mixed - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_consecutive_delimiters - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_multiple_lookaheads - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_multiple_chained_udfs - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_special_characters_in_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_filter - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_empty_dataframe - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_range_between - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_delimiter_not_found - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookaround_with_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_join - AssertionError: assert None == 'A'
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_all_null_inputs - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_all_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_column_name_conflicts - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_single_row - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_limit_zero - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_empty_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_mixed_types_in_udf - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_dense_rank - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_empty_dataframes - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Dept' has more than one occurrence
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_mixed_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_backward_compatibility - assert 0 == 2
 +  where 0 = len([])
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_large_dataset - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_unicode_characters - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_percent_rank - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_drop - ValueError: Robin execute_plan failed: session/df: not found: Column 'Name' not found. Available columns: [avg(Value)]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_complex_aggregation - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_format_specifiers - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_295_withColumnRenamed_nonexistent.py::TestIssue295WithColumnRenamedNonexistent::test_withColumnRenamed_after_join - assert 0 == 2
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 3 columns].count
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_alias - assert None == 5.5
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_empty_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_very_long_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_in_withcolumn - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_window_functions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_idempotent_behavior - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_lag_lead - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_precision_formatting - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_295_withColumnRenamed_nonexistent.py::TestIssue295WithColumnRenamedNonexistent::test_withColumnRenamed_after_orderby - assert 25 == 20
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_case_when - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_duplicate_values - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_empty_delimiter - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_chained_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_first_last_value - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_join_different_case_select_third_case - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "Value2"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_long_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: format_string
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_select - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_coalesce - ValueError: Robin execute_plan failed: expression: unsupported expression op: coalesce
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_ascending_true - AssertionError: assert 'ZZZ' == 'MMM'
  
  - MMM
  + ZZZ
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_string_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_leading_trailing_delimiters - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_anchors - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_cast - assert None == 5
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_ascending_false - AssertionError: assert 'AAA' == 'ZZZ'
  
  - ZZZ
  + AAA
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_multiple_times - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_join_different_case_select_left_column - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "value"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_ntile - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_orderby - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_default_ascending - AssertionError: assert 'ZZZ' == 'MMM'
  
  - MMM
  + ZZZ
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_join_same_case_no_ambiguity - assert None == 2
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_numeric_ascending - assert 10 == 5
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_float_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_multiple_aggregations - assert 0 == 2
 +  where 0 = len([])
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_different_limit_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_nested_lookahead - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_with_different_data_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_numeric_descending - assert 10 == 20
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_cume_dist - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_different_join_types - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_multiple_columns_ascending - assert 10 == 5
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_groupby - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_window_functions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_large_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_multiple_columns_descending - AssertionError: assert 'A' == 'B'
  
  - B
  + A
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_in_filter_context - ValueError: Robin execute_plan failed: expression: unsupported expression op: element_at
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_digits - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_chained_operations - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_with_computed_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_with_column_object - assert 10 == 20
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_multiple_ambiguous_columns - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["AGE", "CITY", "NAME"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_join - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_sort_with_ascending_parameter - AssertionError: assert 'AAA' == 'ZZZ'
  
  - ZZZ
  + AAA
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_where_clause - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_float_base - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_combined_lookahead_lookbehind - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_with_null_values - assert None == 20
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_chained_operations_after_select - ValueError: Robin execute_plan failed: session/df: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_in_join - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_groupby - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_backward_compatibility - assert 10 == 5
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_complex_chained_operations - ValueError: Robin execute_plan failed: session/df: not found: Column 'avg(Value)' not found. Available columns: [Name, Type, MeanValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_union - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_int_base - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_aggregation - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookahead_multiple_conditions - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_join - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_comparison - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_two_equivalent - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_nested_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'avg(Value)' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_distinct - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_mixed_nulls_and_values - assert None == 5
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_window_functions - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_natural_log - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_368_f_dataframe.py::TestIssue368FDataFrame::test_f_dataframe_union_reduce - AssertionError: assert ['Alice', 'Bob'] == ['Alice', 'Bo...lie', 'Disco']
  
  Right contains 2 more items, first extra item: 'Charlie'
  
  Full diff:
    [
        'Alice',
        'Bob',
  -     'Charlie',
  -     'Disco',
    ]
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_negative_numbers - assert 5 == -5
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_word_boundaries - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_union - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_column_alias_in_groupBy - assert 1 == 2
 +  where 1 = len([Row(Person=None, avg(Value)=5.333333333333333)])
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_arithmetic - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_floating_point - assert 10.5 == 5.1
FAILED tests/test_issue_368_f_dataframe.py::TestIssue368FDataFrame::test_f_dataframe_union_multiple_dfs - assert 1 == 4
 +  where 1 = len([Row(id=1, val=a)])
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_union - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_limit - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_different_bases - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_boolean_column - assert True is False
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_unicode_strings - AssertionError: assert '' <= 'caf'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_select_expr - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_fixed_width - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_single_field - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_special_characters - AssertionError: assert 'A-B' == 'A B'
  
  - A B
  + A-B
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_distinct - ValueError: Robin execute_plan failed: session/df: not found: Column 'array_contains(IDs, ID)' not found. Available columns: [Name, Dept, ID, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_multiple_struct_columns - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'Struct1'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_very_long_strings - AssertionError: assert 'CCCCCCCCCCCC...CCCCCCCCCCCCC' == 'AAAAAAAAAAAA...AAAAAAAAAAAAA'
  
  - AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
  + CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_chained_operations - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_column_base - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_alternation - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_withcolumn_renamed - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_multiple_fields - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_369_isin_negation.py::TestIssue369IsinNegation::test_negation_isin_string_column_int_list - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_computed_column - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_limit - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_chained_operations - ValueError: Robin execute_plan failed: session/df: not found: Column 'Category' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_in_select - assert None == 1
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_null_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_nested_select - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_capture_groups - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_distinct - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_multiple_orderby_calls - assert 10 == 20
FAILED tests/test_issue_369_isin_negation.py::TestIssue369IsinNegation::test_negation_isin_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_deeply_nested_struct - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'Level1'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_with_limit - assert 10 == 20
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_multiple_conditions_same_df - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_in_filter - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_in_with_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_case_when_chain - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_multiple_negative_lookaheads - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_orderby_dataframe - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_three_columns - assert (1 == 1 and 1 == 1 and 3 == 1)
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_union - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_369_isin_negation.py::TestIssue369IsinNegation::test_isin_without_negation_string_column_int_list - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_nested_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'array_contains(IDs, ID)' not found. Available columns: [Name, Department, MatchedID]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_duplicate_values - assert 10 == 5
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_equals_dot_notation - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_edge_cases - ValueError: Robin execute_plan failed: expression: unsupported expression op: log
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_limit - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias - assert None == 1
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_coalesce - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_character_classes - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_distinct - ValueError: Robin execute_plan failed: session/df: not found: Column 'StructVal' not found. Available columns: [Name, Extract-E1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_multiple_fields - assert None == 1
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_case_when - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_369_isin_negation.py::TestIssue369IsinNegation::test_negation_isin_string_to_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_nested_struct - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'Outer'
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit - ValueError: Robin execute_plan failed: expression: unsupported expression op: split
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_filter - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_in_withcolumn - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructValue'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_non_capturing_groups - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_cast - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_cast - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_and_other_columns - assert None == 1
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_coalesce - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_370_filter_in_string.py::TestIssue370FilterInString::test_filter_values_in_string_literal - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_null_values - assert None == 1
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_alias - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_single_row_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_aggregation_functions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_nested_struct - AssertionError: assert None == 'A'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_window_function - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_avg - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_complex_nested_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_cast - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_null_struct - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_370_filter_in_string.py::TestIssue370FilterInString::test_filter_values_in_numeric_literal - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_three_rows_all_peers - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_without_alias_still_works - ValueError: Robin execute_plan failed: session/df: not found: Column 'StructValue' not found. Available columns: [StructValue.E1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_count_distinct - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_chained_operations - assert 0 == 1
 +  where 0 = len([])
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_multiple_aggregations - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_unicode - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_max - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_null_field - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_370_filter_in_string.py::TestIssue370FilterInString::test_filter_in_string_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_with_nulls_excluded - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_stddev_variance - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_mixed_nulls - assert None == 1
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_coalesce - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_with_withcolumn - ValueError: Robin execute_plan failed: session/df: not found: Column 'Value' not found. Available columns: [Name, ValueDouble]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_min - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_different_data_types - assert None == 1
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_multiple_fixed_widths - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_orderBy - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_null_values - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_case_sensitivity - assert None == 1
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_multiple_cols_subset_of_partition_by - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_special_characters - assert None == 2
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_with_orderby - AssertionError: assert 'Alice' == 'Bob'
  
  - Bob
  + Alice
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_when_otherwise_nested - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_in_groupby_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_370_filter_in_string.py::TestIssue370FilterInString::test_filter_in_multiple_literals - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_count - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_groupBy - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_empty_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_join - ValueError: Robin execute_plan failed: session/df: not found: Column 'ID' not found. Available columns: [Name, E1-Extract]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_no_order_by_partition_total - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_union - assert 1 == 2
 +  where 1 = len([Row(Name=Alice, E1-Extract=None)])
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_string_operations - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_join - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_with_column_cast_decimal_10_0 - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'DecimalValue'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_performance_large_dataset - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_ntile - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_groupby - assert 0 == 3
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_single_row_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_complex_nested_operations - AssertionError: assert 'Alice' == 'Bob'
  
  - Bob
  + Alice
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_partition_by_order_by - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_limit - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_case_when - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_lowercase - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_large_list - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_cume_dist - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_window_function - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_special_characters - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_with_join - ValueError: Robin execute_plan failed: session/df: not found: Column 'ID' not found. Available columns: [Name, AvgValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_avg_string_column - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_chained_operations - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'StructVal'
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_with_union - assert 1 == 2
 +  where 1 = len([Row(Name=Alice, AvgValue=1.5)])
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_multiple_selects - ValueError: Robin execute_plan failed: session/df: not found: Column 'E1-Extract' not found. Available columns: [FinalE1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_first_value - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_in_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'a' not found. Available columns: [dec]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_case_sensitivity - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_gt_comparison - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_with_window_function - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_running_sum - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileName::test_input_file_name_returns_string_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_array_index - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_with_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_last_value - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_escaped_characters - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_different_precision_scale - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd5_2'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_lt_comparison - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_with_show - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_equivalent_to_getitem - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileName::test_input_file_name_exact_issue_scenario - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_with_limit - AssertionError: assert 'Alice' == 'Charlie'
  
  - Charlie
  + Alice
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_countDistinct - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_quantified_groups - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_after_filter - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'dec'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_ge_comparison - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_struct_field_by_name - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_with_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_with_nulls - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileName::test_input_file_name_select_only - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_string_values - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookahead_with_boundaries - ValueError: Robin execute_plan failed: expression: unsupported expression op: rlike
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_createDataFrame_tuple_column_names - assert 2 == 4
 +  where 2 = len([Row(id=1, age=25, name=alice), Row(id=2, age=30, name=bob)])
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_with_nulls - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'dec'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_le_comparison - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_nested_array_access - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: array element type 'array<long>' not supported
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_different_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_no_partition_running_sum - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_empty_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_float_values - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_in_withcolumn - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_float_to_decimal - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'dec'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_eq_comparison - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_negative_index - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_different_column_order_by_position - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_then_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_avg_string_column_multiple_partitions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_single_row - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_in_select - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_chained_access - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: array element type 'array<long>' not supported
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_complex_filter - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_ne_comparison - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_show_then_collect - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_chained_three_dataframes - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "a" and "col1"
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_integer_type_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_decimal_like - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_after_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_integers - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_partitions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_filter - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_single_digit_precision - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'decimal' for column 'd'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_empty_dataframe_left - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_after_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_single_row_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_empty_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_no_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_conditions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_empty_dataframe_right - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "a"
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_select_after - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_null_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_preserves_schema - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_rowsBetween - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_rank - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_both_empty - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_with_nulls_in_array - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_exact_issue - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_with_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_rangeBetween - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_dense_rank - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_with_nulls - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_null_array_returns_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: array_distinct
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_all_rows_same_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_not_like_exact_issue - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_negative_values - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_percent_rank - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_unionAll_alias - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_float_arrays_preserves_type - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_multiple_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_with_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_zero_values - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_lag - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_single_column - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "other"
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_exact_issue - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_alias - ValueError: Robin execute_plan failed: expression: unsupported expression op: input_file_name
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_boolean_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_lead - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_prefix_pattern - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_duplicate_scores - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_many_columns_different_names - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "c1" and "a"
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_sum - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_underscore_wildcard - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_all_duplicates_int - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_select_struct - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_all_null_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_then_select - ValueError: collect_as_json_rows failed: field not found: id
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_with_decimals - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_empty_result - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_mixed_types - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_all_duplicates_string - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_not_like_multiple_rows - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_row_number - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_then_order_by - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_negative_numbers - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_column_with_underscore - assert None == 42
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_multiple_strings_or - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_desc_ordering - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_expr_like_standalone - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_zero_values - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_scientific_notation - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_then_filter - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "a"
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_sum - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_then_select_subset - ValueError: Robin execute_plan failed: session/df: not found: Column 'B' not found. Available columns: [A, C]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_with_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_asc_ordering - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_suffix_pattern - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_long_type - assert None == 9999999999
FAILED tests/test_issue_431_date_datetime_comparison.py::test_datetime_less_than_date - AssertionError: assert None == datetime.datetime(2023, 6, 15, 10, 0)
 +  where datetime.datetime(2023, 6, 15, 10, 0) = <class 'datetime.datetime'>(2023, 6, 15, 10, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_chained_with_filter - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_with_whitespace - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_mixed_with_plain_select - assert None == 100
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_ne_datetime - AssertionError: assert None == datetime.datetime(2024, 1, 1, 12, 0)
 +  where datetime.datetime(2024, 1, 1, 12, 0) = <class 'datetime.datetime'>(2024, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_avg - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_count - ValueError: collect_as_json_rows failed: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_420_when_comparison_with_none.py::TestIssue420WhenComparisonWithNone::test_when_comparison_with_none_exact_issue - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_and_combined - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_integer_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_unicode_strings - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_literal_cast_string_exact_issue_436 - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_over_partition_order_desc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_420_when_comparison_with_none.py::TestIssue420WhenComparisonWithNone::test_when_comparison_with_none_and_show - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_with_nulls_in_partition - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_mixed_string_numeric_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_or_combined - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_no_type_error - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_multiple_rows_mixed - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_literal_col_cast_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_over_order_desc_no_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_exact_issue - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_zero - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_multiple_window_fields - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_empty_result - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_datetime_to_timestamp_noop - AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_exact_issue_440 - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_single_element - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_all_literals_still_works - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_to_date_noop - AssertionError: assert None == datetime.date(2024, 1, 1)
 +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_reverse_order - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_over_partition_order_asc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_multiple_underscores - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_aliased_column_refs - ValueError: Robin execute_plan failed: session/df: not found: Column 'sm.brand_id = b.code' not found. Available columns: [brand_uuid, sm.taxonomy_id, sm.confidence]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_literals_only - ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_empty_array - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_all_columns_still_works - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_then_filter - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_string_to_timestamp_still_works - AssertionError: assert None == datetime.datetime(2024, 1, 15, 10, 30)
 +  where datetime.datetime(2024, 1, 15, 10, 30) = <class 'datetime.datetime'>(2024, 1, 15, 10, 30, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_left_no_match - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_with_column_pattern - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_expr_not_like_in_with_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_multiple_aliased_tables - ValueError: Robin execute_plan failed: session/df: not found: Column 'u.dept_id = d.dept_id' not found. Available columns: [u.name, d.dept_name, l.city]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_string_to_date_still_works - AssertionError: assert None == datetime.date(2024, 1, 15)
 +  where datetime.date(2024, 1, 15) = <class 'datetime.date'>(2024, 1, 15)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_outer_alias_two_names - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode_outer
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_expression_cast_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_datetime_to_timestamp_with_nulls - AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_inner - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'id_r' has more than one occurrence
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_mixed_literals_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_chain_three_with_window_middle - TypeError: Object of type WindowFunction is not JSON serializable
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_sum_over_partition_order_desc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_aliased_column_without_prefix - ValueError: Robin execute_plan failed: session/df: not found: Column 't1.id = t2.id' not found. Available columns: [id, val, data]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_with_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_to_date_with_nulls - AssertionError: assert None == datetime.date(2024, 1, 1)
 +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_explode_alias_single_name - ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_cast_string_with_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_aliased_self_join - ValueError: Robin execute_plan failed: session/df: not found: Column 'e.manager_id = m.id' not found. Available columns: [employee, manager]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_right - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'b' has more than one occurrence
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_groupby_agg_cast_decimal_drop - ValueError: Robin execute_plan failed: session/df: not found: Column 'Name' not found. Available columns: [CAST(sum(Value) AS DECIMALTYPE(38, 6))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_to_timestamp_midnight - AssertionError: assert None == datetime.datetime(2024, 3, 15, 0, 0)
 +  where datetime.datetime(2024, 3, 15, 0, 0) = <class 'datetime.datetime'>(2024, 3, 15, 0, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_lag_over_partition_order_desc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_middle_wildcard - ValueError: Robin execute_plan failed: expression: unsupported expression op: like
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_map_lookup_key_not_found - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_empty_array - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_datetime_to_date_truncates_time - AssertionError: assert None == datetime.date(2024, 5, 10)
 +  where datetime.date(2024, 5, 10) = <class 'datetime.date'>(2024, 5, 10)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_multiple_cast_expressions - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_complex_condition_with_aliases - ValueError: Robin execute_plan failed: session/df: not found: Column '(o.customer_id = c.customer_id & (o.amount > 30))' not found. Available columns: [o.order_id, c.name, o.amount]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_agg_cast_decimal_drop_different_precision_scale - ValueError: Robin execute_plan failed: session/df: not found: Column 'k' not found. Available columns: [CAST(sum(v) AS DECIMALTYPE(10, 2)), CAST(count(v) AS DECIMALTYPE(5, 0))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_outer - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'right_id' has more than one occurrence
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_first_over_partition_order_desc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_equality_exact_issue - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_nested_arrays - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_same_as_partition_by - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_abs_cast_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_only_string_to_timestamp - ValueError: collect_as_json_rows failed: conversion from `str` to `datetime[s]` failed in column 's' for 1 out of 1 values: ["2024-01-15"]

You might want to try:
- setting `strict=False` to set values that cannot be converted to `null`
- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_agg_cast_decimal_drop_with_nulls - ValueError: Robin execute_plan failed: session/df: not found: Column 'name' not found. Available columns: [CAST(sum(val) AS DECIMALTYPE(38, 2))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_equality_with_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_mixed_order_asc_desc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_with_show - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_then_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_outer_null_handling - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode_outer
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_select_with_cast - AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_length_cast_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_subset_of_partition_by - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_avg_cast_decimal_drop - ValueError: Robin execute_plan failed: session/df: not found: Column 'g' not found. Available columns: [CAST(avg(x) AS DECIMALTYPE(10, 2))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_is_null_workaround_still_works - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_single_row_per_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_no_args_returns_empty_array - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_with_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'Key = Name' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_with_null_value_in_map - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_with_datatype_objects - AssertionError: assert None == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_filter_after - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_differs_from_partition_running_sum - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_leap_day - AssertionError: assert None == datetime.date(2024, 2, 29)
 +  where datetime.date(2024, 2, 29) = <class 'datetime.date'>(2024, 2, 29)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_min_max_cast_decimal_drop - ValueError: Robin execute_plan failed: session/df: not found: Column 'k' not found. Available columns: [CAST(min(v) AS DECIMALTYPE(5, 0)), CAST(max(v) AS DECIMALTYPE(5, 0))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_dot_notation_still_works - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Key' has more than one occurrence
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_avg_over_partition_order_desc - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_list_returns_empty_array - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_numeric_like_keys - ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_float_cast_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_415_orderby_list.py::test_orderby_with_list_of_column_names - assert (1 == 1 and 2 == 1)
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_same_column_name_string_key_still_works - assert 0 == 1
 +  where 0 = len([])
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_and_is_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_avg_order_by_subset_of_partition_by - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_agg_cast_decimal_drop_then_show_and_collect - ValueError: Robin execute_plan failed: session/df: not found: Column 'id' not found. Available columns: [CAST(sum(amt) AS DECIMALTYPE(38, 2))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_433_regexp_in_expr.py::test_filter_regexp_exact_issue_433 - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
FAILED tests/test_issue_415_orderby_list.py::test_orderby_with_single_column_list - assert 2 == 1
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_single_pair - ValueError: Robin execute_plan failed: expression: unsupported expression op: create_map
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_show - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_422_fillna_float.py::TestIssue422FillnaFloat::test_fillna_float_subset_calculated_column - AttributeError: 'Row' object has no attribute 'copy'
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_with_column_alias_cast - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_415_orderby_list.py::test_orderby_desc_with_list - assert (1 == 2)
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_col_desc_still_subset - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_433_regexp_in_expr.py::test_filter_rlike_same_as_regexp - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_single_group_agg_cast_decimal_drop - ValueError: Robin execute_plan failed: session/df: not found: Column 'x' not found. Available columns: [CAST(sum(y) AS DECIMALTYPE(10, 0))]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_or_with_is_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_null
FAILED tests/test_issue_415_orderby_list.py::test_orderby_with_df_columns - AssertionError: assert 'IT' == 'HR'
  
  - HR
  + IT
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_six_pairs - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_415_orderby_list.py::test_orderby_with_string_columns - AssertionError: assert ('Z' == 'A'
  
  - A
  + Z)
FAILED tests/test_issue_433_regexp_in_expr.py::test_expr_regexp_with_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_448_drop_duplicates_list_column.py::test_distinct_after_select_with_array - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_415_orderby_list.py::test_orderby_with_three_columns - assert (3, 2, 1) == (1, 1, 1)
  
  At index 0 diff: 3 != 1
  
  Full diff:
    (
  -     1,
  ?     ^
  +     3,
  ?     ^
  -     1,
  ?     ^
  +     2,
  ?     ^
        1,
    )
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_list_and_array_equivalent - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_with_column_key_exact_issue_441 - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'MapValue'
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_equality_empty_result - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_415_orderby_list.py::test_orderby_then_limit - assert 3 == 1
FAILED tests/test_issue_433_regexp_in_expr.py::test_expr_regexp_single_match - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_multiple_partitions - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_after_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_key_not_found - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
FAILED tests/test_issue_415_orderby_list.py::test_orderby_then_select - assert (3 == 1)
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_expr_and_string_with_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_433_regexp_in_expr.py::test_expr_regexp_no_match - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_samp_over_window - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_in_union - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/test_issue_415_orderby_list.py::test_orderby_with_explicit_list_variable - assert 2 == 1
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_422_fillna_float.py::TestIssue422FillnaFloat::test_fillna_float_multiple_calculated_columns - AttributeError: 'Row' object has no attribute 'copy'
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_exact_issue_434 - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_select_after - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_pop_over_window - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_448_drop_duplicates_list_column.py::test_distinct_then_filter - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issues_376_382_robust.py::test_robust_join_compound_condition - ValueError: Robin execute_plan failed: session/df: not found: Column '(o.customer_id = c.customer_id & (o.amount > 30))' not found. Available columns: [o.order_id, o.amount, c.name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_422_fillna_float.py::TestIssue422FillnaFloat::test_fillna_float_after_filter - AttributeError: 'Row' object has no attribute 'copy'
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_with_integer_literal_exact_issue - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_only - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_then_filter - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_is_null_and_string_equality - ValueError: Robin execute_plan failed: expression: unsupported expression op: is_not_null
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_with_nulls - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_448_drop_duplicates_list_column.py::test_filter_then_drop_duplicates - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_issue_438_leftsemi_join.py::TestIssue438LeftsemiJoin::test_leftsemi_join_excludes_right_columns - assert 0 == 1
 +  where 0 = len([])
FAILED tests/test_issues_376_382_robust.py::test_robust_sql_where_table_prefixed - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_438_leftsemi_join.py::TestIssue438LeftsemiJoin::test_left_semi_join_excludes_right_columns - assert 0 == 2
 +  where 0 = len([])
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_string_type_exact_issue - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_rtrim_only - ValueError: Robin execute_plan failed: expression: unsupported expression op: rtrim
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_null_key_returns_null - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_single_row_per_partition_returns_none - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_drop_duplicates_struct_column_after_materialization_exact_issue_451 - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_string_literal_type_coercion_exact_issue - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issues_376_382_robust.py::test_robust_sql_group_by_table_prefixed - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_string_literal - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/test_issue_438_leftsemi_join.py::TestIssue438LeftsemiJoin::test_leftsemi_join_with_column_expression - ValueError: Robin execute_plan failed: session/df: not found: Column 'id = id' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_coalesce_default - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_nested_ltrim_rtrim_with_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_then_select_and_show - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_429_posexplode_no_alias.py::test_posexplode_without_alias_no_type_error - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issues_376_382_robust.py::test_robust_sql_three_joins_select_third_table - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_drop_duplicates_struct_column_before_materialization - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_workaround_still_works - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_438_leftsemi_join.py::TestIssue438LeftsemiJoin::test_leftanti_join_excludes_right_columns - assert 0 == 2
 +  where 0 = len([])
FAILED tests/test_notebooks.py::test_quickstart - assert 0 == 3
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 6 columns].count
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_multiple_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_rtrim_ltrim_order - ValueError: Robin execute_plan failed: expression: unsupported expression op: rtrim
FAILED tests/test_issue_438_leftsemi_join.py::TestIssue438LeftsemiJoin::test_leftsemi_join_multiple_keys - assert 0 == 1
 +  where 0 = len([])
FAILED tests/test_notebooks.py::test_dataframe_operations - assert 0 == 5
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 7 columns].count
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_distinct_struct_column_after_materialization - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_with_string_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_trim_with_ltrim_rtrim - ValueError: Robin execute_plan failed: expression: unsupported expression op: trim
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_orderby_result - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_drop_duplicates_subset_with_struct_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: struct
FAILED tests/test_issue_438_leftsemi_join.py::TestIssue438LeftsemiJoin::test_leftsemi_join_all_match - assert 0 == 2
 +  where 0 = len([])
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_multiple_values_or - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_429_posexplode_no_alias.py::test_posexplode_without_alias_single_element - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_with_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_when_otherwise - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_and_condition - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_exact_issue_453 - ValueError: Robin execute_plan failed: session/df: not found: Column 'y_int' not found. Available columns: [x, y, y_as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_438_leftsemi_join.py::TestIssue438LeftsemiJoin::test_leftsemi_join_then_select - assert 0 == 1
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_long_issue_243 - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_with_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_chained_with_columns - ValueError: Robin execute_plan failed: session/df: create_dataframe_from_rows: unsupported type 'map<string,string>' for column 'm'
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_integer_arrays_preserves_type - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_default_case_insensitive - AssertionError: assert None == 'Alice'
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_multiple_columns - ValueError: Robin execute_plan failed: session/df: not found: Column 'a_aliased' not found. Available columns: [a, b, a_int, b_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_multiple_in_or - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_mode - assert False is True
 +  where False = is_case_sensitive()
 +    where is_case_sensitive = Configuration(9 settings).is_case_sensitive
 +      where Configuration(9 settings) = <sparkless.session.core.session.SparkSession object at 0x10d833b90>.conf
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_timestamp_type_pass_through - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_select_still_works - AssertionError: assert None == 2
 +  where None = _row_val(Row(y_int=None), 'y_int')
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_string - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_insensitive_select - AssertionError: assert None == 'Alice'
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_two_names_returns_exploded_rows - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_empty_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_create_map_with_column_key - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_string_arrays - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_string_type_with_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_float_column_or - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_then_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'y_renamed' not found. Available columns: [x, y_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_int - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_no_none_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_insensitive_join - ValueError: collect_as_json_rows failed: not found: ID

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_rtrim_empty_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: rtrim
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_with_column_expr - ValueError: Robin execute_plan failed: expression: unsupported expression op: array_distinct
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_string_type_without_format - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_mode_exact_match_required - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_string_type - ValueError: Robin execute_plan failed: session/df: not found: Column 'n' not found. Available columns: [num, num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_zero_start - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_chained_filter_orderby - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_double - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_integer_type_unix_timestamp - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_triple_nested_trim - ValueError: Robin execute_plan failed: expression: unsupported expression op: trim
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_withColumn_fails_with_wrong_case - ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_empty_array - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_filter_fails_with_wrong_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_select_fails_with_wrong_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_double_type - ValueError: Robin execute_plan failed: session/df: not found: Column 'str_val' not found. Available columns: [s, dbl]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_alias - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_long_type_unix_timestamp - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_groupBy_fails_with_wrong_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_multiple_when - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_empty_array - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_column_with_underscore - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_single_element - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_date_type_conversion - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_join_fails_with_wrong_case - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'Dept' has more than one occurrence
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_long_type - ValueError: Robin execute_plan failed: session/df: not found: Column 'l' not found. Available columns: [s, lng]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_pyspark_parity_comprehensive - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_attribute_access_requires_exact_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_single_element - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_null_values - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_inside_upper - ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_in_select_expression - ValueError: collect_as_json_rows failed: cannot compare string with numeric type (i32)
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_sql_queries_require_exact_case - ValueError: Robin SQL failed: Table or view 'employees' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_double_type_unix_timestamp - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_alias - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_as_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_with_nulls - ValueError: Robin execute_plan failed: session/df: not found: Column 'a_aliased' not found. Available columns: [a, a_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_in_select - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_filter_with_ltrim - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_mixed_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_groupBy - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_issue_264_scenario - ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_after_regexp_replace - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_replace
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_complex_expressions - ValueError: Robin execute_plan failed: session/df: not found: Column 'a' not found. Available columns: [result_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_then_filter - ValueError: Robin execute_plan failed: session/df: not found: Column 'v' not found. Available columns: [name, val, val_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_ambiguity_detection - AssertionError: assert 'Bob' == 'Alice'
  
  - Alice
  + Bob
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_datatype_object - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_outer_alias_returns_exploded_rows - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode_outer
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_with_other_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_case_insensitive - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_orderby - assert 3.0 == 1.0
FAILED tests/test_type_strictness.py::TestTypeStrictness::test_to_timestamp_accepts_multiple_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_timestamp
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_then_orderby - AssertionError: assert ['8', '3', '5'] == ['3', '5', '8']
  
  At index 0 diff: '8' != '3'
  
  Full diff:
    [
  +     '8',
        '3',
        '5',
  -     '8',
    ]
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_invalid_string_to_int - ValueError: Robin execute_plan failed: session/df: not found: Column 'text' not found. Available columns: [as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_column_with_underscore - ValueError: Robin execute_plan failed: session/df: not found: Column 'mc' not found. Available columns: [my_column, mc_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_very_long_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_string_array - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_long - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_multiple_columns_ltrim_rtrim - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_in_when_otherwise - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_mixed_with_plain - ValueError: Robin execute_plan failed: session/df: not found: Column 's' not found. Available columns: [id, name, score, score_int, doubled]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double_to_int - ValueError: Robin execute_plan failed: session/df: not found: Column 'double_val' not found. Available columns: [as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_string - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_when_otherwise - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_exceeds_length - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_column_object - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_whitespace_only - ValueError: Robin execute_plan failed: expression: unsupported expression op: ltrim
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_not_between - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_to_boolean - ValueError: Robin execute_plan failed: session/df: not found: Column 'bool_str' not found. Available columns: [as_bool]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_cast - assert None == 5
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_replace_existing_column - ValueError: Robin execute_plan failed: session/df: not found: Column 'a_as_int' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_select_exact_issue_435 - AssertionError: assert ('Alice' == 'Alice'
  
    Alice and None == 123)
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_show_no_none - ValueError: Robin execute_plan failed: expression: unsupported expression op: posexplode
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start_exceeds_length - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_double - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_orderBy - AssertionError: assert (['10', '2', '100'] == ['2', '10', '100']
  
  At index 0 diff: '10' != '2'
  
  Full diff:
    [
  +     '10',
        '2',
  -     '10',
        '100',
    ] or ['10', '2', '100'] == ['2', '100', '10']
  
  At index 0 diff: '10' != '2'
  
  Full diff:
    [
  +     '10',
        '2',
        '100',
  -     '10',
    ])
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_without_cast_still_works - assert None == 2
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_less_than_datetime - AssertionError: assert None == datetime.date(2024, 1, 1)
 +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_chain_three_ops - ValueError: Robin execute_plan failed: session/df: not found: Column 'x_a' not found. Available columns: [x, y, z, x_int, y_int, z_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_cast_without_alias_still_works - assert None == 123
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_partition - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/parity/dataframe/test_double_join_empty_aggregated.py::TestDoubleJoinEmptyAggregated::test_columns_preserved_in_double_join_with_empty_aggregated - ValueError: Robin execute_plan failed: expression: unsupported expression op: concat
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_eq_datetime - AssertionError: assert None == datetime.datetime(2024, 1, 1, 0, 0)
 +  where datetime.datetime(2024, 1, 1, 0, 0) = <class 'datetime.datetime'>(2024, 1, 1, 0, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_string_type - AssertionError: assert None == '123'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_chained - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_after_filter - ValueError: Robin execute_plan failed: session/df: not found: Column 'v' not found. Available columns: [id, val, val_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_lte_datetime - AssertionError: assert None == datetime.datetime(2024, 1, 1, 0, 0)
 +  where datetime.datetime(2024, 1, 1, 0, 0) = <class 'datetime.datetime'>(2024, 1, 1, 0, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_multiple_columns - assert (None == 1)
FAILED tests/unit/dataframe/test_fillna_subset.py::TestFillnaSubset::test_fillna_subset_with_select_operation - AttributeError: 'Row' object has no attribute 'copy'
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_sum - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_gte_datetime - AssertionError: assert None == datetime.date(2024, 6, 15)
 +  where datetime.date(2024, 6, 15) = <class 'datetime.date'>(2024, 6, 15)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_double_type - assert None == 3.14
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_all_column_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: upper
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_empty_dataframe - ValueError: Robin execute_plan failed: session/df: not found: Column 'a_alias' not found. Available columns: [a, a_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_with_nulls - assert None == 1
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_in_select - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_select_multiple_columns - ValueError: Robin execute_plan failed: session/df: not found: Column 'col' not found. Available columns: [double, add, sub]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_round_string_with_whitespace - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_variations - ValueError: Robin execute_plan failed: session/df: not found: Column 'date_str' not found. Available columns: [date_col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_on_table_with_complex_schema - ValueError: can not infer schema from empty dataset
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_then_filter - ValueError: Robin execute_plan failed: session/df: not found: Column 'val_int' not found. Available columns: [name, col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_datatype_object - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/test_issues_376_382_robust.py::test_robust_round_string_with_decimals_and_whitespace - ValueError: Robin execute_plan failed: expression: unsupported expression op: round
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_zero_and_negative - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [as_string, as_bool]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_filter_on_table_with_comparison_operations - ValueError: can not infer schema from empty dataset
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_arithmetic_operations_in_filters - ValueError: can not infer schema from empty dataset
FAILED tests/test_issues_376_382_robust.py::test_robust_select_table_prefixed_after_join - ValueError: Robin execute_plan failed: session/df: not found: Column 't1.id = t2.id' not found. Available columns: [t1.id, t2.label]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_float_string_conversions - ValueError: Robin execute_plan failed: session/df: not found: Column 'double_val' not found. Available columns: [double_str, str_double]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_string - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_complex_nested_operations_in_filters - ValueError: can not infer schema from empty dataset
FAILED tests/test_issues_376_382_robust.py::test_robust_self_join_manager_column_and_row_count - ValueError: can not infer schema from empty dataset
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_empty_string_handling - ValueError: Robin execute_plan failed: session/df: not found: Column 'text' not found. Available columns: [as_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_int - ValueError: Robin execute_plan failed: session/df: not found: Column 'num_str' not found. Available columns: [num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_multiple_keys_complex - assert 0 == 2
 +  where 0 = len([])
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_string_operations_in_filters - ValueError: Robin execute_plan failed: expression: unsupported expression op: startswith
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_type_promotion_int32_int64 - assert 0 == 1
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_column_operation - ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_equals_cast_comprehensive - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_logical_operations_in_filters - ValueError: Robin execute_plan failed: expression: unsupported expression op: !
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_left_on_right_on_different_names - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'code' has more than one occurrence
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_issue_239_example - ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_after_when_otherwise - ValueError: Robin execute_plan failed: session/df: not found: Column 'value' not found. Available columns: [doubled_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_mixed_numeric_strings - assert 0 == 4
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_scientific_notation_strings - assert 0 == 1
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_datatype_object - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_date_pyspark_parity - ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int64_with_string - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_equals_cast - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_long_type - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [as_long]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_string_with_int64 - assert 0 == 2
 +  where 0 = len([])
FAILED tests/parity/dataframe/test_join.py::TestJoinParity::test_inner_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_string - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'text' not found. Available columns: [num, num_str, text_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'col' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_join.py::TestJoinParity::test_left_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_type_aliases - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [as_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_float_with_string - assert 0 == 2
 +  where 0 = len([])
FAILED tests/parity/dataframe/test_join.py::TestJoinParity::test_right_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_int64 - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_basic_substr - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/parity/dataframe/test_join.py::TestJoinParity::test_outer_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=5
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_null - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_with_left_on_right_on - ValueError: Robin execute_plan failed: session/df: duplicate: column with name 'key_right' has more than one occurrence
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_from_second_position - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_zero_values - assert 2 == 4
 +  where 2 = len([Row(key=0, value=A), Row(key=0, value=B)])
FAILED tests/parity/dataframe/test_join.py::TestJoinParity::test_semi_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_multiple_keys_with_type_mismatch - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [num_double]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_large_numbers - assert 2 == 4
 +  where 2 = len([Row(key=2147483647, value=A), Row(key=9223372036854775807, value=B)])
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_type_coercion_parity_pyspark - assert 0 == 2
 +  where 0 = len([])
FAILED tests/parity/dataframe/test_join.py::TestJoinParity::test_anti_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=1
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_orderby - AssertionError: assert '30' == '10'
  
  - 10
  + 30
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_issue_238_example - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_filter - AttributeError: 'Row' object has no attribute 'copy'
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_left_outer_with_type_mismatch - AssertionError: assert 1234 in {'1234', '4567', '9999'}
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_decimal_precision - assert 2 == 4
 +  where 2 = len([Row(key=1.123456789, value=A), Row(key=2.987654321, value=B)])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_boolean - ValueError: Robin execute_plan failed: session/df: not found: Column 'value' not found. Available columns: [value_bool]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_at_one - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int64_string_inner - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_scientific_notation_strings - assert 1 == 2
 +  where 1 = len([Row(key=123.0, value=A)])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int64_with_string - assert 2 == 4
 +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
FAILED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_select - AttributeError: 'Row' object has no attribute 'copy'
FAILED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_after_join - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_string_int64_inner - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_chained_operations - ValueError: Robin execute_plan failed: session/df: not found: Column 'num' not found. Available columns: [doubled_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_beyond_length - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_multiple_numeric_types - ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_all_join_types - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_string_with_int64 - ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_literal - AssertionError: assert None == '123'
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_double_precision_string - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int32_with_string - assert 2 == 4
 +  where 2 = len([Row(key=100, value=A), Row(key=200, value=B)])
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_in_window - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_chained_unions - ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int_float_coercion - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_from_string - ValueError: Robin execute_plan failed: session/df: not found: Column 'date_str' not found. Available columns: [date_col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_float_with_string - assert 2 == 4
 +  where 2 = len([Row(key=1.5, value=A), Row(key=2.5, value=B)])
FAILED tests/unit/functions/test_approx_count_distinct_rsd.py::TestApproxCountDistinctRsd::test_approx_count_distinct_window_without_rsd - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_null_values_in_join_keys - assert 0 >= 2
 +  where 0 = len([])
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_zero - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_basic - AssertionError: assert 'A' == 'D'
  
  - D
  + A
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int32_with_int64 - assert 2 == 4
 +  where 2 = len([Row(key=1234, value=A), Row(key=4567, value=B)])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_all_null_columns - assert 1 == 2
 +  where 1 = len([Row(key=None, value=A)])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_to_date - ValueError: Robin execute_plan failed: expression: unsupported expression op: substring
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_invalid_numeric_strings - assert 0 == 2
 +  where 0 = len([])
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_first - AssertionError: assert 'A' is None
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_int_with_float - assert 2 == 4
 +  where 2 = len([Row(key=100.0, value=A), Row(key=200.0, value=B)])
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_field_access - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_mixed_nulls_and_values - assert 2 == 4
 +  where 2 = len([Row(key=1, value=A), Row(key=None, value=B)])
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_exceeds_remaining - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_na_fill_robust.py::TestNaFillRobust::test_na_fill_with_union - assert 2 == 4
 +  where 2 = len([Row(id=1, name=UNKNOWN, value=10), Row(id=2, name=Alice, value=20)])
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last - AssertionError: assert None == 'C'
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_issue_242_exact_scenario - assert 2 == 4
 +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_types - ValueError: Robin execute_plan failed: session/df: not found: Column 'value' not found. Available columns: [as_int, as_double, as_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_very_large_numbers - assert None == 0
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_string_expression - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first - AssertionError: assert 'A' is None
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_int64_string - assert 2 == 4
 +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_three_dataframes - ValueError: collect_as_json_rows failed: type Float64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_all_four_methods_comprehensive - AssertionError: assert 'A' == 'M'
  
  - M
  + A
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_complex_expression - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_integers - assert 25 == 35
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_in_select - ValueError: Robin execute_plan failed: session/df: not found: Column 'string_1' not found. Available columns: [result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_exact_output_match - assert 2 == 4
 +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_nested_structs - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_string_int64 - ValueError: collect_as_json_rows failed: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_withColumn - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_no_nulls - AssertionError: assert 'A' == 'C'
  
  - C
  + A
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_float_string_decimal_values - assert 2 == 4
 +  where 2 = len([Row(key=1.5, value=A), Row(key=2.7, value=B)])
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_three_column_ordering - AssertionError: assert None == 'B'
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_multiple_numeric_string_columns - assert 1 == 2
 +  where 1 = len([Row(key=1, other=A, value=10)])
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_conditional_expression - TypeError: Object of type CaseWhen is not JSON serializable
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_very_deeply_nested_struct - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_multiple_nulls - AssertionError: assert 'A' == 'C'
  
  - C
  + A
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_null_values - assert 2 == 4
 +  where 2 = len([Row(key=1, value=A), Row(key=None, value=B)])
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_string_comparison_edge_cases - AssertionError: assert 'A' is None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_multiple_columns_comprehensive - assert 1 == 2
 +  where 1 = len([Row(col1=1, col2=10.5, col3=A, col4=100)])
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_when_otherwise - ValueError: Robin execute_plan failed: expression: expression must have 'col', 'lit', 'op', or 'fn'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_first_multiple_nulls - AssertionError: assert 'A' is None
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_complex_ordering_scenario - AssertionError: assert 'IT' == 'HR'
  
  - HR
  + IT
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_cast_operation - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_orderBy - AssertionError: assert 'Charlie' == 'Alice'
  
  - Alice
  + Charlie
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_double_with_string - assert 2 == 4
 +  where 2 = len([Row(key=123.456, value=A), Row(key=789.012, value=B)])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_order_preservation - assert 2 == 4
 +  where 2 = len([Row(key=1, value=A), Row(key=2, value=B)])
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_chained_with_cast - assert None == 5
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_xxhash64_known_values_and_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: xxhash64
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_with_sort_method - AssertionError: assert 'A' == 'D'
  
  - D
  + A
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_duplicate_values - AssertionError: assert 'A' == 'B'
  
  - B
  + A
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_null - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_float_with_double - assert 2 == 4
 +  where 2 = len([Row(key=1.5, value=A), Row(key=2.5, value=B)])
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_with_different_type - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_identical_nulls - assert 1 is None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_equals_substring_function - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_get_json_object_missing_path_and_invalid_json - ValueError: Robin execute_plan failed: expression: unsupported expression op: get_json_object
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParityRobust::test_pyspark_parity_large_dataset - assert 10 == 20
 +  where 10 = len([Row(key=0, value=A0), Row(key=1, value=A1), Row(key=2, value=A2), Row(key=3, value=A3), Row(key=4, value=A4), Row(key=5, value=A5), ...])
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_negative_numbers - assert 2 == 4
 +  where 2 = len([Row(key=-1, value=A), Row(key=-2, value=B)])
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_multiple_columns_ordering - AssertionError: assert None == 'B'
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_arithmetic - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_data_types_ordering - AssertionError: assert None == 'Bob'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_float - assert 1.5299999999999998 < 0.01
 +  where 1.5299999999999998 = abs((3.14 - 4.67))
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_fields_in_sequence - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_last_parity - AssertionError: assert 'A' == 'M'
  
  - M
  + A
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_json_tuple_missing_fields_and_invalid_json - ValueError: Robin execute_plan failed: expression: unsupported expression op: json_tuple
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_negative_numbers - assert -5 == 10
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_add_new_field - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_first_parity - AssertionError: assert 'Z' is None
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_conditional - TypeError: Object of type CaseWhen is not JSON serializable
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_null_literal - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_empty_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_regexp_extract_all_multiple_matches_and_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract_all
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_last_parity - AssertionError: assert 'Z' == 'A'
  
  - A
  + Z
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_string_return_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_string - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_outer_column - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_array_field - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_existing_field - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_first_parity - AssertionError: assert 'Z' is None
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_unicode - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_nulls_at_beginning_middle_end - AssertionError: assert None == 'B'
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_integer_return_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_regexp_extract_all_189.py::test_regexp_extract_all_basic_groups - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract_all
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_multi_column_parity - assert 2 is None
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_zero_value - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_unicode_characters - AssertionError: assert '' is None
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_chained_operations - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_column_expression - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start - ValueError: Robin execute_plan failed: expression: unsupported expression op: substr
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_filter - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_integer_ordering_parity - assert -5 == 0
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_double_return_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_chained_operations - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_float_ordering_parity - assert 1.6400000000000001 < 0.01
 +  where 1.6400000000000001 = abs((1.5 - 3.14))
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_reference_other_nested - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_select - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_computed_expression - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_boolean_return_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_with_literal - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_date_trunc_polars_backend.py::TestDateTruncPolarsBackend::test_date_trunc_month_on_date_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: to_date
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_two_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_multiple_columns_same_udf - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_translate_edge_cases - ValueError: Robin execute_plan failed: expression: unsupported expression op: translate
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_all_null_structs - ValueError: Robin execute_plan failed: expression: unsupported expression op: withField
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_chained - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_timestamp_core_units - ValueError: Robin execute_plan failed: expression: unsupported expression op: date_trunc
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_three_arguments - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_in_orderBy - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_substring_index_edge_cases - ValueError: Robin execute_plan failed: expression: unsupported expression op: substring_index
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_null_struct - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: withField
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_mixed_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_long_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_on_date_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: date_trunc
FAILED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_multiple_when_matched - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_levenshtein_nulls_and_empty_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: levenshtein
FAILED tests/unit/session/test_sql_create_table_as_select.py::test_create_table_as_select_basic - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_select - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_issue_235_example - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_reference_other_struct_field - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/robin/test_robin_sql.py::test_robin_sql_simple_select - ValueError: Robin SQL failed: Table or view 't_robin_sql' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_first_clause_wins - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_float_type - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_matches_delta_table_detail - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_preserves_nulls - ValueError: Robin execute_plan failed: expression: unsupported expression op: date_trunc
FAILED tests/unit/robin/test_robin_sql.py::test_robin_sql_group_by_agg - ValueError: Robin SQL failed: Table or view 't_robin_agg' not found. Register it with create_or_replace_temp_view or saveAsTable.
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_join - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_soundex_null_and_empty - ValueError: Robin execute_plan failed: expression: unsupported expression op: soundex
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_withColumn - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFCustomName::test_udf_with_custom_name - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_partition_columns - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeNotMatchedBySource::test_merge_delete_not_matched_by_source - ValueError: can not infer schema from empty dataset
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_different_data_types - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_string_functions - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/session/test_sql_complex_merge.py::TestComplexMergeBasic::test_merge_with_matched_condition - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_empty_table - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_multiple_joins - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFRegression279::test_udf_with_withColumn_regression_279 - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_crc32_known_values_and_null - ValueError: Robin execute_plan failed: expression: unsupported expression op: crc32
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeNotMatchedBySource::test_merge_not_matched_by_source_no_condition - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_special_characters_in_name - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_nonexistent_table - ValueError: can not infer schema from empty dataset
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_chained_multiple_times - ValueError: Robin execute_plan failed: expression: unsupported expression op: withField
FAILED tests/unit/functions/test_udf_regression_279.py::test_udf_with_withColumn_regression_279 - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_left_join - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_groupBy_aggregation - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeComplexExpressions::test_merge_with_expression_in_set - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_multiple_writes - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_large_table - ValueError: can not infer schema from empty dataset
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_arithmetic_operations - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_where_clause - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_input - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeComplexExpressions::test_merge_with_arithmetic_expression - ValueError: can not infer schema from empty dataset
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_struct - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_different_data_types - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_complex_schema - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_return - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_preserves_all_existing_fields - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_aggregation_after_join - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_in_clause.py::test_sql_in_clause_basic - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_all_required_columns - ValueError: can not infer schema from empty dataset
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_then_add - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_all - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_self_join - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_like_clause.py::test_sql_like_simple_prefix_pattern - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_multiple_partitions - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_update.py::test_update_table_basic - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_single_row - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeInsertAll::test_merge_insert_only_unmatched - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_basic - ValueError: can not infer schema from empty dataset
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_deeply_nested_struct - ValueError: Robin execute_plan failed: session/df: struct value must be object or array
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_table_properties - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_with_schema - ValueError: can not infer schema from empty dataset
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_large_dataframe - ValueError: Robin execute_plan failed: expression: unsupported expression op: udf
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_no_matches - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_overwrite_operation - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_non_delta_table_raises - ValueError: can not infer schema from empty dataset
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_empty_source - ValueError: can not infer schema from empty dataset
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_special_characters_in_column_names - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_union_operation - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_column_objects - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_null_values - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/session/test_sql_complex_merge.py::TestMergeEdgeCases::test_merge_all_matched_deleted - ValueError: can not infer schema from empty dataset
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_preserves_order - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_groupby_context - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_column_objects - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_all_null_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_empty_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_join - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_together - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_numeric_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_zero_and_negative_numbers - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_window_functions - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_boolean_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_with_mixed_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_large_number_of_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_single_column - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_select_operation - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types_comprehensive - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_expressions - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_three_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_filter_operation - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_select_statement - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_nested_expressions - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_after_filter - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_explode_operation - ValueError: Robin execute_plan failed: expression: unsupported expression op: explode
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_string_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_union - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_computed_columns - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: array
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_withcolumn_operation - ValueError: Robin execute_plan failed: session/df: array column value must be null or array
FAILED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_orderby - AssertionError: assert 'Charlie' == 'Alice'
  
  - Alice
  + Charlie
FAILED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_join - assert None is not None
FAILED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_union_operations - assert 2 == 4
 +  where 2 = count()
 +    where count = DataFrame[2 rows, 2 columns].count
FAILED tests/unit/test_first_method.py::TestDataFrameFirst::test_first_after_multiple_transformations - ValueError: Robin execute_plan failed: session/df: not found: Column 'age' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issue_270_tuple_dataframe.py::TestIssue270TupleDataFrame::test_tuple_data_join_operations - assert 0 == 2
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 3 columns].count
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_empty_list - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_star_args - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_array_index - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_out_of_bounds - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_without_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
FAILED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_numeric_eq_string - ValueError: collect_as_json_rows failed: cannot compare string with numeric type (i64)
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookbehind - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_list - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_single_value - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_strings - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_select_case_insensitive - AssertionError: assert None == 'Alice'
 +  where None = Row(Name=None).Name
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_split_result - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_negative_index - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_complex_lookaround - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookahead - ValueError: Robin execute_plan failed: expression: unsupported expression op: regexp_extract
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_column_method - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_mixed_types - ValueError: Robin execute_plan failed: expression: unsupported expression op: isin
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_map_key - ValueError: Robin execute_plan failed: expression: unsupported expression op: getItem
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_orderBy_case_insensitive - assert 30 == 25
 +  where 30 = Row(Age=30, Name=Bob).Age
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_drop_case_insensitive - ValueError: Robin execute_plan failed: session/df: not found: Column 'name' not found. Available columns: [Age, City]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_join_case_insensitive - ValueError: collect_as_json_rows failed: not found: ID

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
===== 1497 failed, 1090 passed, 158 skipped, 1 xfailed in 62.76s (0:01:02) =====
