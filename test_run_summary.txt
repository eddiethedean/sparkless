============================= test session starts ==============================
platform darwin -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0
rootdir: /Users/odosmatthews/Documents/coding/sparkless
configfile: pyproject.toml
testpaths: tests
plugins: anyio-4.11.0, cov-7.0.0, green-light-0.2.0, asyncio-1.2.0, xdist-3.8.0, timeout-2.4.0, hypothesis-6.148.7, alt-pytest-asyncio-0.9.3, async-sqlalchemy-0.2.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
timeout: 300.0s
timeout method: thread
timeout func_only: False
created: 10/10 workers
10 workers [2741 items]

ss..FF.F..F..FFFFFFF....F...F...FFFFFFF.....F.....FFFF...FFFFFF..s....FF [  2%]
F..F.F.F...........FFs..F.....F.FFF..FFFFFFFFFF..FFFFFsFFF..FFs.FsF.FF.F [  5%]
F..FFF...FFFF..FF...F..FF.FF.FFF...F........FFF.F.FFFFF......FFFFFFFF... [  7%]
FF......FFF........s...sFFFFFF.F..FF.FF.FFF..F..s.FF.FFFFFF..F..FFFFFFFF [ 10%]
FFFFF..FFFFFFFF..FFFFFFFFFFFFFFFFF.........FFFFFFFF...FFFFFF...FFFFFFFFF [ 13%]
.F.FFF....FFFFF.FFFFFFFFFFF..........FF................FFFF..F.FFFF.FFF. [ 15%]
F.FFFF.F...FFFFF......F....FFFFFFF.FFFFFFFFF.FFFFFFFF.......FFFFFFFF.FF. [ 18%]
F.F.FFF...FF.FFFFFFFFFF.FFFFFFF.FFFFFF.FFFFFFFFFFFF.F.....FFFFFFFF.FF... [ 21%]
FF.....FFFF...F..FF...F..FF.FFFFF.FFF....FF..FF..FF.FFFFFFFFFFFFFFF.FF.. [ 23%]
....FFFFF...FF.FFF......FFFFF.FF...FF.FFFFFFFFFFFFFFFF..FFFFFF.FF......F [ 26%]
FFFFFF..FFFFFFFFF.F..FFFFFFFFFFFF.FFFFFFFFFFFF.....F...FFF.FFFFFFFFFFFFF [ 28%]
.F.FFFFFFFFFFFFFFFFFFFFFFFFFFFF...FFFF.FFFFFFFFFF.FFFFFFFFFF...F..FFF..F [ 31%]
FFFFFF.FFFFFFFFFF..FFFFFFFFFFFF........FFFF.FFF.FFFFFF..FFFF.FF.FF...... [ 34%]
...FF.FFF.FFFF......FFFFF.....FFFFFFFFFF.FF...FF.FFFFFFFFFFFF...F....... [ 36%]
.....FFFFFF...FFFFFFF.....FFFFFFF...F..F.F.F..FFFFF..F..FFFFFFF...FFFFF. [ 39%]
...FFFFFFFFFFFFFFFFFF...F...F..FF...FF.FFF.F..FF.sFFFFFFFFF.FFFFF.FFFFFF [ 42%]
FFFFFF.FFFFFFFFF.FFF..FFFFFF..s....FF.FFFFFF.FFFF.F..F.FFF.FF.FF..F.FFFF [ 44%]
FFFFFFF.ssFFFF......FFFFFFFFFFFF......FFFF....FF...FFFFF....FFFF...FF.FF [ 47%]
FF.FFFFFFFFFFFF..F..FFFFFFF..FF.FFFFF..F.F.........FFFFFFFFF....FFFFFFFF [ 49%]
FFFFF........FFFFFF..FFFF....FFFFFFF.FF..F.FFFFFFFF.FFFFFF.FFFFF.F..FF.F [ 52%]
FF.FFFF..FFFFFFFFF..........FFF.....sss....FF...FFF.FFFFFF....FF..FF.F.F [ 55%]
F.FFFFFFFF.F.FFF.F....F......F..FF..F.F......FFFFF...FFFF.FF..FFFFFFFFFF [ 57%]
FFFF.F..FFFFF...........FFFFFFFFFFFFF....FFFFFFFFFFFFFF.FFFFFF.FFFFFFFFF [ 60%]
FFFFF.FFFF.FFF..FFFF..FFF..FF.FFFFFFFFFFFFsFF.....FF...FFFF.F.sFFF.F.... [ 63%]
FF.....FFFFF.F.FFsFFFFFFF.FFFFF.......FF............F......s..F....F.... [ 65%]
..............FF..................FFFFF......s.......................... [ 68%]
.........F........FFFF..FFFF..................sFF...F.........FFF....... [ 70%]
....F....................sF........F.FF......FF..............F...F...... [ 73%]
.......FFFFF....FFFFF.F..F.FFF.......FF.....F....FFF.FFF......FF.F..F.FF [ 76%]
F......FFFFFF....FF.....F....FF..FF...F.F.F.FF.F.FFFF....FFFF.F.F....... [ 78%]
....ssF.F............FF......FF..FFFFFF.FFF.FF...FFFF.F.F..FFF......F... [ 81%]
......F.....F.F..FFFFFFFFFFF.F...........F....FFFFFF.....F.FF.F....F.... [ 84%]
..F.................F....................F.........................F.... [ 86%]
.F............F..F.F.F.F.....F.FFF.F..F....FF.ssFFFFF.FF.FFF..FFF.FFFFFF [ 89%]
.FF...F.....F.FF..FFFF..FFFF.FFFFFF.FF...F.FFFFFF.FFFFFFF...FFF..FFFFFFF [ 91%]
FFFFFFF.....FF...FF......F.............F..F...F...F................FF... [ 94%]
.F..FF...FF..FFFF.....F....................................F.FFFFFFFFFFF [ 97%]
FFFFFFFFFF.....F.........F.FFFFFFFFFF.F.........sssF....F.F..FF......... [ 99%]
.....                                                                    [100%]
================================ tests coverage ================================
______________ coverage: platform darwin, python 3.11.13-final-0 _______________

Name                                                                 Stmts   Miss  Cover   Missing
--------------------------------------------------------------------------------------------------
sparkless/__init__.py                                                   24      0   100%
sparkless/_version.py                                                    8      4    50%   10-12, 16-19
sparkless/backend/__init__.py                                            3      0   100%
sparkless/backend/factory.py                                            72     27    62%   45, 105, 113-115, 135-157, 176, 190-191
sparkless/backend/polars/__init__.py                                     4      3    25%   20-23
sparkless/backend/polars/_over_compat.py                                19     19     0%   8-40
sparkless/backend/polars/executors/__init__.py                           1      1     0%   13
sparkless/backend/polars/export.py                                      36     36     0%   7-114
sparkless/backend/polars/expression_translator.py                     2172   2172     0%   8-5251
sparkless/backend/polars/materializer.py                               852    852     0%   8-1944
sparkless/backend/polars/operation_executor.py                        2047   2047     0%   1-4555
sparkless/backend/polars/parquet_storage.py                             41     41     0%   8-119
sparkless/backend/polars/plan_interpreter.py                           381    381     0%   8-531
sparkless/backend/polars/schema_registry.py                             73     73     0%   8-222
sparkless/backend/polars/schema_utils.py                                31     31     0%   3-69
sparkless/backend/polars/storage.py                                    350    346     1%   13-771
sparkless/backend/polars/translators/__init__.py                         1      1     0%   14
sparkless/backend/polars/translators/arithmetic_translator.py           17     17     0%   8-70
sparkless/backend/polars/translators/string_translator.py              145    145     0%   8-302
sparkless/backend/polars/translators/type_translator.py                107    107     0%   8-190
sparkless/backend/polars/type_mapper.py                                 99     99     0%   8-173
sparkless/backend/polars/window_handler.py                             290    290     0%   7-563
sparkless/backend/protocols.py                                          14      0   100%
sparkless/backend/robin/__init__.py                                      4      0   100%
sparkless/backend/robin/export.py                                       46     34    26%   20-29, 36, 41-50, 55-62, 71-77, 80-85
sparkless/backend/robin/materializer.py                                766    323    58%   48-49, 79-83, 97, 102-105, 115-118, 126, 135-140, 142, 151-152, 171, 191, 215, 218, 235, 245, 272, 276, 291, 300, 312, 329, 336, 344-345, 350, 361, 363, 368, 371, 375-376, 380, 433-434, 439, 441, 443, 445, 451-782, 821, 839, 844, 849-850, 869, 920, 934-937, 946-947, 980-984, 996, 1009, 1021-1033, 1037-1049, 1090, 1095, 1135
sparkless/backend/robin/plan_executor.py                               191     52    73%   18-19, 30-32, 43, 50, 55, 69-75, 84, 87-89, 92-97, 127, 142, 160-163, 171-172, 186, 190, 195, 205, 217, 221, 227, 229, 235, 240-244, 246-247, 258-260, 263
sparkless/backend/robin/storage.py                                      52      4    92%   27, 33, 77, 99
sparkless/compat/__init__.py                                             2      0   100%
sparkless/compat/datetime.py                                            74     53    28%   43, 55-57, 61-67, 73-81, 96-103, 115-122, 128-133, 141-146, 162-182
sparkless/config.py                                                     55     10    82%   46-58, 69, 78, 80, 106
sparkless/core/__init__.py                                               9      0   100%
sparkless/core/column_resolver.py                                       33      0   100%
sparkless/core/condition_evaluator.py                                  764    730     4%   27-34, 49-56, 71-245, 260-541, 556-576, 591-604, 619-781, 795-1203, 1218-1229, 1245-1274, 1290-1311, 1324-1340, 1353, 1366-1370, 1384-1403
sparkless/core/data_validation.py                                       80     41    49%   56-85, 91-113, 129, 136-137, 177-185, 205-206, 220-221
sparkless/core/ddl_adapter.py                                           31      8    74%   94, 98-106
sparkless/core/exceptions/__init__.py                                    6      0   100%
sparkless/core/exceptions/analysis.py                                  100     57    43%   51, 57, 91, 109, 142, 145-154, 170-202, 230-245, 269-272, 302-323
sparkless/core/exceptions/base.py                                       22      4    82%   31, 61, 76, 91
sparkless/core/exceptions/execution.py                                  29     12    59%   45, 63, 87-90, 114-117, 135, 153
sparkless/core/exceptions/operation.py                                  87     55    37%   24-34, 49-58, 72-82, 96-106, 120-129, 152, 173-183
sparkless/core/exceptions/py4j_compat.py                                10     10     0%   8-41
sparkless/core/exceptions/runtime.py                                    41     24    41%   53-57, 75, 101-107, 131-134, 158-161, 187-193
sparkless/core/exceptions/validation.py                                 44     24    45%   63, 81, 107-111, 141-147, 171-174, 202-207
sparkless/core/interfaces/__init__.py                                    5      0   100%
sparkless/core/interfaces/dataframe.py                                 180     56    69%   20, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 98, 103, 110, 115, 120, 125, 130, 136, 142, 151, 156, 161, 166, 171, 176, 181, 190, 195, 200, 205, 212, 217, 222, 227, 232, 241, 246, 251, 256, 261, 266, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320
sparkless/core/interfaces/functions.py                                 186     56    70%   23, 28, 33, 42, 47, 56, 61, 70, 75, 84, 89, 94, 99, 108, 113, 118, 123, 130, 135, 144, 149, 154, 159, 164, 173, 178, 185, 192, 197, 202, 207, 212, 221, 226, 231, 236, 241, 250, 255, 263, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 333, 338, 343, 348
sparkless/core/interfaces/session.py                                   117     34    71%   20, 26, 32, 38, 44, 50, 59, 64, 69, 76, 81, 86, 96, 101, 106, 115, 120, 125, 136, 141, 146, 151, 156, 161, 166, 171, 176, 185, 190, 195, 200, 209, 214, 219
sparkless/core/interfaces/storage.py                                   126     38    70%   29, 34, 39, 44, 54, 59, 64, 69, 76, 83, 90, 97, 102, 106, 110, 114, 120, 126, 136, 142, 148, 153, 158, 163, 168, 173, 186, 192, 198, 204, 210, 215, 220, 229, 234, 239, 248, 253
sparkless/core/protocols.py                                             42      0   100%
sparkless/core/safe_evaluator.py                                       125     83    34%   45-50, 66-67, 86, 88, 90, 95, 97-103, 105-134, 145-147, 150-152, 157-164, 169, 171, 173, 176-179, 184-215
sparkless/core/schema_inference.py                                     211     29    86%   73, 132, 199, 218-237, 281, 294, 329, 333, 360-361, 383-384, 395-396, 406-407, 451, 461
sparkless/core/type_utils.py                                            86     51    41%   20-21, 91-93, 117, 140-144, 164-168, 187-199, 223-259, 278, 290-292, 304
sparkless/core/types/__init__.py                                         4      0   100%
sparkless/core/types/data_types.py                                     139     38    73%   22, 27, 32, 37, 42, 47, 52, 57, 66, 76, 81, 91, 97, 102, 111, 121, 127, 132, 141, 146, 155, 160, 170, 175, 180, 190, 196, 201, 206, 211, 221, 226, 231, 240, 249, 254, 259, 264
sparkless/core/types/metadata.py                                       166     47    72%   18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 73, 79, 85, 91, 97, 103, 108, 113, 118, 128, 134, 140, 145, 150, 160, 166, 172, 177, 182, 187, 197, 203, 209, 215, 220, 225, 230, 239, 244, 249, 254, 259, 268, 273, 278, 283, 288
sparkless/core/types/schema.py                                         121     36    70%   22, 28, 34, 40, 45, 50, 55, 60, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 185, 190, 195, 200, 209, 214, 221, 226
sparkless/data_generation/__init__.py                                    4      4     0%   8-12
sparkless/data_generation/builder.py                                    28     28     0%   8-85
sparkless/data_generation/convenience.py                                 9      9     0%   8-64
sparkless/data_generation/generator.py                                 174    174     0%   8-337
sparkless/dataframe/__init__.py                                          6      0   100%
sparkless/dataframe/aggregations/__init__.py                             2      2     0%   8-10
sparkless/dataframe/aggregations/operations.py                          75     75     0%   8-208
sparkless/dataframe/assertions/__init__.py                               3      3     0%   7-10
sparkless/dataframe/assertions/assertions.py                            26     26     0%   8-88
sparkless/dataframe/assertions/operations.py                            16     16     0%   8-45
sparkless/dataframe/attribute_handler.py                                62      8    87%   176, 190-196, 223-224
sparkless/dataframe/casting/__init__.py                                  2      0   100%
sparkless/dataframe/casting/type_converter.py                           95     63    34%   54, 56-58, 62-64, 66, 69-92, 95-110, 132-153, 158-180
sparkless/dataframe/collection_handler.py                               29      9    69%   27-29, 36, 47-53, 81
sparkless/dataframe/condition_handler.py                                52     34    35%   58-64, 80, 109-122, 136-180
sparkless/dataframe/dataframe.py                                       513    154    70%   187-191, 219-224, 243, 262-265, 317, 377, 381, 394, 432, 440, 486, 490, 507-508, 524, 532, 555-561, 565, 569, 621, 625, 630, 634, 638, 642, 700, 715, 719, 723, 742, 746, 750, 756, 760, 780, 791, 803, 809, 813, 817, 821, 829, 835, 839, 843, 847, 852, 856, 860, 864, 875, 894, 960-969, 997, 1002, 1078-1097, 1103, 1152-1153, 1161-1162, 1201-1206, 1210, 1216, 1225, 1250, 1258, 1269, 1284, 1292, 1303, 1311, 1323, 1329, 1335, 1347-1353, 1368-1379, 1383, 1403-1411, 1420-1460
sparkless/dataframe/display/__init__.py                                  3      3     0%   3-6
sparkless/dataframe/display/formatter.py                                37     37     0%   3-57
sparkless/dataframe/display/operations.py                              118    118     0%   8-274
sparkless/dataframe/evaluation/__init__.py                               2      0   100%
sparkless/dataframe/evaluation/evaluators/__init__.py                    1      0   100%
sparkless/dataframe/evaluation/evaluators/conditional_evaluator.py      22      6    73%   42, 45, 57-63
sparkless/dataframe/evaluation/expression_evaluator.py                2615   2308    12%   96, 108, 111, 117-122, 128-130, 134, 145-146, 150, 154, 170-171, 181, 193-259, 280-300, 307, 317-319, 322, 330-343, 350-393, 400, 406-416, 423, 432, 437-448, 458-1021, 1027-1066, 1072-1257, 1263-1340, 1347-1385, 1391-1442, 1448-1534, 1539-1555, 1562-1574, 1578-1593, 1597-1612, 1616-1631, 1635-1650, 1664, 1666, 1672, 1679, 1684, 1686, 1688-1693, 1944, 1948, 1952-1956, 1960-1964, 1968-1972, 1976-1989, 1993-2000, 2004-2014, 2018-2028, 2032-2034, 2040-2043, 2047-2050, 2054-2061, 2065-2070, 2085-2143, 2147-2152, 2163-2207, 2211-2222, 2226-2234, 2240-2242, 2246-2251, 2255-2257, 2261-2263, 2269, 2273-2279, 2283, 2287-2292, 2296-2298, 2302-2304, 2308, 2312, 2316, 2324, 2328, 2332-2335, 2339-2341, 2345-2350, 2354-2357, 2361-2373, 2380, 2384-2416, 2420-2425, 2429-2451, 2455-2477, 2483-2499, 2503-2534, 2540-2575, 2581-2588, 2592-2612, 2616-2659, 2663-2680, 2684-2697, 2702, 2706-2707, 2711, 2715, 2719, 2725-2734, 2738-2747, 2751-2758, 2764, 2768-2782, 2786-2793, 2797-2811, 2815-2822, 2826-2833, 2837-2844, 2848-2857, 2861-2870, 2874-2883, 2887-2894, 2898-2905, 2909-2916, 2920-2927, 2931-2938, 2944, 2948-2957, 2962, 2967, 2972-3004, 3008-3017, 3023, 3029, 3033-3044, 3050, 3057, 3062, 3068, 3073-3097, 3102, 3107, 3112, 3121-3153, 3157-3201, 3205-3249, 3253-3280, 3285-3306, 3314-3376, 3380-3387, 3391-3411, 3417, 3423, 3427-3542, 3547-3558, 3562-3571, 3575, 3579, 3583, 3587, 3591, 3595, 3599, 3603-3608, 3612-3618, 3622-3627, 3631-3636, 3645, 3659-3693, 3699, 3703-3710, 3714-3725, 3730-3739, 3745-3754, 3760-3765, 3771-3776, 3782-3790, 3796-3804, 3808, 3812-3818, 3822-3833, 3837-3840, 3844-3850, 3854-3856, 3861, 3866-3878, 3882, 3886-3892, 3896-3902, 3908-3918, 3922-3929, 3934, 3938-3940, 3944-3967, 3971-3994, 3999, 4004, 4009, 4014, 4019, 4024, 4028-4040, 4046-4053, 4059-4066, 4070-4079, 4085-4092, 4098-4105, 4111-4118, 4126-4140, 4144-4151, 4155-4162, 4167-4182, 4186-4201, 4221, 4226, 4231, 4237-4248, 4255-4258, 4264-4267, 4273-4278, 4283-4287, 4291-4308, 4314-4329, 4335-4350, 4356-4359, 4363-4365, 4370-4378, 4384-4411, 4416-4425, 4429-4431, 4435-4437, 4442-4461, 4465-4482, 4486-4503, 4507-4524, 4528-4533, 4539-4550, 4554-4565, 4569-4574
sparkless/dataframe/export.py                                           15     15     0%   8-46
sparkless/dataframe/grouped/__init__.py                                  5      0   100%
sparkless/dataframe/grouped/base.py                                   1064    600    44%   95, 103, 111-113, 115-117, 122-144, 181, 188, 192-196, 271, 302-307, 314-322, 328, 360, 367, 372-389, 419, 439-442, 465-466, 583-600, 609-624, 673-689, 711-722, 736-765, 802, 807-808, 810-811, 841-844, 851, 855-856, 873, 875-878, 880-881, 911-914, 921, 925-926, 954-955, 981-982, 995-1001, 1003-1009, 1027, 1050-1069, 1072-1089, 1103-1121, 1123-1143, 1145-1151, 1153-1159, 1162-1175, 1178-1191, 1195-1250, 1253-1259, 1267, 1271-1272, 1302-1647, 1709, 1715, 1720-1729, 1750, 1756, 1763, 1781, 1815, 1833-1841, 1843-1853, 1855-1865, 1867-1877, 1879-1889, 1894-1900, 1902-1908, 1911-1916, 1918-1924, 1926-1932, 1945-1952, 2003-2007, 2018-2025, 2036-2043, 2054-2063, 2074-2083, 2094-2103, 2114-2123, 2134-2143, 2154-2163, 2174-2201, 2212-2239, 2268, 2303-2370, 2392-2447
sparkless/dataframe/grouped/cube.py                                     86     22    74%   68-74, 87-96, 123-129, 142-151, 166, 201-209
sparkless/dataframe/grouped/pivot.py                                   493    238    52%   101, 113-119, 142-174, 181-184, 205-215, 236-237, 254, 273-274, 279, 285-289, 291-328, 356, 362-397, 420, 422-425, 435, 437-440, 449-450, 486-492, 498, 531-544, 546-555, 565-641, 649-810, 825, 845, 878-882, 896, 916
sparkless/dataframe/grouped/rollup.py                                   87     22    75%   73-79, 90-99, 128-134, 147-156, 171, 206-214
sparkless/dataframe/joins/__init__.py                                    2      2     0%   8-10
sparkless/dataframe/joins/operations.py                                146    146     0%   8-396
sparkless/dataframe/lazy.py                                           1222   1019    17%   47-73, 106-108, 120-153, 167-173, 188-258, 271-301, 313-337, 352-388, 402-415, 433-447, 453-489, 495-504, 517-519, 523, 562-563, 581-582, 594, 600, 603, 607-611, 617-621, 630-642, 645, 649-655, 692-704, 727-734, 792, 800-806, 827, 839-922, 956, 966, 980-991, 1013, 1016, 1021, 1025, 1072-1075, 1080, 1085, 1095-1099, 1105, 1118-1123, 1157-2251, 2264-2525, 2538-2594, 2609-2837, 2853-2865
sparkless/dataframe/logical_plan.py                                    223     52    77%   26, 28, 33, 73, 84, 105-112, 120-123, 130, 172-180, 184-201, 206, 208, 232, 249-254, 272, 276-277, 279-280, 294, 317-318, 402-407, 425, 440-441, 454
sparkless/dataframe/operations/__init__.py                               2      0   100%
sparkless/dataframe/operations/aggregation_operations.py               128    128     0%   3-313
sparkless/dataframe/operations/join_operations.py                      157    157     0%   3-329
sparkless/dataframe/operations/misc.py                                 516    472     9%   56-77, 103-145, 167-215, 236-250, 267-308, 323-407, 421-501, 518-549, 566-593, 615-630, 643-659, 678-685, 710-742, 770-831, 863-922, 949-986, 1023-1074, 1082-1113, 1117-1135, 1149-1176, 1191-1196, 1216, 1232-1234, 1248-1255, 1266-1267, 1276, 1295-1304, 1323-1324, 1340-1345, 1353, 1366-1369, 1377, 1382, 1391-1392, 1401, 1415-1427
sparkless/dataframe/operations/set_operations.py                       168    140    17%   28-94, 99, 140, 160-290, 296-316, 322-339, 344-346
sparkless/dataframe/protocols.py                                        49      0   100%
sparkless/dataframe/rdd.py                                              83     40    52%   69-70, 118-120, 136-143, 155-166, 174, 185, 193, 201, 209, 217, 229, 240-243, 254-261, 269, 277
sparkless/dataframe/reader.py                                          197    107    46%   127-136, 163-170, 173, 179, 195, 212-265, 275-283, 287-294, 301, 304, 307-312, 317-327, 348-352, 354, 360-380, 383-388, 395, 412-414, 417-422, 436, 444, 459, 474, 491-493
sparkless/dataframe/robin_plan.py                                       78      9    88%   54, 57, 61, 68, 111, 119, 128, 130, 159
sparkless/dataframe/schema/__init__.py                                   3      0   100%
sparkless/dataframe/schema/operations.py                                22      9    59%   23-31, 39-41, 46, 51
sparkless/dataframe/schema/schema_manager.py                           514    182    65%   49-75, 93, 136-151, 258, 300-301, 304, 310-324, 361, 406, 453-465, 469-474, 482, 491, 493, 509-510, 514-517, 530, 563, 573, 591, 692-715, 724, 728, 745, 747, 763-764, 768-771, 777, 788-798, 803-839, 843-846, 850-853, 857-875, 879-887, 905-909, 922-930, 960-964, 975-978, 997, 1009-1019
sparkless/dataframe/services/__init__.py                                 8      0   100%
sparkless/dataframe/services/aggregation_service.py                     99     26    74%   37, 133, 148, 181, 196, 224-250
sparkless/dataframe/services/assertion_service.py                       17      8    53%   25-27, 33-35, 41-43, 49-51
sparkless/dataframe/services/display_service.py                        126     62    51%   40-50, 101, 120-167, 171-174, 182-186, 195-204, 210, 220, 223, 227-232, 238-240, 244-250, 264-267, 280
sparkless/dataframe/services/join_service.py                           248     35    86%   114, 129, 206, 226, 232, 238, 417, 426-428, 460, 510-534, 606-628
sparkless/dataframe/services/misc_service.py                           613    356    42%   57, 67-73, 166, 251, 264-268, 304-352, 376, 387-389, 417-458, 476-560, 574-654, 683-685, 687-689, 753-755, 802-817, 830-846, 865-872, 897-929, 955-1016, 1066, 1077, 1153-1190, 1227-1277, 1285-1318, 1322-1340, 1355-1357, 1419, 1435-1437, 1451-1458, 1469-1472, 1481, 1499-1503, 1518, 1529-1534, 1540, 1551-1554, 1562, 1567, 1576-1577, 1586, 1600-1612
sparkless/dataframe/services/schema_service.py                           4      0   100%
sparkless/dataframe/services/transformation_service.py                 349     59    83%   93, 100, 150, 177, 184-188, 246-247, 259-263, 293, 315, 368, 372, 377, 385-386, 409-414, 421-425, 431-441, 448-452, 456-458, 510, 533-543, 678-680, 772-774, 779, 783, 890-910
sparkless/dataframe/transformations/__init__.py                          2      2     0%   8-10
sparkless/dataframe/transformations/operations.py                      224    224     0%   8-629
sparkless/dataframe/types.py                                             8      8     0%   8-25
sparkless/dataframe/validation/__init__.py                               2      0   100%
sparkless/dataframe/validation/column_validator.py                     171     36    79%   101, 110-112, 137, 150-151, 185-198, 218, 247-279, 289, 337, 348, 401, 473, 485, 514, 541-558, 569-571
sparkless/dataframe/validation_handler.py                               21      2    90%   75-76
sparkless/dataframe/window_handler.py                                  315    315     0%   8-698
sparkless/dataframe/writer.py                                          395    219    45%   113-115, 129, 159-160, 192-194, 205-210, 228-232, 235-238, 258, 288, 294-296, 358-360, 416, 418, 469-495, 509, 521, 537, 549, 561, 573, 580-586, 590-606, 610-613, 617-622, 627-642, 647-656, 661-670, 675-690, 694-699, 720-753, 782-865, 888-892, 896, 908, 912-917, 942-1022
sparkless/delta.py                                                     308    240    22%   46-51, 61-74, 104, 112, 121-122, 127, 131-132, 137-152, 156-185, 189, 198, 210, 281-283, 300-341, 345, 348-352, 355-357, 360-368, 373-379, 384-408, 421-430, 434, 438, 441-446, 449-450, 455-456, 459-461, 464-466, 470-514, 517-523, 526-540, 547-551, 563-576, 581-584, 589-593, 601-629, 637-657
sparkless/error_simulation.py                                           89     89     0%   29-338
sparkless/errors.py                                                     28     10    64%   57, 62, 67, 72, 79, 86, 91, 96, 101, 106
sparkless/functions/__init__.py                                         29      4    86%   562-566
sparkless/functions/aggregate.py                                       323    146    55%   65-66, 299-300, 315-316, 331-332, 370-371, 386-387, 439-443, 461-472, 490-501, 516-517, 534-535, 552-553, 570-571, 591-597, 617-623, 640-641, 658-659, 769-770, 787-788, 803-807, 825-826, 843-844, 857-859, 874-890, 904-912, 930-940, 958-967, 985-994, 1014-1026, 1044-1053, 1071-1080, 1098-1107, 1125-1134, 1152-1161, 1182-1222
sparkless/functions/array.py                                           272    132    51%   78-83, 107, 109, 134-139, 161, 185, 213-219, 245-251, 277-283, 309-315, 346-356, 385-396, 418-421, 440-443, 466, 486-490, 511-514, 538-541, 561-564, 580, 626-629, 644-647, 698-701, 716-719, 737-742, 811-830, 853-883, 900-903, 964, 997-1000, 1018-1022, 1040-1043, 1058-1059, 1074-1086, 1098-1100, 1112-1116
sparkless/functions/base.py                                            135     56    59%   121, 137, 150-161, 165-171, 175-184, 188-201, 205-217, 221-233, 281, 289, 293, 297, 302, 312, 317, 322
sparkless/functions/bitwise.py                                         108     67    38%   31-34, 50-53, 71, 86-89, 107-110, 125-128, 143-146, 161-168, 183-198, 213-228, 243-258, 276-283, 300-307, 324-331, 347-350, 367-370, 387-390, 405-408, 425-428
sparkless/functions/conditional.py                                     396    260    34%   33-115, 147, 152, 295-300, 304-367, 381-384, 396-412, 426-455, 475, 499, 515, 534, 553, 570-603, 622, 637-648, 670, 673, 707-722, 737-752, 767-782, 797-812, 827-842, 854-861, 873-880, 895-908, 923-939, 954-970, 985-1001
sparkless/functions/core/__init__.py                                     6      0   100%
sparkless/functions/core/column.py                                     457     93    80%   43, 224, 336, 389, 399, 470-472, 476-478, 482-484, 492, 500-510, 518-528, 536-546, 554-564, 572-582, 590-600, 609, 706, 740, 744, 748, 752-754, 756, 760, 764, 768, 772, 776, 780, 784, 788, 807, 818-825, 829, 836, 838-842, 844-848, 850-854, 856-860, 880, 958, 991
sparkless/functions/core/expressions.py                                109     74    32%   28-32, 55, 73, 91-94, 108-115, 127-129, 141-143, 155-157, 169-171, 188-228, 240-247, 259-266, 278-285, 297-304, 320-323
sparkless/functions/core/lambda_parser.py                              146    126    14%   58-134, 142-148, 167-175, 189-247, 260-274, 285-298, 309-314, 327-332, 359-361, 369, 377, 381-385
sparkless/functions/core/literals.py                                   131     66    50%   65-76, 86, 108-110, 117-119, 123-125, 129-131, 135-137, 141-143, 147-149, 153-155, 159-161, 171-173, 177-179, 183-185, 189-191, 195-197, 201-203, 207-209, 213, 217, 227-229, 233-240, 244-246, 250-252, 256-258, 272-274, 278-280, 306-308, 312-314, 318-320
sparkless/functions/core/operations.py                                 106     67    37%   27-29, 33-35, 39-41, 45-47, 51-53, 57-59, 63-65, 69, 73, 77-79, 83-85, 89-91, 95-97, 101-103, 107-109, 122, 126, 130, 134, 145, 150-154, 158, 162, 176-189, 199, 203, 211, 219-221, 225-227, 235-237
sparkless/functions/core/sql_expr_parser.py                            308     49    84%   70, 75-78, 149, 151-157, 200-204, 209-226, 248-253, 328, 339, 353, 356-358, 375-381, 399, 401, 405, 419, 428
sparkless/functions/crypto.py                                           48     39    19%   49-71, 91-113, 133-155
sparkless/functions/datetime.py                                        474    254    46%   52, 98, 107, 119-125, 137-143, 155-161, 173-179, 188-189, 205-218, 231-237, 262-301, 327-366, 390-429, 455-500, 520-549, 564-580, 595-601, 616-622, 637-646, 658-664, 676-682, 694-700, 712-718, 730-736, 748-754, 783, 823, 836, 872-876, 889, 905, 921, 937, 954-960, 972-978, 990-994, 1039-1048, 1063-1074, 1088, 1107, 1126, 1149-1159, 1179-1191, 1211-1222, 1231-1234, 1248-1253, 1262-1273, 1283-1294, 1317-1320, 1340-1343, 1368-1372, 1424, 1429, 1435, 1439, 1442-1445, 1451, 1492-1497, 1524, 1529, 1535, 1557-1560, 1576-1579, 1600-1603, 1622-1627, 1646-1647, 1664-1665, 1685-1693, 1711-1727, 1745-1761
sparkless/functions/functions.py                                      1547    450    71%   67-77, 133-136, 142-162, 168-187, 193-212, 218-238, 259, 264, 341, 346, 351, 356, 361, 366, 371, 376, 381, 394-396, 401, 408, 415, 422, 427, 432, 437, 442, 447, 452, 457, 462, 467, 472, 483, 490, 497, 502, 507, 523, 533, 543, 548, 593, 598, 605, 627, 637, 642, 652, 657, 664, 695, 726, 731, 736, 741, 755, 760, 765, 785, 790, 795, 800, 805, 810, 817, 822, 827, 832, 837, 842, 847, 852, 857, 862, 867, 872, 877, 882, 892, 902, 907, 912, 917, 922, 927, 932, 1002, 1007, 1012, 1023, 1028, 1045, 1052, 1059, 1092, 1097, 1104, 1109, 1114, 1119, 1128, 1133, 1138, 1143, 1148, 1155, 1162, 1167, 1172, 1202-1205, 1224, 1231, 1238, 1248, 1296, 1301, 1311, 1316, 1321, 1326, 1331, 1336, 1341, 1346, 1378-1420, 1435, 1442, 1466, 1483, 1496, 1501, 1506, 1511, 1516, 1521, 1533-1538, 1549, 1556, 1563, 1579-1586, 1595-1597, 1706-1713, 1814, 1819, 1824, 1829, 1841, 1855, 1873, 1880, 1887, 1894, 1904, 1913, 1919, 1924, 1934, 1939, 1946, 1951, 1963, 1973, 1978, 1993, 2020, 2029, 2034, 2040, 2045, 2050, 2055, 2062, 2073, 2078, 2085, 2092, 2099, 2108, 2115, 2128-2129, 2152-2158, 2169, 2174, 2179, 2185, 2190, 2195, 2200, 2205, 2210, 2215, 2220, 2225, 2233, 2242-2243, 2248, 2253, 2259, 2264, 2269, 2279, 2285, 2290, 2297, 2302, 2316-2318, 2326-2328, 2336-2338, 2346-2348, 2353-2355, 2360-2362, 2369-2371, 2378-2380, 2387-2389, 2396-2398, 2404, 2409, 2414, 2419, 2424, 2429, 2434, 2439, 2444, 2449, 2454, 2464-2466, 2471-2473, 2492-2494, 2503-2505, 2510-2512, 2517-2519, 2532-2534, 2539-2541, 2546-2548, 2553-2555, 2568-2570, 2575-2577, 2582-2584, 2589-2591, 2596-2598, 2603-2605, 2661, 2716-2741, 2765-2772, 2789-2791, 2797, 2804, 2809, 2814, 2821, 2828, 2833, 2842, 2847, 2854, 2861, 2866, 2871, 2879, 2884, 2891, 2898, 2905, 2913, 2920, 2927, 2933, 2938, 2945, 2950, 2962, 2975, 2989, 3004, 3016, 3023, 3030, 3037, 3044, 3049, 3054, 3059, 3064, 3069, 3074, 3080, 3085, 3090, 3097, 3102, 3107, 3112, 3117, 3122, 3130, 3135, 3140, 3149, 3155, 3160, 3165, 3170, 3175, 3196-3213
sparkless/functions/json_csv.py                                         41     16    61%   31-34, 51-54, 105-107, 127-130, 144-147, 159-161
sparkless/functions/map.py                                             101     50    50%   51-54, 69-72, 87-90, 107-115, 138-143, 204-207, 219, 243-246, 266-269, 292-298, 324-330, 356-362, 391-400, 423-430
sparkless/functions/math.py                                            320    139    57%   51, 66-70, 82-86, 118, 133, 146, 178, 207, 211, 216, 219, 246-249, 264-267, 284-287, 304-307, 349, 362, 378, 394, 409-414, 427, 452, 476-477, 489-490, 505-506, 518-519, 531-532, 544-545, 567-574, 586-587, 599-600, 612-613, 625-626, 638-639, 651-652, 664-665, 677-679, 696-698, 715-716, 729-730, 745-748, 774, 776, 809-810, 823-824, 836-837, 849-850, 859-862, 871-874, 886-887, 902-907, 921-926, 941-960, 972, 990-1003, 1026-1067
sparkless/functions/metadata.py                                         33     13    61%   32, 45, 59, 71, 87-90, 102-109
sparkless/functions/ordering.py                                         28     12    57%   39-42, 56-59, 73-76, 90-93
sparkless/functions/pandas_types.py                                      6      0   100%
sparkless/functions/string.py                                          547    257    53%   66, 82, 97-103, 115-121, 134, 150, 166, 184-196, 209-218, 231-237, 250-256, 268-274, 287-296, 309-318, 332, 350-356, 370-379, 395, 411-420, 435-450, 462-468, 480-484, 496, 508, 521-534, 551, 579, 629, 655, 706, 722, 737-741, 792, 795-796, 819, 839, 860, 900-903, 923-926, 941-944, 963, 1004, 1054-1057, 1075-1078, 1099-1102, 1125, 1147, 1202-1223, 1235-1238, 1251, 1265-1268, 1280-1299, 1329-1332, 1352-1355, 1370-1373, 1391-1394, 1414-1417, 1432-1435, 1451-1457, 1492-1495, 1508-1514, 1529-1540, 1553-1562, 1575-1584, 1601-1610, 1627-1636, 1650, 1673-1684, 1698-1710, 1725-1731, 1746-1752, 1764-1768, 1781-1792, 1807, 1832-1854, 1872-1879, 1897-1902, 1918-1927, 1939-1940
sparkless/functions/udf.py                                              51      1    98%   138
sparkless/functions/window_execution.py                                651    558    14%   58-67, 390-428, 432-471, 478-553, 557-607, 613-629, 633-694, 698-742, 746-790, 794-845, 849-916, 920-981, 987-1024, 1028-1087, 1092, 1101-1146, 1150-1230, 1234-1260, 1268-1304, 1308-1372, 1376-1420, 1424-1468
sparkless/functions/xml.py                                              65     39    40%   25-28, 50-64, 84-87, 107-110, 131-134, 155-158, 179-182, 203-206, 227-230, 251-254, 275-278
sparkless/optimizer/__init__.py                                          3      0   100%
sparkless/optimizer/optimization_rules.py                              174     20    89%   17, 84, 132-140, 151, 162, 193, 242, 264, 278, 287, 299, 342, 376
sparkless/optimizer/query_optimizer.py                                 256    179    30%   48, 50, 52, 54, 56, 58, 67, 72, 80-125, 129-130, 135, 147-174, 178-179, 183-206, 214-234, 238-239, 245-248, 256-288, 292, 297, 305-330, 334, 339-342, 379-392, 403-408, 413, 418-456, 459-472, 477-504, 508, 512, 518
sparkless/performance_simulation.py                                     91      1    99%   150
sparkless/session/__init__.py                                            4      0   100%
sparkless/session/catalog.py                                           258    133    48%   43, 47, 65, 69, 111, 131-133, 150, 170, 173, 178, 187-190, 212, 215, 225, 230-233, 251-253, 267, 272, 275, 278, 281, 299-302, 309-312, 315-318, 338, 341, 344, 349-352, 374, 386-414, 431, 434, 438-443, 463, 466, 470-475, 484, 499, 502, 506-511, 528, 537, 546, 566-575, 606, 617, 630, 633, 636, 640-644, 651, 654, 658-659, 666, 683-716
sparkless/session/config/__init__.py                                     2      0   100%
sparkless/session/config/configuration.py                               54     21    61%   85-86, 94, 102, 110, 118-119, 130, 141, 146, 150, 188, 199-200, 211-212, 224-225, 236-237, 245
sparkless/session/context.py                                            36     10    72%   47, 51, 55, 92, 101, 110, 119, 123, 127, 131
sparkless/session/core/__init__.py                                       4      0   100%
sparkless/session/core/builder.py                                       30      2    93%   54, 71
sparkless/session/core/session.py                                      227     64    72%   12-13, 122, 174-177, 187, 237-239, 249-254, 258-260, 273, 277, 287, 293, 306-308, 350, 368, 380, 391, 414, 421-436, 444-446, 468, 480, 509-510, 544, 553-555, 578-580, 597, 604, 611, 621, 628, 633-643, 652, 661-662, 667
sparkless/session/performance_tracker.py                                39     19    51%   57, 87-109, 117
sparkless/session/services/__init__.py                                   6      0   100%
sparkless/session/services/dataframe_factory.py                        216     83    62%   14-15, 77-78, 97-99, 102-103, 106, 119, 152, 163-164, 190, 206, 211, 218, 255, 271, 281, 313, 323, 343, 350, 361-364, 403, 428, 440, 447, 465-472, 490-506, 517-587
sparkless/session/services/lifecycle_manager.py                         21     10    52%   32-34, 42-43, 55-59
sparkless/session/services/mocking_coordinator.py                       32     21    34%   39-57, 69-72, 84-86, 102-104, 109
sparkless/session/services/protocols.py                                 20      0   100%
sparkless/session/services/sql_parameter_binder.py                      29     25    14%   28-51, 62-74
sparkless/session/session.py                                             0      0   100%
sparkless/session/sql/__init__.py                                        5      0   100%
sparkless/session/sql/executor.py                                     1280    392    69%   83-90, 140-143, 149, 179-190, 204-211, 232-239, 281, 284, 289, 310-342, 366-381, 419, 514, 517-520, 544-545, 556-569, 609-612, 616-631, 637-643, 648-652, 654-658, 668, 698-720, 730-733, 751-754, 793-820, 825-841, 851-867, 875-910, 965-1011, 1053-1061, 1081-1129, 1221-1243, 1303, 1310, 1319-1326, 1329-1336, 1344-1346, 1390, 1405-1406, 1408-1410, 1425-1432, 1446, 1451-1453, 1462-1465, 1472-1473, 1510, 1517-1519, 1554, 1560, 1565, 1588, 1603, 1611, 1627-1641, 1658, 1680, 1690, 1692, 1700-1705, 1729, 1738-1740, 1760-1761, 1802, 1805, 1807, 1811, 1816-1829, 1839, 1853, 1871-1872, 1906, 1915, 1950-1951, 1967, 2002-2030, 2102, 2123, 2194-2249, 2273, 2299-2302, 2314, 2443, 2484, 2566-2576, 2609-2610, 2619-2627, 2637, 2700, 2707-2708, 2711, 2731, 2742-2748, 2768, 2771-2779, 2813-2816, 2860-2867, 2943-2945, 2955, 2963-2971, 2976-2985, 2990, 2995, 2997-3001
sparkless/session/sql/optimizer.py                                      65      0   100%
sparkless/session/sql/parser.py                                        496     59    88%   45, 49, 263, 271-272, 303, 305, 310-315, 358, 486, 509, 562, 564, 599, 601, 603, 674-677, 734-735, 755-765, 790, 820-821, 833, 892, 915, 993, 1019, 1027, 1046-1047, 1049-1050, 1094, 1101, 1121-1141, 1338, 1360-1361
sparkless/session/sql/validation.py                                     85      0   100%
sparkless/spark_types.py                                               404    163    60%   60-74, 111, 115, 123, 350, 368, 420, 432, 439-440, 443, 450-451, 454, 466, 475-477, 480, 489-491, 494, 503-505, 508, 539-544, 570-575, 585-590, 593, 605-606, 654-656, 660, 664-665, 673, 685, 698, 704-713, 718-733, 738-739, 760, 762, 766, 823-826, 840-848, 859-880, 886-888, 892-899, 903-910, 914, 918-943, 957-978, 983-984, 989, 995-997, 1011-1012
sparkless/sql/__init__.py                                               10      0   100%
sparkless/sql/functions.py                                              30      5    83%   70-72, 84-92
sparkless/sql/types.py                                                   2      0   100%
sparkless/sql/utils.py                                                   7      0   100%
sparkless/storage/__init__.py                                           10      0   100%
sparkless/storage/backends/__init__.py                                   0      0   100%
sparkless/storage/backends/file.py                                     206     40    81%   39, 49, 68-69, 93, 96-98, 119, 142, 146, 150, 154-155, 159-161, 225, 238, 242, 246, 250, 254, 258, 262-264, 268, 272, 276, 409-414, 495-498, 501, 507, 519, 538
sparkless/storage/backends/memory.py                                   133     84    37%   22-25, 34, 39, 44, 53-61, 72-77, 85, 93, 97, 101, 105, 109-110, 114-115, 139-141, 152, 160-161, 169, 187-188, 199, 208-209, 217, 229-231, 246-249, 258-259, 271-275, 290-295, 310-312, 324-330, 342, 352-370, 381-390, 402-406, 418-423, 430
sparkless/storage/manager.py                                           135     86    36%   40-45, 58, 70, 82, 94-98, 108, 119, 128-130, 138, 142-149, 153-159, 171, 186, 195, 208, 223, 237, 249, 258, 269, 283, 295, 303, 312, 325, 336, 344-349, 353-358, 366-378, 382, 390-400, 411-432
sparkless/storage/models.py                                             67      1    99%   77
sparkless/storage/serialization/__init__.py                              0      0   100%
sparkless/storage/serialization/csv.py                                  46     32    30%   23-30, 42-47, 57-62, 76-92, 104-120
sparkless/storage/serialization/json.py                                 39     25    36%   23-24, 36-41, 51-63, 75-90, 102-118
sparkless/utils/profiling.py                                            96     40    58%   47-48, 58, 61, 71-76, 85, 88-90, 94, 99, 102, 118-135, 161-172, 182, 188
sparkless/window.py                                                     67      8    88%   78, 91, 114, 127, 148, 167, 234, 239
--------------------------------------------------------------------------------------------------
TOTAL                                                                34045  21220    38%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml
=========================== short test summary info ============================
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_empty_dataframe - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_xxhash64 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_basic - RuntimeError: not found: Column 'struct(Name, Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_149_to_timestamp_string.py::TestIssue149ToTimestampString::test_to_timestamp_with_regexp_replace_cast_string - RuntimeError: not found: Column 'to_timestamp_regexp_replace(date_string, \.\d+, , 1)' not found. Available columns: [date_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_col_function - RuntimeError: not found: Column 'struct(Name, Value, Age)' not found. Available columns: [Age, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_single_column - RuntimeError: not found: Column 'struct(Name)' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_nulls - RuntimeError: not found: Column 'struct(Name, Value, Age)' not found. Available columns: [Age, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_get_json_object - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_149_to_timestamp_string.py::TestIssue149ToTimestampString::test_to_timestamp_with_nested_cast_string - RuntimeError: not found: Column 'to_timestamp_date_string' not found. Available columns: [date_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_149_to_timestamp_string.py::TestIssue149ToTimestampString::test_to_timestamp_with_string_operations - RuntimeError: not found: Column 'to_timestamp_regexp_replace(date_string, T,  , 1)' not found. Available columns: [date_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_json_tuple - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_in_select - RuntimeError: not found: Column 'new_struct' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_151_to_timestamp_validation.py::TestIssue151ToTimestampValidation::test_to_timestamp_with_validation_rule_not_null - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_188_string_concat_cache.py::TestStringConcatenationCacheEdgeCases::test_string_concat_chained_operations - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_year - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_month - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofmonth - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_dayofweek - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_add - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_multiple_types - RuntimeError: not found: Column 'struct(Name, Value, Score, Active)' not found. Available columns: [Active, Name, Score, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_select.py::TestSelectParity::test_select_with_alias - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_151_to_timestamp_validation.py::TestIssue151ToTimestampValidation::test_to_timestamp_with_datetime_operations - RuntimeError: not found: Column 'to_timestamp_regexp_replace(date_string, T,  , 1)' not found. Available columns: [date_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_152_sql_column_aliases.py::TestIssue152SQLColumnAliases::test_sql_with_inner_join_and_aliases - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_152_sql_column_aliases.py::TestIssue152SQLColumnAliases::test_sql_with_left_join_and_aliases - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_286_aggregate_function_arithmetic.py::TestIssue286AggregateFunctionArithmetic::test_empty_group_handling - RuntimeError: not found: Column 'Charlie' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_expressions - RuntimeError: not found: Column 'struct(Name, doubled, age_plus_10)' not found. Available columns: [Age, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_literals - RuntimeError: not found: Column 'struct(Name, constant, Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_chained_with_other_operations - RuntimeError: not found: Column 'name_is_null' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_all_null_columns - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_188_string_concat_cache.py::TestStringConcatenationCacheEdgeCases::test_string_concat_without_caching - AssertionError: String concatenation should work normally without caching
assert None == 'ab'
FAILED tests/test_issue_188_string_concat_cache.py::TestStringConcatenationCacheEdgeCases::test_concat_function_with_caching - RuntimeError: not found: Column 'concat(col1, col2)' not found. Available columns: [col1, col2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_substring_index - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_repeat - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_reverse - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_153_to_timestamp_returns_none.py::TestIssue153ToTimestampReturnsNone::test_to_timestamp_returns_actual_values - RuntimeError: not found: Column 'to_timestamp_regexp_replace(date_string, \.\d+, , 1)' not found. Available columns: [id, date_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_field_access - RuntimeError: not found: Column 'struct(Name, Value, Age)' not found. Available columns: [Age, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_153_to_timestamp_returns_none.py::TestIssue153ToTimestampReturnsNone::test_to_timestamp_with_clean_string - RuntimeError: not found: Column 'to_timestamp_date_string' not found. Available columns: [id, date_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_no_matching_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_mixed_types_and_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_parity - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_sub - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_nested_struct - RuntimeError: not found: Column 'struct(Name, Value)' not found. Available columns: [Age, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_multiple_fields_parity - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_struct_field_alias_parity.py::TestStructFieldAliasParity::test_struct_field_with_alias_and_other_columns_parity - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_actual_bug_reproduction.py::test_bug_with_lazy_polars_expression_reference - RuntimeError: not found: Column 'regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_example_from_issue_261 - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_inclusive_lower_bound - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_inclusive_upper_bound - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_float_values - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_null_values - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_date_format - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_datetime.py::TestDatetimeFunctionsParity::test_to_date - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_arrays - RuntimeError: not found: Column 'struct(Name, Scores)' not found. Available columns: [Name, Scores]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_string_values - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_yyyy_mm_dd_format - RuntimeError: not found: Column 'to_date(date_of_birth, 'yyyy-MM-dd')' not found. Available columns: [id, name, date_of_birth]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_mm_slash_dd_slash_yyyy_format - RuntimeError: not found: Column 'to_date(event_date, 'MM/dd/yyyy')' not found. Available columns: [id, event_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_with_dd_hyphen_mm_hyphen_yyyy_format - RuntimeError: not found: Column 'to_date(event_date, 'dd-MM-yyyy')' not found. Available columns: [id, event_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_to_date_format.py::TestToDateWithFormat::test_to_date_without_format_string - RuntimeError: not found: Column 'to_date(date_str)' not found. Available columns: [id, date_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_to_date_issue_126.py::TestToDateIssue126::test_issue_126_reproduction - RuntimeError: not found: Column 'to_date(date_of_birth, 'yyyy-MM-dd')' not found. Available columns: [id, name, date_of_birth]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_in_join - RuntimeError: not found: Column 'struct(Name, Value)' not found. Available columns: [Name, id, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_aliased_columns - RuntimeError: not found: Column 'struct(n, v)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_multiple_operations - RuntimeError: not found: Column 'struct(Name, Value)' not found. Available columns: [Age, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_basic_parity - RuntimeError: not found: Column 'format_string('%s-%s', StringValue, IntegerValue)' not found. Available columns: [IntegerValue, Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_multiple_args_parity - RuntimeError: not found: Column 'format_string('%s is %d years old and lives in %s', Name, Age, City)' not found. Available columns: [Age, City, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_actual_bug_reproduction.py::test_bug_with_shared_translator_instance - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_empty_dataframe - RuntimeError: not found: Column 'struct(Name, Value)' not found. Available columns: [Name, Value, new_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_lit_none_works - RuntimeError: not found: Column 'None' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_format_string_parity.py::TestFormatStringParity::test_format_string_with_null_parity - RuntimeError: not found: Column 'format_string('%s-%s', Value, Number)' not found. Available columns: [Name, Number, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_cache_key_reproduction.py::test_cache_key_includes_column_names - ValueError: Unsupported materializer type: polars. Sparkless v4 supports only the Robin backend (robin-sparkless).
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_literal_bounds - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_203_filter_with_string.py::TestIssue203FilterWithString::test_filter_with_string_equals - RuntimeError: not found: Column 'IT' not found. Available columns: [dept, name, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_conditional - RuntimeError: not found: Column 'struct(Name, level, Age)' not found. Available columns: [Age, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_window_orderby_list_parity.py::TestWindowOrderByListParity::test_window_orderby_list_multiple_columns_parity - assert 100 == 90
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_in_select_expression - RuntimeError: not found: Column 'in_range' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_float_base_parity - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_natural_log_parity - RuntimeError: not found: Column 'Ln' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_null_literal_casting_to_various_types - RuntimeError: not found: Column 'None' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_cache_key_reproduction.py::test_nested_expression_caching_after_drop - ValueError: Unsupported materializer type: polars. Sparkless v4 supports only the Robin backend (robin-sparkless).
FAILED tests/test_issue_203_filter_with_string.py::TestIssue203FilterWithString::test_filter_with_string_and_condition - RuntimeError: not found: Column 'IT' not found. Available columns: [dept, name, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_287_na_replace.py::TestIssue287NAReplace::test_na_replace_chained_operations - RuntimeError: not found: Column 'TypeA' not found. Available columns: [Name, Type, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_cache_key_reproduction.py::test_reuse_cached_expression_after_drop - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_dropped_column_execution_plan.py::TestIssue160DroppedColumnExecutionPlan::test_dropped_column_in_execution_plan - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_log_float_constant_parity.py::TestLogFloatConstantParity::test_log_with_different_bases_parity - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_abs - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_round - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_null_cast_preserves_schema_type - RuntimeError: not found: Column 'None' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_string_functions - RuntimeError: not found: Column 'struct(upper_name, Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sqrt - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_per_row_column_bounds - RuntimeError: not found: Column 'in_range' not found. Available columns: [lower, upper, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_date_values - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_with_reversed_bounds - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_160_dropped_column_execution_plan.py::TestIssue160DroppedColumnExecutionPlan::test_dropped_column_with_cache - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_add_column_with_null_and_type - RuntimeError: not found: Column 'None' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_pow - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_log - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_160_exact_150_rows.py::test_exactly_150_rows_without_fix - ValueError: Unsupported materializer type: polars. Sparkless v4 supports only the Robin backend (robin-sparkless).
FAILED tests/test_issue_160_exact_150_rows.py::test_149_rows_vs_150_rows - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_with_math_operations - RuntimeError: not found: Column 'struct(sqrt, product, power)' not found. Available columns: [Multiplier, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_289_struct_function.py::TestIssue289StructFunction::test_struct_large_number_of_fields - RuntimeError: not found: Column 'struct(a, b, c, d, e, f, g, h)' not found. Available columns: [a, b, c, d, e, f, g, h]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_two_arguments - RuntimeError: not found: Column 'udf(Value1, Value2)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_two_arguments_string_names - RuntimeError: not found: Column 'udf(Value1, Value2)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_three_arguments - RuntimeError: not found: Column 'udf(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_multiply_arguments - RuntimeError: not found: Column 'udf(x, y)' not found. Available columns: [x, y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_string_concatenation - RuntimeError: not found: Column 'udf(first, second)' not found. Available columns: [first, second]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_nulls - RuntimeError: not found: Column 'udf(a, b)' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_exp - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_261_between.py::TestIssue261Between::test_between_in_when_otherwise_expression - RuntimeError: not found: Column 'value BETWEEN 1 AND 5' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_add_column_from_struct_field - RuntimeError: not found: Column 'None' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_schema_merge_with_type_preservation - RuntimeError: not found: Column 'None' not found. Available columns: [name, job]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_delta_create_or_replace_table_as_select - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: not found: Column 'processed_at' not found. Available columns: [user_id, name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_on_string_column_filter_does_not_error_and_returns_empty - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_on_numeric_column_true_only_for_nan - RuntimeError: not found: Column 'is_nan' not found. Available columns: [id, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_literal_matches_python_math - RuntimeError: not found: Column 'nan' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_on_string_and_numeric_columns_in_select - RuntimeError: not found: Column 's_isnan' not found. Available columns: [id, s, x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_row_number - AssertionError: DataFrames are not equivalent:
Numerical mismatch in column 'row_num' row 2: mock=2, expected=3, diff=1.0
Numerical mismatch in column 'row_num' row 3: mock=3, expected=2, diff=1.0
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_select - RuntimeError: not found: Column 'sum' not found. Available columns: [x, y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_force_bug_reproduction.py::test_force_bug_by_manipulating_cache - ValueError: Unsupported materializer type: polars. Sparkless v4 supports only the Robin backend (robin-sparkless).
FAILED tests/test_issue_160_force_bug_reproduction.py::test_bug_with_write_operation - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_lazy_frame_execution_plan.py::test_lazy_frame_preserves_column_references - Failed: BUG REPRODUCED! Execution plan references dropped columns: not found: Column 'regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
This suggests that Polars lazy execution plan preserves column references.
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_rank - AssertionError: DataFrames are not equivalent:
Numerical mismatch in column 'rank' row 2: mock=1, expected=3, diff=2.0
Numerical mismatch in column 'rank' row 3: mock=1, expected=2, diff=1.0
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_mixed_types - RuntimeError: not found: Column 'udf(name, age, score)' not found. Available columns: [age, name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_263_isnan_string.py::TestIssue263IsnanString::test_isnan_in_when_otherwise_expression - RuntimeError: not found: Column 'isnan(v)' not found. Available columns: [id, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_dense_rank - AssertionError: DataFrames are not equivalent:
Numerical mismatch in column 'dense_rank' row 2: mock=1, expected=3, diff=2.0
Numerical mismatch in column 'dense_rank' row 3: mock=1, expected=2, diff=1.0
FAILED tests/test_issue_160_lazy_frame_execution_plan.py::test_operations_after_select_with_cached_expressions - RuntimeError: not found: Column 'regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_sin - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_160_lazy_frame_execution_plan.py::test_filter_after_select_with_dropped_column_reference - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_sum_over_window - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_single_argument_still_works - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_four_arguments - RuntimeError: not found: Column 'udf(a, b, c, d)' not found. Available columns: [a, b, c, d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_computed_columns - RuntimeError: not found: Column 'udf((x * 2), (y + 1))' not found. Available columns: [x, y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_cos - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_filter - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("date_timestamp")) > (col("date_string"))] FROM
  DF ["Name", "date_string", "date_timestamp"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_tan - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_280_join_groupby_ambiguity.py::TestJoinThenGroupByNoAmbiguity::test_outer_join_then_groupby - assert {1: 1, 2: 1, 3: 1} == {1: 1, None: 1, 3: 1}
  
  Omitting 2 identical items, use -vv to show
  Left contains 1 more item:
  {2: 1}
  Right contains 1 more item:
  {None: 1}
  
  Full diff:
    {
  -     None: 1,
        1: 1,
  +     2: 1,
        3: 1,
    }
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_subtraction - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END - <sparkless.functions.conditional.CaseWhen object at 0x110fe3750>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_addition - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + <sparkless.functions.conditional.CaseWhen object at 0x111091cd0>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_multiplication - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END * <sparkless.functions.conditional.CaseWhen object at 0x1105e2290>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lag - AssertionError: DataFrames are not equivalent:
Value mismatch in column 'lag_salary' row 2: mock='IT', expected=55000
Value mismatch in column 'lag_salary' row 3: mock='IT', expected=50000
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_ceil - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_floor - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_greatest - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_decorator_pattern - RuntimeError: not found: Column 'udf(a, b)' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_empty_dataframe - RuntimeError: not found: Column 'udf(a, b)' not found. Available columns: [a, b, sum]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_five_arguments - RuntimeError: not found: Column 'udf(a, b, c, d, e)' not found. Available columns: [a, b, c, d, e]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_float_arguments - RuntimeError: not found: Column 'udf(x, y, z)' not found. Available columns: [x, y, z]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_boolean_arguments - RuntimeError: not found: Column 'udf(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_filter - RuntimeError: not found: Column 'udf(x, y)' not found. Available columns: [x, y, z]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_orderby - RuntimeError: not found: Column 'udf(score1, score2)' not found. Available columns: [name, score1, score2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_mixed_string_and_column_objects - RuntimeError: not found: Column 'udf(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_nested_with_arithmetic - RuntimeError: not found: Column 'udf((x + y), (z * 2))' not found. Available columns: [x, y, z]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_merge_schema_bidirectional - RuntimeError: not found: Column 'None' not found. Available columns: [name, job]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_delta_lake_schema_evolution.py::TestDeltaLakeSchemaEvolution::test_complete_schema_evolution_scenario - RuntimeError: not found: Column 'None' not found. Available columns: [user_id, name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_division - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END / <sparkless.functions.conditional.CaseWhen object at 0x111090b50>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_modulo - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END % <sparkless.functions.conditional.CaseWhen object at 0x110fe03d0>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_bitwise_or - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END | <sparkless.functions.conditional.CaseWhen object at 0x111092f90>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_lead - AssertionError: DataFrames are not equivalent:
Value mismatch in column 'lead_salary' row 0: mock='IT', expected=55000
Null mismatch in column 'lead_salary' row 2: mock='IT', expected=None
Null mismatch in column 'lead_salary' row 3: mock=None, expected=70000
FAILED tests/test_issue_160_lazy_frame_execution_plan.py::test_write_operation_triggers_re_evaluation - Failed: BUG REPRODUCED during write! Error: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
Write operation triggered re-evaluation that referenced dropped column.
FAILED tests/test_issue_160_lazy_frame_execution_plan.py::test_multiple_materializations_with_shared_cache - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_lazy_polars_expr.py::test_lazy_polars_expression_after_column_drop - Failed: BUG REPRODUCED! Lazy Polars expression referenced dropped column: not found: Column 'regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
This suggests that lazy expressions built before column drop still reference the dropped columns.
FAILED tests/test_issue_160_lazy_polars_expr.py::test_nested_operations_with_drop - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_lazy_polars_expr.py::test_operations_chain_with_intermediate_drop - Failed: BUG REPRODUCED! Operation after drop referenced dropped column: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
This suggests that operations queued after drop still reference dropped columns.
FAILED tests/test_issue_160_lazy_polars_expr.py::test_write_operation_after_drop - Failed: BUG REPRODUCED during write! Error about dropped column: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
This suggests that write operations try to resolve dropped columns.
FAILED tests/test_issue_160_reproduce_actual_bug.py::test_bug_reproduction_with_cache_enabled - RuntimeError: not found: Column 'regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_reproduce_actual_bug.py::test_bug_with_nested_expression_cache - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_reproduce_bug.py::TestIssue160ReproduceBug::test_bug_reproduction_with_150_rows - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_160_reproduce_bug.py::TestIssue160ReproduceBug::test_bug_does_not_occur_with_2_rows - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_all_operators[>-expected_names0] - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("d")) > (col("d_str"))] FROM
  DF ["Name", "d", "d_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_all_operators[>=-expected_names1] - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("d")) >= (col("d_str"))] FROM
  DF ["Name", "d", "d_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_all_operators[<-expected_names2] - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("d")) < (col("d_str"))] FROM
  DF ["Name", "d", "d_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_all_operators[<=-expected_names3] - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("d")) <= (col("d_str"))] FROM
  DF ["Name", "d", "d_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_all_operators[==-expected_names4] - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("d")) == (col("d_str"))] FROM
  DF ["Name", "d", "d_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_column_all_operators[!=-expected_names5] - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("d")) != (col("d_str"))] FROM
  DF ["Name", "d", "d_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_math.py::TestMathFunctionsParity::test_math_least - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_date_operations - RuntimeError: not found: Column 'udf(date1, date2)' not found. Available columns: [date1, date2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_with_cache_enabled.py::test_bug_with_cache_enabled - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_datetime_column_vs_string_column_filter - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("ts")) > (col("ts_str"))] FROM
  DF ["Name", "ts", "ts_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_coalesce - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_cume_dist - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_bitwise_not - RuntimeError: not found: Column '~(CASE WHEN ((Name == Alice)) THEN Value1 ELSE <sparkless.functions.core.literals.Literal object at 0x110fe3a10> END)' not found. Available columns: [Name, Value1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_in_join_condition - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_first_value - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_datetime_column_vs_string_column_all_operators - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("ts")) > (col("ts_str"))] FROM
  DF ["Name", "ts", "ts_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_literal - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value ELSE <sparkless.functions.core.literals.Literal object at 0x1110935d0> END + 10)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_without_fix.py::test_bug_without_fix - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_conditional_logic - RuntimeError: not found: Column 'udf(price, discount, tax)' not found. Available columns: [discount, price, tax]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_160_without_fix.py::test_fix_prevents_bug - RuntimeError: not found: Column 'to_timestamp_regexp_replace(impression_date, \.\d+, , 1)' not found. Available columns: [impression_id, impression_date, campaign_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_reverse_operations - RuntimeError: not found: Column '(100 - <sparkless.functions.conditional.CaseWhen object at 0x111084c50>)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_163_validation_after_drop.py::TestIssue163ValidationAfterDrop::test_validation_after_drop_columns - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_last_value - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_chained_operations - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END - <sparkless.functions.conditional.CaseWhen object at 0x111093fd0>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_percent_rank - AssertionError: DataFrames are not equivalent:
Null mismatch in column 'percent_rank' row 1: mock=nan, expected=0.0
Numerical mismatch in column 'percent_rank' row 2: mock=0.0, expected=1.0, diff=1.0
Numerical mismatch in column 'percent_rank' row 3: mock=0.0, expected=0.5, diff=0.5
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_isnotnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_inner_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_six_arguments - RuntimeError: not found: Column 'udf(a, b, c, d, e, f)' not found. Available columns: [a, b, c, d, e, f]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_date_column_vs_string_literal - RuntimeError: not found: Column '2025-06-15' not found. Available columns: [Name, d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_nulls - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + <sparkless.functions.conditional.CaseWhen object at 0x111086f50>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_multiple_when_conditions - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN <sparkless.functions.core.literals.Literal object at 0x111091d90> ELSE <sparkless.functions.core.literals.Literal object at 0x111092990> END - <sparkless.functions.conditional.CaseWhen object at 0x1110908d0>)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_nested_expressions - RuntimeError: not found: Column '((CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + <sparkless.functions.conditional.CaseWhen object at 0x1110f1e10>) - <sparkless.functions.conditional.CaseWhen object at 0x1110e7450>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_all_null_arguments - RuntimeError: not found: Column 'udf(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_string_functions - RuntimeError: not found: Column 'udf(first, second, third)' not found. Available columns: [first, second, third]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_chained_operations - RuntimeError: not found: Column 'udf(x, y)' not found. Available columns: [x, y, z]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_290_udf_multiple_arguments.py::TestIssue290UdfMultipleArguments::test_udf_with_large_number_of_columns - RuntimeError: not found: Column 'udf(col1, col2, col3, col4, col5, col6, col7, col8, col9, col10)' not found. Available columns: [col1, col10, col2, col3, col4, col5, col6, col7, col8, col9]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_window.py::TestWindowOperationsParity::test_ntile - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_when_otherwise - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_exact_issue - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_multiple_values - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_in_select - RuntimeError: not found: Column 'Result' not found. Available columns: [Exp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_164_schema_inference_numeric.py::TestIssue164SchemaInferenceNumeric::test_schema_inference_mixed_types - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_power_negative_exponent_with_show - RuntimeError: not found: Column '**(3.0)' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nvl - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_165_to_date_timestamp_type.py::TestIssue165ToDateTimestampType::test_to_date_with_timestamp_type - RuntimeError: not found: Column 'to_timestamp_event_timestamp_str' not found. Available columns: [event_id, event_timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_left_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_division_by_zero - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END / <sparkless.functions.conditional.CaseWhen object at 0x111091cd0>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_165_to_date_timestamp_type.py::TestIssue165ToDateTimestampType::test_to_date_with_string_type - RuntimeError: not found: Column 'to_date(date_string, 'yyyy-MM-dd')' not found. Available columns: [event_id, date_string]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_165_to_date_timestamp_type.py::TestIssue165ToDateTimestampType::test_to_date_with_date_type - RuntimeError: not found: Column 'to_date(event_date)' not found. Available columns: [event_id, event_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nullif - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=4
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_filter_isnotnull - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_filter_isnull - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_multiple_filters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_135_datetime_filter.py::TestIssue135DatetimeFilter::test_to_timestamp_with_multiple_operations_and_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_259_datetime_string_comparison.py::TestIssue259DatetimeStringComparison::test_invalid_or_null_date_strings_do_not_raise - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("d")) > (col("d_str"))] FROM
  DF ["Name", "d", "d_str"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_example_from_issue_260 - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[None-None-True] - RuntimeError: not found: Column 'equals' not found. Available columns: [left, right]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[None-x-False] - RuntimeError: not found: Column 'equals' not found. Available columns: [left, right]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_ifnull - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_modulo_by_zero - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END % <sparkless.functions.conditional.CaseWhen object at 0x1110e4a10>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_166_unix_timestamp.py::TestIssue166UnixTimestamp::test_unix_timestamp_with_timestamp_column - RuntimeError: not found: Column 'to_timestamp_event_timestamp_str' not found. Available columns: [event_id, event_timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_null_handling.py::TestNullHandlingFunctionsParity::test_nanvl - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_136_column_rename_validation.py::TestIssue136ColumnRenameValidation::test_column_rename_and_transform_with_filter - RuntimeError: not found: Column 'to_timestamp_regexp_replace(date, \.\d+, , 1)' not found. Available columns: [record_id, cust_id, date, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_negative_exponent.py::TestIssue291PowerNegativeExponent::test_unary_minus_standalone_in_withcolumn - RuntimeError: not found: Column '(Value - None)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[x-None-False] - RuntimeError: not found: Column 'equals' not found. Available columns: [left, right]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_floats - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END * <sparkless.functions.conditional.CaseWhen object at 0x111091a50>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_136_column_rename_validation.py::TestIssue136ColumnRenameValidation::test_multiple_column_renames - RuntimeError: not found: Column 'a' not found. Available columns: [new_col1, new_col2, new_col3]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_166_unix_timestamp.py::TestIssue166UnixTimestamp::test_unix_timestamp_with_string_and_format - RuntimeError: not found: Column 'unix_timestamp(event_timestamp_str, yyyy-MM-dd HH:mm:ss)' not found. Available columns: [event_id, event_timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_136_column_rename_validation.py::TestIssue136ColumnRenameValidation::test_rename_then_add_column_then_filter - RuntimeError: not found: Column '_' not found. Available columns: [id, customer_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_137_datetime_validation.py::TestIssue137DatetimeValidation::test_datetime_validation_with_age_calculation - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_137_datetime_validation.py::TestIssue137DatetimeValidation::test_datetime_validation_simple_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_float_power_column - RuntimeError: not found: Column '**(3.0)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_166_unix_timestamp.py::TestIssue166UnixTimestamp::test_unix_timestamp_current_timestamp - RuntimeError: not found: Column 'unix_timestamp(current_timestamp, yyyy-MM-dd HH:mm:ss)' not found. Available columns: [event_id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_aggregate_cast_parity.py::TestAggregateCastParity::test_cast_with_empty_groups - RuntimeError: not found: Column 'A' not found. Available columns: [group, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_float_power_column_operation - RuntimeError: not found: Column '**(3.0)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_column_power_number - RuntimeError: not found: Column '**(Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[x-x-True] - RuntimeError: not found: Column 'equals' not found. Available columns: [left, right]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_zero_and_negative - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + <sparkless.functions.conditional.CaseWhen object at 0x111085190>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_bitwise_and - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END & <sparkless.functions.conditional.CaseWhen object at 0x111092e50>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_complex_nested_operations - RuntimeError: not found: Column '((CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + <sparkless.functions.conditional.CaseWhen object at 0x110fe3490>) * <sparkless.functions.conditional.CaseWhen object at 0x110fe1e10>)' not found. Available columns: [Name, Value1, Value2, Value3]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_all_reverse_operators - RuntimeError: not found: Column 'add' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_operator_precedence - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + (CASE WHEN ((Name == Alice)) THEN Value2 ELSE Value1 END * 2))' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_large_numbers - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + <sparkless.functions.conditional.CaseWhen object at 0x1110903d0>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_empty_dataframe - RuntimeError: not found: Column '(CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END - <sparkless.functions.conditional.CaseWhen object at 0x11110a2d0>)' not found. Available columns: [Name, Value1, Value2, result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_with_aliases - RuntimeError: not found: Column '(case1 * <sparkless.functions.conditional.CaseWhen object at 0x1110903d0>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_all_arithmetic_operators - RuntimeError: not found: Column 'add' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_288_casewhen_operators.py::TestIssue288CaseWhenOperators::test_casewhen_mixed_with_columns - RuntimeError: not found: Column '((CASE WHEN ((Name == Alice)) THEN Value1 ELSE Value2 END + Value1) - <sparkless.functions.conditional.CaseWhen object at 0x111091c50>)' not found. Available columns: [Name, Value1, Value2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_escaped_characters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_integer_power_column - RuntimeError: not found: Column '**(2)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_137_datetime_validation.py::TestIssue137DatetimeValidation::test_datetime_validation_with_multiple_conditions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_column_power_column - RuntimeError: not found: Column '**(Base)' not found. Available columns: [Base, Exponent]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_float_power_nested_expression - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_select - RuntimeError: not found: Column 'Power' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_filter - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_with_nulls - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_zero_exponent - RuntimeError: not found: Column '**(Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_zero_base - RuntimeError: not found: Column '**(0.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_negative_exponent - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_literal_semantics[x-y-False] - RuntimeError: not found: Column 'equals' not found. Available columns: [left, right]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_coexists_with_standard_equality - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_integer_types - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_float_types - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_date_types - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_datetime_types - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_column_vs_literal - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_column_after_transform - RuntimeError: not found: Column 'to_timestamp_regexp_replace(snapshot_date, \.\d+, , 1)' not found. Available columns: [inventory_id, snapshot_date, quantity_on_hand]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_multiple_columns_after_transform - RuntimeError: not found: Column 'to_timestamp_regexp_replace(snapshot_date, \.\d+, , 1)' not found. Available columns: [inventory_id, snapshot_date, quantity_on_hand, temp_col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_integer_literal - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_chained_operations - RuntimeError: not found: Column '**(**(2.0))' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_rsd_issue_266 - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_168_validation_after_drop.py::TestIssue168ValidationAfterDrop::test_validation_after_drop_columns - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_168_validation_after_drop.py::TestIssue168ValidationAfterDrop::test_validation_after_drop_with_nested_operations - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_168_validation_after_drop.py::TestIssue168ValidationAfterDrop::test_validation_after_drop_with_complex_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_parity - RuntimeError: not found: Column 'split(StringValue, ,, 3)' not found. Available columns: [Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_1_parity - RuntimeError: not found: Column 'split(Value, ,, 1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_without_limit_parity - RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_split_limit_parity.py::TestSplitLimitParity::test_split_with_limit_minus_one_parity - RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_upper - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lower - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_length - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substring - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_substr_method - RuntimeError: not found: Column 'partial_name' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_in_select_expression - RuntimeError: not found: Column 'equals' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_in_join_condition - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_type_coercion - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_quantified_groups - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookahead_with_boundaries - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_column_astype_method - RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_in_withcolumn - RuntimeError: not found: Column 'explode(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_260_eq_null_safe.py::TestIssue260EqNullSafe::test_eqnullsafe_with_multiple_conditions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_materialize_basic - RuntimeError: not found: Column 'regexp_replace(test_date, \.\d+, , 1)' not found. Available columns: [lab_id, test_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_then_select - RuntimeError: not found: Column 'to_timestamp_regexp_replace(snapshot_date, \.\d+, , 1)' not found. Available columns: [inventory_id, snapshot_date, quantity_on_hand]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_mixed_types - RuntimeError: not found: Column '**(2)' not found. Available columns: [FloatValue, IntValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_in_select - RuntimeError: not found: Column 'ExplodedValue' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_multiple_columns - RuntimeError: not found: Column 'regexp_replace(timestamp_str, \.\d+, , 1)' not found. Available columns: [extra_col, id, timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_138_column_drop_reference.py::TestIssue138ColumnDropReference::test_drop_then_filter - RuntimeError: not found: Column 'to_timestamp_regexp_replace(snapshot_date, \.\d+, , 1)' not found. Available columns: [inventory_id, snapshot_date, quantity_on_hand]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_datetime_column - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_concat - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_split - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_regexp_extract - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_trim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_idempotent_behavior - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_with_select - RuntimeError: not found: Column 'regexp_replace(ts_str, \.\d+, , 1)' not found. Available columns: [id, ts_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_169_to_timestamp_drop_error.py::TestIssue169ToTimestampDropError::test_to_timestamp_drop_with_filter - RuntimeError: not found: Column 'regexp_replace(ts_str, \.\d+, , 1)' not found. Available columns: [id, ts_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_basic - RuntimeError: not found: Column 'to_timestamp_event_timestamp' not found. Available columns: [event_id, event_timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_with_drop - RuntimeError: not found: Column 'to_timestamp_ts_str' not found. Available columns: [id, ts_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_with_select - RuntimeError: not found: Column 'to_timestamp_ts_str' not found. Available columns: [id, ts_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_170_to_date_timestamp_type.py::TestIssue170ToDateTimestampType::test_to_date_on_timestamp_type_with_filter - RuntimeError: not found: Column 'to_timestamp_ts_str' not found. Available columns: [id, ts_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_173_validation_during_materialization.py::TestIssue173ValidationDuringMaterialization::test_validation_during_materialization_with_dropped_columns - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_date_column_and_operations - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_ltrim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rtrim - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_datetime_comparison - RuntimeError: not found: Column 'to_timestamp_txn_date_str' not found. Available columns: [txn_id, txn_date_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_multiple_datetime_columns - RuntimeError: not found: Column 'to_timestamp_start_date_str' not found. Available columns: [record_id, start_date_str, end_date_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_139_datetime_validation_compatibility.py::TestIssue139DatetimeValidationCompatibility::test_validation_with_datetime_after_column_rename - RuntimeError: not found: Column 'to_timestamp_snapshot_date' not found. Available columns: [inventory_id, snapshot_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_approx_count_distinct_rsd_parity.py::TestApproxCountDistinctRsdParity::test_approx_count_distinct_window_without_rsd_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_contains - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_lpad - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_empty_dataframe - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value, Result]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_fractional_exponent - RuntimeError: not found: Column '**(Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_case_when - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: select' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/sql/test_advanced.py::TestSQLAdvancedParity::test_sql_with_like - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_large_numbers - RuntimeError: not found: Column '**(Base)' not found. Available columns: [Base, Exponent]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_small_numbers - RuntimeError: not found: Column '**(Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_string_coercion - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_ddl.py::TestSQLDDLParity::test_create_table_with_select - assert 0 == 2
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 0 columns].count
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_position - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_145_string_cast.py::test_string_cast_works_with_to_timestamp - RuntimeError: not found: Column 'to_date(to_timestamp_timestamp_str)' not found. Available columns: [user_id, timestamp, value, timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_orderby - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_chained_operations - RuntimeError: not found: Column 'A' not found. Available columns: [Category, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_join_different_case_select_third_case - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "Value2"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_join_different_case_select_left_column - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "value"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_different_join_types - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_multiple_ambiguous_columns - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["AGE", "CITY", "NAME"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_complex_nested_expression - RuntimeError: not found: Column '**(**(A))' not found. Available columns: [A, B, C]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_with_arithmetic_combination - RuntimeError: not found: Column '(**(2.0) + **(Value))' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rpad - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_integers - RuntimeError: not found: Column 'explode(Numbers)' not found. Available columns: [Name, Numbers]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_empty_arrays - RuntimeError: not found: Column 'explode(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_null_arrays - RuntimeError: not found: Column 'explode(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_with_conditional - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Flag, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_multiple_columns - RuntimeError: not found: Column '**(Base1)' not found. Available columns: [Base1, Base2, Exp1, Exp2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_chained_operations_after_select - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_groupby_after_select_with_ambiguous_column - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "bonus"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_like - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_multiple_matches_uses_requested_name - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME"]; PROJECT */1 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_empty_dataframes - RuntimeError: not found: NaMe

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_null_values_in_joined_columns - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_one_exponent - RuntimeError: not found: Column '**(Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_string_rlike - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_concat_ws - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_different_case_variations - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME"]; PROJECT */1 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_with_column_after_select - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_297_join_different_case_select.py::TestIssue297JoinDifferentCaseSelect::test_drop_after_select - RuntimeError: not found: name

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["NAME", "score"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_ascii - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_one_base - RuntimeError: not found: Column '**(1.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_size - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_element_at - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_explode - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=9
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_distinct - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_outer_with_null_arrays - RuntimeError: not found: Column 'explode_outer(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit - RuntimeError: not found: Column 'split(StringValue, ,, 3)' not found. Available columns: [Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_join - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_1 - RuntimeError: not found: Column 'split(Value, ,, 1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_multiple_columns - RuntimeError: not found: Column 'explode(Tags)' not found. Available columns: [Age, Name, Tags]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_chained_operations - RuntimeError: not found: Column 'explode(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_decimal_base_exponent - RuntimeError: not found: Column '**(Base)' not found. Available columns: [Base, Exp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_basic - RuntimeError: not found: Column 'format_string('%s-%s', StringValue, IntegerValue)' not found. Available columns: [IntegerValue, Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_table - RuntimeError: not found: Column 'Alice' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_update_multiple_columns - RuntimeError: not found: Column 'Alice' not found. Available columns: [name, age, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_hex - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_floats - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_booleans - RuntimeError: not found: Column 'explode(Flags)' not found. Available columns: [Flags, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_base64 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_union - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_mixed_types - RuntimeError: not found: Column 'explode(Mixed)' not found. Available columns: [Mixed, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_union - RuntimeError: not found: Column '**(2.0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_332_cast_alias_select.py::TestIssue332CastAliasSelect::test_cast_alias_select_with_join - RuntimeError: datatypes of join keys don't match - `ID`: str on left does not match `ID`: i64 on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["ID", "Name"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_multiple_columns - RuntimeError: not found: Column 'format_string('%s is %d years old and lives in %s', Name, Age, City)' not found. Available columns: [Age, City, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_single_element_arrays - RuntimeError: not found: Column 'explode(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_2 - RuntimeError: not found: Column 'split(Value, ,, 2)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_with_null_values - RuntimeError: not found: Column 'format_string('%s-%s', Value, Number)' not found. Available columns: [Name, Number, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/sql/test_dml.py::TestSQLDMLParity::test_insert_from_select - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: not found: Column 'IT' not found. Available columns: [name, age, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_initcap - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_with_alias - RuntimeError: not found: Column 'TwoToPower' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_very_large_exponent - RuntimeError: not found: Column '**(Base)' not found. Available columns: [Base, Exp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_without_limit - RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_larger_than_splits - RuntimeError: not found: Column 'split(Value, ,, 10)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_sort - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array.py::TestArrayFunctionsParity::test_array_remove - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_basic_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_multiple_matches_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_large_arrays - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_return_type - RuntimeError: not found: Column 'udf(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_groupby_agg - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Category, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_orderby - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_distinct - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_without_return_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_float_base_integer_exponent - RuntimeError: not found: Column '**(2.5)' not found. Available columns: [Exp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_soundex - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_in_select - RuntimeError: not found: Column 'NewValue' not found. Available columns: [IntegerValue, Name, StringValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_limit_minus_one - RuntimeError: not found: Column 'split(Value, ,, -1)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_integer_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_291_power_operator_float_column.py::TestIssue291PowerOperatorFloatColumn::test_power_in_multiple_withcolumns - RuntimeError: not found: Column '**(Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_union - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/functions/test_array_contains_join_parity.py::TestArrayContainsJoinParity::test_array_contains_join_left_parity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_translate - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_levenshtein - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/parity/functions/test_string.py::TestStringFunctionsParity::test_crc32 - AssertionError: DataFrames are not equivalent:
Row count mismatch: mock=0, expected=3
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_mixed_nulls - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_different_data_types - RuntimeError: not found: Column 'IntField' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_case_sensitivity - RuntimeError: not found: Column 'UpperE1' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_float_values - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_partitions - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_null_values - RuntimeError: not found: Column 'split(Value, ,, 2)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_with_empty_string - RuntimeError: not found: Column 'split(Value, ,, 2)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_in_select - RuntimeError: not found: Column 'Array' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_multi_char_delimiter - RuntimeError: not found: Column 'split(Value, ::, 2)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_special_regex_characters - RuntimeError: not found: Column 'split(Value, ., 3)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookahead - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_whitespace_delimiter - RuntimeError: not found: Column 'split(Value,  , 2)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_different_format_specifiers - RuntimeError: not found: Column 'format_string('Name: %s, Age: %d, Salary: %.2f', Name, Age, Salary)' not found. Available columns: [Age, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_consecutive_delimiters - RuntimeError: not found: Column 'split(Value, ,, 3)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_empty_strings - RuntimeError: not found: Column 'format_string('%s-%s', Value, Number)' not found. Available columns: [Name, Number, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_delimiter_not_found - RuntimeError: not found: Column 'split(Value, ,, 2)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_computed_column - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_multiple_arguments - RuntimeError: not found: Column 'udf(a, b)' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_positive_lookahead - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_stddev_variance - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn, withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_many_columns - RuntimeError: not found: Column 'format_string('%s-%d-%.1f-%s-%d-%s', A, B, C, D, E, F)' not found. Available columns: [A, B, C, D, E, F]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_numeric_edge_cases - RuntimeError: not found: Column 'format_string('%d|%d|%d|%.2f|%.2f', Int, Neg, Large, Float, NegFloat)' not found. Available columns: [Float, Int, Large, Neg, NegFloat]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_unicode - RuntimeError: not found: Column 'format_string('%s from %s says %s', Name, City, Emoji)' not found. Available columns: [City, Emoji, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_multiple_columns - assert 100 == 90
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_limit_zero - RuntimeError: not found: Column 'split(Value, ,, 0)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_special_characters - RuntimeError: not found: Column 'FieldAlias' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_no_partition - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_rowsBetween - RuntimeError: not found: Column '(sum() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC), rowsBetween(-9223372036854775808, 0))) > 150)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_rangeBetween - RuntimeError: not found: Column '(sum() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC), rangeBetween(-9223372036854775808, 0))) > 150)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_negative_values - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_zero_values - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_join - RuntimeError: not found: Column 'StructValue.E1' not found. Available columns: [ID, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_union - RuntimeError: not found: Column 'StructValue.E1' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_both_list - assert 100 == 90
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_duplicate_scores - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_in_select - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_in_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_gt_comparison - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) > 0)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_groupby - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Category, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_with_window_function - RuntimeError: not found: Column 'StructValue.E1' not found. Available columns: [Name, StructValue, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_multiple_selects - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_when_otherwise - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_cast - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_string_operations - RuntimeError: not found: Column 'explode(Words)' not found. Available columns: [Name, Words]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_multiple_explodes - RuntimeError: not found: Column 'explode(Tags)' not found. Available columns: [Name, Numbers, Tags]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_join - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [ID, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_outer_with_empty_arrays - RuntimeError: not found: Column 'explode_outer(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_alias - RuntimeError: not found: Column 'Exploded' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_filter_after - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_unicode_characters - RuntimeError: not found: Column 'split(Value, |, 2)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_very_long_string - RuntimeError: not found: Column 'split(Value, ,, 10)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_special_characters_in_format - RuntimeError: not found: Column 'format_string('Value: %s | Number: %d | End', A, B)' not found. Available columns: [A, B]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_all_null - RuntimeError: not found: Column 'format_string('%s-%s-%s', A, B, C)' not found. Available columns: [A, B, C]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_mixed_types - RuntimeError: not found: Column 'format_string('%s-%d-%.2f-%s', Str, Int, Float, Bool)' not found. Available columns: [Bool, Float, Int, Str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_string_names - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_rows_between - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_empty_delimiter - RuntimeError: not found: Column 'split(Value, , -1)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookbehind - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_basic - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_lt_comparison - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) < 5)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_complex_lookaround - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_regexp_alias_lookaround - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_regexp_like_alias_lookaround - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_without_lookaround - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_case_insensitive_lookaround - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_multiple_lookaheads - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_ge_comparison - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) >= 1)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_chained_operations - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_vs_function_interface - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_null_values - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_different_data_types - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_multiple_udfs_same_dataframe - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_computed_columns - RuntimeError: not found: Column 'udf(a_plus_1, b_times_2)' not found. Available columns: [a, b, a_plus_1, b_times_2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_all_null_partition - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Type, Score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_leading_trailing_delimiters - RuntimeError: not found: Column 'split(Value, ,, 4)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_filter_before - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Age, Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_mixed_types - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Category, Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookaround_with_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_empty_dataframe - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_inner - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_format_specifiers - RuntimeError: not found: Column 'format_string('%x', Hex)' not found. Available columns: [Dec, Hex, Oct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_precision_formatting - RuntimeError: not found: Column 'format_string('%05d', Num)' not found. Available columns: [Float, Num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_326_format_string.py::TestIssue326FormatString::test_format_string_long_strings - RuntimeError: not found: Column 'format_string('%s-%d', Long, Num)' not found. Available columns: [Long, Num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_empty_list_error - RuntimeError: not found: Column '__dummy__' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_date_type - RuntimeError: not found: Column 'udf(date_str)' not found. Available columns: [date_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_timestamp_type - RuntimeError: not found: Column 'udf(ts_str)' not found. Available columns: [ts_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_array_type - RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_desc_ordering - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_le_comparison - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) <= 1)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_left - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_different_limit_values - RuntimeError: not found: Column 'split(Value, ,, 1)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_three_arguments - RuntimeError: not found: Column 'udf(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_join - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [id, name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_asc_ordering - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score ASC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_orderby_columns - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC, Age ASC))) == 1)' not found. Available columns: [Age, Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_window_function - assert 1 == 2
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_eq_comparison - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) == 1)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_union - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_multiple_matches - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_no_matches - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_328_split_limit.py::TestIssue328SplitLimit::test_split_in_filter_context - RuntimeError: not found: Column 'element_at(split(Value, ,, 2), 1)' not found. Available columns: [Category, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_select_subset - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Age, Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_empty_dataframe - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_in_select - RuntimeError: not found: Column 'Matches' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_distinct - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_float_base - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_ne_comparison - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) != 0)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_range_between - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_293_explode_withcolumn.py::TestIssue293ExplodeWithColumn::test_explode_with_count - RuntimeError: not found: Column 'explode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_from_string_timestamps - RuntimeError: not found: Column 'hour(Timestamp)' not found. Available columns: [Name, Timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_null_arrays - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_null_ids - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_dense_rank - assert 1 == 2
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_window_function_in_value - RuntimeError: not found: Column 'Rank1 = Rank2' not found. Available columns: [Name, Score, Type, Rank1, Rank2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_orderby - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_in_withcolumn - RuntimeError: not found: Column 'RLIKE(Name, (?i)^(?!.*(Alice\sCat)).*$)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_conditions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_different_timezone_formats - RuntimeError: not found: Column 'hour(Timestamp)' not found. Available columns: [Name, Timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_special_characters - RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_int_base - RuntimeError: not found: Column 'Log2' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_right - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_chained_operations - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_rank - RuntimeError: not found: Column '(rank() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) <= 2)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_outer - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_different_formats - RuntimeError: not found: Column 'hour(Timestamp)' not found. Available columns: [Name, Timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_in_select - RuntimeError: not found: Column 'hour' not found. Available columns: [Name, Timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_unicode - RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_very_long_strings - RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_with_null_values - assert None == 10
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_dense_rank - RuntimeError: not found: Column '(dense_rank() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_select - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_anchors - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_conditional_logic - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_percent_rank - RuntimeError: not found: Column '(percent_rank() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 0.0)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_filter - RuntimeError: not found: Column 'hour(Timestamp)' not found. Available columns: [Name, Timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_exception_handling - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_percent_rank - assert 0.0 == 0.5
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_lag_lead - AssertionError: assert 'A' is None
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_first_last_value - AssertionError: assert 'A' == 80
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_lag - RuntimeError: not found: Column '(lag() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) IS NULL)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_nested_lookahead - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_column_name_conflicts - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_empty_dataframes - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_natural_log - RuntimeError: not found: Column 'Ln' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_different_bases - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_column_base - RuntimeError: not found: Column 'LogBase' not found. Available columns: [Base, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_ntile - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_with_null_values - RuntimeError: not found: Column 'hour(Timestamp)' not found. Available columns: [Name, Timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_nested_calls - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_with_null_values - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_digits - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_empty_arrays - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_in_with_column - RuntimeError: not found: Column 'log(10.0, Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_combined_lookahead_lookbehind - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_cume_dist - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_294_hour_minute_second_string_timestamps.py::TestIssue294HourMinuteSecondStringTimestamps::test_hour_minute_second_in_groupby_agg - RuntimeError: not found: Column 'hour(Timestamp)' not found. Available columns: [Category, Timestamp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_lead - RuntimeError: not found: Column '(lead() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) IS NULL)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_327_orderby_ascending.py::TestIssue327OrderByAscending::test_orderby_mixed_nulls_and_values - assert None == 5
FAILED tests/test_issue_329_log_float_constant.py::TestIssue329LogFloatConstant::test_log_edge_cases - RuntimeError: not found: Column 'Log10' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_sum - RuntimeError: not found: Column '(sum() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) > 150)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_multiple_fields - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_duplicate_values - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_string_arrays - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_float_arrays - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_eqNullSafe - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) <=> 1)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_isnotnull - RuntimeError: not found: Column '(lead() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) IS NOT NULL)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_in_withcolumn - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_and_other_columns - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_large_arrays - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_where_clause - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_aggregation - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_window_functions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_negative_lookahead_multiple_conditions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_null_values - RuntimeError: not found: Column '(lag() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) IS NULL)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_empty_dataframe - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) > 0)' not found. Available columns: [Name, Type, GT-Zero]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_word_boundaries - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_fixed_width - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_alternation - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_capture_groups - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_multiple_negative_lookaheads - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_with_character_classes - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_union - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_single_row - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Type))) == 1)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_coalesce - RuntimeError: not found: Column 'coalesce(avg(Value), 0)' not found. Available columns: [Name, avg(Value)]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_float_precision - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_distinct - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_boolean_logic - RuntimeError: not found: Column 'udf(a, b)' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_null_values - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_drop_operation - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_multiple_chained_udfs - RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_limit - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_multiple_conditions_same_df - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_nested_select - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_case_when - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join, withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_coalesce - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_nested_struct - RuntimeError: not found: Column 'E2-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_non_capturing_groups - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_all_null_inputs - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_331_array_contains_join.py::TestIssue331ArrayContainsJoin::test_array_contains_join_with_cast - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_alias - RuntimeError: not found: Column 'source_file' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_aggregation_functions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn, withColumn, withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_large_dataset - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) <= 10)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_multiple_window_functions - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_arithmetic_operations - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) + 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_select - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_cast - assert None == 5
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_without_alias_still_works - RuntimeError: not found: Column 'StructValue.E1' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_complex_nested_lookaround - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_unicode - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookbehind_multiple_fixed_widths - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_in_groupby_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_performance_large_dataset - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_with_special_characters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_292_rlike_lookaround.py::TestIssue292RlikeLookaround::test_rlike_lookahead_case_sensitivity - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_orderby - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_groupby - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_join - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_union - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_distinct - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_limit - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_complex_chained_operations - RuntimeError: not found: Column 'MeanValue' not found. Available columns: [Name, Type, avg(Value)]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_column_alias_in_groupBy - RuntimeError: not found: Column 'Person' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_single_field - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_330_struct_field_alias.py::TestIssue330StructFieldAlias::test_struct_field_with_alias_chained_operations - RuntimeError: not found: Column 'E1-Extract' not found. Available columns: [Name, StructValue]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_limit - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_chained_operations - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_array_index - RuntimeError: not found: Column 'getItem(ArrayVal)' not found. Available columns: [ArrayVal, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_equivalent_to_getitem - RuntimeError: not found: Column 'getItem(arr)' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_struct_field_by_name - RuntimeError: not found: Column 'person.name' not found. Available columns: [id, person]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_complex_condition_with_aliases - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_select - RuntimeError: not found: Column 'Value1' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_chained_operations - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_nested_select - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_case_when_chain - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_nested_array_access - RuntimeError: not found: Column 'getItem(nested)' not found. Available columns: [nested]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_multiple_fields - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_mixed_types_in_udf - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_296_udf_decorator.py::TestIssue296UdfDecorator::test_udf_decorator_with_complex_aggregation - RuntimeError: not found: Column 'udf(avg_salary, avg_bonus)' not found. Available columns: [dept, avg_salary, avg_bonus]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_coalesce - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_cast - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_avg - RuntimeError: not found: Column '(avg() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) > 85)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_same_as_partition_by - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_alias - RuntimeError: not found: Column 'MeanValue' not found. Available columns: [Name, avg(Value)]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_337_grouped_data_mean.py::TestIssue337GroupedDataMean::test_grouped_data_mean_with_case_when - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_chain_three_with_window_middle - RuntimeError: not found: Column 'struct(a)' not found. Available columns: [a, k]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_groupby_agg_cast_decimal_drop - TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_agg_cast_decimal_drop_different_precision_scale - TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'
FAILED tests/test_issue_335_window_orderby_list.py::TestIssue335WindowOrderByList::test_window_orderby_list_with_count_distinct - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_or_string_equality - RuntimeError: not found: Column 'Y' not found. Available columns: [Name, Status]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_and_is_null - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_select - RuntimeError: not found: Column 'Value1' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_in_select - RuntimeError: not found: Column 'E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_in_filter - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_equals_dot_notation - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_nested_struct - RuntimeError: not found: Column 'Outer.Inner.E1' not found. Available columns: [Name, Outer]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_literal_contains_and - RuntimeError: not found: Column 'yes and no' not found. Available columns: [Msg]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_or_with_is_null - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_string_equality_single_condition - RuntimeError: not found: Column 'Y' not found. Available columns: [Status]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_equality_empty_result - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_369_isin_negation.py::TestIssue369IsinNegation::test_negation_isin_string_to_string - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_370_filter_in_string.py::TestIssue370FilterInString::test_filter_equality_string_works - RuntimeError: not found: Column '20' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_371_cast_decimal.py::TestIssue371CastDecimal::test_cast_decimal_in_select - RuntimeError: not found: Column 'dec' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_negative_index - RuntimeError: not found: Column 'getItem(arr)' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_358_getfield.py::TestIssue358GetField::test_getfield_chained_access - RuntimeError: not found: Column 'getField(getItem(matrix))' not found. Available columns: [matrix]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_both_empty - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_with_nulls - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_no_type_error - RuntimeError: not found: Column 'pos' not found. Available columns: [x, y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_max - RuntimeError: not found: Column '(max() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == Score)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_subset_of_partition_by - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_alias - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_differs_from_partition_running_sum - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_avg_order_by_subset_of_partition_by - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_unionAll_alias - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_single_column - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "other"
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_many_columns_different_names - RuntimeError: lengths don't match: unable to vstack, column names don't match: "c1" and "a"
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_agg_cast_decimal_drop_with_nulls - TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_numeric_and_string - RuntimeError: not found: Column 'A' not found. Available columns: [Grade, Name, Score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_avg_cast_decimal_drop - TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_min_max_cast_decimal_drop - TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_agg_cast_decimal_drop_then_show_and_collect - TypeError: '<' not supported between instances of 'NoneType' and 'NoneType'
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_min - RuntimeError: not found: Column '(min() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == Score)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_single_element - RuntimeError: not found: Column 'idx' not found. Available columns: [arr, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_alias_two_names_empty_array - RuntimeError: not found: Column 'pos' not found. Available columns: [arr, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_then_select - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_col_desc_still_subset - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_406_aggregate_cast_decimal_drop.py::TestIssue406AggregateCastDecimalDrop::test_single_group_agg_cast_decimal_drop - assert None == 3.0
 +  where None = _decimal_value(None)
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_expr_and_string_with_column - RuntimeError: not found: Column '(Status = Y & Name IS NOT NULL)' not found. Available columns: [Name, Status]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_select_after - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_is_null_and_string_equality - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_null_struct - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_null_field - RuntimeError: not found: Column 'StructVal.E2' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_string_type_exact_issue - RuntimeError: not found: Column 'to_date(DateNumber, 'yyyyMMdd')' not found. Available columns: [DateNumber, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_single_row_partition - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_outer_alias_two_names - RuntimeError: not found: Column 'pos' not found. Available columns: [id, arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_orderBy - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_groupBy - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_three_rows_all_peers - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_partition - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_multiple_partitions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_explode_alias_single_name - RuntimeError: not found: Column 'num' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_then_order_by - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_then_filter - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "a"
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_samp_over_window - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_case_when - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_comparison - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_arithmetic - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_count - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_string_literal - RuntimeError: not found: Column 'to_date(DateNumber, 'yyyyMMdd')' not found. Available columns: [DateNumber]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_with_show - RuntimeError: not found: Column 'to_date(DateNumber, 'yyyyMMdd')' not found. Available columns: [DateNumber, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_count - RuntimeError: not found: Column '(count() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) > 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_ntile - RuntimeError: not found: Column '(ntile() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_cume_dist - RuntimeError: not found: Column '(cume_dist() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) > 0.5)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_first_value - RuntimeError: not found: Column '(first_value() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == Score)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_last_value - RuntimeError: not found: Column '(last_value() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) == Score)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_countDistinct - RuntimeError: not found: Column '(countDistinct() OVER (WindowSpec(partitionBy(Type), orderBy(Score DESC))) > 1)' not found. Available columns: [Name, Score, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_empty_array - RuntimeError: not found: Column 'pos' not found. Available columns: [arr, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_nested_arrays - RuntimeError: not found: Column 'idx' not found. Available columns: [nested]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_pop_over_window - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_multiple_struct_columns - RuntimeError: not found: Column 'Struct1.E1' not found. Available columns: [Name, Struct1, Struct2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_computed_column - RuntimeError: not found: Column 'struct(Name, X)' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_336_window_function_comparison.py::TestIssue336WindowFunctionComparison::test_window_function_comparison_with_string_values - RuntimeError: not found: Column '(row_number() OVER (WindowSpec(partitionBy(Type), orderBy(Category DESC))) == 1)' not found. Available columns: [Category, Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_over_partition_order_desc - KeyError: 3
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_with_nulls_excluded - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_over_order_desc_no_partition - RuntimeError: not found: Column 'value DESC' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_in_select - RuntimeError: not found: Column 'DateCol' not found. Available columns: [DateNumber]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_366_alias_posexplode.py::TestIssue366AliasPosexplode::test_posexplode_outer_null_handling - RuntimeError: not found: Column 'pos' not found. Available columns: [id, arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_with_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_deeply_nested_struct - RuntimeError: not found: Column 'Level1.Level2.Level3.Value' not found. Available columns: [Level1, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_multiple_values_or - RuntimeError: cannot compare string with numeric type (i64)
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_with_nulls - RuntimeError: not found: Column 'to_date(DateNumber, 'yyyyMMdd')' not found. Available columns: [DateNumber]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_single_row_per_partition_returns_none - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_different_format - RuntimeError: not found: Column 'to_date(DateNumber, 'yyyyMMdd')' not found. Available columns: [DateNumber]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_then_filter - RuntimeError: not found: Column 'to_date(DateNumber, 'yyyyMMdd')' not found. Available columns: [DateNumber]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_407_stddev_window.py::TestIssue407StddevWindow::test_stddev_over_window_then_select_and_show - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_396_to_date_cast.py::TestIssue396ToDateCast::test_to_date_cast_integer_type_column - RuntimeError: not found: Column 'to_date(DateNum, 'yyyyMMdd')' not found. Available columns: [DateNum]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_and_condition - RuntimeError: cannot compare string with numeric type (i64)
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_empty_result - RuntimeError: cannot compare string with numeric type (i64)
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_with_show - RuntimeError: cannot compare string with numeric type (i64)
FAILED tests/test_issue_420_when_comparison_with_none.py::TestIssue420WhenComparisonWithNone::test_when_comparison_with_none_exact_issue - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_no_args_returns_empty_array - RuntimeError: not found: Column 'array()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_420_when_comparison_with_none.py::TestIssue420WhenComparisonWithNone::test_when_comparison_with_none_and_show - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_union - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_distinct - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_cast - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_window_function - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal, Type, Rank]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_exact_issue - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_reverse_order - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_over_partition_order_asc - AssertionError: assert (1, 'a', 1) in [(None, 1, 1), (None, 2, 2), (None, 1, 1)]
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_column - RuntimeError: not found: Column 'round(Value, 0)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_with_decimals - RuntimeError: not found: Column 'round(val, 2)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_negative_numbers - RuntimeError: not found: Column 'round(val, 0)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_scientific_notation - RuntimeError: not found: Column 'round(val, 1)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_list_returns_empty_array - RuntimeError: not found: Column 'array()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_row_number_with_column_pattern - assert 2 == 1
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_sum_over_partition_order_desc - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_lag_over_partition_order_desc - AssertionError: assert 'a' == 3
 +  where 'a' = _norm('a')
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_with_whitespace - RuntimeError: not found: Column 'round(val, 0)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_integer_strings - RuntimeError: not found: Column 'round(val, 0)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_mixed_string_numeric_columns - RuntimeError: not found: Column 'round(str_val, 0)' not found. Available columns: [num_val, str_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_373_round_string.py::TestIssue373RoundString::test_round_string_zero - RuntimeError: not found: Column 'round(val, 0)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_aliased_column_refs - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_multiple_aliased_tables - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join, join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_left_no_match - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_order_by_multiple_cols_subset_of_partition_by - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_inner - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_multiple_aggregations - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_coalesce - RuntimeError: not found: Column 'StructVal.E1' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_when_otherwise_nested - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_exact_issue - RuntimeError: not found: Column 'struct(apples)' not found. Available columns: [apples, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_339_column_subscript.py::TestIssue339ColumnSubscript::test_column_subscript_with_string_operations - RuntimeError: not found: Column 'upper(StructVal.E1)' not found. Available columns: [Name, StructVal]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_right - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_first_over_partition_order_desc - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_mixed_order_asc_desc - KeyError: ('a', 3)
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_single_row_per_partition - assert None == 1
 +  where None = _norm(None)
FAILED tests/test_issue_414_row_number_over_descending.py::TestIssue414RowNumberOverDescending::test_avg_over_partition_order_desc - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_select_struct - RuntimeError: not found: Column 'struct(v)' not found. Available columns: [id, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_aliased_column_without_prefix - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_374_join_aliased_columns.py::TestIssue374JoinAliasedColumns::test_join_aliased_self_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_429_posexplode_no_alias.py::test_posexplode_without_alias_single_element - RuntimeError: not found: Column 'posexplode(arr)' not found. Available columns: [arr, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_show - RuntimeError: not found: Column 'array()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_outer - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_in_select - RuntimeError: not found: Column 'empty_array' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_list_and_array_equivalent - RuntimeError: not found: Column 'arr_no_args' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_after_filter - RuntimeError: not found: Column 'array()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_in_union - RuntimeError: not found: Column 'array()' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_multiple_times - RuntimeError: not found: Column 'arr1' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_with_different_data_types - RuntimeError: not found: Column 'array()' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_with_computed_columns - RuntimeError: not found: Column 'sum' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_in_join - RuntimeError: not found: Column 'array()' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_row_number - RuntimeError: not found: Column 'struct(x)' not found. Available columns: [id, x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_sum - RuntimeError: not found: Column 'struct(v)' not found. Available columns: [g, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_392_window_sum_peers.py::TestIssue392WindowSumPeers::test_sum_no_order_by_partition_total - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_partition_by_order_by - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_avg_string_column - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_running_sum - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileName::test_input_file_name_returns_string_column - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [dataset, table]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileName::test_input_file_name_exact_issue_scenario - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [dataset, table]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileName::test_input_file_name_select_only - RuntimeError: not found: Column 'path' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_two_names_returns_exploded_rows - RuntimeError: not found: Column 'Value1' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_no_none_values - RuntimeError: not found: Column 'pos' not found. Available columns: [x, y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_chained_filter_orderby - RuntimeError: not found: Column 'pos' not found. Available columns: [name, vals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_empty_array - RuntimeError: not found: Column 'pos' not found. Available columns: [arr, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_with_show - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_invalid_numeric_returns_null - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_integer_column_numeric_bounds_unchanged - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_367_array_empty.py::TestIssue367ArrayEmpty::test_array_empty_two_equivalent - RuntimeError: not found: Column 'no_args' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_different_column_names_with_select - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_with_show - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_empty_dataframe - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [a, path]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_avg - RuntimeError: not found: Column 'struct(v)' not found. Available columns: [g, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_with_lit_bounds - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_single_element - RuntimeError: not found: Column 'pos' not found. Available columns: [arr, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_415_orderby_list.py::test_filter_then_orderby_list - RuntimeError: not found: Column 'a' not found. Available columns: [id, grp]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_421_join_column_names.py::TestIssue421JoinColumnNames::test_join_dot_notation_still_works - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_with_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_no_partition_running_sum - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_avg_string_column_multiple_partitions - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_decimal_like - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_single_row_partition - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_393_sum_string_column.py::TestIssue393SumStringColumn::test_sum_string_column_select_after - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_exact_issue - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_not_like_exact_issue - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_with_show - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_in_select_expression - RuntimeError: not found: Column 'in_range' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_prefix_pattern - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_inclusive_boundaries - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_mixed_columns - RuntimeError: not found: Column 'pos' not found. Available columns: [a, arr, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_outer_alias_returns_exploded_rows - RuntimeError: not found: Column 'pos' not found. Available columns: [id, arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_single_row - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_with_nulls_in_partition - RuntimeError: not found: Column 'struct(v)' not found. Available columns: [g, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_multiple_window_fields - RuntimeError: not found: Column 'struct(v)' not found. Available columns: [g, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_398_withfield_window.py::TestIssue398WithFieldWindow::test_withfield_window_then_filter - RuntimeError: not found: Column 'struct(val)' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_column_with_underscore - RuntimeError: not found: Column 'mc' not found. Available columns: [my_column]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_mixed_with_plain - RuntimeError: not found: Column 's' not found. Available columns: [id, name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_replace_existing_column - RuntimeError: not found: Column 'a_as_int' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_chain_three_ops - RuntimeError: not found: Column 'x_a' not found. Available columns: [x, y, z]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_different_column_order_by_position - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_chained_three_dataframes - RuntimeError: lengths don't match: unable to vstack, column names don't match: "a" and "col1"
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_empty_dataframe_left - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "x"
FAILED tests/test_issue_413_union_createDataFrame.py::TestIssue413UnionCreateDataFrame::test_union_empty_dataframe_right - RuntimeError: lengths don't match: unable to vstack, column names don't match: "id" and "a"
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_underscore_wildcard - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_after_filter - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_with_nulls_in_array - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_null_excluded - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_negative_numbers - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_string_array - RuntimeError: not found: Column 'pos' not found. Available columns: [arr, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_after_select - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_preserves_schema - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_not_like_multiple_rows - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_expr_like_standalone - RuntimeError: not found: Column 'like(Name, '%TEST%')' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_suffix_pattern - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_and_combined - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_then_orderby - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_or_combined - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_null_array_returns_null - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_in_when_otherwise - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_float_arrays_preserves_type - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_after_filter - RuntimeError: not found: Column 'v' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_string_literal_type_coercion_exact_issue - RuntimeError: cannot compare string with numeric type (i64)
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_with_show - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_column_object - RuntimeError: not found: Column 'idx' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_empty_result - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_not_between - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_chained_with_select - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter, filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_369_isin_negation.py::TestIssue369IsinNegation::test_negation_isin_string_column_int_list - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_boolean_arrays - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_all_duplicates_int - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_all_duplicates_string - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_430_posexplode_alias_execution.py::test_posexplode_alias_show_no_none - RuntimeError: not found: Column 'Value1' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_less_than_datetime - AssertionError: assert '2024-01-01' == datetime.date(2024, 1, 1)
 +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_eq_datetime - AssertionError: assert '2024-01-01T00:00:00.000000' == datetime.datetime(2024, 1, 1, 0, 0)
 +  where datetime.datetime(2024, 1, 1, 0, 0) = <class 'datetime.datetime'>(2024, 1, 1, 0, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_lte_datetime - AssertionError: assert '2024-01-01T00:00:00.000000' == datetime.datetime(2024, 1, 1, 0, 0)
 +  where datetime.datetime(2024, 1, 1, 0, 0) = <class 'datetime.datetime'>(2024, 1, 1, 0, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_gte_datetime - AssertionError: assert '2024-06-15' == datetime.date(2024, 6, 15)
 +  where datetime.date(2024, 6, 15) = <class 'datetime.date'>(2024, 6, 15)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_431_date_datetime_comparison.py::test_datetime_less_than_date - AssertionError: assert '2023-06-15T10:00:00.000000' == datetime.datetime(2023, 6, 15, 10, 0)
 +  where datetime.datetime(2023, 6, 15, 10, 0) = <class 'datetime.datetime'>(2023, 6, 15, 10, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_ne_datetime - AssertionError: assert '2024-01-01T12:00:00.000000' == datetime.datetime(2024, 1, 1, 12, 0)
 +  where datetime.datetime(2024, 1, 1, 12, 0) = <class 'datetime.datetime'>(2024, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_431_date_datetime_comparison.py::test_date_datetime_with_and - RuntimeError: not found: Column 'A' not found. Available columns: [d, dt, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_datetime_to_timestamp_noop - AssertionError: assert '2023-01-01T12:00:00.000000' == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_to_date_noop - AssertionError: assert '2024-01-01' == datetime.date(2024, 1, 1)
 +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_string_to_timestamp_still_works - AssertionError: assert None == datetime.datetime(2024, 1, 15, 10, 30)
 +  where datetime.datetime(2024, 1, 15, 10, 30) = <class 'datetime.datetime'>(2024, 1, 15, 10, 30, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_empty_dataframe - RuntimeError: not found: Column 'a_alias' not found. Available columns: [a, a_int]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_369_isin_negation.py::TestIssue369IsinNegation::test_negation_isin_show - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_429_posexplode_no_alias.py::test_posexplode_without_alias_no_type_error - RuntimeError: not found: Column 'posexplode(Values)' not found. Available columns: [Name, Values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_round_string_with_whitespace - RuntimeError: not found: Column 'round(val, 0)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_round_string_with_decimals_and_whitespace - RuntimeError: not found: Column 'round(val, 2)' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_select_table_prefixed_after_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_all_rows_same_type - RuntimeError: not found: Column 'input_file_name()' not found. Available columns: [i]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_360_input_file_name.py::TestIssue360InputFileNameRobust::test_input_file_name_multiple_columns - RuntimeError: not found: Column 'path' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_to_date_with_nulls - AssertionError: assert '2024-01-01' == datetime.date(2024, 1, 1)
 +  where datetime.date(2024, 1, 1) = <class 'datetime.date'>(2024, 1, 1)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_to_timestamp_midnight - AssertionError: assert '2024-03-15T00:00:00.000000' == datetime.datetime(2024, 3, 15, 0, 0)
 +  where datetime.datetime(2024, 3, 15, 0, 0) = <class 'datetime.datetime'>(2024, 3, 15, 0, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_datetime_to_date_truncates_time - AssertionError: assert '2024-05-10' == datetime.date(2024, 5, 10)
 +  where datetime.date(2024, 5, 10) = <class 'datetime.date'>(2024, 5, 10)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_date_only_string_to_timestamp - RuntimeError: conversion from `str` to `datetime[s]` failed in column 's' for 1 out of 1 values: ["2024-01-15"]

You might want to try:
- setting `strict=False` to set values that cannot be converted to `null`
- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_select_with_cast - AssertionError: assert '2023-01-01T12:00:00.000000' == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_filter_after_cast - RuntimeError: cannot compare 'date/datetime/time' to a string value

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'filter' failed <---
FILTER [(col("dt")) >= (String(2024-01-01T00:00:00))] FROM
  DF ["dt", "id"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_zero_bounds - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_string_to_date_still_works - AssertionError: assert '2024-01-15' == datetime.date(2024, 1, 15)
 +  where datetime.date(2024, 1, 15) = <class 'datetime.date'>(2024, 1, 15)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_datetime_to_timestamp_with_nulls - AssertionError: assert '2023-01-01T12:00:00.000000' == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_419_filter_in_or_parse_exception.py::TestIssue419FilterInOrParseException::test_filter_in_or_workaround_still_works - RuntimeError: cannot compare string with numeric type (i64)
FAILED tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_select_expression_raises - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/backend/test_robin_unsupported_raises.py::TestRobinUnsupportedRaises::test_unsupported_raises_with_clear_message - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_with_datatype_objects - AssertionError: assert '2023-01-01T12:00:00.000000' == datetime.datetime(2023, 1, 1, 12, 0)
 +  where datetime.datetime(2023, 1, 1, 12, 0) = <class 'datetime.datetime'>(2023, 1, 1, 12, 0, 0)
 +    where <class 'datetime.datetime'> = datetime.datetime
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_long_type - RuntimeError: not found: Column 'lng' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_zero_values - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_self_join_manager_column_and_row_count - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_mixed_with_plain_select - RuntimeError: not found: Column 'score_int' not found. Available columns: [id, name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_invalid_string_to_int - assert None == 123
FAILED tests/test_issues_376_382_robust.py::test_robust_join_compound_condition - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_multiple_underscores - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_432_cast_datetime_date_noop.py::test_cast_leap_day - AssertionError: assert '2024-02-29' == datetime.date(2024, 2, 29)
 +  where datetime.date(2024, 2, 29) = <class 'datetime.date'>(2024, 2, 29)
 +    where <class 'datetime.date'> = datetime.date
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_chained_with_filter - RuntimeError: not found: Column 'array_distinct(vals)' not found. Available columns: [id, vals]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_unicode_strings - RuntimeError: not found: Column 'array_distinct(a)' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_multiple_rows_mixed - RuntimeError: not found: Column 'array_distinct(arr)' not found. Available columns: [id, arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_sql_where_table_prefixed - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_modulo - RuntimeError: not found: Column '(2 % number_2)' not found. Available columns: [number_2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_exact_issue_440 - RuntimeError: not found: Column 'getItem(map(1, Small, 2, Medium, 3, Large))' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_literal_cast_string_exact_issue_436 - RuntimeError: not found: Column 'TextColumn' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_sql_group_by_table_prefixed - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_433_regexp_in_expr.py::test_filter_regexp_exact_issue_433 - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_expr_not_like_in_with_column - RuntimeError: not found: Column '(CASE WHEN like(Name, '%TEST%') THEN FALSE ELSE TRUE END)' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_with_nulls - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_394_like_in_expr.py::TestIssue394LikeInExpr::test_filter_like_middle_wildcard - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_equality_exact_issue - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_string_equality_with_show - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_395_filter_and_string_expr.py::TestIssue395FilterAndStringExpr::test_filter_and_is_null_workaround_still_works - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_select_multiple_columns - assert None == 6.0
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_reverse_operations - RuntimeError: not found: Column '(5 - col)' not found. Available columns: [col, add]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issues_376_382_robust.py::test_robust_sql_three_joins_select_third_table - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Join execution failed: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double_to_int - assert None == 3
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_literals_only - RuntimeError: not found: Column 'map_col' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_in_select - assert None == 50.0
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_to_boolean - RuntimeError: casting from string to boolean failed for value ''
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_chained - AssertionError: assert None == '123'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_all_column_operations - RuntimeError: not found: Column 'upper_str' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_long_issue_243 - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x1135f0510> ELSE <sparkless.functions.core.literals.Literal object at 0x1135f1850> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_all_operators_in_single_expression - RuntimeError: not found: Column '((((a * 2) + 10) - (5 / a)) + (3 % a))' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_string - AssertionError: assert None == '1'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_basic_astype_int - assert None == 1
FAILED tests/test_issue_433_regexp_in_expr.py::test_filter_rlike_same_as_regexp - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_433_regexp_in_expr.py::test_expr_regexp_with_column - RuntimeError: not found: Column 'regexp(Value, 'sales|tech')' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_433_regexp_in_expr.py::test_expr_regexp_single_match - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_string - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x1136091d0> ELSE <sparkless.functions.core.literals.Literal object at 0x113609110> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_int - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x1135f1090> ELSE <sparkless.functions.core.literals.Literal object at 0x1135f0c50> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_to_double - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x113609250> ELSE <sparkless.functions.core.literals.Literal object at 0x1136090d0> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_notebooks.py::test_quickstart - assert 0 == 3
 +  where 0 = count()
 +    where count = DataFrame[0 rows, 6 columns].count
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_zero_and_negative - RuntimeError: casting from string to boolean failed for value '-1'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_float_string_conversions - TypeError: argument of type 'NoneType' is not iterable
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_after_when_otherwise - AssertionError: assert None in ['2', '2.0']
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_date_pyspark_parity - RuntimeError: not found: Column 'final_date' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_long_type - assert None == 1
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_string_type_aliases - AssertionError: assert None == '123'
FAILED tests/test_issue_433_regexp_in_expr.py::test_expr_regexp_no_match - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_exact_issue_434 - RuntimeError: not found: Column 'ltrim(rtrim(Value))' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_only - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_rtrim_only - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_nested_ltrim_rtrim_with_column - RuntimeError: not found: Column 'ltrim(rtrim(Value))' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_rtrim_ltrim_order - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_literal_col_cast_string - RuntimeError: not found: Column 's' not found. Available columns: [n]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_column_operation - RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_issue_239_example - RuntimeError: not found: Column 'substring(proc_date, 1, 10)' not found. Available columns: [proc_date]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_datatype_object - RuntimeError: not found: Column 'num_str' not found. Available columns: [num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_in_select - AssertionError: assert None == '1'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_null - AssertionError: assert None == '1'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_double - assert None == 1.0
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_boolean - RuntimeError: casting from string to boolean failed for value '5'
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_chained_operations - AssertionError: assert None in ['2', '2.0']
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_literal - AssertionError: assert None == '123'
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_timestamp_type_pass_through - RuntimeError: not found: Column 'to_timestamp_timestamp_str' not found. Available columns: [timestamp_str, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_trim_with_ltrim_rtrim - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_with_filter - RuntimeError: not found: Column 'ltrim(rtrim(Value))' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_with_nulls - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_empty_string - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_rtrim_empty_string - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_basic_substr - RuntimeError: not found: Column 'partial_name' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_string_type_with_format - RuntimeError: not found: Column 'to_timestamp_timestamp_str' not found. Available columns: [timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_string_type_without_format - RuntimeError: not found: Column 'to_timestamp_timestamp_str' not found. Available columns: [timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_integer_type_unix_timestamp - RuntimeError: not found: Column 'to_timestamp_unix_ts' not found. Available columns: [unix_ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_long_type_unix_timestamp - RuntimeError: not found: Column 'to_timestamp_unix_ts' not found. Available columns: [unix_ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_date_type_conversion - RuntimeError: not found: Column 'to_timestamp_date_col' not found. Available columns: [date_col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_double_type_unix_timestamp - RuntimeError: not found: Column 'to_timestamp_unix_ts' not found. Available columns: [unix_ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_drop_duplicates_struct_column_after_materialization_exact_issue_451 - RuntimeError: not found: Column 'struct(id, value)' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_drop_duplicates_struct_column_before_materialization - RuntimeError: not found: Column 'struct(id, value)' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_distinct_struct_column_after_materialization - RuntimeError: not found: Column 'struct(id, value)' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_451_drop_duplicates_struct_column.py::test_drop_duplicates_subset_with_struct_column - RuntimeError: not found: Column 'struct(id, value)' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_exact_issue_453 - RuntimeError: not found: Column 'y_int' not found. Available columns: [x, y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_multiple_columns - RuntimeError: not found: Column 'a_aliased' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_select_still_works - RuntimeError: not found: Column 'y_int' not found. Available columns: [y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_then_select - RuntimeError: not found: Column 'y_renamed' not found. Available columns: [x, y]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_string_type - RuntimeError: not found: Column 'n' not found. Available columns: [num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_double_type - RuntimeError: not found: Column 'str_val' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_long_type - RuntimeError: not found: Column 'l' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_with_nulls - RuntimeError: not found: Column 'a_aliased' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_multiple_when - RuntimeError: not found: Column 'CASE WHEN ((value == 1)) THEN low ELSE high END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_mixed_literals_columns - RuntimeError: not found: Column 'map_col' not found. Available columns: [v1, v2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_all_literals_still_works - RuntimeError: not found: Column 's' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_triple_nested_trim - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_to_timestamp_compatibility.py::TestToTimestampCompatibility::test_to_timestamp_after_regexp_replace - RuntimeError: not found: Column 'regexp_replace(timestamp_str, \.\d+, , 1)' not found. Available columns: [id, timestamp_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_from_second_position - RuntimeError: not found: Column 'from_second' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_null_values - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x1135e9f90> ELSE <sparkless.functions.core.literals.Literal object at 0x1135ea190> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_type_strictness.py::TestTypeStrictness::test_to_timestamp_accepts_multiple_types - RuntimeError: not found: Column 'to_timestamp_date_str' not found. Available columns: [date_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_column_with_underscore - RuntimeError: not found: Column 't' not found. Available columns: [my_col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_inside_upper - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_in_select - RuntimeError: not found: Column 'result' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestCaseWhenCast::test_casewhen_cast_with_datatype_object - RuntimeError: not found: Column 'CASE WHEN ((value == A)) THEN <sparkless.functions.core.literals.Literal object at 0x113614910> ELSE <sparkless.functions.core.literals.Literal object at 0x1136172d0> END' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_all_columns_still_works - RuntimeError: not found: Column 's' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_expression_cast_string - RuntimeError: not found: Column 'greeting' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_filter_with_ltrim - RuntimeError: not found: Column 'ltrim(Value)' not found. Available columns: [Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_rtrim_case_insensitive - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_453_alias_cast_withcolumn.py::test_alias_cast_withcolumn_then_filter - RuntimeError: not found: Column 'v' not found. Available columns: [name, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_filter - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_orderBy - AssertionError: assert 'Charlie' == 'Alice'
  
  - Alice
  + Charlie
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_date_from_string - assert None is not None
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_substring_to_date - RuntimeError: not found: Column 'date_col' not found. Available columns: [datetime_str]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_multiple_types - assert None == 123
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_with_alias - AssertionError: assert None == '1'
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_issue_238_example - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_long - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_cast_string_with_nulls - RuntimeError: not found: Column 's' not found. Available columns: [n]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_map_lookup_key_not_found - RuntimeError: not found: Column 'getItem(map(1, A, 2, B))' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_multiple_columns_ltrim_rtrim - RuntimeError: not found: Column 'la' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_string - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_astype.py::TestColumnAstype::test_astype_on_complex_expressions - AssertionError: assert None in ['10', '10.0']
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_equals_substring_function - RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_multiple_cast_expressions - RuntimeError: not found: Column 's' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_in_select - RuntimeError: not found: Column 'm' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_then_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_with_null_value_in_map - RuntimeError: not found: Column 'getItem(map(1, one, 2, two))' not found. Available columns: [k, v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_numeric_like_keys - RuntimeError: not found: Column 'map_col' not found. Available columns: [k]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_when_otherwise - RuntimeError: not found: Column '(value * 2) > 10' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_with_cast - assert None == 5
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_at_one - RuntimeError: not found: Column 'first_three' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_beyond_length - RuntimeError: not found: Column 'beyond' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_null - RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_zero - RuntimeError: not found: Column 'empty' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_length_exceeds_remaining - RuntimeError: not found: Column 'long' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_operations - RuntimeError: not found: Column 'partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_empty_string - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_to_double - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_partition - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(partitionBy(category), orderBy(value)))' not found. Available columns: [category, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_sum - RuntimeError: not found: Column 'sum() OVER (WindowSpec(orderBy(id), rowsBetween(-9223372036854775808, 0)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_in_select - RuntimeError: not found: Column 'rank' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_casewhen_windowfunction_cast.py::TestWindowFunctionCast::test_window_function_cast_with_datatype_object - RuntimeError: not found: Column 'row_number() OVER (WindowSpec(orderBy(id)))' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_434_ltrim_rtrim_in_expr.py::test_expr_ltrim_whitespace_only - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_select_exact_issue_435 - RuntimeError: not found: Column 'ValueNew' not found. Available columns: [Name, ValueOld]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_without_cast_still_works - RuntimeError: not found: Column 'B_renamed' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_cast_without_alias_still_works - AssertionError: assert '123' == 123
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_string_type - RuntimeError: not found: Column 'num_str' not found. Available columns: [num]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_unicode - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_zero_start - RuntimeError: not found: Column 'partial' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_multiple_columns - RuntimeError: not found: Column 'A_int' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_chained_arithmetic.py::TestChainedArithmetic::test_reverse_operations_modulo_by_zero - RuntimeError: not found: Column '(10 % col)' not found. Available columns: [col]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_single_pair - RuntimeError: not found: Column 'map_col' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_440_create_map_list.py::test_create_map_list_six_pairs - RuntimeError: not found: Column 'getItem(map(1, a, 2, b, 3, c, 4, d, 5, e, 6, f))' not found. Available columns: [v]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_abs_cast_string - RuntimeError: not found: Column 's' not found. Available columns: [n]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_select - RuntimeError: not found: Column 'first_two' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_length_cast_string - RuntimeError: not found: Column 't' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_with_column_key_exact_issue_441 - RuntimeError: not found: Column 'getItem(MapValue)' not found. Available columns: [MapValue, Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_double_type - RuntimeError: not found: Column 'dbl' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_with_nulls - RuntimeError: not found: Column 'a_int' not found. Available columns: [a]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_then_filter - RuntimeError: not found: Column 'val_int' not found. Available columns: [name, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_column_with_underscore - RuntimeError: not found: Column 'mc_int' not found. Available columns: [my_column]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_withColumn - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_key_not_found - RuntimeError: not found: Column 'getItem(m)' not found. Available columns: [k, m]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_in_select - RuntimeError: not found: Column 'val' not found. Available columns: [data, id, key]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_then_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_null_key_returns_null - RuntimeError: not found: Column 'getItem(m)' not found. Available columns: [k, m]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_filter_after - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_with_alias - RuntimeError: not found: Column 'first_two_chars' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_pyspark_parity_comprehensive - RuntimeError: not found: Column 'result' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_in_groupBy - RuntimeError: not found: Column 'substr(name)' not found. Available columns: [name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_chained_with_other_operations - RuntimeError: not found: Column 'upper_partial' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_coalesce_default - RuntimeError: not found: Column 'coalesce(getItem(m), -1)' not found. Available columns: [k, m]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_multiple_in_select - RuntimeError: not found: Column 'v1' not found. Available columns: [k1, k2, m]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_orderby_result - RuntimeError: not found: Column 'getItem(m)' not found. Available columns: [id, k, m]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_float_cast_string - RuntimeError: not found: Column 's' not found. Available columns: [f]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_436_concat_cast_string.py::test_concat_with_column_alias_cast - RuntimeError: not found: Column 's' not found. Available columns: [x]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_when_otherwise - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: withColumn' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_chained_with_columns - RuntimeError: not found: Column 'getItem(m)' not found. Available columns: [k, m]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_441_map_column_subscript.py::test_map_column_subscript_create_map_with_column_key - RuntimeError: not found: Column 'getItem(map(1, Small, 2, Medium, 3, Large))' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_435_alias_cast_select.py::test_alias_cast_then_select_subset - assert (None == 1)
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_very_long_string - RuntimeError: not found: Column 'first_100' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_start_exceeds_length - RuntimeError: not found: Column 'beyond' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_column_substr.py::TestColumnSubstr::test_substr_negative_start_exceeds_length - RuntimeError: not found: Column 'result' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_numeric_bounds_exact_issue_445 - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_numeric_bounds_both_in_range - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_numeric_bounds_none_in_range - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/test_issue_445_between_string_column_numeric_bounds.py::test_between_string_column_float_bounds - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_whitespace_in_string_keys - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_integer_arrays_preserves_type - RuntimeError: not found: Column 'array_distinct(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_string_arrays - RuntimeError: not found: Column 'array_distinct(tags)' not found. Available columns: [tags]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_with_column_expr - RuntimeError: not found: Column 'distinct_values' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_empty_array - RuntimeError: not found: Column 'array_distinct(arr)' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/test_issue_439_array_distinct.py::TestIssue439ArrayDistinct::test_array_distinct_single_element - RuntimeError: not found: Column 'array_distinct(arr)' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_string_with_int64 - RuntimeError: datatypes of join keys don't match - `key`: str on left does not match `key`: i64 on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_string - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_float_with_string - RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int32_with_int64 - AssertionError: assert (1234, 'A', 'X') in {(1234, 'A', None), (4567, 'B', None)}
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_with_left_on_right_on - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_multiple_keys_with_type_mismatch - RuntimeError: datatypes of join keys don't match - `key1`: i64 on left does not match `key1`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key1", "key2", "value_right"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_na_fill.py::TestNaFill::test_na_fill_after_join - assert 0 == 2
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_type_coercion_parity_pyspark - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_left_outer_with_type_mismatch - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int64_string_inner - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercion::test_join_int64_with_string - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "value_right"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_groupBy_via_plan_interpreter - ModuleNotFoundError: No module named 'polars'
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_in_select - assert None == 2.0
FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_cast_between_power - ModuleNotFoundError: No module named 'polars'
FAILED tests/unit/dataframe/test_logical_plan.py::TestLogicalPlanPhase4::test_plan_interpreter_window_row_number - ModuleNotFoundError: No module named 'polars'
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_multiple_numeric_types - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_chained_unions - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_chained_multiple_times - RuntimeError: not found: Column 'my_struct.withField(field1, ...).withField(field2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_with_when_otherwise - RuntimeError: not found: Column '(string_1 / 5) > 3' not found. Available columns: [string_1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_string_int64_inner - RuntimeError: datatypes of join keys don't match - `key`: str on left does not match `key`: i64 on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_all_join_types - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "right_val"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_double_precision_string - RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_int_float_coercion - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: f64 on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_null_values_in_join_keys - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_arithmetic_operations - RuntimeError: not found: Column 'my_struct.withField(product, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_preserves_all_existing_fields - RuntimeError: not found: Column 'my_struct.withField(field2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_invalid_numeric_strings - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_multiple_keys_complex - RuntimeError: datatypes of join keys don't match - `key1`: i64 on left does not match `key1`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key1", "key2", "other"]; PROJECT */3 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionEdgeCases::test_union_three_dataframes - RuntimeError: type Float64 is incompatible with expected type String
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_integers - assert None == 35
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_modulo_with_numeric - RuntimeError: not found: Column '(string_1 % 3)' not found. Available columns: [string_1]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercionParity::test_pyspark_parity_string_int64 - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_chained_with_cast - assert None == 5
FAILED tests/unit/dataframe/test_string_arithmetic.py::TestStringArithmetic::test_string_arithmetic_all_operations_comprehensive - RuntimeError: not found: Column '(string_1 % 5)' not found. Available columns: [string_1, add, sub, mul, div]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_left_on_right_on_different_names - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_mixed_numeric_strings - RuntimeError: datatypes of join keys don't match - `key`: i64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_field_access - RuntimeError: not found: Column 'my_struct.withField(computed_from_nested, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_join_type_coercion.py::TestJoinTypeCoercionParity::test_pyspark_parity_scientific_notation_strings - RuntimeError: datatypes of join keys don't match - `key`: f64 on left does not match `key`: str on right

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["key", "other"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_string_expression - RuntimeError: not found: Column 'my_struct.withField(combined_string, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_struct - RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_then_add - RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_asc_nulls_last_parity - AssertionError: assert None == 'A'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_multiple_nulls - AssertionError: assert None == 'C'
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_deeply_nested_struct - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_with_sort_method - AssertionError: assert None == 'D'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_multi_column_parity - AssertionError: assert None == 'A'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_multiple_columns_ordering - AssertionError: assert None == 'A'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_float - TypeError: unsupported operand type(s) for -: 'NoneType' and 'float'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_negative_numbers - assert None == 10
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_nested_structs - RuntimeError: not found: Column 'my_struct.withField(combined, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_very_deeply_nested_struct - RuntimeError: not found: Column 'my_struct.withField(from_deep_nest, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_null - RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_arithmetic - RuntimeError: not found: Column 'my_struct.withField(nested_product, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_conditional - RuntimeError: not found: Column 'my_struct.withField(nested_status, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_with_outer_column - RuntimeError: not found: Column 'my_struct.withField(combined, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_integer_ordering_parity - assert None == 10
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_complex_expression - RuntimeError: not found: Column 'my_struct.withField(computed, ...)' not found. Available columns: [id, multiplier, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_add_new_field - RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_chained_operations - RuntimeError: not found: Column 'my_struct.withField(field1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_union_type_coercion.py::TestUnionTypeCoercion::test_union_string_with_int64 - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_existing_field - RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_conditional_expression - RuntimeError: not found: Column 'my_struct.withField(status, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_nested_struct_reference_other_nested - RuntimeError: not found: Column 'my_struct.withField(nested_sum, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_column_expression - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, other_value, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_cast_operation - RuntimeError: not found: Column 'my_struct.withField(id_int, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_float_ordering_parity - TypeError: unsupported operand type(s) for -: 'NoneType' and 'float'
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_computed_expression - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_nulls_at_beginning_middle_end - AssertionError: assert None == 'B'
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_replace_with_different_type - RuntimeError: not found: Column 'my_struct.withField(value_1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_fields_in_sequence - RuntimeError: not found: Column 'my_struct.withField(field1, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_null_literal - RuntimeError: not found: Column 'my_struct.withField(null_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_multiple_chained - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_single_row - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_string_return_type - RuntimeError: not found: Column 'udf(text)' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_array_field - RuntimeError: not found: Column 'my_struct.withField(array_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_filter - RuntimeError: not found: Column 'my_struct.withField(new_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_unicode_characters - AssertionError: assert '' is None
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_very_large_numbers - assert None == 999999999
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_desc_nulls_last_basic - AssertionError: assert None == 'D'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_all_four_methods_comprehensive - AssertionError: assert None == 'Z'
FAILED tests/unit/functions/test_date_trunc_polars_backend.py::TestDateTruncPolarsBackend::test_date_trunc_month_on_date_column - RuntimeError: not found: Column 'to_date(d)' not found. Available columns: [d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_timestamp_core_units - RuntimeError: not found: Column 'year_trunc' not found. Available columns: [ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_on_date_column - RuntimeError: not found: Column 'year_trunc' not found. Available columns: [d]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_date_trunc_robust.py::TestDateTruncRobust::test_date_trunc_preserves_nulls - RuntimeError: not found: Column 'month_trunc' not found. Available columns: [ts]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_integer_return_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_double_return_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_large_dataframe - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFBasicOperations::test_udf_boolean_return_type - RuntimeError: not found: Column 'udf(age)' not found. Available columns: [age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_null_struct - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_asc_nulls_last - AssertionError: assert None == 'A'
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_string - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_zero_value - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_chained_operations - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_combined_with_select - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, other_col, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_issue_235_example - RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_all_null_structs - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_two_arguments - RuntimeError: not found: Column 'udf(first)' not found. Available columns: [first, second]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_empty_dataframe - RuntimeError: not found: Column 'my_struct.withField(value_2, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_different_data_types - RuntimeError: not found: Column 'my_struct.withField(int_field, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_translate_edge_cases - RuntimeError: not found: Column 'm1' not found. Available columns: [s, t]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_with_literal - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_substring_index_edge_cases - RuntimeError: not found: Column 'p2' not found. Available columns: [n, s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_levenshtein_nulls_and_empty_strings - RuntimeError: not found: Column 'd' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_soundex_null_and_empty - RuntimeError: not found: Column 'sx' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_crc32_known_values_and_null - RuntimeError: not found: Column 'c' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_reference_other_struct_field - RuntimeError: not found: Column 'my_struct.withField(value_3, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_multiple_columns_same_udf - RuntimeError: not found: Column 'udf(first)' not found. Available columns: [first, second]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_three_arguments - RuntimeError: not found: Column 'udf(a)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_three_column_ordering - AssertionError: assert None == 'A'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_string_comparison_edge_cases - AssertionError: assert 'a' is None
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFMultiArgument::test_udf_mixed_types - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_select - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_withColumn - RuntimeError: not found: Column 'udf(name)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_filter - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFInDifferentOperations::test_udf_in_groupBy_aggregation - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [category, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_input - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFNullHandling::test_udf_with_null_return - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_complex_ordering_scenario - AssertionError: assert None == 'HR'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_ordering_with_duplicate_values - AssertionError: assert None == 'B'
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingNulls::test_mixed_data_types_ordering - AssertionError: assert None == 'Alice'
FAILED tests/unit/dataframe/test_withfield.py::TestWithField::test_withfield_with_string_functions - RuntimeError: not found: Column 'my_struct.withField(upper_id, ...)' not found. Available columns: [id, my_struct]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFComplexScenarios::test_udf_in_orderBy - RuntimeError: not found: Column 'udf(age)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_long_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFWithDifferentDataTypes::test_udf_with_float_type - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFCustomName::test_udf_with_custom_name - RuntimeError: not found: Column 'my_upper' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFRegression279::test_udf_with_withColumn_regression_279 - RuntimeError: not found: Column 'udf(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_udf_regression_279.py::test_udf_with_withColumn_regression_279 - RuntimeError: not found: Column 'udf(Value)' not found. Available columns: [Name, Value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_xxhash64_known_values_and_null - RuntimeError: not found: Column 'h' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_get_json_object_missing_path_and_invalid_json - RuntimeError: not found: Column 'a' not found. Available columns: [j]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_json_tuple_missing_fields_and_invalid_json - RuntimeError: not found: Column 'json_tuple(j, ...)' not found. Available columns: [j]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_column_ordering.py::TestColumnOrderingParity::test_pyspark_desc_nulls_last_parity - AssertionError: assert None == 'Z'
FAILED tests/unit/functions/test_issue_189_string_functions_robust.py::TestIssue189StringFunctionsRobust::test_regexp_extract_all_multiple_matches_and_nulls - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/functions/test_regexp_extract_all_189.py::test_regexp_extract_all_basic_groups - RuntimeError: not found: Column 'm' not found. Available columns: [s]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_self_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/functions/test_udf_comprehensive.py::TestUDFEdgeCases::test_udf_empty_dataframe - RuntimeError: not found: Column 'udf(value)' not found. Available columns: [value, upper]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_create_table_as_select.py::test_create_table_as_select_basic - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: not found: Column 'IT' not found. Available columns: [age, dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_describe_detail.py::TestDescribeDetail::test_describe_detail_nonexistent_table - AssertionError: Expected table not found error, got: failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.
assert ('not found' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'does not exist' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'table or view' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.' or 'cannot be found' in 'failed to execute query: table test_nonexistent_detail is not a delta table. describe detail can only be used with delta format tables.')
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_select_operation - RuntimeError: not found: Column 'size' not found. Available columns: [values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_like_clause.py::test_sql_like_simple_prefix_pattern - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_filter_operation - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_single_column - RuntimeError: not found: Column 'array(Name)' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types_comprehensive - RuntimeError: not found: Column 'array(str_val, int_val, float_val, bool_val)' not found. Available columns: [bool_val, float_val, int_val, str_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_string_columns - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_strings - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_column_objects - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_filter_all_case_variations - RuntimeError: not found: Column 'Alice' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_multiple_joins - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Join execution failed: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_special_characters_in_column_names - RuntimeError: not found: Column 'array(col-name, col_name)' not found. Available columns: [col-name, col_name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_preserves_order - RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_three_columns - RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_columns - RuntimeError: not found: Column 'array((a + b), (a * b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_computed_columns - RuntimeError: not found: Column 'array((a + b), (a - b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_empty_strings - RuntimeError: not found: Column 'array(val1, val2)' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_left_join - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_select_statement - RuntimeError: not found: Column 'format1' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_list_of_column_objects - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_explode_operation - RuntimeError: not found: Column 'value' not found. Available columns: [id, values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_together - RuntimeError: not found: Column 'array(Name, Type)' not found. Available columns: [Name, Type]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_mixed_types - RuntimeError: not found: Column 'array(name, age, active)' not found. Available columns: [active, age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_after_filter - RuntimeError: not found: Column 'array(a, b)' not found. Available columns: [a, b, id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_groupby_context - RuntimeError: not found: Column 'array(name, age)' not found. Available columns: [age, dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/spark_types/test_array_type_robust.py::TestArrayTypeRobust::test_array_type_elementtype_with_withcolumn_operation - RuntimeError: not found: Column 'size(values)' not found. Available columns: [id, values]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_pairs - RuntimeError: not found: Column 'map_col' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_join - RuntimeError: not found: Column 'array(name)' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_window_functions - RuntimeError: not found: Column 'array(value)' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_large_number_of_columns - RuntimeError: not found: Column 'array(col_0, col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9)' not found. Available columns: [col_0, col_1, col_2, col_3, col_4, col_5, col_6, col_7, col_8, col_9]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_join_all_case_variations - RuntimeError: not found: ID

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_selectExpr_all_case_variations - RuntimeError: not found: Column 'full_name' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_zero_and_negative_numbers - RuntimeError: not found: Column 'array(a, b, c)' not found. Available columns: [a, b, c]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_all_formats_with_mixed_types - RuntimeError: not found: Column 'array(name, age, active, score)' not found. Available columns: [active, age, name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_coalesce_all_case_variations - RuntimeError: not found: Column 'result' not found. Available columns: [Col1, Col2, Col3]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_computed_expressions - RuntimeError: not found: Column 'array(val, (val * 2))' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_nested_struct_field_access_all_cases - ValueError: RobinMaterializer requires a non-empty schema
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_null_values - RuntimeError: not found: Column 'array(name, age)' not found. Available columns: [name, age]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_expressions_with_case_variations - RuntimeError: not found: Column 'upper(name)' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_nested_expressions - RuntimeError: not found: Column 'array(((a + b) * 2), (a - b), (a * b))' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_all_null_columns - RuntimeError: not found: Column 'array(val1, val2)' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_where_clause - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_numeric_types - RuntimeError: not found: Column 'array(int_val, float_val, long_val)' not found. Available columns: [float_val, int_val, long_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_select - RuntimeError: not found: Column 'empty_map' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_returns_empty_map - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_returns_empty_map - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_sql_queries_all_case_variations - RuntimeError: not found: Column 'IT' not found. Available columns: [Age, Dept, Name, Salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_groupby_agg - RuntimeError: not found: Column 'info' not found. Available columns: [dept, name, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_special_characters_in_keys - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_in_union - RuntimeError: not found: Column 'array(val)' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_distinct_with_case_variations - RuntimeError: type Int64 is incompatible with expected type String
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_tuple_returns_empty_map - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_different_data_types - RuntimeError: not found: Column 'map()' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_column_case_variations.py::TestColumnCaseVariations::test_issue_264_withColumn_case_insensitive - RuntimeError: not found: Column 'upper(Key)' not found. Available columns: [key]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_literals - RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_filter - RuntimeError: not found: Column 'map_col' not found. Available columns: [val1, val2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_all_literals - RuntimeError: not found: Column 'map_col' not found. Available columns: [dummy]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_numeric_types - RuntimeError: not found: Column 'map_col' not found. Available columns: [float_val, int_val, long_val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_boolean_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [flag1, flag2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_array_parameter_formats.py::TestArrayParameterFormats::test_array_with_boolean_types - RuntimeError: not found: Column 'array(flag1, flag2)' not found. Available columns: [flag1, flag2]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_column_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [first, last]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_nested_in_expressions - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_select - RuntimeError: not found: Column 'empty_map' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/session/test_sql_cte_robust.py::test_cte_with_aggregation_after_join - sparkless.core.exceptions.execution.QueryExecutionException: Failed to execute query: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_empty_string_keys - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_in_withcolumn - RuntimeError: not found: Column 'map(name, name, age, age)' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_after_filter - RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_different_data_types - RuntimeError: not found: Column 'map()' not found. Available columns: [name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_computed_values - RuntimeError: not found: Column 'map_col' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_multiple_maps_in_select - RuntimeError: not found: Column 'name_map' not found. Available columns: [age, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_null_handling - RuntimeError: not found: Column 'map()' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_multiple_times - RuntimeError: not found: Column 'map1' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_multiple_times - RuntimeError: not found: Column 'map1' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_after_filter - RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_computed_columns - RuntimeError: not found: Column 'sum' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_union - RuntimeError: not found: Column 'map()' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_show - RuntimeError: not found: Column 'map()' not found. Available columns: [Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_with_computed_columns - RuntimeError: not found: Column 'sum' not found. Available columns: [a, b]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_in_join - RuntimeError: not found: Column 'map()' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_after_union - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_with_null_keys - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_groupby_context - RuntimeError: not found: Column 'map()' not found. Available columns: [dept, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_join - RuntimeError: not found: Column 'map()' not found. Available columns: [id, name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_with_window_functions - RuntimeError: not found: Column 'map()' not found. Available columns: [id, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_union - RuntimeError: not found: Column 'map()' not found. Available columns: [id, val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_preserves_type - RuntimeError: not found: Column 'map()' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_list_and_create_map_equivalent - RuntimeError: not found: Column 'map_no_args' not found. Available columns: [id]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_large_number_of_pairs - RuntimeError: not found: Column 'map_col' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_create_map.py::TestCreateMap::test_create_map_empty_in_nested_expressions - RuntimeError: not found: Column 'val > 5' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_nested_transformations - AssertionError: Expected result=20 for id=1, got None
assert None == ((1 * 10) * 2)
 +  where None = Row(id=1, name=a, result=None).result
 +  and   1 = Row(id=1, name=a, result=None).id
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_with_filters - RuntimeError: not found: Column '(id % 2)' not found. Available columns: [id, name, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issue_355.py::TestIssue355DiamondDependency::test_unionByName_diamond_dependency_complex_expressions - AssertionError: Unexpected computed value None for id=1
assert None in [25, 5]
 +  where None = Row(computed=None, id=1).computed
FAILED tests/unit/test_issues_225_231.py::TestIssue225StringToNumericCoercion::test_numeric_eq_string - RuntimeError: not found: Column '150' not found. Available columns: [value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_split_result - RuntimeError: not found: Column 'first' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_negative_index - RuntimeError: not found: Column 'val' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue226IsinWithValues::test_isin_with_empty_list - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_map_key - RuntimeError: not found: Column 'val' not found. Available columns: [map]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_complex_lookaround - RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookahead - RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_with_lookbehind - RuntimeError: not found: Column 'extracted' not found. Available columns: [text]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_out_of_bounds - RuntimeError: not found: Column 'val' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue228RegexLookAheadLookBehind::test_regexp_extract_without_lookaround - RuntimeError: not found: Column 'domain' not found. Available columns: [email]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue227GetItem::test_getItem_with_array_index - RuntimeError: not found: Column 'first' not found. Available columns: [arr]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_filter_case_insensitive - RuntimeError: not found: Column 'Alice' not found. Available columns: [Age, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_multiply - RuntimeError: not found: Column 'percentile' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_add - RuntimeError: not found: Column 'row_plus_10' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rmul - RuntimeError: not found: Column 'percentile' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_radd - RuntimeError: not found: Column 'hundred_plus_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_subtract - RuntimeError: not found: Column 'zero_indexed' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_divide - RuntimeError: not found: Column 'row_half' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rsub - RuntimeError: not found: Column 'ten_minus_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_negate - RuntimeError: not found: Column 'neg_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_rdiv - RuntimeError: not found: Column 'twelve_div_row' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_function_chained_operations - RuntimeError: not found: Column 'score' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_ntile_with_arithmetic - RuntimeError: not found: Column 'percentile_group' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_dense_rank_with_arithmetic - RuntimeError: not found: Column 'rank_score' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_rank_with_arithmetic - RuntimeError: not found: Column 'rank_times_5' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lead_with_arithmetic - RuntimeError: not found: Column 'diff' not found. Available columns: [date, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_lag_with_arithmetic - RuntimeError: not found: Column 'diff' not found. Available columns: [date, value]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_multiple_window_functions_with_arithmetic - RuntimeError: not found: Column 'row_times_10' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_sum_window_with_arithmetic - RuntimeError: not found: Column 'running_sum_div_100' not found. Available columns: [amount, dept]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_avg_window_with_arithmetic - RuntimeError: not found: Column 'double_avg' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_with_nulls - RuntimeError: not found: Column 'row_times_2' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_complex_nested_arithmetic - RuntimeError: not found: Column 'complex' not found. Available columns: [val]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_filter - RuntimeError: not found: Column '(percent_rank() OVER (WindowSpec(partitionBy(dept), orderBy(salary))) * 100)' not found. Available columns: [dept, salary]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_window_arithmetic.py::TestWindowFunctionArithmetic::test_window_arithmetic_in_orderby - RuntimeError: not found: Column '(-row_number() OVER (WindowSpec(orderBy(score))))' not found. Available columns: [name, score]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/unit/test_issues_225_231.py::TestIssue230CaseInsensitiveColumnMatching::test_join_case_insensitive - RuntimeError: not found: ID

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_insensitive_filter - RuntimeError: not found: Column 'Alice' not found. Available columns: [Age, Name]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_insensitive_join - RuntimeError: not found: ID

Resolved plan until failure:

	---> FAILED HERE RESOLVING 'join' <---
DF ["Dept", "id"]; PROJECT */2 COLUMNS; SELECTION: None
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_mode_exact_match_required - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_withColumn_fails_with_wrong_case - RuntimeError: not found: Column 'upper(key)' not found. Available columns: [key]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_filter_fails_with_wrong_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_select_fails_with_wrong_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_groupBy_fails_with_wrong_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_join_fails_with_wrong_case - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: join' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_attribute_access_requires_exact_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_sql_queries_require_exact_case - Failed: DID NOT RAISE <class 'Exception'>
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_case_sensitive_issue_264_scenario - RuntimeError: not found: Column 'upper(key)' not found. Available columns: [key]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/integration/test_case_sensitivity.py::TestCaseSensitivityConfiguration::test_ambiguity_detection - AssertionError: assert None == 'Alice'
FAILED tests/parity/dataframe/test_double_join_empty_aggregated.py::TestDoubleJoinEmptyAggregated::test_columns_preserved_in_double_join_with_empty_aggregated - RuntimeError: not found: Column 'concat(first_name,  , last_name)' not found. Available columns: [patient_id, first_name, last_name, age, age_group, gender, insurance_provider]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter.py::TestFilterParity::test_filter_on_table_with_complex_schema - RuntimeError: not found: Column 'initial_run_1' not found. Available columns: [run_id, run_mode, run_started_at, run_ended_at, execution_id, pipeline_id, schema, phase, step_name, step_type, start_time, end_time, duration_secs, table_fqn, write_mode, input_rows, output_rows, rows_written, rows_processed, table_total_rows, valid_rows, invalid_rows, validation_rate, success, error_message, memory_usage_mb, cpu_usage_percent, metadata, created_at]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_filter_on_table_with_comparison_operations - RuntimeError: not found: Column 'active' not found. Available columns: [id, score, status]. Check spelling and case sensitivity (spark.sql.caseSensitive).
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_string_operations_in_filters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
FAILED tests/parity/dataframe/test_filter_isinstance_ordering.py::TestIsInstanceOrdering::test_logical_operations_in_filters - sparkless.core.exceptions.operation.SparkUnsupportedOperationError: Operation 'Operations: filter' is not supported
Reason: Backend 'robin' does not support these operations
Alternative: In v4 only the Robin backend is supported; see docs/v4_behavior_changes_and_known_differences.md for supported operations.
ERROR tests/parity/dataframe/test_parquet_format_table_append.py
ERROR tests/test_backend_capability_model.py
ERROR tests/test_issue_160_manual_cache_manipulation.py
ERROR tests/test_issue_160_nested_operations.py
=========== 1397 failed, 1313 passed, 31 skipped, 4 errors in 56.46s ===========
